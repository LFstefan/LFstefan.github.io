<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Tomecat源码解析]]></title>
    <url>%2F2021%2F06%2F13%2FTomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Tomecat源码解析 宏观架构层次 connector连接器 warpper映射servlet Pipeline-Valve管道 Lifecycle声明周期 类加载 springboot内嵌tomcat 宏观架构层次 顶层server容器（唯一，只有一个） 服务service容器（不唯一，允许存在多个，即多个应用服务共享tomcat容器） connector：管理处理网络连接（不唯一，一个service服务可以拥有多个connectors，例如，分别处理http和https等） container：管理处理servlet（唯一，一个service服务一个） Engine：（唯一，一个service只有一个） host：（虚拟主机，不唯一） context：（具体我们部署的一个应用程序，不唯一） wrapper：（不唯一，每一个wrapper封装一个servlet） wrapper context host： 服务service容器 … Connector深入理解 Connector用于接受请求并将请求封装成Request，然后交给Container进行处理，Container处理完之后在交给Connector封装成Response返回给客户端。 Ajp/Http（通讯协议） - apr/nio/nio2(nio2=aio)（io模型） - protocol tomcat本身支持AJP协议和HTTP协议 AJP（Apache JServ Protocol）是定向包协议。 apr (Apache Portable Runtime/Apache可移植运行库)，是Apache HTTP服务器的支持库。你可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件io读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式 connector核心组成 ProtocolHandler：连接使用的协议以及模式 网络通信的 I/O 模型是变化的, 应用层协议也是变化的，但是整体的处理逻辑是不变的 Http11AprProtocol，Http11NioProtocol， Http11Nio2Protocol AjpAprProtocol，AjpNioProtocol，AjpNio2Protocol Endpoint组件：处理socket，实现tcp/ip协议 NioEndpoint特殊分析：一共包含 LimitLatch、Acceptor、Poller、SocketProcessor和 Executor 共 5 个组件，分别分工合作实现整个 TCP/IP 协议的处理。 LimitLatch是连接控制器，它负责控制最大连接数，NIO 模式下默认是 10000，达到这个阈值后，连接请求被拒绝。 Acceptor跑在一个单独的线程里，它在一个死循环里调用 accept方法来接收新连接，一旦有新的连接请求到来，accept方法返回一个 Channel 对象，接着把 Channel对象交给 Poller 去处理。 Poller 的本质是一个 Selector，也跑在单独线程里。Poller在内部维护一个 Channel数组，它在一个死循环里不断检测 Channel的数据就绪状态，一旦有 Channel可读，就生成一个 SocketProcessor任务对象扔给 Executor去处理。 SocketProcessor实现了 Runnable接口，其中run方法中的 getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL); 代码则是获取handler并执行处理 socketWrapper，最后通过socket 获取合适应用层协议处理器，也就是调用 Http11Processor组件来处理请求。 Executor就是线程池，负责运行 SocketProcessor任务类，SocketProcessor 的 run方法会调用 Http11Processor 来读取和解析请求数据。我们知道，Http11Processor是应用层协议的封装，它会调用容器获得响应，再把响应通过 Channel写出。 Processor组件：封装request/response，实现http协议 Adapter组件：请求适配到servlet Wrapper深入理解一个请求是如何定位到让哪个 Wrapper 的 Servlet 处理的？答案是，Tomcat 是用 Mapper 组件来完成这个任务的。 Mapper 组件的功能就是将用户请求的 URL 定位到一个 Servlet，它的工作原理是：Mapper组件里保存了 Web 应用的配置信息，其实就是容器组件与访问路径的映射关系，比如 Host容器里配置的域名、Context容器里的 Web应用路径，以及 Wrapper容器里 Servlet 映射的路径，你可以想象这些配置信息就是一个多层次的 Map。 当一个请求到来时，Mapper 组件通过解析请求 URL 里的域名和路径，再到自己保存的 Map 里去查找，就能定位到一个 Servlet。请你注意，一个请求 URL 最后只会定位到一个 Wrapper容器，也就是一个 Servlet。 Pipeline-Valve 管道 连接器中的 Adapter 会调用container容器的 Service 方法来执行 Servlet，最先拿到请求的是 Engine 容器，Engine 容器对请求做一些处理后，会把请求传给自己子容器 Host 继续处理，依次类推，最后这个请求会传给 Wrapper 容器，Wrapper 会调用最终的 Servlet 来处理。那么这个调用过程具体是怎么实现的呢？答案是使用 Pipeline-Valve 管道。 Pipeline-Valve 是责任链模式，责任链模式是指在一个请求处理的过程中有很多处理者依次对请求进行处理，每个处理者负责做自己相应的处理，处理完之后将再调用下一个处理者继续处理，Valve 表示一个处理点（也就是一个处理阀门），因此 invoke方法就是来处理请求的。 每层容器都有自己的Pipeline链表，链表的尾节点指向下一层容器Pipeline链表的首节点 整个过程分是通过connector连接器中的 CoyoteAdapter 触发，它会调用 Engine 的第一个 Valve： connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); Pipeline-Valve 管道和servlet filter过滤器的区别 Wrapper 容器的最后一个 Valve 会创建一个 Filter 链，并调用 doFilter() 方法，最终会调到 Servlet的 service方法。 Valve是 Tomcat的私有机制，与 Tomcat 的基础架构 API是紧耦合的 过滤器filter是Servlet API是公有的标准，所有的 Web 容器包括 Jetty 都支持 Filter 机制。 Valve工作在 Web 容器级别，拦截所有应用的请求；而 Servlet Filter 工作在应用级别，只能拦截某个 Web 应用的所有请求。如果想做整个 Web容器的拦截器，必须通过 Valve来实现。 Lifecycle 生命周期任何管理？ 如何统一管理组件的创建、初始化、启动、停止和销毁？如何做到代码逻辑清晰？如何方便地添加或者删除组件？如何做到组件启动和停止不遗漏、不重复？ 抽象公共上层接口，定义流程编排：init初始化-start启动-stop停止-destory销毁 如何扩展，保持开闭原则 使用事件event和监听listener来实现新逻辑的扩展（观察者模式） Tomcat 为了实现一键式启停以及优雅的生命周期管理，并考虑到了可扩展性和可重用性，将面向对象思想和设计模式发挥到了极致，Containaer接口维护了容器的父子关系，Lifecycle 组合模式实现组件的生命周期维护，生命周期每个组件有变与不变的点，运用模板方法模式。 分别运用了组合模式、观察者模式、骨架抽象类和模板方法。 Tomcat 热加载 Tomcat通过一个后台线程做周期性的任务，定期检测类文件的变化，如果有变化就重新加载类 Tomcat的热加载就是在 Context 容器实现，主要是调用了 Context 容器的 reload 方法，具体动作如下： 停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。 停止和销毁 Context 容器关联的 Listener 和 Filter。 停止和销毁 Context 下的 Pipeline 和各种 Valve。 停止和销毁 Context 的类加载器，以及类加载器加载的类文件资源。 启动 Context 容器，在这个过程中会重新创建前面四步被销毁的资源。 在这个过程中，类加载器发挥着关键作用。一个 Context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。Context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。 如何避免防止 Web 应用自己的类覆盖 JRE 的核心类类加载层次 tomcat作为Servlet容器，负责加载我们写的Servlet类，以及我们所依赖的jar包 tomcat自身也是java，也需要加载自己的类和自己的依赖jar包 由于支持多应用部署，不同应用的相同类名加载应该保持隔离，即各自加载一份 不同应用依赖的相同jar包，因该加载一份，共享即可，避免内存占用过多 如何解决上述问题： 解决不同web应用类隔离：WebAppClassLoader：每个 Web 应用创建一个类加载器实例；Context 容器组件对应一个 Web 应用，因此，每个 Context容器负责创建和维护一个 WebAppClassLoader加载器实例。这背后的原理是，不同的加载器实例加载的类被认为是不同的类；Web 应用之间通过各自的类加载器互相隔离 解决不同web应用相同依赖库共享：SharedClassLoader：作为 WebAppClassLoader的父加载器，专门来加载 Web 应用之间共享的类。如果 WebAppClassLoader自己没有加载到某个类，就会委托父加载器 SharedClassLoader去加载这个类，SharedClassLoader会在指定目录下加载共享类 解决tomcat自身类和web应用类隔离：CatalinaClassloader：负责加载tomcat自身的类文件 解决tomcat和web应用含有相同依赖的jar包共享：CommonClassLoader（作为 CatalinaClassloader和 SharedClassLoader的父加载器。CommonClassLoader能加载的类都可以被 CatalinaClassLoader和 SharedClassLoader使用）；位于CATALINA_HOME/lib下 类加载顺序 类加载顺序（默认） Bootstrap classes of your JVM /WEB-INF/classes of your web application /WEB-INF/lib/*.jar of your web application System class loader classes (described above) Common class loader classes (described above) 类加载顺序（特殊配置） Bootstrap classes of your JVM System class loader classes (described above) Common class loader classes (described above) /WEB-INF/classes of your web application /WEB-INF/lib/*.jar of your web application 要共享可以通过父子关系，要隔离那就需要兄弟关系了。兄弟关系就是指两个类加载器是平行的，它们可能拥有同一个父加载器 核心配置文件：conf目录下的server.xml配置文件 tomcat目录下，webapps/目录 = 一个host，host下默认主应用是webapps/ROOT/目录（可以设置修改），访问地址不需要添加目录名，非默认其他应用需要添加目录名才能正确访问 web应用部署方式 应用可以以war包的形式部署到tomcat的wabapps目录下，也可以以文件夹的形式部署 war包格式： 项目文件名 META-INF WEB-INF web.xml classes/ lib/ spirngboot启动内嵌tomcat容器过程 内嵌后的类加载流程 tomcat原生加载类文件基于文件路径位置，判断路径使用不同的类加载器加载，springboot内嵌后不一样 因为没有了tomcat启动的所面临的问题，多个webapp隔离(只有一个)，tomcat和应用隔离 使用TomcatEmbeddedWebappClassLoader extends ParallelWebappClassLoader 加载应用类文件 核心方法：this.createWebServer(); 核心类：TomcatServletWebServerFactory12345678910111213141516171819202122//初始化构造tomcat容器，未启动容器@Overridepublic WebServer getWebServer(ServletContextInitializer... initializers) &#123; if (this.disableMBeanRegistry) &#123; Registry.disableRegistry(); &#125; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); connector.setThrowOnFailure(true); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat);&#125;]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RMI]]></title>
    <url>%2F2021%2F05%2F29%2FRMI%2F</url>
    <content type="text"><![CDATA[RMI 使用样例 实现原理 源码解析 分布式垃圾回收-DGC 类比其他语言 c++ php golang 扩展 duboo的服务端多个tcp长链接复用如何实现 远程调用是否可以实现调用接口缓存（幂等/非幂等） 使用样例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 定义远程调用接口，服务端负责编写需要暴露给客户端的远程调用接口，写好后打包提供给客户端使用import java.rmi.Remote; import java.rmi.RemoteException; // Creating Remote interface for our application public interface Hello extends Remote &#123; void printMsg() throws RemoteException; &#125; // 服务端实现暴露接口，赋予具体实现逻辑// Implementing the remote interface public class ImplExample implements Hello &#123; // Implementing the interface method public void printMsg() &#123; System.out.println(&quot;This is an example RMI program&quot;); &#125; &#125; // 服务端绑定注册暴露给远程调用的方法到注册服务中去import java.rmi.registry.Registry; import java.rmi.registry.LocateRegistry; import java.rmi.RemoteException; import java.rmi.server.UnicastRemoteObject; public class Server extends ImplExample &#123; public Server() &#123;&#125; public static void main(String args[]) &#123; try &#123; // Instantiating the implementation class ImplExample obj = new ImplExample(); // Exporting the object of implementation class // (here we are exporting the remote object to the stub) Hello stub = (Hello) UnicastRemoteObject.exportObject(obj, 0); // Binding the remote object (stub) in the registry Registry registry = LocateRegistry.getRegistry(); // 绑定注册暴露给远程调用的方法，内部采用hashtable数据结构进行存储 registry.bind(&quot;Hello&quot;, stub); System.err.println(&quot;Server ready&quot;); &#125; catch (Exception e) &#123; System.err.println(&quot;Server exception: &quot; + e.toString()); e.printStackTrace(); &#125; &#125; &#125; // 客户端发起远程调用，远程地址视情况而定import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; public class Client &#123; private Client() &#123;&#125; public static void main(String[] args) &#123; try &#123; // Getting the registry Registry registry = LocateRegistry.getRegistry(host); // Looking up the registry for the remote object Hello stub = (Hello) registry.lookup(&quot;Hello&quot;); // Calling the remote method using the obtained object stub.printMsg(); // System.out.println(&quot;Remote method invoked&quot;); &#125; catch (Exception e) &#123; System.err.println(&quot;Client exception: &quot; + e.toString()); e.printStackTrace(); &#125; &#125; &#125; 实现原理 启动一个监听远程端口服务（默认1099）：负责注册本地方法和提供接受远程方法调用查找功能 java/bin目录下有脚本文件rmiregister来启动注册服务 RegistryImpl服务端绑定注册/查找暴露方法 RegistryImpl_Stub客户端需要远程连接服务端RegistryImpl调用服务端的方法来实现绑定注册/查找暴露方法等操作 需要暴露给远程的方法需要注册到指定服务上，这样才能被找到 暴露方法的实际存放数据结构：private Hashtable bindings = new Hashtable&lt;&gt;(101); 源码解析 主要分析RegistryImpl_Stub类，该类是客户端发起远程调用的关键类，包含了tcp连接的建立等重要信息 RegistryImpl_Stub是由LocateRegistry.getRegistry(host)返回 RemoteRef的子类UnicastRef类的newCall方法发起远程调用 newCall方法中由ref.getChannel().newConnection()获取tcp连接 TcpChannel类中newConnection方法会有先从private final List freeList = new ArrayList&lt;&gt;();中获取，没有，新建连接 tcp连接如果开启了重用，则会存入freeList中供下次使用，节省连接创建开销，即使用单一长链接模式 连接模式为：单一长链接模式或者短链接模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225// LocateRegistry类获取注册中心public static Registry getRegistry(String host, int port,RMIClientSocketFactory csf) throws RemoteException&#123; Registry registry = null; if (port &lt;= 0) port = Registry.REGISTRY_PORT; if (host == null || host.length() == 0) &#123; // If host is blank (as returned by &quot;file:&quot; URL in 1.0.2 used in // java.rmi.Naming), try to convert to real local host name so // that the RegistryImpl&apos;s checkAccess will not fail. try &#123; host = java.net.InetAddress.getLocalHost().getHostAddress(); &#125; catch (Exception e) &#123; // If that failed, at least try &quot;&quot; (localhost) anyway... host = &quot;&quot;; &#125; &#125; /* + Create a proxy for the registry with the given host, port, and + client socket factory. If the supplied client socket factory is + null, then the ref type is a UnicastRef, otherwise the ref type + is a UnicastRef2. If the property + java.rmi.server.ignoreStubClasses is true, then the proxy + returned is an instance of a dynamic proxy class that implements + the Registry interface; otherwise the proxy returned is an + instance of the pregenerated stub class for RegistryImpl. **/ LiveRef liveRef = new LiveRef(new ObjID(ObjID.REGISTRY_ID), new TCPEndpoint(host, port, csf, null), false); RemoteRef ref = (csf == null) ? new UnicastRef(liveRef) : new UnicastRef2(liveRef); return (Registry) Util.createProxy(RegistryImpl.class, ref, false);&#125;@SuppressWarnings(&#123;&quot;deprecation&quot;, &quot;serial&quot;&#125;)public final class RegistryImpl_Stub extends java.rmi.server.RemoteStub implements java.rmi.registry.Registry, java.rmi.Remote &#123; // 远程调用服务端注册中心的所有方法列表 private static final java.rmi.server.Operation[] operations = &#123; new java.rmi.server.Operation(&quot;void bind(java.lang.String, java.rmi.Remote)&quot;), new java.rmi.server.Operation(&quot;java.lang.String list()[]&quot;), new java.rmi.server.Operation(&quot;java.rmi.Remote lookup(java.lang.String)&quot;), new java.rmi.server.Operation(&quot;void rebind(java.lang.String, java.rmi.Remote)&quot;), new java.rmi.server.Operation(&quot;void unbind(java.lang.String)&quot;) &#125;; private static final long interfaceHash = 4905912898345647071L; // constructors public RegistryImpl_Stub() &#123; super(); &#125; public RegistryImpl_Stub(java.rmi.server.RemoteRef ref) &#123; super(ref); &#125; // methods from remote interfaces // implementation of bind(String, Remote) public void bind(java.lang.String $param_String_1, java.rmi.Remote $param_Remote_2) throws java.rmi.AccessException, java.rmi.AlreadyBoundException, java.rmi.RemoteException &#123; try &#123; // RemoteRef的子类UnicastRef类的newCall方法发起远程调用 StreamRemoteCall call = (StreamRemoteCall)ref.newCall(this, operations, 0, interfaceHash); try &#123; java.io.ObjectOutput out = call.getOutputStream(); out.writeObject($param_String_1); out.writeObject($param_Remote_2); &#125; catch (java.io.IOException e) &#123; throw new java.rmi.MarshalException(&quot;error marshalling arguments&quot;, e); &#125; ref.invoke(call); ref.done(call); &#125; catch (java.lang.RuntimeException e) &#123; throw e; &#125; catch (java.rmi.RemoteException e) &#123; throw e; &#125; catch (java.rmi.AlreadyBoundException e) &#123; throw e; &#125; catch (java.lang.Exception e) &#123; throw new java.rmi.UnexpectedException(&quot;undeclared checked exception&quot;, e); &#125; &#125; // implementation of list() public java.lang.String[] list() throws java.rmi.AccessException, java.rmi.RemoteException &#123; try &#123; StreamRemoteCall call = (StreamRemoteCall)ref.newCall(this, operations, 1, interfaceHash); ref.invoke(call); java.lang.String[] $result; try &#123; java.io.ObjectInput in = call.getInputStream(); $result = (java.lang.String[]) in.readObject(); &#125; catch (ClassCastException | IOException | ClassNotFoundException e) &#123; call.discardPendingRefs(); throw new java.rmi.UnmarshalException(&quot;error unmarshalling return&quot;, e); &#125; finally &#123; ref.done(call); &#125; return $result; &#125; catch (java.lang.RuntimeException e) &#123; throw e; &#125; catch (java.rmi.RemoteException e) &#123; throw e; &#125; catch (java.lang.Exception e) &#123; throw new java.rmi.UnexpectedException(&quot;undeclared checked exception&quot;, e); &#125; &#125; // implementation of lookup(String) public java.rmi.Remote lookup(java.lang.String $param_String_1) throws java.rmi.AccessException, java.rmi.NotBoundException, java.rmi.RemoteException &#123; try &#123; StreamRemoteCall call = (StreamRemoteCall)ref.newCall(this, operations, 2, interfaceHash); try &#123; java.io.ObjectOutput out = call.getOutputStream(); out.writeObject($param_String_1); &#125; catch (java.io.IOException e) &#123; throw new java.rmi.MarshalException(&quot;error marshalling arguments&quot;, e); &#125; ref.invoke(call); java.rmi.Remote $result; try &#123; java.io.ObjectInput in = call.getInputStream(); $result = (java.rmi.Remote) in.readObject(); &#125; catch (ClassCastException | IOException | ClassNotFoundException e) &#123; call.discardPendingRefs(); throw new java.rmi.UnmarshalException(&quot;error unmarshalling return&quot;, e); &#125; finally &#123; ref.done(call); &#125; return $result; &#125; catch (java.lang.RuntimeException e) &#123; throw e; &#125; catch (java.rmi.RemoteException e) &#123; throw e; &#125; catch (java.rmi.NotBoundException e) &#123; throw e; &#125; catch (java.lang.Exception e) &#123; throw new java.rmi.UnexpectedException(&quot;undeclared checked exception&quot;, e); &#125; &#125;...&#125;// UnicastRef类的newCall方法public RemoteCall newCall(RemoteObject obj, Operation[] ops, int opnum,long hash) throws RemoteException&#123; clientRefLog.log(Log.BRIEF, &quot;get connection&quot;); // 获取tcp连接 Connection conn = ref.getChannel().newConnection(); try &#123; clientRefLog.log(Log.VERBOSE, &quot;create call context&quot;); /* log information about the outgoing call */ if (clientCallLog.isLoggable(Log.VERBOSE)) &#123; logClientCall(obj, ops[opnum]); &#125; RemoteCall call = new StreamRemoteCall(conn, ref.getObjID(), opnum, hash); try &#123; marshalCustomCallData(call.getOutputStream()); &#125; catch (IOException e) &#123; throw new MarshalException(&quot;error marshaling &quot; + &quot;custom call data&quot;); &#125; return call; &#125; catch (RemoteException e) &#123; ref.getChannel().free(conn, false); throw e; &#125;&#125;// 获取tcp连接public class TCPChannel implements Channel &#123;// 默认不使用多路复用private boolean usingMultiplexer = false;...public Connection newConnection() throws RemoteException &#123; TCPConnection conn; // loop until we find a free live connection (in which case // we return) or until we run out of freelist (in which case // the loop exits) do &#123; conn = null; // 优先从空闲连接list中获取连接 // try to get a free connection synchronized (freeList) &#123; int elementPos = freeList.size()-1; if (elementPos &gt;= 0) &#123; // If there is a security manager, make sure // the caller is allowed to connect to the // requested endpoint. checkConnectPermission(); conn = freeList.get(elementPos); freeList.remove(elementPos); &#125; &#125; // at this point, conn is null iff the freelist is empty, // and nonnull if a free connection of uncertain vitality // has been found. if (conn != null) &#123; // 校验链接是否已经失效/不可用/超时断开 // check to see if the connection has closed since last use if (!conn.isDead()) &#123; TCPTransport.tcpLog.log(Log.BRIEF, &quot;reuse connection&quot;); return conn; &#125; // 连接不可用时，释放该链接，跳出循环，新建连接 // conn is dead, and cannot be reused (reuse =&gt; false) this.free(conn, false); &#125; &#125; while (conn != null); // 没有空闲连接，创建新连接 // none free, so create a new connection return (createConnection());&#125;... 分布式垃圾回收-DGC基础概念 Java虚拟机中，一个远程对象不仅会被本地虚拟机内的变量引用，还会被远程引用。 只有当一个远程对象不受到任何本地引用和远程引用，这个远程对象才会结束生命周期。 服务端的一个远程对象在3个地方被引用： 服务端的一个本地对象持有它的本地引用 服务端的远程对象已经注册到rmiregistry注册表中，也就是说，rmiregistry注册表持有它的远程引用。 客户端获得远程对象的存根对象，也就是说，客户端持有它的远程引用。 服务端判断客户端是否持有远程对象引用的方法： 当客户端获得一个服务端的远程对象的存根时，就会向服务器发送一条租约(lease)通知，以告诉服务器自己持有了这个远程对象的引用了。 客户端定期地向服务器发送租约通知，以保证服务器始终都知道客户端一直持有着远程对象的引用。 租约是有期限的，如果租约到期了，服务器则认为客户端已经不再持有远程对象的引用了。 实现原理 在分布式系统中，就像在本地系统中一样，希望自动删除那些不再被任何客户端引用的远程对象。这使程序员无需跟踪远程对象的客户端，以便它可以适当地终止。 RMI 使用类似于 Modula-3 的网络对象的引用计数垃圾收集算法。 （参见 Birrell、Nelson 和 Owicki 的“网络对象”，数字设备公司系统研究中心技术报告 115，1994 年。） 为了完成引用计数垃圾收集，RMI 运行时会跟踪每个 Java 虚拟机中的所有活动引用。当实时引用进入 Java 虚拟机时，其引用计数会增加。对对象的第一次引用将“引用”消息发送到该对象的服务器。由于在本地虚拟机中发现未引用实时引用，因此计数递减。当最后一个引用被丢弃时，一个未引用的消息被发送到服务器。协议中存在许多微妙之处；其中大部分与维护引用和未引用消息的顺序有关，以确保不会过早收集对象。 当远程对象没有被任何客户端引用时，RMI 运行时使用弱引用来引用它。如果不存在对该对象的其他本地引用，弱引用允许 Java 虚拟机的垃圾收集器丢弃该对象。分布式垃圾收集算法通过保持对对象的正常或弱引用，以通常的方式与本地 Java 虚拟机的垃圾收集器交互。 只要对远程对象的本地引用存在，就不能被垃圾收集，并且可以在远程调用中传递或返回给客户端。传递远程对象会将其传递到的虚拟机的标识符添加到引用集。需要未引用通知的远程对象必须实现 java.rmi.server.Unreferenced 接口。当这些引用不再存在时，将调用未引用的方法。当发现引用集为空时调用 unreferenced ，因此它可能会被多次调用。仅当不再存在本地或远程引用时才收集远程对象。 请注意，如果客户端和远程服务器对象之间存在网络分区，则可能会发生远程对象的过早收集（因为服务端可能认为客户端崩溃了）。由于有过早收集的可能性，远程引用不能保证引用完整性；换句话说，远程引用总是有可能实际上不引用现有对象。尝试使用此类引用将生成必须由应用程序处理的 RemoteException。 RMI 子系统实现基于引用计数的“分布式垃圾回收”(DGC)，以便为远程服务器对象提供自动内存管理设施。 当客户机创建（序列化）远程引用时，会在服务器端 DGC 上调用dirty()。当客户机完成远程引用后，它会调用对应的clean()方法。 针对远程对象的引用由持有该引用的客户机租用一段时间。租期从收到dirty()调用开始。在此类租约到期之前，客户机必须通过对远程引用额外调用dirty()来更新租约。如果客户机不在租约到期前进行续签，那么分布式垃圾收集器会假设客户机不再引用远程对象。 DGCClient 可实现 RMI 分布式垃圾回收系统的客户机端。DGCClient 的外部接口是registerRefs()方法。 当远程对象的 LiveRef 进入 JVM 时，它必须向 DGCClient 注册以参与分布式垃圾回收。当注册针对特定远程对象的第一个 LiveRef 时，会对远程对象的服务器端 DGC 调用dirty()。该调用会返回租约，保证服务器端 DGC 在特定时间不会回收远程对象。如果存在针对特定服务器上的远程对象的 LiveRef 实例，那么 DGCClient 会定期发送更多的 dirty 调用以续签其租约。DGCClient 将使用虚引用来跟踪已注册 LiveRef 实例的本地可用性。在本地对特定远程对象的 LiveRef 实例进行垃圾回收时，将对服务器端 DGC 调用clean()。该调用表明服务器不需要为此客户机保持活动的远程对象。RenewCleanThread 将通过续签租约并进行 clean 调用来处理异步客户机端 DGC 活动。因此，此线程将一直等待，直至下一次续签租约，或直至有任何虚引用排队以根据需要生成 clean 请求。 类比其他语言 c++ php：grpc golang 扩展 duboo的服务端多个tcp长链接复用如何实现 远程调用是否可以实现调用接口缓存（幂等/非幂等） 除了Socket，RPC还有其他的通信方法，比如：http、操作系统自带的管道等技术来实现对于远程程序的调用。微软的Windows系统中，RPC就是采用命名管道进行通信。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>RMI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库连接池]]></title>
    <url>%2F2021%2F05%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[数据库连接池 简述连接池 threadlocal HikariPool 简述连接池 连接池的作用，大家都不陌生，降低连接创建所带来的消耗，避免过多的连接导致资源枯竭等，总而言之是为了应用更安全，更高效的运行。 threadlocal为什么数据库连接池需要用到threadlocal 一个conn连接同一时间只能给一个线程使用，线程从连接池中争夺连接资源来完成需要执行的sql 每一个sql的执行，最终会走到获取conn连接的地步，拿到连接创建statement，执行sql，然后释放conn连接 由于事物的实现会跨越多个sql语句，而事物只能在同一个conn连接中生效，所以就需要多个sql使用同一个conn连接 threadlocal可以将获取到的conn连接绑定到当前线程，从而使的之后需要执行的sql全部在同一个conn连接中，从而保证事物 使用threadlocal最重要的作用就是实现跨方法的参数传递，将一开始获取的conn供之后的所有sql执行使用 HikariPool优点 字节码精简 ：优化代码，编译后的字节码量极少，使得CPU缓存可以加载更多的程序代码；HikariCP在优化并精简字节码上也下了功夫，使用第三方的Java字节码修改类库Javassist来生成委托实现动态代理.动态代理的实现在ProxyFactory类，速度更快，相比于JDK Proxy生成的字节码更少，精简了很多不必要的字节码。 优化代理和拦截器：减少代码，例如HikariCP的Statement proxy只有100行代码，只有BoneCP的十分之一； 自定义数组类型（FastStatementList）代替ArrayList：避免ArrayList每次get()都要进行range check，避免调用remove()时的从头到尾的扫描（由于连接的特点是后获取连接的先释放）； 自定义集合类型（ConcurrentBag）：提高并发读写的效率； 设计核心结构 ConcurrentBag：自定义并发类 CopyOnWriteArrayList sharedList：并发list，存储共享连接 ThreadLocal]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC-ParallelGC]]></title>
    <url>%2F2021%2F04%2F04%2FGC-ParallelGC%2F</url>
    <content type="text"><![CDATA[GC-ParallelGC 算法实现 优点缺点 参数配置 日志解释 调优策略 以下所有内容均基于java8而写，新版本java可能会有变动 parallel collector 又叫做 throughput collector 算法实现 在年轻代使用 标记-复制(mark-copy)算法, 在老年代使用 标记-清除-整理(mark-sweep-compact)算法。年轻代和老年代的垃圾回收都会触发STW事件,暂停所有的应用线程来执行垃圾收集。两者在执行 标记和 复制/整理阶段时都使用多个线程, 因此得名“(Parallel)”。通过并行执行, 使得GC时间大幅减少。 并行垃圾收集器适用于多核服务器,主要目标是增加吞吐量。因为对系统资源的有效使用,能达到更高的吞吐量: 在GC期间, 所有 CPU 内核都在并行清理垃圾, 所以暂停时间更短 在两次GC周期的间隔期, 没有GC线程在运行,不会消耗任何系统资源 因为此GC的所有阶段都不能中断, 所以并行GC很容易出现长时间的卡顿. 如果延迟是系统的主要目标, 那么就应该选择其他垃圾收集器组合。 优点缺点 在具有N个大于8的N个硬件线程的机器上，并行收集器使用N的固定部分作为垃圾收集器线程的数量。对于较大的N值，该分数约为5/8。在N的值小于8时，使用的数字为N。在选定的平台上，该分数下降为5/16。垃圾收集器线程的特定数量可以使用命令行选项（稍后将进行描述）进行调整。在具有一个处理器的主机上，由于并行执行（例如，同步）所需的开销，并行收集器的性能可能不如串行收集器。但是，当运行具有中型到大型堆的应用程序时，在具有两个处理器的机器上，它通常比串行收集器的性能要适度，并且通常在两个以上处理器可用时的性能要明显好于串行收集器。 垃圾回收器线程的数量可以通过命令行选项-XX：ParallelGCThreads = 来控制。如果使用命令行选项对堆进行显式调整，则并行收集器要获得良好性能所需的堆大小与串行收集器所需的堆大小相同。但是，启用并行收集器应缩短收集暂停时间。因为多个垃圾收集器线程正在参与次要收集，所以由于收集期间从年轻代到老年代的晋升，可能会产生一些碎片。minor gc 中涉及的每个垃圾回收线程都保留了使用权的一代中的一部分以进行提升，并且将可用空间划分为这些“提升缓冲区”会导致碎片效应。减少垃圾收集器线程的数量并增加使用期限的大小将减少这种碎片效应。 JVM GC Ergonomics(自适应调节策略) 参数 -XX:+UseAdaptiveSizePolicy 来开启 AdaptiveSizePolicy 如果开启 AdaptiveSizePolicy，则每次 GC 后会重新计算 Eden、From 和 To 区的大小，计算依据是 GC 过程中统计的 GC 时间、吞吐量、内存占用量。 AdaptiveSizePolicy有三个预期目标 最大暂停时间目标 吞吐量目标 最小占用空间 首先达到最大暂停时间目标。只有在达到目标之后，才能实现吞吐量目标。同样，只有在达到前两个目标后，才会考虑最小占用空间。 最大垃圾回收暂停时间：最大暂停时间目标是通过命令行选项-XX：MaxGCPauseMillis = 指定的。这被解释为需要毫秒或更短的暂停时间的提示；默认情况下，没有最大暂停时间目标。如果指定了暂停时间目标，则会调整堆大小和与垃圾回收相关的其他参数，以使垃圾回收的暂停时间短于指定值。这些调整可能导致垃圾收集器降低应用程序的整体吞吐量，并且无法始终满足所需的暂停时间目标，即该参数是软目标，jvm尽最大努力实现，但不保证。 吞吐量：吞吐量目标是根据进行垃圾收集所花费的时间与在垃圾收集之外所花费的时间（称为应用程序时间）来衡量的。该目标由命令行选项-XX：GCTimeRatio = 指定，该选项将垃圾回收时间与应用程序时间的比率设置为1 /（1 + ）。例如，-XX：GCTimeRatio = 19将垃圾收集目标的目标设置为总时间的1/20或5％。默认值为99，导致垃圾回收的目标时间为1％。java8没有该参数，可能已经废弃或者在新版本中。 占用空间：使用选项-Xmx 指定最大堆占用空间。另外，收集器还有一个隐含的目标，即只要满足其他目标，就使堆的大小最小化。 为实现这三个目标，会涉及到以下操作： 收集器保留的统计信息（例如平均暂停时间）会在每个收集结束时进行更新。然后进行确定目标是否达到的测试，并对堆大小进行任何必要的调整。唯一的例外是，在保留统计信息和调整堆大小方面，将忽略显式垃圾回收（例如，对System.gc（）的调用）。 增长和缩小堆各个代的大小是通过增加作为各代大小的固定百分比来实现的，这样一来，各代就可以朝其期望的大小递增或递减。生长和收缩以不同的速率进行。默认情况下，各代以20％的增量增长，而以5％的增量萎缩。增长百分比由命令行选项-XX：YoungGenerationSizeIncrement = （对于年轻一代）和-XX：TenuredGenerationSizeIncrement = （对于老年代）控制。通过命令行标志-XX：AdaptiveSizeDecrementScaleFactor = 可以调整各代收缩的百分比。如果增长增量为X％，则收缩的增量为X / D％。java8没有该参数，可能已经废弃或者在新版本中。 如果没有达到最大暂停时间目标，则一次仅缩小一代的大小。如果两个世代的暂停时间都超过了目标，则首先缩减具有较大暂停时间的世代的大小。 如果未达到吞吐量目标，则两代产品的大小都会增加。每一个都按其对总垃圾收集时间的贡献成比例地增加。例如，如果年轻一代的垃圾收集时间为总收集时间的25％，并且如果年轻一代的全部增量将增加20％，则年轻一代将增加5％。 由 AdaptiveSizePolicy 可能引发的 GC 问题 eden和surivivor大小比例失衡，导致某一空间大小过小 解决方案： 加上参数 -Xmn100m -XX:SurvivorRatio=8；强制限定了 Eden 和 Survivor 之间的比例。 JDK 1.8 中，如果使用 CMS，无论 UseAdaptiveSizePolicy 如何设置，都会将 UseAdaptiveSizePolicy 设置为 false。 参数配置参数配置样例 1&quot; -XX:+UseParallelGC -XX:+DoEscapeAnalysis -XX:+PrintCompilation -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining -XX:+PrintAdaptiveSizePolicy -XX:+PrintTenuringDistribution -XX:+UseGCOverheadLimit -XX:+PrintGCDetails -Xloggc:/logs/jvm/gc.log -XX:-HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/logs/jvm/heapdump.log -XX:ErrorFile=/logs/jvm/error.log &quot; 日志解释日志样例12345678349870.271: [GC (Allocation Failure) AdaptiveSizePolicy::update_averages: survived: 1075648 promoted: 24576 overflow: falseAdaptiveSizeStart: 349870.284 collection: 13471 avg_survived_padded_avg: 7641306.000000 avg_promoted_padded_avg: 1940767.125000 avg_pretenured_padded_avg: 0.000000 tenuring_thresh: 1 target_size: 7864320Desired survivor size 7864320 bytes, new threshold 1 (max 15)PSAdaptiveSizePolicy::compute_eden_space_size: costs minor_time: 0.001974 major_cost: 0.000012 mutator_cost: 0.998014 throughput_goal: 0.990000 live_space: 996563968 free_space: 1162870784 old_eden_size: 679477248 desired_eden_size: 679477248AdaptiveSizePolicy::survivor space sizes: collection: 13471 (7864320, 7864320) -&gt; (7864320, 7864320)AdaptiveSizeStop: collection: 13471[PSYoungGen: 687648K-&gt;1050K(691200K)] 1941073K-&gt;1254499K(2089472K), 0.0129194 secs] [Times: user=0.04 sys=0.00, real=0.02 secs] 日志内容解释自适应调整策略启动：启动时间：收集数量期望survivor空间大小，本次晋升阀值（最大晋升阀值）自适应调整策略：eden区间大小计算：花费：minor消耗时间；major消耗时间：motator变异消耗时间：吞吐目标：当前空间大小：当前空闲空间大小：旧eden空间大小：期望eden空间大小自适应调整策略：survivor空间大小：收集数量：from/to空间变化自适应调整策略停止：收集数量：容量大小变化：（年轻代）gc前空间大小 -&gt; gc后空间大小（容量上限）：（老年代）gc前空间大小 -&gt; gc后空间大小（容量上限） 调优策略 本次晋升阀值小于最大晋升阀值时，说明对象提前晋升，即年轻代空间容量不足/suivivor空间太小，应该及时查看参数设置是否合理，还是异常请求导致的短周期对象激增 年轻代受对象的分配速率影响，老年代受对象的晋升速率影响，两者过高都会导致gc的频繁，从而影响应用的整体吞吐量 只能根据 minor GC 计算提升速率。 Full GC 的日志不能用于计算提升速率, 因为 major GC 会清理掉老年代中的一部分对象。 从gc日志的每次 minor gc 的时间和年轻代增加空间大小可以算出分配速率 适当增大年轻代来降低gc的次数，从而控制吞吐 将频繁产生临时对象的接口（例如：批量/大作业）剥离整体应用，独立出来，从而降低对整体应用吞吐量的影响]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC-CMS]]></title>
    <url>%2F2021%2F04%2F04%2FGC-CMS%2F</url>
    <content type="text"><![CDATA[GC-CMS 算法实现 优点缺点 参数配置 日志解释 调优策略 以下所有内容均基于java8而写，新版本java可能会有变动 算法实现 “Mostly Concurrent Mark and Sweep Garbage Collector”(主要并发-标记-清除-垃圾收集器). 其对年轻代采用并行 STW方式的 mark-copy (标记-复制)算法, 对老年代主要使用并发 mark-sweep (标记-清除)算法。 详细执行阶段 阶段 1: Initial Mark(初始标记). 这是第一次STW事件。 此阶段的目标是标记老年代中所有存活的对象, 包括 GC ROOR 的直接引用, 以及由年轻代中存活对象所引用的对象。 后者也非常重要, 因为老年代是独立进行回收的。 阶段 2: Concurrent Mark(并发标记). 在此阶段, 垃圾收集器遍历老年代, 标记所有的存活对象, 从前一阶段 “Initial Mark” 找到的 root 根开始算起。 顾名思义, “并发标记”阶段, 就是与应用程序同时运行,不用暂停的阶段。 请注意, 并非所有老年代中存活的对象都在此阶段被标记, 因为在标记过程中对象的引用关系还在发生变化。 阶段 3: Concurrent Preclean(并发预清理). 此阶段同样是与应用线程并行执行的, 不需要停止应用线程。 因为前一阶段是与程序并发进行的,可能有一些引用已经改变。如果在并发标记过程中发生了引用关系变化,JVM会(通过“Card”)将发生了改变的区域标记为“脏”区(这就是所谓的卡片标记,Card Marking)。 阶段 4: Concurrent Abortable Preclean(并发可取消的预清理). 此阶段也不停止应用线程. 本阶段尝试在 STW 的 Final Remark 之前尽可能地多做一些工作。本阶段的具体时间取决于多种因素, 因为它循环做同样的事情,直到满足某个退出条件( 如迭代次数, 有用工作量, 消耗的系统时间,等等)。 阶段 5: Final Remark(最终标记). 这是此次GC事件中第二次(也是最后一次)STW阶段。本阶段的目标是完成老年代中所有存活对象的标记. 因为之前的 preclean 阶段是并发的, 有可能无法跟上应用程序的变化速度。所以需要 STW暂停来处理复杂情况。 阶段 6: Concurrent Sweep(并发清除). 此阶段与应用程序并发执行,不需要STW停顿。目的是删除未使用的对象,并收回他们占用的空间。 阶段 7: Concurrent Reset(并发重置). 此阶段与应用程序并发执行,重置CMS算法相关的内部数据, 为下一次GC循环做准备。 优点缺点 并发标记扫描（CMS）收集器是为那些希望较短的垃圾收集暂停并且可以在应用程序运行时与垃圾收集器共享处理器资源的应用程序而设计的。通常，具有相对较长的长期数据集（大量使用期限）并在具有两个或多个处理器的计算机上运行的应用程序往往会受益于此收集器的使用。但是，对于暂停时间要求低的任何应用程序，都应考虑使用该收集器。 CMS收集器通过命令行选项-XX：+ UseConcMarkSweepGC启用。 与其他可用的收集器类似，CMS收集器也是分代的。因此，minor gc 和 major gc 都发生了。 CMS收集器尝试通过使用单独的垃圾收集器线程在执行应用程序线程的同时并跟踪可访问对象，来减少由于 major gc 而导致的暂停时间。在每个主要的收集周期中，CMS收集器会在收集开始时短暂暂停所有应用程序线程，并在收集中途再次暂停。第二个停顿往往是两个停顿中较长的一个。在两个暂停期间都使用多个线程来执行收集工作。集合的其余部分（包括大多数活动对象的跟踪和无法访问对象的清除）是通过与应用程序同时运行的一个或多个垃圾收集器线程完成的。minor gc可以与正在进行的主要周期交错，并且以与并行收集器类似的方式完成（注意：在 minor gc 期间,应用程序线程是停止的）。 并发模式故障: CMS收集器使用一个或多个垃圾收集器线程，这些线程与应用程序线程同时运行。如前所述，在正常操作中，CMS收集器在应用程序线程仍在运行的情况下执行其大部分跟踪和清除工作，因此应用程序线程仅会看到短暂的暂停。但是，如果CMS收集器无法及时完成对无法访问的对象的回收，或者如果可用空闲空间块无法满足分配要求，则将暂停应用程序，并使得所有应用程序线程均已停止。无法同时完成收集的情况称为并发模式故障，表示需要调整CMS收集器参数。如果并发收集被显式垃圾回收（System.gc（））中断，或者为提供诊断工具信息所需的垃圾收集中断了，则将报告并发模式中断。 过多的GC时间和OutOfMemoryError: 如果在垃圾回收上花费了太多时间，则CMS收集器将抛出OutOfMemoryError：如果在垃圾回收上花费了总时间的98％以上，并且回收的堆少于2％，则抛出OutOfMemoryError。此功能旨在防止应用程序长时间运行，而由于堆太小而几乎没有进展，甚至没有进展。如有必要，可以通过在命令行中添加选项-XX：-UseGCOverheadLimit来禁用此功能。 该策略与并行收集器中的策略相同，除了执行并发收集所花费的时间不计入98％的时间限制。换句话说，只有在应用程序停止时执行的收集才计入过多的GC时间。此类收集通常是由于并发模式故障或显式收集请求（例如，对System.gc的调用）引起的。 浮动垃圾: 与Java HotSpot VM中的所有其他收集器一样，CMS收集器是一个跟踪收集器，它需要标识堆中的所有可访问对象。CMS它是一个增量更新收集器。由于应用程序线程和垃圾收集器线程在 major gc 期间同时运行，因此垃圾收集器线程跟踪的对象随后可能会在收集过程结束时变得不可访问。此类无法访问的对象称为浮动垃圾。浮动垃圾的数量取决于并发收集周期的持续时间以及应用程序对引用更新（也称为变异）的频率。此外，由于年轻代和 老年代是独立收集的，因此彼此之间起着根源的作用。作为粗略的指导，请尝试将永久代的大小增加20％，以解决浮动垃圾的问题。在一个并发收集周期结束时，在下一个收集器中收集堆中的浮动垃圾 并发阶段: 可达对象图的并发跟踪发生在初始标记暂停和二次标记暂停之间。 在此并发跟踪阶段，一个或多个并发垃圾收集器线程可能正在使用处理器资源，否则这些资源将可供应用程序使用。 结果，即使没有暂停应用程序线程，在此阶段和其他并发阶段中，受计算绑定的应用程序的应用程序吞吐量也可能会相应下降。 二次标记暂停后，并发扫描阶段将收集被标识为不可访问的对象。 收集周期完成后，CMS收集器将等待，几乎不消耗任何计算资源，直到下一个主要收集周期开始。 安排暂停: 年轻代gc和老年代gc的暂停独立发生。 它们不会重叠，但可能会快速连续发生，看起来像是一个较长的暂停。 为了避免这种情况，CMS收集器尝试在上次和下一个年轻暂停之间的大致中间时间安排remark暂停。 当前尚未为初始标记阶段执行此暂停计划，该时间通常比标记暂停要短得多 增量模式: i-cms，请注意，在Java SE 8中不推荐使用增量模式，并且在将来的主要版本中可能会删除它。这里就不多做解释了。 参数配置 -XX:CMSExpAvgFactor=percent：设置在计算并发集合统计信息的指数平均值时用于加权当前样本的时间百分比（0到100），默认25 -XX:CMSInitiatingOccupancyFraction=percent：老年代何时触发cms，默认-1，表示使用参数 -XX:CMSTriggerRatio 来决定 -XX:CMSTriggerRatio=percent：设置-XX：MinHeapFreeRatio指定的值的百分比（0到100），该值在CMS收集周期开始之前分配；默认值80 -XX:+CMSScavengeBeforeRemark：在CMS二次标记步骤之前启用清除尝试 -XX:ConcGCThreads=threads：并发线程数量 参数配置样例1-XX:+UseConcMarkSweepGC 日志解释日志样例12345678910111213141516[GC [1 CMS-initial-mark: 13991K(20288K)] 14103K(22400K), 0.0023781 secs][GC [DefNew: 2112K-&gt;64K(2112K), 0.0837052 secs] 16103K-&gt;15476K(22400K), 0.0838519 secs]...[GC [DefNew: 2077K-&gt;63K(2112K), 0.0126205 secs] 17552K-&gt;15855K(22400K), 0.0127482 secs][CMS-concurrent-mark: 0.267/0.374 secs][GC [DefNew: 2111K-&gt;64K(2112K), 0.0190851 secs] 17903K-&gt;16154K(22400K), 0.0191903 secs][CMS-concurrent-preclean: 0.044/0.064 secs][GC [1 CMS-remark: 16090K(20288K)] 17242K(22400K), 0.0210460 secs][GC [DefNew: 2112K-&gt;63K(2112K), 0.0716116 secs] 18177K-&gt;17382K(22400K), 0.0718204 secs][GC [DefNew: 2111K-&gt;63K(2112K), 0.0830392 secs] 19363K-&gt;18757K(22400K), 0.0832943 secs]...[GC [DefNew: 2111K-&gt;0K(2112K), 0.0035190 secs] 17527K-&gt;15479K(22400K), 0.0036052 secs][CMS-concurrent-sweep: 0.291/0.662 secs][GC [DefNew: 2048K-&gt;0K(2112K), 0.0013347 secs] 17527K-&gt;15479K(27912K), 0.0014231 secs][CMS-concurrent-reset: 0.016/0.016 secs][GC [DefNew: 2048K-&gt;1K(2112K), 0.0013936 secs] 17527K-&gt;15479K(27912K), 0.0014814 secs] 日志内容解释调优策略]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC-G1]]></title>
    <url>%2F2021%2F04%2F04%2FGC-G1%2F</url>
    <content type="text"><![CDATA[GC-G1 算法实现 优点缺点 参数配置 日志解释 调优策略 以下所有内容均基于java8而写，新版本java可能会有变动 算法实现 从逻辑上讲，G1是世代相传的。一组空区域被指定为逻辑年轻代。在图中，年轻一代是浅蓝色的。分配是从逻辑上年轻的一代中完成的，当年轻一代已满时，该区域集将被垃圾收集（一个年轻的集合）。在某些情况下，可以同时收集一组年轻区域之外的区域（深蓝色的旧区域）。这称为混合集合。在图中，正在收集的区域用红色框标记。该图说明了混合的集合，因为同时收集了年轻区域和旧区域。垃圾收集是一个压缩收集，它将活动对象复制到选定的最初为空的区域。根据幸存对象的年龄，可以将对象复制到幸存者区域（标有“ S”）或复制到旧区域（未具体显示）。标有“ H”的区域包含的绒毛物体大于一个区域的一半，并且经过特殊处理 分配（疏散）失败: 与CMS一样，当应用程序继续运行时，G1收集器将运行其部分收集，并且存在这样的风险，即应用程序分配对象的速度将超过垃圾收集器可以回收可用空间的速度。 在G1中，当G1将活动数据从一个区域复制（撤离）到另一个区域时，发生故障（Java堆耗尽）。 复制是为了压缩实时数据。 如果在撤离正在收集垃圾的区域时找不到空闲（空）区域，则会发生分配失败（因为没有空间可以从正在撤离的区域分配有生命的物体），并且会停止（ STW）已完成完整收集。 浮动垃圾: 对象可能在G1收集期间死亡，无法收集。 G1使用一种称为快照快照（SATB）的技术来确保垃圾收集器找到所有活动对象。 SATB指出，出于收集的目的，在并发标记（整个堆上的标记）开始时处于活动状态的任何对象都被视为处于活动状态。 SATB以类似于CMS增量更新的方式允许浮动垃圾。 暂停: G1暂停应用程序以将活动对象复制到新区域。这些暂停可以是仅收集年轻区域的年轻收集暂停，也可以是疏散年轻和旧区域的混合收集暂停。与CMS一样，在应用程序停止时，有最后的标记或remark暂停以完成标记。 CMS还具有初始标记暂停，而G1则作为疏散暂停的一部分进行初始标记工作。 G1在gc收集的结尾有一个清理阶段，该阶段部分是STW，部分是并发的。清理阶段的STW部分标识空区域，并确定旧区域作为下一个集合的候选对象。 卡表和并发阶段: 如果垃圾收集器没有收集整个堆（增量收集），则垃圾收集器需要知道从堆的未收集部分到正在收集的堆部分的指针在哪里。这通常用于分代垃圾收集器，其中堆的未收集部分通常是旧的一代，而堆的收集部分是年轻的一代。用于保存此信息的数据结构（指向年轻一代对象的老一代指针）是一个可记住的集合。卡表是一种特殊的记忆结构。 Java HotSpot VM使用字节数组作为卡表。每个字节称为卡。卡与堆中的地址范围相对应。弄脏卡意味着将字节的值更改为脏值。脏值可能会在卡所覆盖的地址范围内包含从旧一代到年轻一代的新指针。处理卡意味着查看卡，看是否有老一代指向年轻一代的指针，并可能对该信息进行某些处理，例如将其传输到另一个数据结构。 G1具有并发标记阶段，该阶段标记从应用程序中找到的活动对象。并发标记从疏散暂停（完成初始标记工作）结束到标记为止。并发清理阶段将集合清空的区域添加到空闲区域列表中，并清除记住的那些区域集。此外，并发优化线程将根据需要运行，以处理已被应用程序写入弄脏并且可能具有跨区域引用的卡表条目。 G1 GC是一个区域化的分代垃圾收集器，这意味着Java对象堆（堆）被划分为多个大小相等的区域。启动时，Java虚拟机（JVM）设置区域大小。区域大小可以从1 MB到32 MB不等，具体取决于堆大小。目标是不超过2048个区域。伊甸区，幸存者区和旧代区是这些地区的逻辑集合，并不连续。 G1 GC具有尝试达到的暂停时间目标（软实时）。在年轻系列中，G1 GC会调整其年轻一代（伊甸园和幸存者的大小），以达到柔和的实时目标。 在混合收集期间，G1 GC根据目标混合垃圾收集数量，堆中每个区域中的活动对象百分比以及总体可接受的堆废物百分比，来调整收集的旧区域的数量。 G1 GC通过将活动对象从一个或多个区域集（称为集合集（CSet））递增并行复制到一个或多个不同的新区域中来实现压缩，从而减少了堆碎片。目标是从包含最大可回收空间的那些区域开始，尽可能多地回收堆空间，同时尝试不超过暂停时间目标（首先是垃圾）。 G1 GC使用独立的记忆集（RSets）来跟踪区域中的引用。独立的RSets可以并行和独立地收集区域，因为只有区域的RSet必须被扫描以寻找对该区域的引用，而不是整个堆的引用。 G1 GC使用 写后屏障 来记录对堆的更改并更新RSets。 垃圾收集阶段: 除了组成暂停世界（STW）的年轻垃圾和混合垃圾收集的撤离暂停（请参阅垃圾优先垃圾收集器中的分配（撤离）失败部分）外，G1 GC还具有并行，并发和多阶段标记周期。 G1 GC使用 “开始时快照”（SATB）算法，该算法在标记周期开始时从逻辑上对堆中活动对象集进行快照。活动对象集还包括自标记周期开始以来分配的对象。 G1 GC标记算法使用预写屏障来记录和标记属于逻辑快照的对象。 年轻代垃圾收集: G1 GC满足了来自添加到eden区域集中的区域的大多数分配请求。在年轻的垃圾收集期间，G1 GC从先前的垃圾收集中收集了伊甸园地区和幸存者地区。来自伊甸园地区和幸存者地区的活物被复制或撤离到一组新的地区。特定对象的目标区域取决于对象的年龄。经过充分老化的物体已被疏散到较旧的区域（即被提升）；否则，该对象将撤离到幸存者区域，并将包含在下一个年轻垃圾或混合垃圾收集的CSet中。 混合垃圾收集: 成功完成并发标记周期后，G1 GC从执行年轻垃圾收集切换为执行混合垃圾收集。在混合垃圾收集中，G1 GC可以选择将一些旧区域添加到将要收集的伊甸园区域和幸存者区域中。所添加的旧区域的确切数量由多个标志控制。在G1 GC收集到足够数量的旧区域（通过多个混合垃圾收集）之后，G1恢复执行新的垃圾收集，直到下一个标记周期完成。 标记周期的各个阶段 初始标记阶段：G1 GC在此阶段标记根。此阶段由常规（STW）的年轻垃圾回收承载。 根区域扫描阶段：G1 GC扫描在初始标记阶段标记的幸存者区域，以参考旧一代并标记所参考的对象。该阶段与应用程序（不是STW）同时运行，并且必须在下一个STW年轻垃圾收集开始之前完成。 并发标记阶段：G1 GC在整个堆中找到可访问的（活动的）对象。此阶段与应用程序同时发生，并且可以被STW年轻的垃圾回收中断。 标记阶段：此阶段是STW收集，有助于完成标记周期。 G1 GC耗尽SATB缓冲区，跟踪未访问的活动对象，并执行参考处理。 清理阶段：在此最后阶段，G1 GC执行记帐和RSet清理的STW操作。在记帐期间，G1 GC会确定完全空闲的区域和混合垃圾收集候选对象。清除阶段在重置并将空闲区域返回到空闲列表时，部分处于并发状态。 优点缺点 Garbage-First（G1）垃圾收集器是一种服务器样式的垃圾收集器，适用于具有大内存的多处理器计算机。它尝试以高概率满足垃圾收集（GC）暂停时间目标，同时实现高吞吐量。全堆操作（例如全局标记）与应用程序线程同时执行。这样可以防止与堆或活动数据大小成比例的中断。 G1收集器通过多种技术实现了高性能和暂停时间目标。 堆被划分为一组大小相等的堆区域，每个堆区域都有一个连续的虚拟内存范围。 G1执行并发全局标记阶段，以确定整个堆中对象的活动性。标记阶段完成后，G1知道哪些区域大部分为空。它首先收集这些区域，这通常会产生大量的自由空间。这就是为什么这种垃圾收集方法称为“垃圾优先”的原因。顾名思义，G1将其收集和压缩活动集中在可能充满可回收对象（即垃圾）的堆区域中。 G1使用暂停预测模型来满足用户定义的暂停时间目标，并根据指定的暂停时间目标选择要收集的区域数。 G1将对象从堆的一个或多个区域复制到堆上的单个区域，并且在此过程中，压缩和释放了内存。该操作是在多处理器上并行执行的，以减少暂停时间并增加吞吐量。因此，对于每个垃圾回收，G1都会不断减少碎片。这超出了先前两种方法的能力。 CMS（并发标记扫描）垃圾收集不会进行压缩。并行压缩仅执行整个堆压缩，这会导致相当长的暂停时间。 重要的是要注意，G1不是实时收集器。它很有可能达到设定的暂停时间目标，但不是绝对确定的。根据先前收集的数据，G1估计在目标时间内可以收集多少个区域。因此，收集器具有收集区域成本的合理准确的模型，并且收集器使用此模型来确定要收集哪些区域和多少区域，同时保持在暂停时间目标之内。 G1的首要重点是为运行需要大型堆且GC延迟有限的应用程序的用户提供解决方案。这意味着堆大小约为6 GB或更大，并且稳定且可预测的暂停时间低于0.5秒。 如果应用程序具有以下一个或多个特征，那么今天运行CMS或并行压缩的应用程序将从切换到G1中受益。 超过50％的Java堆被实时数据占用。 对象分配率或提升率差异很大。 该应用程序正在经历不希望的长时间垃圾收集或压缩暂停（长于0.5到1秒）。 计划将G1作为并发标记扫描收集器（CMS）的长期替代产品。将G1与CMS进行比较，可以发现使G1成为更好解决方案的差异。一个区别是G1是压紧收集器。此外，G1提供的垃圾收集暂停比CMS收集器更具可预测性，并允许用户指定所需的暂停目标。 与CMS一样，G1专为需要更短GC暂停的应用而设计。 开始并发收集周期: 如前所述，无论是旧区还是旧区，都是混合收集的垃圾。为了收集旧区域，G1对堆中的活动对象进行了完整的标记。这样的标记是通过并发标记阶段完成的。当整个Java堆的占用达到参数InitiatingHeapOccupancyPercent的值时，将开始并发标记阶段。使用命令行选项-XX：InitiatingHeapOccupancyPercent = 设置此参数的值。 InitiatingHeapOccupancyPercent的默认值为45。 暂停时间目标: 使用标志MaxGCPauseMillis为G1设置一个暂停时间目标。 G1使用预测模型来确定在该目标暂停时间内可以完成多少垃圾收集工作。在收集结束时，G1选择要在下一个收集（收集集）中收集的区域。集合集将包含年轻区域（其大小的总和决定逻辑年轻代的大小）。 G1部分地通过选择集合集中的年轻区域的数量来控制GC暂停的长度。您可以像其他垃圾收集器一样在命令行上指定年轻代的大小，但是这样做可能会妨碍G1达到目标暂停时间的能力。除了暂停时间目标之外，您还可以指定可能发生暂停的时间段的长度。您可以在此时间跨度（GCPauseIntervalMillis）中指定最小的转换器使用量以及暂停时间目标。 MaxGCPauseMillis的默认值为200毫秒。 GCPauseIntervalMillis（0）的默认值等效于时间跨度上的任何要求。 大对象分配 对于G1 GC，任何大于区域大小一半的对象都被认为是巨大的对象。这样的对象在老一代中直接分配到庞大的区域中。这些巨大的区域是一组连续的区域。 StartsHumongous标志着连续集合的开始，ContinuesHumongous标志着集合的继续。 在分配任何大型区域之前，将检查标记阈值，并在必要时启动并发循环。 在清理阶段以及整个垃圾收集周期的标记周期结束时，将释放死掉的巨型对象。 为了减少复制开销，巨大的对象不包括在任何撤离暂停中。完整的垃圾收集周期将庞大的对象压缩到位。 因为每个单独的StartsHumongous和ContinuesHumongous区域集仅包含一个humongous对象，所以未使用humongous对象的末尾与该对象所覆盖的最后一个区域的末尾之间的空间。对于刚好大于堆区域大小倍数的对象，未使用的空间可能导致堆碎片化。 如果您看到由于庞大的分配而启动的背对背并发周期，并且如果此类分配使您的上一代分裂了，请增加-XX：G1HeapRegionSize的值，以使先前的庞大对象不再是庞大的对象，并且将遵循常规分配路径。 参数配置 G1 GC是具有默认设置的自适应垃圾收集器，可使其无需修改即可高效工作 -XX:G1HeapRegionSize=n : 设置G1区域的大小。 该值为2的幂，范围为1 MB到32 MB。 目标是根据最小Java堆大小具有大约2048个区域。 -XX:MaxGCPauseMillis=200 : 为所需的最大暂停时间设置目标值。 默认值为200毫秒。 指定的值不适合您的堆大小。 -XX:G1NewSizePercent=5 : 设置要用作年轻代大小的最小值的堆百分比。 默认值为Java堆的5％。这是一个实验性标志。 有关示例，请参见如何解锁实验性VM标志。 此设置替换-XX：DefaultMinNewGenPercent设置。 -XX:G1MaxNewSizePercent=60 : 设置堆大小的百分比，以用作年轻代大小的最大值。 默认值为Java堆的60％。这是一个实验性标志。 有关示例，请参见如何解锁实验性VM标志。 此设置替换-XX：DefaultMaxNewGenPercent设置。 -XX:ParallelGCThreads=n : 设置STW工作线程的值。 将n的值设置为逻辑处理器的数量。 n的值与最多等于8的逻辑处理器的数量相同。如果逻辑处理器多于八个，则将n的值设置为逻辑处理器的大约5/8。 除较大的SPARC系统外，这在大多数情况下均有效，其中n的值约为逻辑处理器的5/16。 -XX:ConcGCThreads=n : 设置并发标记线程的数量。 将n设置为并行垃圾回收线程数（ParallelGCThreads）的大约1/4。 -XX:InitiatingHeapOccupancyPercent=45 : 设置触发标记周期的Java堆占用阈值。 默认占用率为整个Java堆的45％。 -XX:G1MixedGCLiveThresholdPercent=85 : 设置要包含在混合垃圾收集周期中的旧区域的占用阈值。 默认占用率为85％。这是一个实验性标志。 有关示例，请参见如何解锁实验性VM标志。 此设置替换-XX：G1OldCSetRegionLiveThresholdPercent设置。 -XX:G1HeapWastePercent=5 : 设置您愿意浪费的堆百分比。 当可回收百分比小于堆垃圾百分比时，Java HotSpot VM不会启动混合垃圾回收周期。 默认值为5％。 -XX:G1MixedGCCountTarget=8 : 设置标记周期后混合垃圾回收的目标数量，以收集具有最多G1MixedGCLIveThresholdPercent个实时数据的旧区域。 默认值为8个混合垃圾回收。 混合馆藏的目标是在此目标数量之内。 -XX:G1OldCSetRegionThresholdPercent=10 : 设置在混合垃圾收集周期中要收集的旧区域数的上限。 默认值为Java堆的10％。 -XX:G1ReservePercent=10 : 设置保留内存的百分比以使其保持空闲状态，以减少空间溢出的风险。 默认值为10％。 当您增加或减少百分比时，请确保将总Java堆调整相同的数量。 如何解锁实验性VM标志: 要更改实验性标志的值，您必须先将其解锁。您可以通过在任何实验性标志之前在命令行上显式设置-XX：+ UnlockExperimentalVMOptions来执行此操作 参数配置样例1-XX:+UseG1GC 日志解释 Young GC：所有Eden区域满了后触发，并行收集，且完全STW。 并发标记周期：它的第一个阶段初始化标记和YGC一起发生，这个周期的目的就是找到回收价值最大的Region集合（垃圾很多，存活对象很少），为接下来的Mixed GC服务。 Mixed GC：回收所有年轻代的Region和部分老年代的Region Full GC：非常慢，STW且回收所有类型的Region。 日志样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// YGC log3.378: [GC pause (G1 Evacuation Pause) (young), 0.0015185 secs] [Parallel Time: 0.7 ms, GC Workers: 4] [GC Worker Start (ms): Min: 3378.1, Avg: 3378.3, Max: 3378.6, Diff: 0.5] [Ext Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6] [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Processed Buffers: Min: 0, Avg: 0.2, Max: 1, Diff: 1, Sum: 1] [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3] [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.3, Diff: 0.3, Sum: 0.7] [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 0.1, Avg: 0.4, Max: 0.6, Diff: 0.6, Sum: 1.8] [GC Worker End (ms): Min: 3378.7, Avg: 3378.7, Max: 3378.8, Diff: 0.1] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.1 ms] [Other: 0.7 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.5 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.1 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.1 ms] [Free CSet: 0.1 ms] [Eden: 304.0M(304.0M)-&gt;0.0B(304.0M) Survivors: 2048.0K-&gt;2048.0K Heap: 304.5M(512.0M)-&gt;529.0K(512.0M)] [Times: user=0.01 sys=0.00, real=0.00 secs] // 抽象后为 GC pause (G1 Evacuation Pause) (young) ├── Parallel Time ├── GC Worker Start ├── Ext Root Scanning ├── Update RS ├── Scan RS ├── Code Root Scanning ├── Object Copy ├── Code Root Fixup ├── Code Root Purge ├── Clear CT ├── Other ├── Choose CSet ├── Ref Proc ├── Ref Enq ├── Redirty Cards ├── Humongous Register ├── Humongous Reclaim ├── Free CSet // 并发标记周期# 这一行日志是全局并发标记的第一个阶段，即初始化标记，是伴随YGC一起发生的，后面的857M-&gt;617M表示YGC发生前后堆内存变化，0.0112237表示YGC的耗时[GC pause (G1 Evacuation Pause) (young) (initial-mark) 857M-&gt;617M(1024M), 0.0112237 secs]# 开始并发ROOT区域扫描[GC concurrent-root-region-scan-start]# 结束并发ROOT区域扫描，并统计这个阶段的耗时[GC concurrent-root-region-scan-end, 0.0000525 secs][GC concurrent-mark-start][GC concurrent-mark-end, 0.0083864 secs]# 最终标记阶段完成并发标记阶段后遗留的工作，即SATB buffer处理，并统计这个阶段耗时[GC remark, 0.0038066 secs]# 清理阶段会根据所有Region标记信息，计算出每个Region存活对象信息，并且把Region根据GC回收效率排序[GC cleanup 680M-&gt;680M(1024M), 0.0006165 secs]// Mixed gc29.268: [GC pause (G1 Evacuation Pause) (mixed), 0.0059011 secs] [Parallel Time: 5.6 ms, GC Workers: 4] ... ... [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.1 ms] [Other: 0.3 ms] ... ... [Eden: 14.0M(14.0M)-&gt;0.0B(156.0M) Survivors: 10.0M-&gt;4096.0K Heap: 165.9M(512.0M)-&gt;148.7M(512.0M)] [Times: user=0.02 sys=0.01, real=0.00 secs] // Full gc // 手动显示gc导致的（手动调用System.gc()） 4.358: [Full GC (System.gc()) 298M-&gt;509K(512M), 0.0101774 secs] [Eden: 122.0M(154.0M)-&gt;0.0B(230.0M) Survivors: 4096.0K-&gt;0.0B Heap: 298.8M(512.0M)-&gt;509.4K(512.0M)], [Metaspace: 3308K-&gt;3308K(1056768K)] [Times: user=0.01 sys=0.00, real=0.01 secs] // 堆空间满导致的full gc 805.815: [GC pause (G1 Evacuation Pause) (young) 96G-&gt;74G(100G), 2.4778659 secs] 813.964: [GC pause (G1 Evacuation Pause) (mixed)-- 97G-&gt;99G(100G), 23.7970094 secs] 837.762: [GC pause (G1 Evacuation Pause) (mixed)-- 99G-&gt;99G(100G), 32.0781615 secs] 869.842: [Full GC (Allocation Failure) 99G-&gt;62G(100G), 169.3897706 secs] 日志内容解释内存溢出和耗尽日志消息 当在日志中看到“空间溢出（to-space overflow）”或“空间耗尽（ to-space exhausted）”消息时，G1 GC没有足够的内存来存储幸存者或升级对象，或两者都没有。 此时Java堆处于最大状态。消息示例： 12924.897: [GC pause (G1 Evacuation Pause) (mixed) (to-space exhausted), 0.1957310 secs]924.897: [GC pause (G1 Evacuation Pause) (mixed) (to-space overflow), 0.1957310 secs] 解决方案 增加-XX：G1ReservePercent选项的值（并相应增加总堆），以增加“至空间”的保留内存量。 通过减小-XX：InitiatingHeapOccupancyPercent的值来更早地开始标记周期。 增加-XX：ConcGCThreads选项的值，以增加并行标记线程的数量。 调优策略牢记以下建议 年轻代大小：避免使用-Xmn选项或任何其他相关选项（例如-XX：NewRatio）来显式设置年轻代大小。固定年轻代的大小会覆盖目标暂停时间目标。 暂停时间目标：当您评估或调整任何垃圾收集时，总会有延迟与吞吐量之间的权衡。 G1 GC是具有统一暂停的增量垃圾收集器，但在应用程序线程上也有更多开销。 G1 GC的吞吐量目标是90％的应用时间和10％的垃圾收集时间。与Java HotSpot VM并行收集器进行比较。并行收集器的吞吐量目标是99％的应用程序时间和1％的垃圾收集时间。因此，在评估G1 GC的吞吐量时，请放宽暂停时间目标。设置过于激进的目标表示您愿意承担垃圾收集开销的增加，这直接影响了吞吐量。在评估G1 GC的延迟时，您可以设置所需的（软）实时目标，G1 GC会尝试达到此目标。副作用是，吞吐量可能会受到影响。 混合垃圾收集：调整混合垃圾收集时，请尝试以下选项 -XX：InitiatingHeapOccupancyPercent：用于更改标记阈值。 -XX：G1MixedGCLiveThresholdPercent和-XX：G1HeapWastePercent：用于更改混合垃圾回收决策。 -XX：G1MixedGCCountTarget和-XX：G1OldCSetRegionThresholdPercent：用于调整旧区域的CSet。]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC-ZGC]]></title>
    <url>%2F2021%2F04%2F04%2FGC-ZGC%2F</url>
    <content type="text"><![CDATA[GC-ZGC 算法实现 优点缺点 参数配置 日志解释 调优策略 算法实现优点缺点参数配置参数配置样例日志解释日志样例日志内容解释调优策略]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Distributed Lock]]></title>
    <url>%2F2021%2F03%2F13%2FRedisLock%2F</url>
    <content type="text"><![CDATA[Distributed lock 实现原理 问题隐患 redis实现 实现原理 所谓的分布式锁其实就是将多个锁抽象成一个锁，也就是将原来多个位置的锁抽离到一个位置，简化成一个锁；例如：redis分布式锁：将锁抽象成redis中的一个key，客户端不断尝试去主动获取锁资源，cpu消耗较多zookeeper分布式锁：将锁抽象成zk目录结构中的一个目录，客户端注册锁监听等待锁释放通知 问题隐患 锁过期时间：不能太长，不能太短 锁释放错误：线程A执行超时后释放了线程B的锁 超时并发：线程A超时后导致和其他线程形成并发 应用获取锁等待超时：数据库事务内等待锁资源而导致事务超时 集群切换master：存在2个应用同时获取到锁的情况 惊群效应：zk采用临时节点实现分布式锁的方式，在锁释放的时候会通知到所有等待客户端，但是实际只能有一个获取到锁 问题隐患的解决方案 锁过期时间：根据具体业务需求而定 锁释放错误：锁添加线程唯一标识 超时并发：新增watch-dog自动检测延长锁的过期时间，一般为每过1/3操作未结束就增加1/3的过期时间 应用获取锁等待超时：事务内尽量避免使用，同时控制超时时间 集群切换master：Redis 的作者 antirez 提供了 RedLock 的算法来实现一个分布式锁，算法详情见官网 惊群效应：使用临时顺序节点替代临时节点，临时顺序节点可以实现监听程序只监听比自己小的第一个节点即可 redis实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153public class RedisLock &#123; @Autowired RedisTemplate&lt;String, String&gt; redisTemplate; /** * 支持可重入锁 */ static final RedisScript LOCK_SCRIPT = RedisScript.of(&quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;hset&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + &quot;return redis.call(&apos;pttl&apos;, KEYS[1]);&quot;, Long.class); static final RedisScript UNLOCK_SCRIPT = RedisScript.of(&quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end;&quot; + &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[3]) == 0) then &quot; + &quot;return nil;&quot; + &quot;end; &quot; + &quot;local counter = redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[3], -1); &quot; + &quot;if (counter &gt; 0) then &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[2]); &quot; + &quot;return 0; &quot; + &quot;else &quot; + &quot;redis.call(&apos;del&apos;, KEYS[1]); &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end; &quot; + &quot;return nil;&quot;, Long.class); ThreadLocal&lt;Long&gt; threadId = new ThreadLocal&lt;&gt;(); public static final List&lt;String&gt; LOCK_KEYS = new ArrayList&lt;String&gt;(1) &#123;&#123; add(LOCK_KEY); &#125;&#125;; static final String LOCK_KEY = &quot;LOCK&quot;; public static final String LOCK_VALUE = &quot;lock_&quot;; // 时间单位为毫秒 static final long LOCK_EXPIRE_TIME = 10000; static final String THREAD_ID = &quot;thread&quot;; static Timer timer = new Timer(); private WatchDog watchDog; /** * Try lock long. * non-blocked acquire lock * * @param key the key * @return the long if return null acquire lock success else return long num which is current lock&apos;s expire time */ public Long tryLock(String key) &#123; return null; &#125; /** * Try lock long. * non-blocked acquire lock * * @param key the key * @param expireTime the expire time * @return the long if return null acquire lock success else return long num which is current lock&apos;s expire time */ public Long tryLock(String key, long expireTime) &#123; return null; &#125; public boolean lock() &#123; // 将锁的value值加上当前线程唯一标示id, 避免释放锁的时候释放错(A线程执行超时完成后释放掉B线程获取的锁) Long id = redisTemplate.opsForValue().increment(THREAD_ID); Long lock = (Long) redisTemplate.execute(LOCK_SCRIPT, LOCK_KEYS, LOCK_VALUE + id, LOCK_EXPIRE_TIME); assert Objects.nonNull(lock); if (1 == lock) &#123; System.out.println(&quot;线程[&#123;&quot; + id + &quot;&#125;] 获取锁成功&quot;); threadId.set(id); // 创建守护线程, 当过期时间还剩百分之十的时候, 如果当前线程还未完成任务, 则适当延长锁的过期时间(重新设置过期时间为原过期时间的百分之五十), 避免线程执行超时造成并发操作 // 该锁的延期操作只会发生一次, 如果延期之后线程依然超时未完成, 就可能会造成并发错误操作 // 由于TimerTask对象在安排执行或者取消执行后，其内部状态（由state指定）已经发生变化，是不可以重新安排执行， 因此只能每次new一个新的守护线程; TODO 暂时没想到更优的方案替换每次new DaemonTask() watchDog = new WatchDog(); watchDog.setThreadId(id); // 记录锁的初始过期时间, 便于后续根据初始过期时间来计算延期时间 watchDog.setExpireTime(LOCK_EXPIRE_TIME); // 当锁的过期过期时间还剩十分之一(该值可自定义)的时候, 守护线程会去验证关联的线程任务是否完成, 未完成自动为该锁延期初始过期时间的百分之五十, 以此来避免线程任务执行超时造成并发操作 // 上述方案存在一定的风险性，就是在任务执行即将结束的时候才去延期，由于时间差较小容易造成失败，所以方案更改为没过三分之一过期时间就自动延期三分之一（借鉴redisson实现方案） timer.schedule(watchDog, Math.round(LOCK_EXPIRE_TIME * 0.3), Math.round(LOCK_EXPIRE_TIME * 0.3)); System.out.println(&quot;守护线程启动...&quot;); return true; &#125; return false; &#125; public void unlock() &#123; try &#123; redisTemplate.delete(THREAD_ID); watchDog.cancel(); Long unlock = (Long) redisTemplate.execute(UNLOCK_SCRIPT, LOCK_KEYS, LOCK_VALUE + threadId.get()); assert Objects.nonNull(unlock); if (unlock &gt; 0) &#123; watchDog.cancel(); System.out.println(&quot;线程[&#123;&quot; + threadId.get() + &quot;&#125;] 释放锁失败&quot;); &#125; System.out.println(&quot;线程[&#123;&quot; + threadId.get() + &quot;&#125;] 释放锁成功&quot;); &#125; catch (Exception e) &#123; watchDog.cancel(); throw new RuntimeException(e); &#125; &#125;&#125;public class WatchDog extends TimerTask &#123; @Autowired RedisTemplate&lt;String, String&gt; redisTemplate; static final RedisScript LOCK_EXTEND = RedisScript.of(&quot;if (redis.call(&apos;get&apos;, KEYS[1]) == ARGV[1]) then return redis.call(&apos;pexpire&apos;,KEYS[1],tonumber(ARGV[2])) else return 0 end&quot;, Long.class); private long threadId; private long expireTime; public long getThreadId() &#123; return threadId; &#125; public void setThreadId(long threadId) &#123; this.threadId = threadId; &#125; public long getExpireTime() &#123; return expireTime; &#125; public void setExpireTime(long expireTime) &#123; this.expireTime = expireTime; &#125; @Override public void run() &#123; System.out.println(&quot;锁自动延期三分之一...&quot;); Long lock = (Long) redisTemplate.execute(LOCK_EXTEND, LOCK_KEYS, LOCK_VALUE + getThreadId(), getExpireTime()); assert Objects.nonNull(lock); if (lock != 1) &#123; System.out.println(&quot;锁延期失败...&quot;); throw new RuntimeException(); &#125; System.out.println(&quot;锁延期成功...&quot;); &#125;&#125;]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MethodAccessor]]></title>
    <url>%2F2020%2F12%2F15%2FMethodAccessor%2F</url>
    <content type="text"><![CDATA[MethodAccessor 是什么 是什么？]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis ACL]]></title>
    <url>%2F2020%2F12%2F15%2FRedis%20ACL%2F</url>
    <content type="text"><![CDATA[Redis ACL(Access Control List) 基本用法 ACL的好处 ACL命名行配置 ACL rules ACL实时变更 ACL配置格式 哨兵/从库权限配置 在默认配置中，Redis 6（第一个具有ACL的版本）的工作方式与Redis的旧版本完全相同，也就是说，每个新连接都能够调用每个可能的命令并访问每个键，因此ACL功能与旧版本向后兼容。 客户和应用程序。 同样，使用requirepass配置指令配置密码的旧方法仍然可以按预期工作，但是现在，它的作用只是为默认用户设置密码。 基本用法 AUTH AUTH （旧版本用法） AUTH : 发生的是用于认证的用户名是“default”，因此仅指定密码就意味着我们要针对默认用户进行认证。 这提供了与过去的完美向后兼容性。 ACL的好处 通过限制对命令和密钥的访问来提高安全性，以便不受信任的客户端无法访问，而受信任的客户端仅具有对数据库的最低访问级别才能执行所需的工作。例如，某些客户端可能仅能够执行只读命令。 提高操作安全性，以防止由于软件错误或人为错误而导致进程或人员访问Redis，从而损坏数据或配置。例如，没有必要让工作人员从Redis获取延迟的作业来调用FLUSHALL命令。 ACL命名行配置 默认情况下，只有一个用户定义，称为default。 我们可以使用ACL LIST命令来检查当前活动的ACL并验证新启动的，默认配置的Redis实例的配置是： ACL LIST（查看所有用户权限信息） “user default on nopass ~ &amp; +@all” ACL SETUSER newuser newuser存在不做任何操作，不存在创建用户 “user newuser off -@all”（新建立的用户处于未激活状态，不可以操作任何命令） ACL SETUSER newuser on &gt;newpwd ~prefix* +get 设置详细权限，密码自动加密处理（从redis6开始，CONFIG GET requirepass 结果也是），如下123127.0.0.1:6379&gt; acl list1) &quot;user default on nopass ~* +@all&quot;2) &quot;user newuser on #b221bf17bde0cc7ab86c92e8a707b126a7d8ba0dbc6d582ef02bcad8f9394ef5 ~prefix* -@all +get&quot; AUTH user password 切换用户，终端只对切换后的第一个命令生效，之后自动切换回原用户 ACL GETUSER newuser 查看单个用户的权限信息 ACL SETUSER newuser ~objects ~items ~public* 一次性添加可以操作的多个匹配key模式（空格隔开） 其他权限设置类似，以空格隔开多个同类型权限设置 ACL SETUSER newuser -client +client|setname +client|getname 设置允许某一模块下的某些子命令 ACL GENPASS redis提供的生成加强版密码的命令 ACL rules启用和禁止用户： on：启用用户：可以认证为该用户。 off：禁用用户：不再可以与此用户进行身份验证，但是已经过身份验证的连接仍然可以使用。请注意，如果默认用户被标记为关闭，则新连接将不会通过身份验证开始，并且将要求用户发送带有AUTH选项的AUTH或HELLO，以便以某种方式进行身份验证，而与默认用户配置无关。允许和禁止命令：1234567+&lt;命令&gt;：将该命令添加到用户可以调用的命令列表中。-&lt;命令&gt;：将命令从用户可以调用的命令列表中删除。+@&lt;**类别**&gt;：添加要由用户调用的该类别中的所有命令，有效类别为@ admin，@ set，@ sortedset等，等等，请通过调用ACL CAT查看完整列表命令。特殊类别@all表示所有命令，包括当前在服务器中存在的命令，以及将来将通过模块加载的命令。-@&lt;类别&gt;：类似于+@&lt;类别&gt;，但是从客户端可以调用的命令列表中删除命令。+ &lt;命令&gt; |子命令：允许某命令的特定子命令，其他禁止。注意，这种形式不允许像-DEBUG | SEGFAULT那样为负数，而只能以“ +”开头。如果命令在整体上已经处于活动状态，则此ACL将导致错误。allcommands：+@all的别名。请注意，这意味着可以执行将来通过模块系统加载的所有命令。nocommands：-@all的别名。 acl 命令模块种类 acl cat（列出所有的模块类目） acl cat （列出指定模块类目下的所有命令）1234567891011121314151617181920212223242526272829303132333435363738394041424344127.0.0.1:6379&gt; acl cat 1) &quot;keyspace&quot; 2) &quot;read&quot; 3) &quot;write&quot; 4) &quot;set&quot; 5) &quot;sortedset&quot; 6) &quot;list&quot; 7) &quot;hash&quot; 8) &quot;string&quot; 9) &quot;bitmap&quot;10) &quot;hyperloglog&quot;11) &quot;geo&quot;12) &quot;stream&quot;13) &quot;pubsub&quot;14) &quot;admin&quot;15) &quot;fast&quot;16) &quot;slow&quot;17) &quot;blocking&quot;18) &quot;dangerous&quot;19) &quot;connection&quot;20) &quot;transaction&quot;21) &quot;scripting&quot;127.0.0.1:6379&gt; acl cat string 1) &quot;mset&quot; 2) &quot;substr&quot; 3) &quot;getrange&quot; 4) &quot;strlen&quot; 5) &quot;getset&quot; 6) &quot;incrby&quot; 7) &quot;incr&quot; 8) &quot;setex&quot; 9) &quot;set&quot;10) &quot;mget&quot;11) &quot;incrbyfloat&quot;12) &quot;psetex&quot;13) &quot;get&quot;14) &quot;stralgo&quot;15) &quot;decrby&quot;16) &quot;append&quot;17) &quot;decr&quot;18) &quot;msetnx&quot;19) &quot;setnx&quot;20) &quot;setrange&quot; 允许和禁止某些键：123〜&lt;模式&gt;：添加可以在命令中提及的键模式。例如〜*允许所有键。该模式是类似于KEYS之一的球形样式的模式。**可以指定多个模式**。allkeys：〜*的别名。resetkeys：刷新允许的密钥模式列表。例如，ACL 〜foo：* 〜bar：* resetkeys 〜objects：*，将导致客户端仅能够​​访问与模式object：*相匹配的键。 允许和禁止发布/订阅频道：(单独在users.acl文件中设置该项会造成配置文件语法错误，原因未知，可能是版本问题，待定)123＆&lt;pattern&gt;：添加可由用户访问的Pub/Sub通道的全局样式的模式。可以指定多个通道模式。请注意，仅对PUBLISH和SUBSCRIBE提及的通道进行模式匹配，而PSUBSCRIBE要求在其通道模式与用户允许的通道模式之间进行文字匹配。allchannels：＆*的别名，允许用户访问所有发布/订阅通道。resetchannels：刷新允许的通道模式列表，如果用户的Pub/Sub客户端不再能够访问其各自的通道和/或通道模式，则断开其连接。 为用户配置有效密码：123456&gt; &lt;密码&gt;：将此密码添加到用户的有效密码列表中。例如，&gt; mypass会将“ mypass”添加到有效密码列表中。该指令清除nopass标志（请参阅下文）。**每个用户可以具有任意数量的密码**。&lt; &lt;密码&gt;：从有效密码列表中删除此密码。万一实际上您未设置要删除的密码，则会发出错误消息。＃&lt;hash&gt;：将此SHA-256哈希值添加到用户的有效密码列表中。该哈希值将与为ACL用户输入的密码的哈希值进行比较。这允许用户将哈希存储在acl.conf文件中，而不是存储明文密码。仅接受SHA-256哈希值，因为密码哈希必须为64个字符，并且只能为容器的小写十六进制字符。！&lt;hash&gt;：从有效密码列表中删除该哈希值。当您不知道哈希值指定的密码但想从用户中删除密码时，这很有用。nopass：删除用户的所有设置密码，并将该用户标记为不需要密码：这意味着每个密码都将对该用户起作用。如果此指令用于默认用户，则每个新连接都将立即用默认用户进行身份验证，而无需任何显式的AUTH命令。请注意，resetpass指令将清除此条件。resetpass：刷新允许的密码列表。而且删除nopass状态。重置密码后，用户没有关联的密码，并且没有添加一些密码（或稍后将其设置为密码）的方法就无法进行身份验证。 ACL实时变更 重启服务器 定义外部acl文件 使用ACL LOAD命令重新加载acl配置文件 使用ACL SAVE命令将当前acl配置写入acl配置文件 ACL配置格式 redis.conf和users.acl文件中格式都一样，如下： user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99 哨兵/从库权限配置 如果您不想为Redis副本和Redis Sentinel实例提供对Redis实例的完全访问权限，则以下是必须允许使用的命令集，以确保一切正常工作。通道的设置可能有些问题，如果报错语法解析错误，先考虑去掉通道的权限内容（allchannels，&amp;*）试试； 注意⚠️：哨兵模式下，主从的用户权限设置要保持一致，否则会导致主从故障切换失败 对于Sentinel，允许用户在master和replica实例中都访问以下命令： AUTH, CLIENT, SUBSCRIBE, SCRIPT, PUBLISH, PING, INFO, MULTI, SLAVEOF, CONFIG, CLIENT, EXEC Sentinel不需要访问数据库中的任何键，但需要使用Pub/Sub，因此ACL规则如下（注意：不需要AUTH，因为始终允许使用AUTH）： ACL SETUSER sentinel-user on &gt;somepassword allchannels +multi +slaveof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill Redis replica需要在master实例上将以下命令列入白名单 PSYNC, REPLCONF, PING ACL setuser replica_user on &gt;somepassword +psync +replconf +ping]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>ACL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SPI]]></title>
    <url>%2F2020%2F12%2F15%2FSPI%2F</url>
    <content type="text"><![CDATA[SPI 是什么 应用场景 java SPI的不足 doubbo自定义SPI 如何自定义自己的SPI 是什么？ SPI(Service Provider Interface)：本质是将接口实现类的全限定名配置在文件中，并由服务加载器ServiceLoader读取配置文件，加载实现类。在Java中SPI是被用来设计给服务提供商做插件使用的。基于策略模式 来实现动态加载的机制 。我们在程序只定义一个接口，具体的实现交个不同的服务提供者；在程序启动的时候，读取配置文件，由配置确定要调用哪一个实现；通过 SPI 机制为我们的程序提供拓展功能。 怎么用 定义一个标准接口interface来提供给服务供应商 resources目录下创建META-INF/services 文件夹，创建文件（文件名为接口全路径名）内容为具体实现类的全路径名 编译打包后的路径就是在classpath路径下的META-INF/services 具体实现类可以有多个，一行写一个即可 使用服务加载器加载所有的实现类：ServiceLoader.load(service) ServiceLoader根据接口的全限定名称去指定目录下找相同名字的文件加载，具体方式就是通过classloader类的资源加载方法获取到URL类，利用URL打开文件流读取文件，然后加载具体实现类 懒加载12345678910111213141516171819202122public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125;public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service,ClassLoader loader)&#123; return new ServiceLoader&lt;&gt;(service, loader);&#125;private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125;public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader);&#125;// 服务加载器只是把需要加载的实现类和类加载器告诉了LazyIterator，等真正需要使用的时候才会去加载private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader;&#125; 注意：ServiceLoader属于Java核心类，由启动类加载器负责加载，但是具体的实现类属于应用程序类，应该由应用程序加载器加载，但是同一个线程内使用的是同一个类加载器，所以需要打破双亲委派模型，使用Thread类的setContextClassLoader方法来切换线程内的类加载器，由启动类加载器切换到应用程序加载器，加载完具体spi实现类后在切换回去。 应用场景 应用程序解藕，将扩展部分独立出去，与核心模块分离，可以随时替换扩展部分，增强灵活性 多版本控制，不同的版本不同的实现，可以任意切换不同的版本 ClassLoader(类加载器) 通过一个类的全限定名来获取描述此类的二进制字节流“这个动作在虚拟机外部实现， 同一份class文件，不同的类加载器加载后形成的类不一样 jvm判定两个class是否相同：class的全限定名是否相同；是否同一个ClassLoader加载 启动类加载器：BoostropClassLoader，c++实现，虚拟机自身一部分（负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等） 其他所有类加载器：java实现，虚拟机外部 扩展类加载器（负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar） 应用程序加载器（负责加载应用程序classpath目录下的所有jar和class文件） 自定义加载器（例如：加载网络中的class文件） String rootUrl = “http://localhost:8080/httpweb/classes“; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Object obj1 = clazz1.newInstance(); 双亲委派模型：类加载器收到类加载请求后，将请求委派给父加载器，所有的请求最终被传送到启动类加载器上，只有父加载器自己无法完成加载后，子加载器才会自己加载，这样可以有效防止类的重复加载 java SPI的不足 不能按需加载。Java SPI在加载扩展点的时候，会一次性加载所有可用的扩展点，很多是不需要的，会浪费系统资源 可以改造成key-value形式的配置来实现加载指定扩展 获取某个实现类的方式不够灵活，只能通过 Iterator 形式获取，不能根据某个参数来获取对应的实现类 由配置规则决定，同上，将规则调整为key-value形式后就可以避免每次循环查找 不支持AOP与依赖注入 优化核心就是修改文件定义格式，即需要改写文件解析的代码，也就是重写loadResource(filename)方法 doubbo自定义SPI实现流程 自定义了配置文件加载路径有3个，分别为META-INF/dubbo/internal/，META-INF/dubbo/，META-INF/services/三个文件夹 根据不同的用途区分了不同的文件目录 自定义加载类 ExtensionLoader 重写加载流程 强制使用自定义spi注解标识特有的扩展接口，会有强制验证 自定义配置文件内容格式：key=impl_full_class_name ，弥补Java原生的不足 将配置文件转化成 java.net.URL 类，然后开启文件流读取文件内容 解析文件内容加载具体实现类，放入缓存 实例化具体实现类，加入实例化缓存map，然后以set的方式向实现类对象中注入依赖（IOC） 将具体实例化对象包裹在相应的 Wrapper 包装代理对象中，用作AOP 加载结束 源码实现跟踪123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204// 加载扩展点，缓存中查找，没有就去构建扩展点，根据接口类的全限定名称去指定目录下查找文件加载@SuppressWarnings(&quot;unchecked&quot;)public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException(&quot;Extension type == null&quot;); &#125; if (!type.isInterface()) &#123; throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an interface!&quot;); &#125; // 强制限定spi接口添加注解，可以自定义一些规则来自定义限制 if (!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an extension, because it is NOT annotated with @&quot; + SPI.class.getSimpleName() + &quot;!&quot;); &#125; ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125;// 创建扩展点private T createExtension(String name, boolean wrap) &#123; Class&lt;?&gt; clazz = (Class)this.getExtensionClasses().get(name); if (clazz == null) &#123; throw this.findException(name); &#125; else &#123; try &#123; T instance = EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.getDeclaredConstructor().newInstance()); instance = EXTENSION_INSTANCES.get(clazz); &#125; // 实现 IOC 注入功能 this.injectExtension(instance); // 生成包装代理类，实现 AOP 功能 if (wrap) &#123; List&lt;Class&lt;?&gt;&gt; wrapperClassesList = new ArrayList(); if (this.cachedWrapperClasses != null) &#123; wrapperClassesList.addAll(this.cachedWrapperClasses); wrapperClassesList.sort(WrapperComparator.COMPARATOR); Collections.reverse(wrapperClassesList); &#125; if (CollectionUtils.isNotEmpty(wrapperClassesList)) &#123; Iterator var6 = wrapperClassesList.iterator(); label37: while(true) &#123; Class wrapperClass; Wrapper wrapper; do &#123; if (!var6.hasNext()) &#123; break label37; &#125; wrapperClass = (Class)var6.next(); wrapper = (Wrapper)wrapperClass.getAnnotation(Wrapper.class); &#125; while(wrapper != null &amp;&amp; (!ArrayUtils.contains(wrapper.matches(), name) || ArrayUtils.contains(wrapper.mismatches(), name))); instance = this.injectExtension(wrapperClass.getConstructor(this.type).newInstance(instance)); &#125; &#125; &#125; this.initExtension(instance); return instance; &#125; catch (Throwable var9) &#123; throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + this.type + &quot;) couldn&apos;t be instantiated: &quot; + var9.getMessage(), var9); &#125; &#125;&#125;// duboo添加了ioc的功能，遍历每个扩展类属性，查找是否有注入的注解和set方法，然后加载需要被注入的类，执行set方法注入private T injectExtension(T instance) &#123; if (objectFactory == null) &#123; return instance; &#125; try &#123; for (Method method : instance.getClass().getMethods()) &#123; if (!isSetter(method)) &#123; continue; &#125; /** * Check &#123;@link DisableInject&#125; to see if we need auto injection for this property */ if (method.getAnnotation(DisableInject.class) != null) &#123; continue; &#125; Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) &#123; continue; &#125; try &#123; String property = getSetterProperty(method); Object object = objectFactory.getExtension(pt, property); if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;Failed to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125;// 根据不同的加载策略 LoadingStrategy （针对不同的加载目录而言进行区分）进行spi扩展点加载private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; this.cacheDefaultExtensionName(); Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap(); LoadingStrategy[] var2 = strategies; int var3 = var2.length; for(int var4 = 0; var4 &lt; var3; ++var4) &#123; LoadingStrategy strategy = var2[var4]; this.loadDirectory(extensionClasses, strategy.directory(), this.type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); this.loadDirectory(extensionClasses, strategy.directory(), this.type.getName().replace(&quot;org.apache&quot;, &quot;com.alibaba&quot;), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); &#125; return extensionClasses;&#125;// 加载指定目录下的扩展点文件，归根到底是把指定文件转化成 java.net.URL 类，然后使用 URL 打开文件流读取文件内容解析，然后生成class类// URL 类的生成无论是Java原生还是dubbo都是使用的Java的ClassLoader类的资源获取方法（例如：getResources(String name)等）得到private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) &#123; String fileName = dir + type; try &#123; Enumeration&lt;java.net.URL&gt; urls = null; ClassLoader classLoader = findClassLoader(); if (extensionLoaderClassLoaderFirst) &#123; ClassLoader extensionLoaderClassLoader = ExtensionLoader.class.getClassLoader(); if (ClassLoader.getSystemClassLoader() != extensionLoaderClassLoader) &#123; urls = extensionLoaderClassLoader.getResources(fileName); &#125; &#125; if (urls == null || !urls.hasMoreElements()) &#123; if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; &#125; if (urls != null) &#123; while(urls.hasMoreElements()) &#123; java.net.URL resourceURL = (java.net.URL)urls.nextElement(); this.loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); &#125; &#125; &#125; catch (Throwable var11) &#123; logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, var11); &#125;&#125;// 文件加载解析获取具体实现类的全限定名称，文件内容格式为 key=impl_full_class_nameprivate void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) &#123; try &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8)); Throwable var7 = null; try &#123; String clazz = null; String line; while((line = reader.readLine()) != null) &#123; int ci = line.indexOf(35);// 35表示#，意思是解析排除注释 if (ci &gt;= 0) &#123; line = line.substring(0, ci); &#125; line = line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name = null; int i = line.indexOf(61);// 61表示=，意思是解析key=value，实现O(1)速度查找 if (i &gt; 0) &#123; name = line.substring(0, i).trim(); clazz = line.substring(i + 1).trim(); &#125; else &#123; clazz = line; &#125; if (StringUtils.isNotEmpty(clazz) &amp;&amp; !this.isExcluded(clazz, excludedPackages)) &#123; this.loadClass(extensionClasses, resourceURL, Class.forName(clazz, true, classLoader), name, overridden); &#125; &#125; catch (Throwable var22) &#123; IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class (interface: &quot; + this.type + &quot;, class line: &quot; + line + &quot;) in &quot; + resourceURL + &quot;, cause: &quot; + var22.getMessage(), var22); this.exceptions.put(line, e); &#125; &#125; &#125; &#125; catch (Throwable var23) &#123; var7 = var23; throw var23; &#125; finally &#123; if (reader != null) &#123; if (var7 != null) &#123; try &#123; reader.close(); &#125; catch (Throwable var21) &#123; var7.addSuppressed(var21); &#125; &#125; else &#123; reader.close(); &#125; &#125; &#125; &#125; catch (Throwable var25) &#123; logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + this.type + &quot;, class file: &quot; + resourceURL + &quot;) in &quot; + resourceURL, var25); &#125;&#125;// 最终拿到具体实现类的全限定名称后，使用Class.forName(clazz, true, classLoader)来加载具体实现类this.loadClass(extensionClasses, resourceURL, Class.forName(clazz, true, classLoader), name, overridden); 如何自定义自己的SPI 配置文件的加载流程使用的是Java原生方法功能，我们保持不变，变化的其实就是文件加载后的解析方式，以及使用方式，辅助一些自定义校验逻辑，缓存逻辑]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用多版本控制]]></title>
    <url>%2F2020%2F12%2F15%2F%E5%BA%94%E7%94%A8%E5%A4%9A%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[应用多版本控制 基于接口API实现版本隔离 URL携带版本号 基于SPI实现动态加载不同版本 自定义SPI实现 ##]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Finalize/Cleaner]]></title>
    <url>%2F2020%2F12%2F03%2FFinalize%3ACleaner%2F</url>
    <content type="text"><![CDATA[Finalize/Cleaner 存在的意义 finalize存在哪些问题 cleaner对于finalize来说有哪些优点 java中可以怎么用 使用场景有哪些 存在的意义 两者存在的意义都是释放nativa对象，也就是堆外内存释放，堆内内存的占用依靠gc来完成对象回收，内存释放，但是堆外，jvm无法操控，只能依赖程序猿自己手动释放。两者就是给程序员提供了一种可以回收堆外内存的方式。 finalize方法定义在Obejct类中，子类对象可以重写改方法，在方法体中编写自己的native对象内存释放逻辑 protected void finalize() throws Throwable { } 当GC确定不再有对该对象的引用时，由GC调用该对象的finalize方法。 finalize的一般约定是，当Java™虚拟机确定不再有任何手段可以使尚未死亡的任何线程可以访问该对象时（除非是由于操作而导致），调用finalize。由完成的其他一些对象或类的完成确定。 finalize方法可以采取任何措施，包括使该对象可再次用于其他线程。但是，完成的通常目的是在清除对象之前将其清除。例如，代表输入/输出连接的对象的finalize方法可能会执行显式I / O事务，以在永久丢弃该对象之前中断连接。 Java编程语言不能保证哪个线程将为任何给定对象调用finalize方法。但是，可以保证，在调用finalize时，调用finalize的线程将不持有任何用户可见的同步锁。如果finalize方法抛出未捕获的异常，则该异常将被忽略，并且该对象的终结将终止。 在为对象调用finalize方法之后，直到Java虚拟机再次确定不再有任何方法可以由尚未死亡的任何线程访问该对象之后，才采取进一步的措施，包括可能的措施可以通过其他准备完成的对象或类来完成，此时可以丢弃该对象。 对于任何给定的对象，Java虚拟机都不会多次调用finalize方法。 由finalize方法引发的任何异常都将导致此对象的终止终止，但否则将被忽略。 手动执行finalize方法：System.gc()与System.runFinalization()方法增加了finalize()方法执行的机会，但不可盲目依赖它们 finalize存在的问题： 如果两个对象同时变成unreachable，他们的finalize方法执行顺序是任意的。因此在一个对象的finalize方法中使用另一个对象持有的native指针，将有可能访问一个已经释放的C++对象，从而导致native heap corruption。 根据Java语法规则，一个对象的finalize方法是可以在它的其他方法还在执行时被调用的。因此其他方法如果正在访问它所持有的native指针，将有可能发生use-after-free的问题。 如果Java对象很小，而持有的native对象很大，则需要显示调用System.gc()以提早触发GC。否则单纯依靠Java堆的增长来达到触发水位，可能要猴年马月了，而此时垃圾的native对象将堆积成山。 finalize()方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize()的执行 对象再生问题：finalize()方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的。当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后（释放非堆内存资源），GC会再次判断该对象是否可达（二次标记），若不可达，则进行回收，否则，对象“复活”。 鉴于finalize方法有诸多缺陷，最终在JDK 9中被弃用。替代它的是Cleaner类。 cleaner对于finalize来说有哪些优点 cleaner继承自虚引用，不会阻止被引用对象的gc回收 123456public class Cleaner extends PhantomReference&lt;Object&gt; &#123; private static final ReferenceQueue&lt;Object&gt; dummyQueue = new ReferenceQueue(); private static Cleaner first = null; private Cleaner next = null; private Cleaner prev = null; private final Runnable thunk; java中可以怎么用 使用场景有哪些]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reference]]></title>
    <url>%2F2020%2F12%2F03%2FReference%2F</url>
    <content type="text"><![CDATA[Reference 存在的意义 jvm中具体怎么用 java中可以怎么用 ReferenceQueue存在的意义 实战场景应用 属性pending和ReferenceHandler存在的意义 存在的意义gc的可达行分析步骤 由静态属性/常量，或者栈帧/本地变量表等找出扫描所需的跟节点对象 然后由各个根节点对象开始遍历扫描找出不可达对象 reference中state状态就是对象是否可达的标志，inactive表示对象不可达 reference中的属性discovered指向下一个关联引用对象，属性pending表示当前本对象所关联的对象引用有哪些；discovered和pending共同决定了当前对象的状态 使用reference来描述各个对象当前是否处于可达状态以及与其他对象的引用关系链是如何的，通过stata描述当前引用状态，通过discovered描述下一个关联引用对象 和pending 辅助判定gc的可达性模型分析，根据reference的不同类型（强，软，弱，虚4种不同类型）以及当前类型实例所处的state状态（active，pending，enqueued，inactive）来判定对象是否可达，从而进行gc回收工作 reference的不同类型的实例状态之间的流转和Java版本有关什么是引用？什么是引用对象？什么是非引用对象？ 就是一个reference对象，内部含有被引用的对象实例，即reference对象指向被引用对象，而这个指向的类型取决于reference的类型，如果是weakReferenece，那么该指向就是弱引用指向（被指向对象还可能被其他很多对象指向，包括引用对象和正常对象），不会影响被指向对象的gc回收判断 123456789101112131415public abstract class Reference&lt;T&gt; &#123; //引用的对象 private T referent; //回收队列，由使用者在Reference的构造函数中指定 volatile ReferenceQueue&lt;? super T&gt; queue; //当该引用被加入到queue中的时候，该字段被设置为queue中的下一个元素，以形成链表结构 volatile Reference next; //在GC时，JVM底层会维护一个叫DiscoveredList的链表，存放的是Reference对象，discovered字段指向的就是链表中的下一个元素，由JVM设置 transient private Reference&lt;T&gt; discovered; //进行线程同步的锁对象 static private class Lock &#123; &#125; private static Lock lock = new Lock(); //等待加入queue的Reference对象，在GC时由JVM设置，会有一个java层的线程(ReferenceHandler)源源不断的从pending中提取元素加入到queue private static Reference&lt;Object&gt; pending = null;&#125; 一个Reference实例有4种内部状态，该状态被编码为属性queue（ReferenceQueue&lt;? super T&gt;）和next（Reference），也就是由这2个属性的值共同决定所处的状态；如果next字段属性为null，则说明处于active状态，如果非null，则gc正常处理该Reference实例。 Active：新创建的实例处于活动状态，该状态的Reference实例会被gc特殊处理，处理可能变成Pending或者Inactive Pending：pending-Reference list中的元素,等待被 Reference-handler 线程处理入队列 ReferenceQueue Enqueued：已经入队列 ReferenceQueue 的元素，出队列后变成 Inactive 状态 Inactive：一旦变成该状态就不可再变更 jvm中具体怎么用 discovered-list：基于状态表示不同链表中的下一个待处理的对象，主要是pending-reference列表的下一个元素 pending-list：ReferenceHandler线程的主要功能是处理pending链表中的引用对象，存放的就是待扫描判定是否可达的所有对象，判定不可达后会被放入reference-queue队列中 reference-queue：pending-list中处理完的对象被放入reference-queue队列中供GC扫描， 参数-XX:SoftRefLRUPolicyMSPerMB=time：设置在最后一次引用之后，软可达对象在堆上保持活动状态的时间（以毫秒为单位）。 缺省值是堆中每个空闲兆字节的生命周期的一秒钟。 -XX：SoftRefLRUPolicyMSPerMB选项接受整数值，该整数值表示当前堆大小（对于Java HotSpot Client VM）或最大可能堆大小（对于Java HotSpot Server VM）每1兆字节毫秒。 这种差异意味着客户端VM倾向于刷新软引用而不是增大堆，而服务器VM倾向于增大堆而不是刷新软引用。 在后一种情况下，-Xmx选项的值对软引用被垃圾收集的速度有很大影响 Java中使用样例 ThreadLocal 使用了弱引用 内部ThreadLocalMap的Entry extends WeakReference]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Reference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双亲委派模型]]></title>
    <url>%2F2020%2F12%2F03%2F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[双亲委派模型 什么是双亲委派模型 存在的意义 演进规则有哪些 如何自定义类加载器 如果打破双亲委派模型 为什么会需要打破该模型 打破方式有哪些 实际场景应用 什么是双亲委派模型 java语言中一种class类加载顺序模型，该模型强调如何保证类的唯一性加载 存在的意义 防止类的重复加载 各个加载器之间的基础类加载的统一性问题（不会造成基础公共类由于用户重写了一个一摸一样的而到处泛滥，不知道具体该用哪一个），越是基础的类越是由上层加载器加载；基础类几乎总是被用户代码所调用 注意⚠️：基础类大部分情况下是被用户代码所调用，但是不可避免特殊情况下基础类需要回调用户代码，比如JNDI服务是java的标准服务，由启动类加载器加载，但是JNDI的目的是对资源进行集中管理和查找，他的调用由独立厂商实现并提供部署在应用程序的classpath目录下的spi代码，启动类加载器不认识该代码，也就是该代码应该由应用类加载器去加载，也就是当加载JNDI服务加载到一半时需要切换类加载器（由启动类加载器切换到应用类加载器）去加载spi代码，然后再切换回来继续加载JNDI服务。基于上述需求，出现了线程上下文类加载器（thread context classloader）。java中所有涉及到spi的加载动作都是基于这种方式完成的。 什么是SPI 不同于我们常说的API，API是功能性调用接口，而SPI是应用程序预留扩展接口，只提供标准，不提供具体实现，具体实现留给不同厂商自己去实现。 类加载机制类加载过程 加载-（验证-准备-解析（只有该阶段执行顺序不一定，可变））统称为连接-初始化-使用-卸载 加载： 通过一个类 的全限定名来获取的此类的二进制字节流 将这字节流所代表的静态存储结构转化为方法区运行时数据结构 在内存中生成一个代表这个类的class对象，作为方法区这个类的各种数据的访问入口 验证：连接第一步，保证class文件中字节流包好信息符合虚拟机要求，其中包括文件格式，元数据验证，字节码验证，符号引用验证 准备：类变量分配内存（包好static，不包含实例变量），初始化变量值 解析：虚拟机将 常量池内符号引用替换为直接引用 符号引用：与虚拟机布局无关，引用目标不一定加载到内存中，class文件中明确规定 直接引用：与虚拟机布局有关，引用目标必然存在于内存中 初始化：执行类构造器方法的过程 方法详解 编译器自动收集类中所有的类变量的赋值动作和静态语句块中语句合并而成（静态语句块中只能访问到定义在静态语句块之前的变量，定义在之后的只能赋值，不能访问） 不同于构造函数（init()函数），它不会显示的调用父类构造器，虚拟机保证在子类的clinit之前父类clinit已经执行完毕，所以虚拟机中第一个执行的肯定是object的clinit 如果一个类或者接口中没有静态语句块，并且没有对变量的赋值操作，编译器可以不生成clinit方法 类加载器 通过一个类的全限定名来获取描述此类的二进制字节流“这个动作在虚拟机外部实现， 同一份class文件，不同的类加载器加载后形成的类不一样 jvm判定两个class是否相同：class的全限定名是否相同；是否同一个classloader加载 启动类加载器：BoostropClassLoader，c++实现，虚拟机自身一部分（负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等） 其他所有类加载器：java实现，虚拟机外部 扩展类加载器（负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目录下的所有jar） 应用程序加载器（负责加载应用程序classpath目录下的所有jar和class文件） 自定义加载器（例如：加载网络中的class文件） String rootUrl = “http://localhost:8080/httpweb/classes“; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Object obj1 = clazz1.newInstance(); 线程上下文类加载器（thread context classloader） 通过类Thread的setContextClassLoader()方法进行设置，如果创建线程时还没设置，会从父线程继承一个，如果全局都没有设置过的话，默认使用应用类加载器 双亲委派模型：类加载器收到类加载请求后，将请求委派给父加载器，所有的请求最终被传送到启动类加载器上，只有父加载器自己无法完成加载后，子加载器才会自己加载，这样可以有效防止类的重复加载 如何自定义类加载器 继承classloader类，重写loadclass方法，或者重写findclass方法（父类无法加载的时候会调用自己的findclass方法） 如何打破双亲委派模型为什么会需要打破该模型 参考JNDI的实现，由于不同场景的需要，类加载顺序不能按照双亲委派模型规定的来执行，但是这并不意味着该模型不对，不合理，而是单纯的特殊场景诉求导致了新的需求产生，双亲委派模型当初拟订的时候并没有考虑所有情况，所以打破还是遵守都是根据具体实际场景需求来决定。 打破方式有哪些 由于双亲委派模型制定的加载规则都写在classloadder的loadclass方法里，所以通常都是按照规则来加载，但是我们可以继承classloader来重写loadclass方法实现自定义加载器 自定义类加载器，重写loadclass方法/或者findclass方法 Thread类的setContextClassLoader方法 实际场景应用 自定义类加载器 java自带服务JNDI的实现（借助Thread类的setContextClassLoader方法实现） 热插拔，热部署，模块化。意思是添加一个功能或减去一个功能不用重启，只需要把这模块连同类加载器一起换掉就实现了代码的热替换。 典型代表：OSGI基于自定义类加载器机制实现的模块热部署/切换 一个模块一个自定义类加载器，把这模块连同类加载器一起换掉实现热替换 有自己制定的一套完整的类加载顺序机制（基于并兼容双亲委派模型） Tomcat 的类加载器是怎么设计的？ 内容基于tomcat8阐述，实时详情请登录官网找对应版本文档进行查看；该机制用于提供Servlet规范2.4版中定义的功能-特别是9.4和9.6节。详情参考官方文档：https://tomcat.apache.org/tomcat-8.0-doc/class-loader-howto.html 首先Tomcat是个web容器， 那么它需要解决什么问题： 一个web容器可能需要部署两个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，不能要求同一个类库在同一个服务器只有一份，因此要保证每个应用程序的类库都是独立的，保证相互隔离。 部署在同一个web容器中相同的类库相同的版本可以共享。否则，如果服务器有10个应用程序，那么要有10份相同的类库加载进虚拟机。 web容器也有自己依赖的类库，不能和应用程序的类库混淆。基于安全考虑，应该让容器的类库和程序的类库隔离开来。 web容器要支持jsp的修改，我们知道，jsp 文件最终也是要编译成class文件才能在虚拟机中运行，但程序运行后修改jsp已经是司空见惯的事情，所以，web容器需要支持 jsp 修改后不用重启。 tomcat8类加载器机制 类加载树形图如 123456789101112131415161718 Bootstrap | System | Common / \ Webapp1 Webapp2 ... // 增强配置加载机制 Bootstrap | System | Common / \Server Shared / \ Webapp1 Webapp2 ... 类加载顺序（默认） Bootstrap classes of your JVM /WEB-INF/classes of your web application /WEB-INF/lib/*.jar of your web application System class loader classes (described above) Common class loader classes (described above) 类加载顺序（特殊配置） Bootstrap classes of your JVM System class loader classes (described above) Common class loader classes (described above) /WEB-INF/classes of your web application /WEB-INF/lib/*.jar of your web application 扩展 同一个目录下的不同jar包的加载顺序 tomcat8以后WEB-ING/lib目录下的jar由原来的字母顺序加载改为了随机加载 源码调用方法明确指出，使用file.list()方法，不能保证结果数组中的名称字符串将以任何特定顺序出现；不能保证它们以字母顺序出现。 如何自定义调整某些jar包的加载顺序 tomcat的conf中修改context.xml文件即可实现，具体修改内容自行搜索 同一个jar包里面的不同类的加载顺序 可以按字母顺序加载，也可以随机，没有什么特殊需求]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO]]></title>
    <url>%2F2020%2F10%2F21%2FNIO%2F</url>
    <content type="text"><![CDATA[NIO JAVA怎么实现 基于操作做系统的那些函数 C语言怎么实现 操作系统怎么实现 以样例代码为主，辅以文字解释 ByteBufferAsCharBufferRB DirectCharBufferRS JavaBuffers buffer是什么 其实就是一个数组和指向数组中不同位置的多个指针 0 &lt;= mark（特殊标记位） &lt;= position（当前位置） &lt;= limit（上限） &lt;= capacity（容量） java 中支持流式编程：buffer.mark().position(5).reset(); 怎么创建一个buffer java中对应的buffer类都是抽象类，不能使用new关键字创建 方式一： CharBuffer charBuffer = CharBuffer.allocate (100); 方式二： char [] myArray = new char [100]; CharBuffer charbuffer = CharBuffer.wrap (myArray); buffer order 数据存储顺序：ByteOrder；BIG_ENDIAN（大端存储），LITTLE_ENDIAN（小端存储） int value = buffer.order (ByteOrder.BIG_ENDIAN).getInt();结果：0x3BC5315E int value = buffer.order (ByteOrder.LITTLE_ENDIAN).getInt();结果：0x5E31C53B buffer type buffer的类型有多种，但是channel接受的只有byte类型的buffer，所以其他类型都必须转换成byte类型 direct buffer 都知道，io操作操作的是字节byte（所以channel直接接受byte buffer），意味着作为I / O操作目标的存储区必须是连续的字节序列；但是在JVM中，字节数组可能不会连续存储在内存中，否则垃圾回收器可以随时移动它。数组是Java中的对象，数据在该对象中的存储方式可能因一个JVM实现而异。因此，引入了direct buffer。 尽最大努力将字节元素存储在通道可用于直接或原始访问的内存区域中，方法是使用本机代码告诉操作系统直接使用或填充内存区域。 直接缓冲区使用的内存是通过绕过标准JVM堆调用本地特定于操作系统的代码来分配的。根据主机操作系统和JVM的实现，设置和拆除直接缓冲区可能比堆驻留缓冲区昂贵得多。直接缓冲区的内存存储区不受垃圾回收的影响，因为它们在标准JVM堆之外。 建议使用旧的软件准则：首先使其运行，然后使其快速运行。不必太担心预先优化；首先专注于正确性。 JVM实现可能能够执行缓冲区缓存或其他优化，从而为您提供所需的性能，而无需您付出很多不必要的努力。 non direct buffer其实最终还是会转换成direct buffer（创建临时direct buffer），这可能会导致每个I / O上的缓冲区复制和对象流失，这正是我们想要避免的事情。但是，根据实现的不同，情况可能不会很糟。运行时可能会缓存和重用直接缓冲区，或者执行其他巧妙的技巧来提高吞吐量。如果您只是创建用于一次性使用的缓冲区，则差异并不明显。另一方面，如果您要使用在高性能场景中反复使用缓冲区，您最好分配直接缓冲区并重新使用它们。 创建direct buffer ByteBuffer.allocateDirect() wrap()方法创建出来的始终是non direct buffer MappedByteBuffer Channel channel是什么 将buffer通过channle写到file文件或者socket网络中 channle怎么用 123456789101112131415// 打开channelSocketChannel sc = SocketChannel.open();sc.connect (new InetSocketAddress (&quot;somehost&quot;, someport));ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind (new InetSocketAddress (somelocalport));DatagramChannel dc = DatagramChannel.open();RandomAccessFile raf = new RandomAccessFile (&quot;somefile&quot;, &quot;r&quot;); FileChannel fc = raf.getChannel();// 使用channelFileInputStream input = new FileInputStream (fileName); FileChannel channel = input.getChannel();channel.write (buffer);// 关闭channelchannel.close() Scatter/Gather 通道提供了一种重要的新功能，称为分散/聚集（在某些情况下称为矢量I / O）。 散布/聚集是一个简单而强大的概念。 它指的是跨多个缓冲区执行单个I / O操作。 对于写操作，依次从几个缓冲区中收集（排空）数据并沿着通道发送数据。 缓冲区不需要具有相同的容量（通常不需要）。 效果与所有缓冲区的内容在发送之前被串联到一个大缓冲区中一样。 对于读取，将从通道读取的数据依次散布到多个缓冲区，每个缓冲区都填充到其极限，直到从通道或整个缓冲区空间中取出的数据用完为止。 1234567891011121314151617181920ByteBuffer header = ByteBuffer.allocateDirect (10); ByteBuffer body = ByteBuffer.allocateDirect (80); ByteBuffer [] buffers = &#123; header, body &#125;;// 从多个buffer读取数据int bytesRead = channel.read (buffers);body.clear();body.put(&quot;FOO&quot;.getBytes()).flip(); // &quot;FOO&quot; as bytesheader.clear();header.putShort (TYPE_FILE).putLong (body.limit()).flip();// 将多个buffer的数据写入long bytesWritten = channel.write (buffers);FileOutputStream fos = new FileOutputStream (DEMOGRAPHIC); **GatheringByteChannel** gatherChannel = fos.getChannel();ByteBuffer [] bs = utterBS (reps);while (gatherChannel.write (bs) &gt; 0) &#123; // Loop until write() returns zero&#125;fos.close(); file lock 12345678910fileChannel.lock (0L, Long.MAX_VALUE, false);// 有共享锁，有独占锁，详情自行查看apiFileLock lock = fileChannel.lock()try &#123;&lt;perform read/write/whatever on channel&gt;&#125; catch (IOException) [ &lt;handle unexpected exception&gt;&#125; finally &#123; lock.release()&#125; mmap 通过内存映射机制访问文件比通过常规方式读取或写入数据要高效得多，即使使用通道也是如此。无需进行显式的系统调用，这可能很耗时。更重要的是，操作系统的虚拟内存系统会自动缓存内存页面。这些页面将使用系统内存进行缓存，并且不会占用JVM内存堆中的空间。 12// 映射整个文件MappedByteBuffers buffer = fileChannel.map (FileChannel.MapMode.READ_ONLY, 0, fileChannel.size()); Socket Channels 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 传统阻塞socket使用样例// 服务端ServerSocket ss=new ServerSocket(3333); Socket s=ss.accept(); DataInputStream din=new DataInputStream(s.getInputStream()); DataOutputStream dout=new DataOutputStream(s.getOutputStream()); BufferedReader br=new BufferedReader(new InputStreamReader(System.in)); String str=&quot;&quot;,str2=&quot;&quot;; while(!str.equals(&quot;stop&quot;))&#123; str=din.readUTF(); System.out.println(&quot;client says: &quot;+str); str2=br.readLine(); dout.writeUTF(str2); dout.flush(); &#125; din.close(); s.close(); ss.close(); // 客户端Socket s=new Socket(&quot;localhost&quot;,3333); DataInputStream din=new DataInputStream(s.getInputStream()); DataOutputStream dout=new DataOutputStream(s.getOutputStream()); BufferedReader br=new BufferedReader(new InputStreamReader(System.in)); String str=&quot;&quot;,str2=&quot;&quot;; while(!str.equals(&quot;stop&quot;))&#123; str=br.readLine(); dout.writeUTF(str); dout.flush(); str2=din.readUTF(); System.out.println(&quot;Server says: &quot;+str2); &#125; dout.close(); s.close(); // nio模式，客户端SocketChannel sc = SocketChannel.open();sc.configureBlocking (false); // nonblocking ...if ( ! sc.isBlocking()) &#123; doSomething (cs);&#125;Socket socket = null;Object lockObj = serverChannel.blockingLock();// have a handle to the lock object, but haven&apos;t locked it yet// may block here until lock is acquiredsynchronize (lockObj)&#123; // This thread now owns the lock; mode can&apos;t be changed boolean prevState = serverChannel.isBlocking(); serverChannel.configureBlocking (false); socket = serverChannel.accept(); serverChannel.configureBlocking (prevState);&#125;// lock is now released, mode is allowed to changeif (socket != null) &#123; doSomethingWithTheSocket (socket);&#125;// 服务端ServerSocketChannel ssc = ServerSocketChannel.open(); ServerSocket serverSocket = ssc.socket().bind (new InetSocketAddress (1234));...// 建立连接SocketChannel sc = ssc.accept();buffer.rewind(); // 向客户端发送数据sc.write (buffer); sc.close(); DatagramChannel udp连接 Selectors selector有啥用 将多个channel注册到selector中，由selector负责监控那些channel数据准备好了返回; 一个channel可以注册到多个selector中，但是一个selector中只能注册一次 SelectionKey用来关联channel和selector，channel注册到selector中后返回一个key，key中包含了读写等权限信息 怎么将channel注册到Selector中 12345678Selector selector = Selector.open();channel1.register (selector, SelectionKey.OP_READ); channel2.register (selector, SelectionKey.OP_WRITE); channel3.register (selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);// 阻塞等待指定时间查询是否含有就绪的channel，只要有一个或者多个就绪channel后就返回，或者时间到了自动返回readyCount = selector.select (10000);// 非阻塞查询是否有就绪的channel，没有直接返回selector.selectNow() 如何停止selector的当前阻塞式查询就绪channel 123456// 如果查询操作正在进行，直接返回。如果还没开始查询，第一次查询直接返回；后续的查询不受影响，同一次查询操作时间调用该方法多次跟一次一样selector.wakeup();// 所有的查询操作直接返回，然后所有注册的channel取消注册，key释放selector.close();// selector.interrupt(); 使用select()来管理多个channel示例 以前的模式相当于是一个socket和一个serverSocket，然后阻塞等待接收对方的消息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class SelectSockets &#123; public static int PORT_NUMBER = 1234; public static void main (String [] argv) throws Exception &#123; new SelectSockets().go (argv); &#125; public void go (String [] argv) throws Exception &#123; int port = PORT_NUMBER; if (argv.length &gt; 0) &#123; // Override default listen port port = Integer.parseInt (argv [0]); &#125; System.out.println (&quot;Listening on port &quot; + port); // 开启一个服务端socket channel ServerSocketChannel serverChannel = ServerSocketChannel.open(); ServerSocket serverSocket = serverChannel.socket(); // 打开一个selector Selector selector = Selector.open(); // 服务端socket需要绑定监听端口 serverSocket.bind (new InetSocketAddress(port)); // 配置非阻塞模式 serverChannel.configureBlocking (false); // 将channel注册到selector上，由selector来负责监听channel是否准备完善 serverChannel.register (selector, SelectionKey.OP_ACCEPT); while (true) &#123; // 非阻塞访问是否有准备好的channel，有处理，无继续轮训访问 int n = selector.select(); if (n == 0) &#123; continue; // nothing to do &#125; // channel的类型的操作权限有key来决定 Iterator it = selector.selectedKeys().iterator(); while (it.hasNext()) &#123; SelectionKey key = (SelectionKey) it.next(); if (key.isAcceptable()) &#123; // 如果channel是一个连接建立请求事件，接受新的连接，生成对应新的channel，注册到selector中一起监听 ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel channel = server.accept(); registerChannel(selector, channel, SelectionKey.OP_READ); sayHello(channel); &#125; if (key.isReadable()) &#123; // 如果channel是一个已有的发送请求数据的事件，读取该channel的流入数据内容（通过buffer读取） readDataFromSocket (key); &#125; it.remove(); &#125; &#125; &#125; protected void registerChannel (Selector selector, SelectableChannel channel, int ops)throws Exception&#123; if (channel == null) &#123;// could happen return; &#125; channel.configureBlocking (false); channel.register (selector, ops); &#125; private ByteBuffer buffer = ByteBuffer.allocateDirect (1024); protected void readDataFromSocket (SelectionKey key) throws Exception&#123; SocketChannel socketChannel = (SocketChannel) key.channel(); int count; buffer.clear(); while ((count = socketChannel.read (buffer)) &gt; 0) &#123; buffer.flip(); // Make buffer readable while (buffer.hasRemaining()) &#123; socketChannel.write (buffer); &#125; buffer.clear(); &#125; if (count &lt; 0) &#123; socketChannel.close(); &#125; &#125; private void sayHello (SocketChannel channel)throws Exception&#123; buffer.clear(); buffer.put (&quot;Hi there!\r\n&quot;.getBytes()); buffer.flip(); channel.write (buffer); &#125;&#125; 并发 selector对象是线程安全，但是key集合（sets）不是；所以多线程共享操作selector中的key时可能会出现问题，因此通常的模型为：单线程操作selector来监控多个channel，最终将准备好的channel交给指定工作线程池处理； 变种一：将n个channel交给多个selector负责，不同的selector将接收到的channel转发到不同的线程池处理 变种二：一个selector处理所有channel，将channel分类，例如所有的连接交给一个worker线程池，所有的command交给一个worker线程池… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class SelectSocketsThreadPool extends SelectSockets &#123; private static final int MAX_THREADS = 5; private ThreadPool pool = new ThreadPool(MAX_THREADS); public static void main (String [] argv) throws Exception &#123; new SelectSocketsThreadPool().go (argv); &#125; protected void readDataFromSocket (SelectionKey key) throws Exception &#123; WorkerThread worker = pool.getWorker(); if (worker == null) &#123; return; &#125; worker.serviceChannel (key); &#125;&#125;public class WorkerThread extends Thread &#123; private ByteBuffer buffer = ByteBuffer.allocate (1024); private ThreadPool pool; private SelectionKey key; WorkerThread (ThreadPool pool) &#123; this.pool = pool; &#125; // Loop forever waiting for work to do public synchronized void run() &#123; System.out.println (this.getName() + &quot; is ready&quot;); while (true) &#123; try &#123; // Sleep and release object lock this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (key == null) &#123; continue; // just in case &#125; System.out.println (this.getName() + &quot; has been awakened&quot;); try &#123; drainChannel (key); &#125; catch (Exception e) &#123; System.out.println (&quot;Caught &apos;&quot; + e + &quot;&apos; closing channel&quot;); // Close channel and nudge selector try &#123; key.channel().close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; key.selector().wakeup(); &#125; key = null; this.pool.returnWorker (this); &#125; &#125; synchronized void serviceChannel (SelectionKey key) &#123; this.key = key; key.interestOps (key.interestOps() &amp; (~SelectionKey.OP_READ)); this.notify(); &#125; void drainChannel (SelectionKey key)throws Exception &#123; SocketChannel channel = (SocketChannel) key.channel(); int count; buffer.clear(); // Empty buffer while ((count = channel.read (buffer)) &gt; 0) &#123; buffer.flip(); // make buffer readable while (buffer.hasRemaining()) &#123; channel.write (buffer); &#125; buffer.clear(); &#125; if (count &lt; 0) &#123; channel.close(); return; &#125; key.interestOps (key.interestOps() | SelectionKey.OP_READ); key.selector().wakeup(); &#125;&#125;public class ThreadPool &#123; List&lt;WorkerThread&gt; idle = new LinkedList&lt;&gt;(); ThreadPool (int poolSize) &#123; WorkerThread thread = new WorkerThread (this); idle.add (thread); &#125; WorkerThread getWorker() &#123; WorkerThread worker = null; synchronized (idle) &#123; if (idle.size() &gt; 0) &#123; worker = idle.remove (0); &#125; &#125; return (worker); &#125; void returnWorker (WorkerThread worker) &#123; synchronized (idle) &#123; idle.add (worker); &#125; &#125;&#125;]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪共享]]></title>
    <url>%2F2020%2F08%2F30%2F%E4%BC%AA%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[伪共享 是什么 为什么 实际场景有什么 jvm card table数据结构导致的伪共享 java对象大小可能导致的伪共享 如何避免 建议读者自行了解java的技术体系结构以及java虚拟机的历史发展，这里不做叙述！ 什么是伪共享 缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 缓存系统中是以缓存行（cache line）为单位存储的。缓存行通常是 64 字节，并且它有效地引用主内存中的一块地址。一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。所以，如果你访问一个 long 数组，当数组中的一个值被加载到缓存中，它会额外加载另外 7 个，以致你能非常快地遍历这个数组。事实上，你可以非常快速的遍历在连续的内存块中分配的任意数据结构。而如果你在数据结构中的项在内存中不是彼此相邻的（如链表），你将得不到免费缓存加载所带来的优势，并且在这些数据结构中的每一个项都可能会出现缓存未命中。 为什么会发生伪共享 举个最简单的例子：同一个缓存行中，第一个位置存着一个元素A，最后一个位置存着一个元素B；有一天线程1过来看望元素A，线程2过来看望元素B，双方互不影响；但是稍后线程1对元素A不满要改她的值，于是把元素A改成了a；这个时候就导致了整个缓存行的失效，于此同时，线程2又一次兴冲冲来看望元素B，但是发现看不了了，由于邻家A的装修改动导致了邻居B的亲戚短时间内无法访问，只能等待，等待缓存行的更新。这种情况下就直接导致了多线程的无效竞争。 实际场景有哪些jvm card table数据结构导致的伪共享 现代JVM，堆空间通常被划分为新生代和老年代。由于新生代的垃圾收集通常很频繁，如果老年代对象引用了新生代的对象，那么，需要跟踪从老年代到新生代的所有引用，从而避免每次YGC时扫描整个老年代，减少开销。对于HotSpot JVM，使用了卡标记（Card Marking）技术来解决老年代到新生代的引用问题。具体是，使用卡表（Card Table）和写屏障（Write Barrier）来进行标记并加快对GC Roots的扫描。 在高并发情况下，频繁的写屏障很容易发生虚共享（false sharing），从而带来性能开销。 假设CPU缓存行大小为64字节，由于一个卡表项占1个字节，这意味着，64个卡表项将共享同一个缓存行。 HotSpot每个卡页为512字节，那么一个缓存行将对应64个卡页一共64*512=32KB。 如果不同线程对对象引用的更新操作，恰好位于同一个32KB区域内，这将导致同时更新卡表的同一个缓存行，从而造成缓存行的写回、无效化或者同步操作，间接影响程序性能。 解决方案：jvm7提供了一个新的参数控制-XX:+UseCondCardMark，就是不采用无条件的写屏障，而是先检查卡表标记，只有当该卡表项未被标记过才将其标记为dirty。(实际源码改动就是多了一个判断)12if (CARD_TABLE [this address &gt;&gt; 9] != 0) CARD_TABLE [this address &gt;&gt; 9] = 0; java对象大小可能导致的伪共享 java对象计算：可以根据jvm的java对象内存模型计算java对象大小（对象头，data数据，对齐填充（jvm会自行调整参数位置后进行对齐填充，达到最终结果大小最小化的状态）） 一定要含有volatile关键字，才会触发写屏障，导致缓存行刷新，否则不会触发缓存行更新，也就不存在所谓的伪共享 一个java对象大小如果小于缓存行的大小，就可能会存在N个不相干的对象在统一缓存行上的情况，这时如何存在高并发多线程访问这个N个java对象，便会出现伪共享 java8提供了@Contended注解来填充对象大小，从而避免伪共享的发生；该注解可以作用在类上填充类的大小，也可以作用在字段上填充字段的大小 填充分组：对字段进行分组，同一组的字段会和其他字段有访问冲突，但是和同一组的没有。例如，（同一个线程的）代码同时更新2个字段是很常见的情况 如何避免 最有效的方法就是将不相干的数据尽量放在不同的缓存行中，尤其是存在竞态的数据，这样可以让多线程去访问不同的缓存行 - 例如：空间换时间，缓存行填充，数组存放时间隔一定距离而不是紧凑存放 与此同时引申的问题就是，所有相关的数据尽量放在一起，使用数组结构，以便加快访问速度，提升性能 但是实际情况往往是我们并不知道数据在内存中怎么分配的，是否分配到了一起，存在于同一个缓存行，除非我们自己定义一个数组，然后往里面塞值类似这种的我们可以知道有些数据是在一起存放的，可能会存在伪共享行为]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Cache</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再遇分库分表]]></title>
    <url>%2F2020%2F08%2F29%2F%E5%86%8D%E9%81%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[再遇分库分表 想当年，我以为分库分表是这样式的 现如今，疯狂打脸，刷新认知 shardingsphere探索 支持做那些事 基于配置文件的改造 源码改造扩展 分库分表和shardingsphere的基础知识自行查阅相关资料，这里不做论述！ 想当年，我以为分库分表是这样式的 可以参考之前的写的初识分库分表 思维这个东西有时候真的会受限于当下环境或者之前的刻板印象，之前我接触到过分库分表，同时还用过，想过，粗浅的研究过，导致我一直以来都认为只要提及分库分表方案，那就是直接取模，取余，提前预估数据容量，然后备好数据迁移和数据扩容方案，怎么迁移，怎么扩容都一套一套的想好了。实在不行一致性哈希算法最大程度减少扩容迁移成本；就从来都没有从实际业务场景和需求考虑过，更没有想过怎么做到零迁移，无限扩容等等。 现如今，疯狂打脸，刷新认知 年初开始又一次接触到了分库分表的诉求，同样需要给出一个合适的方案；场景大概是这样： 众多数据表中拆分其中几张数据量增长量较大，未来可能单表单库无法满足存储需求的表 被拆分表不涉及连表需求 被拆分表A有分页查询等类似的需求，有较多的非等值范围查询sql，对数据结果（拆分后会存在聚合）响应时间有较高的要求 被拆分表B数据有明显的额冷热属性，按时间维度区分冷热，冷数据自动归档；同时增长速度呈指数型增长 分区键可能不唯一，可能不同的模块会采用不同的分区键，要求分区键相对自由可控，同时可能多级分区键 部分sql可能不含分区键，但依然有分区诉求，所以需要外部分区键，不在sql中，手动指定分区键 同时sql因该具有模块化属性，同一模块的sql因该路由到同一分区集群分区库中，避免跨库查询带来的切换消耗 支持随时动态扩容，零数据迁移 shardingsphere探索 基于4.1.1版本探讨 supported 按照指定规则分库，分表；优点是支持自定义路由规则 unsupported 不支持update case when语句（语法文件支持，但是语法树映射到java对象没考虑这种结构，可以自行手动补充，难度系数适中） 分库分表配置节点规则不支持复杂结构/语法（可以放弃yaml改用java配置注入相对又自由一点，但还是受限）]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Heap</tag>
        <tag>Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shardingsphere Parser Sql]]></title>
    <url>%2F2020%2F08%2F28%2FShardingSphere%20Parser%20Sql%2F</url>
    <content type="text"><![CDATA[Shardingsphere Parser Sql Preface Shardingsphere antlr4工具 .g4语法文件 抽象语法树 java映射 实战源码 Preface ShardingSphere基础知识请阅读官方文档：https://shardingsphere.apache.org 本文主要讨论Shardingsphere（基于4.1.1版本）知识点 解析sql生成语法树 映射到java类文件 寻找分片键，定位sql路由 最后修改源码提供Shardingsphere目前并不支持的update case when语句 Shardingsphereantlr4 ANTLR（另一种语言识别工具）是功能强大的解析器生成器，用于读取，处理，执行或翻译结构化文本或二进制文件。 它被广泛用于构建语言，工具和框架。 ANTLR从语法中生成一个解析器，该解析器可以构建解析树，还生成一个侦听器界面（或访问者），该侦听器界面使响应感兴趣的短语的识别变得容易。https://github.com/antlr/antlr4 antlr4使用流程如下 定义.g4语法文件，编写解析语法规则 使用antlr4提供了脚本将自己编写的语法文件生成具体的java解析类 根据antlr提供的api（其实就是上一步生成的解析类）进行词法，语法解析生成语法树 可以自定义java映射结构，将整个语法树或者部分语法树映射到自己想要的结构中去使用 下面对照shardingsphere实际文件进行解读.g4语法文件 首先sql解析包是shardingsphere-sql-parser/shardingsphere-sql-parser-dialect/shardingsphere-sql-parser-mysql（以mysql为例，其他同理） 位置：src/main/antlr4/import/mysql/ 文件：MysqlStatement.g4（主文件，其他为辅助文件，明细文件） 语法文件内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/* * 这是MySQLStatement.g4主文件内容（部分），整体总结了mysql几乎的所有语法，每一种具体的语法规则明细在其他文件，例如：insert/update等语句在DMLStatement.g4文件中（主文件已经引用了该文件 import ）[具体的语法文件编写规则不在讨论范围内，官方文档自行阅读] */grammar MySQLStatement;//MySQLStatement和语法文件名保持一致import Symbol, Comments, DMLStatement, DDLStatement, TCLStatement, DCLStatement, DALStatement, RLStatement;execute : (select | insert | update | delete | replace | createTable | alterTable | repairTable | renameTableSpecification ... | rollback | savepoint | grant | revoke ... | showOther | setVariable | call | changeMasterTo | startSlave | stopSlave ) SEMI_? ;/* * dml语句解析语法定义文件，例如下面详细编写了如何解析insert语句的语法规则 */grammar DMLStatement;import Symbol, Keyword, MySQLKeyword, Literals, BaseRule;insert : INSERT insertSpecification_ INTO? tableName partitionNames_? (insertValuesClause | setAssignmentsClause | insertSelectClause) onDuplicateKeyClause? ;insertSpecification_ : (LOW_PRIORITY | DELAYED | HIGH_PRIORITY)? IGNORE? ;insertValuesClause : columnNames? (VALUES | VALUE) assignmentValues (COMMA_ assignmentValues)* ;insertSelectClause : columnNames? select ;onDuplicateKeyClause : ON DUPLICATE KEY UPDATE assignment (COMMA_ assignment)* ;replace : REPLACE replaceSpecification_? INTO? tableName partitionNames_? (insertValuesClause | setAssignmentsClause | insertSelectClause) ;replaceSpecification_ : LOW_PRIORITY | DELAYED ;... java解析类 idea有antlr4的插件，可以打开MySQLStatement.g4主文件，右键自动生成解析类；或者使用antlr4提供的脚本也可以，自行选择。 每个辅助文件都可以单独生成自己的解析类，但是shardingsphere最终需要的是主文件解析类，也就是MySQLStatement.g4 生成文件包括 MySQLStatement.interp MySQLStatement.tokens MySQLStatementBaseListener.java MySQLStatementBaseVisitor.java（MySQLStatementVisitor.java实现类） MySQLStatementLexer.java（负责词法解析） MySQLStatementLexer.interp MySQLStatementLexer.tokens MySQLStatementListener.java（shardingsphere没有使用，暂不讨论） MySQLStatementParser.java（负责语法解析，生成语法树） MySQLStatementVisitor.java（接口，将语法树映射为java自定义结构） ⚠️注意：shardingsphere源码中没有自动生成这些文件，源码测试需要自行生成并放到指定目录下（org/apache/shardingsphere/sql/parser/autogen/） antlr4 api使用样例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// 测试demopublic class MysqlStatementTest &#123; public static void main(String[] args) &#123; CharStream sql = CharStreams.fromString(&quot;sql string&quot;); MySQLStatementLexer lexer = new MySQLStatementLexer(sql); CommonTokenStream tokenStream = new CommonTokenStream(lexer); MySQLStatementParser parser = new MySQLStatementParser(tokenStream); // 解析生层语法树 ParseTree parseTree = parser.execute(); // 自定义MySQLStatementVisitor的实现类，编写自己的映射关系 MySQLVisitor visitor = new MySQLVisitor(); // 将语法树映射为自定义的结构 T t = visitor.visit(parseTree); &#125;&#125;/* * shardingsphere源码 * sql 解析引擎类 ，负责生产语法树，映射为java目标结构 */@RequiredArgsConstructorpublic final class SQLParserEngine &#123; private final String databaseTypeName; private final SQLParseResultCache cache = new SQLParseResultCache(); ... private SQLStatement parse0(final String sql, final boolean useCache) &#123; // 缓存语法树的java映射 if (useCache) &#123; Optional&lt;SQLStatement&gt; cachedSQLStatement = cache.getSQLStatement(sql); if (cachedSQLStatement.isPresent()) &#123; return cachedSQLStatement.get(); &#125; &#125; // 由于shardingsphere支持不同类型的数据库，所以这里根据数据库类型获取对应的parser生成语法树 ParseTree parseTree = new SQLParserExecutor(databaseTypeName, sql).execute().getRootNode(); // 同理，根据数据库类型获取对应的visitor构造java映射，这里对应的映射为SQLStatement（是个基类，返回结果多为它的子类） SQLStatement result = (SQLStatement) ParseTreeVisitorFactory.newInstance(databaseTypeName,VisitorRule.valueOf(parseTree.getClass())).visit(parseTree); if (useCache) &#123; cache.put(sql, result); &#125; return result; &#125;&#125;/* * shardingsphere源码 * 语法树映射java结构的具体实现，MySQLStatementBaseVisitor来自自动生成的解析文件，包含了默认的映射规则，我们需要继承该类重写映射规则，将语法树映射为我们自定义的目标结构 * ASTNode是语法树中每个节点对应的java对象节点（基类） * 映射的过程就是遍历语法树将语法树的每一个节点转换为java目标对象节点 */@Getter(AccessLevel.PROTECTED)public abstract class MySQLVisitor extends MySQLStatementBaseVisitor&lt;ASTNode&gt; &#123; // 该字段的作用是记录当前预编译sql语句的参数（预编译sql中的？）位置/下标；同时同步到对应的节点中，好让每个参数节点知道自己具体对应参数列表中那个值（index），最终的目标是得到分区键的值对应预编译参数列表中那个值（index值） private int currentParameterIndex; /* * 下面是一个具体映射样例 * 方法是基类的重载，方法ParameterMarkerContext（相当于语法树的一个叶子节点类型，不同的方法用于处理不同类型的叶子节点）参数来自MySQLStatementParser（自动生成的解析类）的内部类ParameterMarkerContext；方法内容就是将语法树叶子节点类型转化为我们自定义的结构类型ParameterMarkerValue（来自基类ASTNode）；该节点刚好还是个预编译参数节点，所以同时还更新了currentParameterIndex字段值 */ @Override public final ASTNode visitParameterMarker(final ParameterMarkerContext ctx) &#123; return new ParameterMarkerValue(currentParameterIndex++); &#125; ...&#125; 自定义映射结构完善源码 shardingsphere当前版本（4.1.1）不支持update case when语句，查看源码语法文件可以发现，语法文件是编写了改语句的解析规则，也就是支持该语句的；然后查看MySQLVisitor映射文件可以发现是具体映射实现没有详细实现，而是直接映射为了字符串 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 源码实现，只是简单映射为了字符串类型@Overridepublic final ASTNode visitCaseExpression(final CaseExpressionContext ctx) &#123; return new OtherLiteralValue(ctx.getText());&#125;// 自定义改造// 首先要知道case when 语法在语法树中的具体节点类型是什么，可以使用idea插件根据实际sql直接观察，然后再MySQLStatementVisitor.java接口中找到对应的映射方法，在MySQLVisitor类中重载@Overridepublic final ASTNode visitCaseExpression(final CaseExpressionContext ctx) &#123; Collection&lt;CaseWhenExpressionSegment&gt; caseWhen = new ArrayList&lt;&gt;(ctx.caseWhen_().size()); ctx.caseWhen_().forEach(e -&gt; caseWhen.add((CaseWhenExpressionSegment) visitCaseWhen_(e))); return new CaseFlowExpressionSegment(ctx.getStart().getStartIndex(), ctx.getStop().getStopIndex(), (SQLSegment) visitSimpleExpr(ctx.simpleExpr()), caseWhen);&#125;@Overridepublic final ASTNode visitCaseWhen_(final CaseWhen_Context ctx) &#123; Collection&lt;ExpressionSegment&gt; statementList = new ArrayList&lt;&gt;(ctx.expr().size()); ctx.expr().stream().skip(1).forEach(e -&gt; statementList.add((ExpressionSegment) visitExpr(e))); return new CaseWhenExpressionSegment(ctx.getStart().getStartIndex(), ctx.getStop().getStopIndex(), (SQLSegment) visitExpr(ctx.expr(0)), statementList);&#125;@Overridepublic final ASTNode visitCaseElse_(final CaseElse_Context ctx) &#123; return new CaseElseExpressionSegment(ctx.getStart().getStartIndex(), ctx.getStop().getStopIndex(), (ExpressionSegment) visitExpr(ctx.expr()));&#125;// 辅助自定义映射类型；所处包：shardingsphere-sql-parser/shardingsphere-sql-parser-statement；所处文件夹：org/apache/shardingsphere/sql/parser/sql/segment/dml/expr/// 可以自定义文件夹，也可以直接在现有文件夹下直接新建映射文件public interface CaseExpressionSegment extends ExpressionSegment &#123;&#125;@RequiredArgsConstructor@Getter@ToStringpublic class CaseFlowExpressionSegment implements CaseExpressionSegment &#123; private final int startIndex; private final int stopIndex; private final SQLSegment caseValue; private final Collection&lt;CaseWhenExpressionSegment&gt; caseWhen;&#125;@RequiredArgsConstructor@Getter@ToStringpublic class CaseWhenExpressionSegment implements CaseExpressionSegment &#123; private final int startIndex; private final int stopIndex; private final SQLSegment searchCondition; private final Collection&lt;ExpressionSegment&gt; statementList;&#125;@RequiredArgsConstructor@Getter@ToStringpublic class CaseElseExpressionSegment implements CaseExpressionSegment &#123; private final int startIndex; private final int stopIndex; private final ExpressionSegment statementList;&#125;]]></content>
      <categories>
        <category>ShardingSphere</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>MySql</tag>
        <tag>ShardingSphere</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Encoder]]></title>
    <url>%2F2020%2F04%2F12%2FEncoder%2F</url>
    <content type="text"><![CDATA[Encoder 哈希加密 Base64编码 压缩解压 哈希加密哈希概述 哈希函数（Hash Function），也称为散列函数或杂凑函数。哈希函数是一个公开函数，可以将任意长度的消息M映射成为一个长度较短且长度固定的值H（M），称H（M）为哈希值、散列值（Hash Value）、杂凑值或者消息摘要（Message Digest）。它是一种单向密码体制，即一个从明文到密文的不可逆映射，只有加密过程，没有解密过程。 它的函数表达式为：h=H（m） 无论输入是什么数字格式、文件有多大，输出都是固定长度的比特串。以比特币使用的Sh256算法为例，无论输入是什么数据文件，输出就是256bit。 哈希特点 易压缩：对于任意大小的输入x，Hash值的长度很小，在实际应用中，函数H产生的Hash值其长度是固定的。 易计算：对于任意给定的消息，计算其Hash值比较容易。 不可逆：对于给定的Hash值，要找到使得在计算上是不可行的，即求Hash的逆很困难。在给定某个哈希函数H和哈希值H（M）的情况下，得出M在计算上是不可行的。即从哈希输出无法倒推输入的原始数值。这是哈希函数安全性的基础。 抗碰撞性：理想的Hash函数是无碰撞的，但在实际算法的设计中很难做到这一点。有两种抗碰撞性：一种是弱抗碰撞性，即对于给定的消息，要发现另一个消息，满足在计算上是不可行的；另一种是强抗碰撞性，即对于任意一对不同的消息，使得在计算上也是不可行的。 高灵敏性：这是从比特位角度出发的，指的是1比特位的输入变化会造成1/2的比特位发生变化。消息M的任何改变都会导致哈希值H（M）发生改变。即如果输入有微小不同，哈希运算后的输出一定不同。 哈希加密和对称/非对称加密区别 哈希密码是不可逆的，因此无法从密文中获取到原文，而对称/非对称加密可以； 哈希密码加密大部分不需要密钥（除了HMAC），而对称/非对称加密需要； 哈希加密不管是短数据还是长数据，加密后得到的密文长度是固定的，而对称/非对称通常和原文的长度成正比； 哈希加密有可能碰撞，虽然理论的哈希加密是不可能碰撞的，但是只是理论，王小云教授之前就提出碰撞的方法。而对于对称/非对称，一个密文用密钥解密后的结果一定是唯一的； 加密算法 MD5信息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。MD5由美国密码学家罗纳德·李维斯特（Ronald Linn Rivest）设计，于1992年公开，用以取代MD4算法。这套算法的程序在 RFC 1321 标准中被加以规范。1996年后该算法被证实存在弱点，可以被加以破解，对于需要高度安全性的数据，专家一般建议改用其他算法，如SHA-2。2004年，证实MD5算法无法防止碰撞（collision），因此不适用于安全性认证，如SSL公开密钥认证或是数字签名等用途。 SHA-1（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种密码散列函数，美国国家安全局设计，并由美国国家标准技术研究所（NIST）发布为联邦数据处理标准（FIPS）。SHA-1可以生成一个被称为消息摘要的160位（20字节）散列值，散列值通常的呈现形式为40个十六进制数。SHA-1已经不再视为可抵御有充足资金、充足计算资源的攻击者。2005年，密码分析人员发现了对SHA-1的有效攻击方法，这表明该算法可能不够安全，不能继续使用，自2010年以来，许多组织建议用SHA-2或SHA-3来替换SHA-1。Microsoft、Google以及Mozilla都宣布，它们旗下的浏览器将在2017年前停止接受使用SHA-1算法签名的SSL证书。2017年2月23日，CWI Amsterdam与Google宣布了一个成功的SHA-1碰撞攻击，发布了两份内容不同但SHA-1散列值相同的PDF文件作为概念证明。 SHA-2/SHA-256。SHA-2有多种不同的位数，导致这个名词有一些混乱。但是无论是“SHA-2”，“SHA-256”或“SHA-256位”，其实都是指同一种加密算法。但是SHA-224”，“SHA-384”或“SHA-512”，表示SHA-2的二进制长度。还要另一种就是会把算法和二进制长度都写上，如“SHA-2 384”。 SSL行业选择SHA作为数字签名的散列算法，从2011到2015，一直以SHA-1位主导算法。但随着互联网技术的提升，SHA-1的缺点越来越突显。从去年起，SHA-2成为了新的标准，所以现在签发的SSL证书，必须使用该算法签名。也许有人偶尔会看到SHA-2 384位的证书，很少会看到224位，因为224位不允许用于公共信任的证书，512位，不被软件支持。 HMAC是密钥相关的哈希运算消息认证码（Hash-based Message Authentication Code）的缩写，由H.Krawezyk，M.Bellare，R.Canetti于1996年提出的一种基于Hash函数和密钥进行消息认证的方法，并于1997年作为RFC2104被公布，并在IPSec和其他网络协议（如SSL）中得以广泛应用，现在已经成为事实上的Internet安全标准。它可以与任何迭代散列函数捆绑使用。 HMAC运算利用hash算法，以一个消息M和一个密钥K作为输入，生成一个定长的消息摘要作为输出。HMAC算法利用已有的Hash函数，关键问题是如何使用密钥。 HMAC的密钥长度可以是任意大小，如果小于n（hash输出值的大小），那么将会消弱算法安全的强度。建议使用长度大于n的密钥，但是采用长度大的密钥并不意味着增强了函数的安全性。密钥应该是随机选取的，可以采用一种强伪随机发生器，并且密钥需要周期性更新，这样可以减少散列函数弱密钥的危险性以及已经暴露密钥所带来的破坏使用SHA-1、SHA-224、SHA-256、SHA-384、SHA-512所构造的HMAC，分别称为HMAC-SHA1、HMAC-SHA-224、HMAC-SHA-384、HMAC-SHA-512。HMAC算法更象是一种加密算法，它引入了密钥，其安全性已经不完全依赖于所使用的Hash算法。 用途 哈希加密除了用在密码加密上，它还有很多的用途，如提取内容摘要、生成签名、文件对比、区块链等等 文件、图片等数据的标识码： 对文件进行md5加密，得到一个唯一的文件摘要，把摘要存储，之后再次上传文件时前端先计算摘要，如果文件的摘要在后端发现重复的，那么就不进行上传。这样可以为服务器节省大量的硬盘资源。这主要利用了哈希加密的压缩性、唯一性； Java实现用法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public static String md5(String text) throws NoSuchAlgorithmException &#123; MessageDigest messageDigest = MessageDigest.getInstance("MD5"); byte[] bytes = messageDigest.digest(text.getBytes()); return Hex.encodeHexString(bytes);&#125;/** * sha1加密 */public static String sha1(String text) throws NoSuchAlgorithmException &#123; MessageDigest messageDigest = MessageDigest.getInstance("SHA-1"); byte[] bytes = messageDigest.digest(text.getBytes()); return Hex.encodeHexString(bytes);&#125;/** * sha256加密 */public static String sha256(String text) throws NoSuchAlgorithmException &#123; MessageDigest messageDigest = MessageDigest.getInstance("SHA-256"); byte[] bytes = messageDigest.digest(text.getBytes()); return Hex.encodeHexString(bytes);&#125;/** * hmac-sha1加密 */public static String hmacSha1(String text, String key) throws Exception &#123; SecretKeySpec sk = new SecretKeySpec(key.getBytes(), "HmacSHA1"); return hmacSha1(text, sk);&#125;/** * hmac-sha1加密 */public static String hmacSha1(String text, SecretKeySpec sk) throws Exception &#123; Mac mac = Mac.getInstance("HmacSHA1"); mac.init(sk); byte[] rawHmac = mac.doFinal(text.getBytes()); return new String(Base64.encodeBase64(rawHmac));&#125;/** * 生成 HmacSha1 密钥 */public static SecretKeySpec createHmacSha1Key(String key) &#123; return new SecretKeySpec(key.getBytes(), "HmacSHA1");&#125;/** * hmac-sha256加密 */public static String hmacSha256(String text, String key) throws Exception &#123; SecretKeySpec sk = new SecretKeySpec(key.getBytes(), "HmacSHA256"); return hmacSha1(text, sk);&#125;/** * hmac-sha256加密 */public static String hmacSha256(String text, SecretKeySpec sk) throws Exception &#123; Mac mac = Mac.getInstance("HmacSHA256"); mac.init(sk); byte[] rawHmac = mac.doFinal(text.getBytes()); return new String(Base64.encodeBase64(rawHmac));&#125;/** * 生成 HmacSha256 密钥 */public static SecretKeySpec createHmacSha256Key(String key) &#123; return new SecretKeySpec(key.getBytes(), "HmacSHA256");&#125; Base64编码 Base64是一种用64个字符来表示任意二进制数据的方法。 Base64编码可用于在HTTP环境下传递较长的标识信息 Base64的原理很简单，首先，准备一个包含64个字符的数组： 然后，对二进制数据进行处理，每3个字节一组，一共是3x8=24bit，划为4组，每组正好6个bit： 这样我们得到4个数字作为索引，然后查表，获得相应的4个字符，就是编码后的字符串。所以，Base64编码会把3字节的二进制数据编码为4字节的文本数据，长度增加33%，好处是编码后的文本数据可以在邮件正文、网页等直接显示。 如果要编码的二进制数据不是3的倍数，最后会剩下1个或2个字节怎么办？Base64用\x00字节在末尾补足后，再在编码的末尾加上1个或2个=号，表示补了多少字节，解码的时候，会自动去掉 1234private static Base64.Encoder encoder = Base64.getEncoder();private static Base64.Encoder urlEncoder = Base64.getUrlEncoder();private static Base64.Decoder decoder = Base64.getDecoder();private static Base64.Decoder urlDecoder = Base64.getUrlDecoder(); 注意：然而，标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。为解决此问题，可采用一种用于URL的改进Base64编码，它不仅在末尾去掉填充的’=’号，并将标准Base64中的“+”和“/”分别改成了“-”和“_”，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。]]></content>
      <categories>
        <category>Encoder</category>
      </categories>
      <tags>
        <tag>Base64</tag>
        <tag>Encoder</tag>
        <tag>Decoder</tag>
        <tag>MD5</tag>
        <tag>SHA</tag>
        <tag>HAMC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT]]></title>
    <url>%2F2020%2F04%2F12%2FJWT%2F</url>
    <content type="text"><![CDATA[JWT Token的基础内容 web网站登陆Token验证 系统间交互权限验证 API接口签名校验 Token的基础内容原理 用户登陆成功服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。 12345&#123; "姓名": "张三", "角色": "管理员", "到期时间": "2018年7月1日0点0分"&#125; 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名。 这样的话，服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。 Token组成 它是一个很长的字符串，中间用点（.）分隔成三个部分 JWT 的三个部分依次如下。 Header（头部） Payload（负载） Signature（签名） 写成一行，就是下面的样子。 Header.Payload.Signature Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。1234&#123; "alg": "HS256", "typ": "JWT"&#125; 上面代码中，alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。 最后，将上面的 JSON 对象使用 Base64URL 算法转成字符串就是header了。 Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。 iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。 12345&#123; "sub": "1234567890", "name": "John Doe", "admin": true&#125; 同理，都需要使用 Base64URL 算法转成字符串 Signature 部分是对前两部分的签名，防止数据篡改。 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。 HMACSHA256(base64UrlEncode(header) + “.” +base64UrlEncode(payload),secret) 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。 扩展Base64 JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。 跨域问题 客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。Authorization: Bearer ；另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。 注意 JWT其实是一种思维，上面的内容只是做了一个样例，每一部分都可以根据实际具体需求场景进行不同的修改升级改版，包括签名模式，加密算法等。 web网站登陆Token验证 单个浏览器多个HttpSession Spring Session拥有在单个浏览器实例中支持多个Session的能力。提供这种能力就可以支持在同一个浏览器实例中的多用户认证（如：Google账户）。 123456789101112131415161718192021222324252627if ("web_login".equals(behavior)) &#123; // 模拟网站登录验证场景 if (loginCache.exist(token)) &#123; // 用户已登录状态，更新登录时间戳，从token中获取完整详细的用户信息 merchant = JwtFactory.unCompressInfo(loginCache.get(token)); // 当前请求内缓存用户登录信息对象，以供整个请求内使用，当前请求内有效 servletRequest.setAttribute(CURRENT_MERCHANT, merchant); &#125; else &#123; // 未登录或者登录已过期，如果调用的是登录接口，走登录逻辑；否则返回错误信息：未登录或者登录已过期，请重新登录！ if ("login".equals(method)) &#123; // 模拟登录信息验证并查询db获取到完整详细的用户信息对象 merchant = validationLoginInfo(merchant); // 创建新的用户登录信息缓存 Customer customer = new Customer(); customer.setBusinessFiled(JsonUtil.toJson(merchant)); // 根据登录用户信息生成新的token值 token = JwtFactory.buildToken(customer); // 压缩存储用户登录信息对象 loginCache.cache(token, JwtFactory.compressInfo(merchant)); // 当前请求内缓存用户登录信息对象，以供整个请求内使用，当前请求内有效 servletRequest.setAttribute(CURRENT_MERCHANT, merchant); filterChain.doFilter(servletRequest, servletResponse); &#125; else &#123; servletResponse.getWriter().println("未登录或者登录已过期，请重新登录！"); &#125; &#125;&#125; 系统间交互权限验证12345678910111213141516171819202122232425else if ("external_sys_call".equals(behavior)) &#123; // 模拟底层系统之间交互权限验证，包括api接口的签名校验 if (StringUtils.isEmpty(sign)) &#123; // 没有签名的请求直接拒绝访问 servletResponse.getWriter().println("该请求不合法！"); &#125; // 根据双方约定好的签名规则以及私钥，重新构建签名用以校验签名的合法性 String ownSign = JwtFactory.buildSign(servletRequest); if (!ownSign.equals(sign)) &#123; // api接口签名验证失败，预防恶意攻击 servletResponse.getWriter().println("该请求不合法！"); &#125; if (callCache.exist(nickNo)) &#123; // 该账户存在，继续校验其他合法性 merchant = JwtFactory.unCompressInfo(callCache.get(nickNo)); if (validationMerchant(merchant)) &#123; // 账户信息校验通过；当前请求内缓存账户信息，以供整个请求内使用，当前请求内有效 servletRequest.setAttribute(CURRENT_MERCHANT, merchant); &#125; else &#123; servletResponse.getWriter().println("账户信息有变动，列如：该账户已被冻结！"); &#125; &#125; else &#123; servletResponse.getWriter().println("nickNo无效，无效的用户请求"); &#125;&#125; controller层如何获取用户登录缓存信息/或者是类似的账号验证等信息等 （此类验证信息需要存储到缓存中，并且接口的调用会有过滤器拦截做校验，之后把信息塞入request中供controller使用） 使用@RequestAttribute(CURRENT_MERCHANT) Merchant merchant：基于请求的将用户信息缓存下来，在controller层获取用户信息 service层如何获取用户登录信息—基于请求 1234public static Merchant currentMerchant() &#123; return (Merchant)RequestContextHolder.currentRequestAttributes().getAttribute(CURRENT_MERCHANT, 0);// return (Merchant)RequestContextHolder.getRequestAttributes().getAttribute(CURRENT_MERCHANT, 0);&#125; API接口签名校验 普遍方式：toSign.append(key).append(“=”).append(value).append(“&amp;”);—–最会在加上securit key 1234567891011121314151617181920212223242526272829303132333435363738/** * @author liufei * @date 3/28/20 * 接口API认证，每一个请求都进行认证 * 一个简单的签名认证：规则如下 * 请求参数按照ascii码排序 * 将排好序的参数拼接为key=value&amp;key=value...的字符串（sign参数除外） * 混合上秘钥（secret，秘钥由被请求方分配得来）进行sha512（MD5、SHA256）加密后获得最终的签名，与请求的签名sign比较 */public class SignTest &#123; private static final String SIGN = "sign"; // 秘钥-16位 private static final String SECRET = "2jk34njn4234nll7"; public boolean validationSign(HttpServletRequest request) &#123; // 从请求参数中获取签名，todo 此类数据放到请求采参数中合适还是放到header中合适 String requestSign = request.getParameter(SIGN); if (StringUtils.isBlank(requestSign))&#123; // 没有签名的请求直接拒绝访问 return false; &#125; // 一个参数key可能对应多个value值// Map&lt;String, String[]&gt; param = request.getParameterMap(); Set&lt;String&gt; keys = request.getParameterMap().keySet(); keys.remove(SIGN); // 本次签名由秘钥开头，秘钥结束 StringBuffer temp = new StringBuffer(SECRET); keys.forEach(v -&gt; &#123; temp.append(v).append("=").append(request.getParameter(v)).append("&amp;"); &#125;); temp.deleteCharAt(temp.length()-1); temp.append(SECRET); // 获得最终签名，与请求签名比较校验 String sign = DigestUtils.md5DigestAsHex(temp.toString().getBytes()); return StringUtils.equals(sign, requestSign); &#125;&#125;]]></content>
      <categories>
        <category>JWT</category>
      </categories>
      <tags>
        <tag>JWT</tag>
        <tag>Session</tag>
        <tag>Request</tag>
        <tag>Sign</tag>
        <tag>Token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器输入一个网址后发生了什么？]]></title>
    <url>%2F2020%2F04%2F12%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E5%90%8E%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[浏览器输入一个网址后发生了什么 url解析 DNS查询 使用TCP协议栈 构建套接字Socket 负载均衡 正/反向代理 url解析 http:–//–域名—服务器文件地址 http协议方法（get，put，post，delete，head，option，trace，connect…） 操作系统的网络功能 ，操作系统才具有操控网络，发送数据的功能，程序没有，程序只是调用操作系统，Socket 库是用于调用网络功能的程序组件集合。 向DNS服务器根据域名查询ip 对于DNS服务器，我们的计算机上 一定有相应的DNS 客户端，而相当于DNS 客户端的部分称为DNS 解析 器，或者简称解析器。 通过DNS查询IP地址的操作称为域名解析，因此 负责执行解析（resolution）这一操作的就叫解析器（resolver）了。 解析器实际上是一段程序，它包含在操作系统的Socket库中 gethostbyname（域名） 要访问的Web 服务器已经在DNS服务器上注册，那么这 条记录就能够被找到 顺带一提，向DNS服务器发送消息时，我们当然也需要知道DNS服 务器的IP地址。只不过这个IP地址是作为TCP/IP的一个设置项目事先设 置好的，不需要再去查询了。 DNS 服务器会从域名与 IP 地址的对照表中查找相应的记录，并 返回 IP 地址。 DNS服务器有一 个缓存 A 功能，可以记住之前查询过的域名。如果要查询的域名和相关信息已 经在缓存中，那么就可以直接返回响应 操作系统内部的协议栈向拿到的ip地址发送数据 向操作系统内部的协议栈发出委托时，需要按照指定的顺序来调 用 Socket 库中的程序组件。 TCP协议栈—构建套接字通道—双向数据流动 首先，服务器一方 先创建套接字，然后等待客户端向该套接字连接管道 A。当服务器进入等待状态时，客户端就可以连接管道了 管道在连接时是由客户端发起的，但在断开 时可以由客户端或服务器任意一方发起 A。其中一方断开后，另一方也会随之 断开，当管道断开后，套接字也会被删除 浏览器等应用程序并不会自 己去做连接管道、放入数据这些工作，而是委托协议栈来代劳 应用程序是通过“描述符”这一类似号码牌的东西来识别套接字的。 建立套接字socket通道开始传输数据 浏览器、邮件等一般应用程序收发数据时用 TCP； DNS 查询等收发较短的控制数据时用 UDP 在Windows中可以用netstat命令显示套接字内容（图2.2）A。 图中每一行相当于一个套接字，当创建套接字时，就会在这里增加一行新 的控制信息，赋予“即将开始通信”的状态 客户端和服务器在通信中会将必要的信息记录在头部并相互确认， 连接操作的第一步是在TCP模块处创建表示连接控制信息的头部。 通过TCP头部中的发送方和接收方端口号可以找到要连接的套 接字 MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去头部之后，一个网络包所能容纳的TCP数据的最大 长度。 route print 命令来显示路由表 arp -a 显 示 ARP缓存的方法和MAC地址 控制用的短数据这种情况就适合使用UDP。像DNS查询等交换控制信息的操作基本 上都可以在一个包的大小范围内解决，这种场景中就可以用UDP来代替 TCPA。 UDP没有TCP的接收确认、窗口等机制，因此在收发数据之前也不 需要交换控制信息，也就是说不需要建立和断开连接的步骤，只要在从应 用程序获取的数据前面加上UDP 头部，然后交给IP 进行发送就可以了 还有另一个场景会使用UDP，就是发送音频和视频数据的时候。音频 和视频数据必须在规定的时间内送达，一旦送达晚了，就会错过播放时机， 导致声音和图像卡顿。 负载均衡器 dns负载均衡，一个域名对应多个ip，但没办法解决跨页面需求：当操作跨多个页面时，则不考虑Web 服务器的负载，而是必须将请求 发送到同一台Web 服务器上 判断条件有很多种，根据操作是否跨多个页面，判断条件也会有所不 同。如果操作没有跨多个页面，则可以根据Web 服务器的负载状况来进行 判断。负载均衡器可以定期采集Web 服务器的CPU、内存使用率，并根据 这些数据判断服务器的负载状况，也可以向Web 服务器发送测试包，根据 响应所需的时间来判断负载状况。当然，Web 服务器的负载可能会在短时间内上下波动，因此无法非常准确地把握负载状况 密集地去查询服务器的负载，这个查询操作本身就会增加Web 服务器的负 载。因此也有一种方案是不去查询服务器的负载，而是根据事先设置的服 务器性能指数，按比例来分配请求。 正向代理：放置在客户端 其实正向代理并不是一开始就叫这个名字，最早说的“代理”指的就是我 们现在说的正向代理，或者也叫“代理服务器”。这是因为最早只有这么 一种代理，后来出现了各种其他方式的代理， 为了相互区别才起了“×× 代理”这样的名字。此外，由于代理种类变多了，叫“×× 代理服务器” 实在太长，一般都会省略“服务器”3 个字。 代理（Proxy）本来的意思并不是“转发”消息，而是先把消息收下来，然 后“伪装”成原始客户端向 Web 服务器发出访问请求 由于代理在转发过程中可以查看请求的内容，所以可以根据内 容判断是否允许访问。也就是说，通过代理可以禁止员工访问危险的网站， 或者是与工作内容无关的网站。 包过滤方式的防火墙只能根据IP地址和端 口号进行判断，因此无法实现这一目的。 反向代理 放置在服务端，么服务器不知道谁会来访问， 也没办法去设置客户端的浏览器，因此无法采用这种方法来实现。]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>Http</tag>
        <tag>Tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL注入]]></title>
    <url>%2F2020%2F03%2F22%2FSQL%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[SQL注入 什么是sql注入 如何sql注入 如何在项目中进行防sql注入 什么是sql注入 攻击者通过影响传递给数据库的内容来修改sql的自身语法和功能 如何sql注入 构造动态字符串 经典的 ‘ OR 1=1 的例子 使用注释符号终止部分where条件 例如：’ or 1=1; – 或者高级：where username =’admin’/‘ and password = ‘/‘’ 拆分出来好理解些：等价于用户名写的是admin’/，密码写的是/‘ 转义字符处理不当 sql数据库将单引号解析成代码的和数据的分界线（针对字符串数据类型） 单引号外面的内容均为代码，单引号引起来的内容均为数据 典型例子：使用字符串单引号注入 columnsValue=xxxx ‘ group by xxxx having 1=1 类型处理不当 数字类型不需要单引号 典型例子：使用数字类型衔接其他指令注入 9 union select LOAD_FILE(‘/etc/passwd’) 查询集处理不当 动态构建查询字段，表名时没有校验，被攻击者替换 sql错误处理不当 详细的返回sql错误信息会给攻击者提示数据库的相关信息 高级注入 拼接多条语句 可以提升用户权限 可以新增用户，更改数据 通过union返回其他数据 例如：id=12; update users set isadmin=1 堆迭查询 根据sql错误信息判断数据库类型/或者注入版本查询语句，select version() order by 能接受一个特定的列名作为参数，也可以接受一个能标识特定列的数字作为参数 条件查询语句：IF condition THEN dosomething，同样注入在参数中 枚举数据库中所有表，所有列，使用union 数据库如何将查询结果写入文件—-mysql—select …. into outfile（dumpfile） filepath(不写，文件默认路径为datadir变量) mysql的数据存储目录—datadir变量 sql盲注：在没法获取数据库错误信息的情况下，利用查询的输入审查漏洞提取数据库信息，也就是没法直接直观的获取数据库的信息，只能盲猜或者通过其他方式获取 即使是强制返回通用错误模板，也可能被分析出注入点（大佬） 利用数据库—访问文件系统—控制操作系统 mysql的load data inline命令和load_file命令 例如：union select LOAD_FILE(‘/etc/passwd’) 如何在项目中进行防sql注入代码层sql注入防御 动态字符串构造，动态sql—参数化语句 入参校验（黑名单，白名单），拒绝不良字符，如字符串中的单引号 关联请求/表单提交需要关联验证 特殊字符的编码格式，编码后可以混过校验 处理敏感数据，如密码口令，sha512哈希，避免入参直接和库中数据比较，中间加一步换算 避免使用众所周知的字段名存储重要信息，如password， 开发中，禁止返回数据库的详细错误信息，甚至是程序的，统一返回封装好的错误模板信息 清除参数中的所有空格/或者使用多行注释替换空格符号 sql语句中单行注释符号：– ，多行注释符号：/ / 例如：id=12 or 1=1 替换为：id=12or1=1；或者为：id=12//or//1=1 数据路层sql注入防御 避免让开发人员使用内置的账户连接数据库 保证最低的数据库权限模式下运行程序 分离授权角色，不同的数据库用户执行不同的命令，select，update，delete等 扩展 数据库的带外通信，即通过不同的信道来传递信息，请求和响应不在同一个连接中 数据库的e-mail邮件通知功能（如何设置数据库的邮件通知功能？)]]></content>
      <categories>
        <category>SQL注入</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Native]]></title>
    <url>%2F2020%2F01%2F30%2FNative%2F</url>
    <content type="text"><![CDATA[Java native 关键字 Java的跨平台性 JNI DLL共享库（动态链接库文件） 什么时候会进行DLL文件加载 DLL文件加载方式 Native Method 适用范围 实现步骤 加载流程 潜在风险 Java的跨平台性 既然实现跨平台，所付出的代价就是牺牲一些对底层的控制（因为不同的平台，其底层操作不同），而java要实现对底层的控制，就需要一些其他语言的帮助，这个就是native的作用了 使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。 JNI Java平台有个用户和本地C代码进行互操作的API，称为Java Native Interface (Java本地接口，即JNI)。 JNI是一个很强大的特性，它让你既可以利用Java平台的特性，同时可以使用其他语言完成的代码．作为Java虚拟机实现一部，JNI是一种双向接口，既允许Java应程序调用原生代码，同时也允许原生代码调用Java代码 DLL（dynamic link library） 库文件有两种，一种是静态库，另一种是动态库即DLL(Dynamic Link Library)文件，是动态链接库文件，又称“应用程序拓展”，是软件文件类型。 静态库和动态库的区别是：静态库在程序的链接阶段被复制到了程序中，和程序运行的时候没有关系；动态库在链接阶段没有被复制到程序中，而是程序在运行时由系统动态加载到内存中供程序调用。使用动态库的优点是系统只需载入一次动态库，不同的程序可以得到内存中相同的动态库的副本，因此节省了很多内存。在Windows中，许多应用程序并不是一个完整的可执行文件，它们被分割成一些相对独立的动态链接库，即DLL文件，放置于系统中。当我们执行某一个程序时，相应的DLL文件就会被调用。一个应用程序可使用多个DLL文件，一个DLL文件也可能被不同的应用程序使用，这样的DLL文件被称为共享DLL文件。 你可以简单的把DLL看成一种仓库，它提供给你一些可以直接拿来用的变量、函数或类。在仓库的发展史上经历了“无库－静态链接库－动态链接库”的时代。静态链接库与动态链接库都是共享代码的方式，如果采用静态链接库，则无论你愿不愿意，lib中的指令都被直接包含在最终生成的EXE文件中了。但是若使用DLL，该DLL不必被包含在最终EXE文件中，EXE文件执行时可以“动态”地引用和卸载这个与EXE独立的DLL文件。静态链接库和动态链接库的另外一个区别在于静态链接库中不能再包含其他的动态链接库或者静态库，而在动态链接库中还可以再包含其他的动态或静态链接库。 注意： DLL 的编制与具体的编程语言及编译器无关 只要遵循约定的DLL接口规范和调用方式，用各种语言编写的DLL都可以相互调用 我们在Windows目录下的system32文件夹中会看到kernel32.dll、user32.dll和gdi32.dll，windows的大多数API都包含在这些DLL中。kernel32.dll中的函数主要处理内存管理和进程调度；user32.dll中的函数主要控制用户界面；gdi32.dll中的函数则负责图形方面的操作。 什么是Native Method 简单地讲，一个Native Method就是一个java调用非java代码的接口。一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。这个特征并非java所特有，很多其它的编程语言都有这一机制，比如在C＋＋中，你可以用extern “C”告知C＋＋编译器去调用一个C的函数。 在定义一个native method时，并不提供实现体（有些像定义一个java interface），因为其实现体是由非java语言在外面实现的。 Java native方法适用范围 为了使用底层的主机平台的某个特性，而这个特性不能通过JAVA API访问 为了访问一个老的系统或者使用一个已有的库，而这个系统或这个库不是用JAVA编写的 为了加快程序的性能，而将一段时间敏感的代码作为本地方法实现。 实现native方法步骤 在Java中声明native()方法，然后编译； 用javah产生一个.h文件； 写一个.cpp文件实现native导出方法，其中需要包含第二步产生的.h文件（注意其中又包含了JDK带的jni.h文件（jni.h: 这个头文件提供了所有原生代码需要调用的JNI方法，编写原生代码的时候，你通常必须在你的头文件中包含该文件））； 将第三步的.cpp文件编译成动态链接库文件； 只需要使用任意C语言的工具集构建出动态链接库即可. 如果你使用的是gcc，可以使用以下命令行构建： gcc -I/path/to/java/include HelloWorld.c -o libHelloWorld.so 在ubuntu上使用命令如下： gcc -I/home/wangli/env/jdk/usr/java/jdk1.8.0_20/include -I/home/wangli/env/jdk/usr/java/jdk1.8.0_20/include/linux HelloWorld.c -shared -o libHelloWorld.so -fPIC 如果你使用的是Visual Studio，创建一个动态链接库工程直接构建即可． 或者使用以下命令行： cl -I/path/to/java/include -MD -LD HelloWorld.c -FHelloWorld.dll 在Java中用System.loadLibrary()方法加载第四步产生的动态链接库文件，这个native()方法就可以在Java中被访问了。 正确的设置动态链接库的路径对于程序成功运行只管重要，在加载时候需要将动态链接库所对应的目录加入系统LD_LIBRARY_PATH环境变量，或者在执行java命令的时候加入java.library.path选项，制定库所在目录． java -Djava.library.path=. HelloWorld Native Method的加载流程 和普通方法一样，当class文件被加载进入内存并转为Class实例之后，会记录该class的所有相关信息，如：方法代码存于何处，它有哪些参数，方法的描述符（public之类）等等。 如果一个方法描述符内有native，这个描述符块将有一个指向该方法的实现的指针。 native方法的实现在一些DLL文件内，但是它们会被操作系统加载到java程序的地址空间。 当一个带有本地方法的类被加载时，其相关的DLL并未被加载，因此指向方法实现的指针并不会被设置。当本地方法被调用之前，这些DLL才会被加载，这是通过调用java.system.loadLibrary()实现的。 使用JNI的潜在风险 一旦一个程序使用了JNI,他就丢失了两种Java平台的优势． 第一，使用了JNI的Java应用程序便不可以直接运行在不同的宿主环境中．即使使用Java语言编写的那部分应用程序代码是可移植的，你也必须重新编译使用原生代码完成的那部分代码． 第二，Java语言是类型安全的，但是C/C++则不是．所以，在用到JNI的应用程序中，你要格外的小心，一个原生方法的错误使用，可能让整个程挂掉．也是因为这个，Java应用程序中，建议在使用JNI特性之前都进行安全检查． Sun的解释器(编译器javac)是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用java实现的]]></content>
      <categories>
        <category>Native</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Native</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gossip协议]]></title>
    <url>%2F2019%2F12%2F14%2FGossip%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[Gossip协议 什么是gossip协议 算法原理 应用场景 什么是gossip协议 Gossip protocol 也叫 Epidemic Protocol （流行病协议），或者“流言算法”、“疫情传播算法”等。可以类比电脑病毒的传播，森林大火，细胞扩散等等。 算法原理 一句话来概括就是图的并行广度优先遍历；定义好定时周期，一秒发一次消息定义好广度散播最大节点数，每次最多散播3个节点每个节点收到消息后重复同样的步骤，只不过会过滤掉发送方节点，同时还可以验证一下消息是否已经接受过所有节点均是异步发送消息，不关注对方是否收到最终所有节点信息会保持一致 算法权衡点 异步：快 扩展性：横向任意扩 数据一致性：最终所有节点数据一定是一致的 容错性：任意节点故障不影响消息的传播 去中心化：任何一个节点无需知道整个网络状态就可以将消息散播到全网 一致性收敛：收敛速度，一传十，十传百，传播速度logN 消息冗余：大量重复性消息占用带宽资源 消息延迟：消息的最终一致性，实时性要求高的场景不适用 信息的两种传播类型 全量信息传递：信息最终一定一致 增量信息传递：信息最终可能不一致 节点间通信模式 push：推 pull：拉 push/pull：推拉结合，收敛速度最快 应用场景 主要用在分布式数据库系统中各个副本节点同步数据之用，这种场景的一个最大特点就是组成的网络的节点都是对等节点，是非结构化网络，这区别与用于结构化网络中的 DHT 算法 Kadmelia。大名鼎鼎的 Bitcoin 就是使用了 Gossip 协议来传播交易和区块信息]]></content>
      <categories>
        <category>Distribution</category>
      </categories>
      <tags>
        <tag>Gossip</tag>
        <tag>Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kademlia协议]]></title>
    <url>%2F2019%2F12%2F14%2FKademlia%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[Kademlia协议 什么是Kademlia协议 算法原理 应用场景 什么是Kademlia协议 Kademlia是一种分布式哈希表（DHT），是第三代对等网络的节点动态管理和路由协议。与前两代协议如 Chord、CAN、Pastry 等相比，Kad以全局唯一id标记对等网络节点，以节点ID异或（XOR）值度量节点之间距离，并通过距离分割子树构建路由表，建立了一种全新的网络拓扑结构。相比于其他算法，更简单，更高效。 算法原理 网络中分散的各个节点一起组成了一张网状图，可以理解为数据结构中的无向图 每个节点拥有一个唯一id标识，id由160bit的二进制位组成 节点间的距离使用逻辑上的抽象表示，即2个节点id的异或（xor）结果的二进制bit位数来表示 节点id之间的最长公共前缀lcp和节点之间的距离有一定的数学关系，由于节点间的距离采用节点id的异或结果的二进制bit位数表示，所以，lcp越长，节点间的距离(dis)越小（lcp + dis = 160） 每个节点都维护着一个路由表，记录着网络中的部分节点信息；该路由表本质上是一个数组（bucket数据）数组的下标表示dis，数组内存储的就是距离本节点相同dis的其他节点 bucket的大小视具体实现算法而定，可以直接初始化为160；可以初始化为1，后续自动分裂；可以初始化为固定某值 相同dis的节点数量限制为最大k 节点路由：当前节点和目标节点id值异或算出dis，然后根据dis查看当前节点的bucket数组，是否含有目标节点；否，向这些相同dis的节点发出咨询请求，查找目标节点 节点路由表变更 新节点的加入上线：需要一个种子节点的配合，即将一个已经存在的节点S加入到新节点路由表中，然后发起节点查询请求。其一可以告诉节点S有新节点的加入，其二通过节点S告诉网络中其他节点有新节点的加入，同时其他节点也可能将自己的部分节点信息主动push到新节点供新节点使用 旧节点下线：离线事件最终会反馈到网络节点的路由表中，将其从路由表中剔除即可 算法优缺点 网络中所有节点的映射关系避免了每个节点全量存储，分散到了各个节点，同时每个节点的信息至少存储在&gt;1个节点中，保证了任意一个节点下线不会影响到其他节点 但是节点的批量下线就可能会导致某些刚上线的新节点不可达，因为新节点刚上线，本身还没有路由表，这时候其他拥有该节点信息的节点批量下线，就会造成该新节点的不可达（孤立无援，求助都找不到人） 解决思路：新节点加入的时候，其他节点探测到有新节点后，将本地距离更为近的节点信息push到新节点 鉴于p2p网络中，节点变动较为频繁，如此操作可能会导致网络压力增大，所以建议改为定时；同时检测节点是否有必要进行数据同步（已经是最新，最近刚刚同步过）；各个节点分散操作，避免所有节点同时操作，增大网络压力]]></content>
      <categories>
        <category>Distribution</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Kademlia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq]]></title>
    <url>%2F2019%2F12%2F14%2FRabbitMQ%2F</url>
    <content type="text"><![CDATA[RabbitMq AMQP协议 消息的可靠性投递 消息的可靠性消费 消息幂等 重复消费 rabbitmq整合spring amqp MQ比较 AMQP协议 高级消息队列模型规范，上层协议 同样的规范还有jms等，基于不同的规范可以书写出不同的消息队列框架 Rabbitmq基于AMQP协议，ActiveMQ基于jms AMQP协议模型 生产者（往路由扔消息） 消费者（从队列中消费消息） exchange交换机（路由与队列相互绑定） message queue 消息队列 server：又叫做broker，服务端 connection：网络连接，应用端和服务端的连接 channel：网络信道，消息读写的通道，客户端可以建立多个通道，每一个通道表示一个会话任务；类似于数据库的session，建立连接后建立session；channel也是，建立连接后先建立channel message：消息；不同的协议定义的消息结构不一样，rabbitmq的消息结构又properties属性和body消息体组成；properties定义消息属性，body就是消息内容 virtual host：虚拟主机；主要用于逻辑隔离。最上层的消息路由；一个虚拟主机中可以含有若干个exchange和queue，但是同一个虚拟主机中不能含有相同名称的exchange和queue exchange交换机：接受消息，根据路由键转发消息到绑定的队列中 binding绑定：exchange和queue之间的虚拟连接，绑定中可以含有routing key routing key：路由规则 queue：消息队列 TTL：过期时间：过期不被消费自动移除 exchange交换机 name：交换机名称 type：交换机类型，direct，topic，fanout,headers direct：直连，生产端的routingkey和消费端的routiungkey完全匹配绑定，否则抛弃消息 topic：模糊匹配，#一个或者多个，*就一个， fanout：广播，不做任何路由匹配，最快 headers： durability：持久化 aotu delete：当最后一个绑定在exchange上的队列删除后，自动删除exchange binding 绑定关系 exchange交换机和queue队列绑定 exchange交换机和交换机也可以绑定，相当于调用链变长 消息的可靠性投递 怎么样才算是消息百分之百投递成功 生产者客户端保证消息成功发出 mq节点broker成功接受并发出ack确认接收应答（异步回调） 发送端收到mq的确认应答 对于未接受到ack的消息进行补偿重发 rabbitmq提供的confirm消息确认机制 服务端发送消息给broker后，broker收到消息后会回复一个确认ack，服务端异步监听接受这个确认ack channel上开启确认模式：channel.confirmSelect() channel上添加监听：addConfirmListener；具体结果具体处理，重发还是丢弃 rabbitmq提供的return返回消息机制 return listener 用于处理一些不可路由的消息；当前exchange不存在或者路由routingkey不可达 mandatory属性：为true，监听器会接受处理路由不可达的消息，然后进行后续处理；为false，则broker自动删除该消息 解决方案样例 消息落库，对消息状态标记（会产生两次落库操作，多一次消息落库操作） 发送前将消息落库（业务数据落库，例如订单已提交；消息数据落库，消息已发出状态为0） 发送消息给MQ MQ给发送端发送确认消息ack，并将库中消息状态更新由0改为1(MQ已收到) 分布式定时任务（保证同一时刻只有一个应用服务器操纵库）轮询检查库中消息的状态，将状态为0的消息重复发送，直到达到重试上限，标记消息状态为2（消息发送失败） 消息延迟投递，二次确认，回调检查（减少库的交互操作，提高并发） （大厂不加事务，严重影响性能） 发送消息前业务数据落库，不操作消息数据，直接发送消息出去给queue1（五分钟后（指定延迟时间）会有一个消息检查机制发送消息给queue2询问之前发送的消息是否处理成功） broker中queue1收到消息 消费者从queue1消费消息成功，并回发一个给MQ一个确认ack消息到queue3 三方回调应用callback会在broker的queue3消费ack确认消息并将其结果落库，与此同时，三方回调应用还会消费queue2的询问消息，到库中查询ack确认记录是否存在，否，发起RPC调用通知应用服务器，你发送的这条消息没有被正常处理，建议重新发送 spring amqp代码样例12345678910111213141516171819// rabbitmq自带的消息投递的可靠性保证，1. 回调ack，2. broker处理异常返回rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (!ack) &#123; // correlationData是个 null // 如何保证可靠性投递，以及避免重复投递，内存中保留发送前的唯一id，收到ack为true后删除，ack为false重发或者其他，未收到ack说明ack丢失，但是消息不一定丢失（分情况考虑） // 消息发送失败, 此回调中没有消息内容，没法进行重发// log.warn("消息发送失败:correlationData(&#123;&#125;)),cause(&#123;&#125;)", correlationData, cause); &#125; &#125;&#125;);rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; // 消息不可达，exchange不存在，或者routingkey找不到对应的queue// log.info("消息丢失:exchange(&#123;&#125;),route(&#123;&#125;),replyCode(&#123;&#125;),replyText(&#123;&#125;),message:&#123;&#125;", exchange, routingKey, replyCode, replyText, new String(message.getBody())); &#125;&#125;); 消息的可靠性消费 其实与生产端类似，都是异步ack机制，只不过是有broker操控，所以消费端能做的就是做到消息幂等和避免重复性消费 rabbitmq提供的自定义消费者 消费者其实就是监听队列中是否含有消息，监听其实就是轮询 rabbitmq提供了一个defaultConsumer来继承可以实现自定义消费者，避免了手动写while循环去 spring amqp代码样例123456789101112131415161718192021222324252627282930313233@RabbitListener(queues = &#123;STOCK_SYNC_QUEUE_1&#125;, containerFactory = "stockSyncContainerFactory", autoStartup = "true")// @RabbitHandler public void handler(@Payload MqMsgParam param, Message message, Channel channel) &#123; try &#123; // 业务逻辑处理// log.info("业务逻辑处理正常-----消费端拿到的消息来自&#123;&#125;，消息内容为：&#123;&#125;", param.getNickNo(), param.getMessage());// log.info("业务逻辑处理正常----2-----消费端拿到的消息来自&#123;&#125;，消息内容为：&#123;&#125;", param.getNickNo(), param.getMessage());// Thread.sleep(10000);// log.info("Message 的内容是否能获取到：&#123;&#125;", message.getMessageProperties().getContentType()); &#125; catch (Exception e) &#123; // 业务执行失败，给broker回传告诉重回队列，重新消费// try &#123;// channel.basicNack(message.getMessageProperties().getDeliveryTag(), true, true);// &#125; catch (IOException ex) &#123;// ex.printStackTrace();// // 回传nack失败// &#125; &#125; // 业务逻辑全都正确处理完成，给broker回传ack try &#123; // 实际测试表明，basicQos()的设置只是限制了broker一次性发给consumer的消息数量，并不会因为某一个consumer消费能力弱就会把多余的消息负载均衡到其他consumer； // broker只会把消息平均分发给各个consumer channel.basicQos(1);// channel.basicQos(1, false); // prefetchSize：服务器将传送的最大内容量（消息的大小限制）（以八位字节为单位） // prefetchCount：消息的个数限制// channel.basicQos(1, 1, false); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; catch (IOException e) &#123; e.printStackTrace(); // 业务处理成功， 但是回传ack失败，最终会导致重复消费 &#125; &#125; 消息幂等和重复消费 由于broker提供了异步ack机制来确保消息的不丢失，但是与此同时造也成了某些情况下，由于消费端的原因，未能将ack回传broker，所以就会导致消息的重回队列重新消费 解决方案 唯一id+指纹码；利用数据库主键去重 指纹码：业务规则，区别统一id的不同的操作 先查后操作 利用id路由分库分表实现多库的幂等 利用redis原子性实现 如果需要落库，怎么保证库和缓存的一致性 不落库，怎么设置缓存的同步策略 rabbitmq提供的消费端的消息限流 消费端关闭自动签收autoACK，避免将消息队列中堆积的消息一次性全部涌进消费端服务器 消费端设置一次接受多少条消息（prefetch），处理完后发送ack给消息队列，然后在发送一部分，依次类推 消费端ack和重回队列 确定消费端收到来自消息队列的消息，可以自动ack，可以手动ack，也可以nack（表示没有接收到消息） 处理失败的消息可以发回重新发送，重新消费 重回队列将处理失败的消息重新放回队列的尾部排队重新发送消费处理 消息处理失败后可以选择重回队列重新处理，也可以直接丢弃 消息的TTL有效期 消息发送时指定的ttl 消息队列中的消息有效期，从进入队列后起的一定有效时间内没有被消费即被丢弃 死信队列 dead-letter-exchange 当消息在队列（队列会设置监听检测是否含有死信消息）中变成死信消息后便会被发送到指定的死信exchange中，然后通过死信exchange绑定的队列进行统一发送处理 死信消息（即不会被消费端消费的消息） 消息被拒绝 消息ttl过期 队列达到最大长度 rabbitmq整合spring AMQP rabbitAdmin @configuration标注配置文件 @configScan配置扫描路径 注入rabbitmq的connectionFactory设置连接信息以连接配置，利用springboot的catchingConnectionFactory注入 利用注入的连接工厂connectionFactory来注入rabbitAdmin并设置属性autoStartUp为true rabbitAdmin底层实现：使用rabbitTemplate的execute方法实现一系列基础的rabbitmq操作 在service类中，使用@autowired引入rabbitAdmin后便可以开始使用 bindingBuilder工具类， 绑定交换机和队列的同时进行声明交换机和队列 spring把rabbitmq中所有内容都封装成了对象，例如，交换机DirectionExchange类…Queue类等；原生客户端我们是直接写字符串类定义，spring封装成了对象，并添加了额外属性。 springAMQP声明交换机，队列，绑定 原生api中我们使用channel来声明交换机，队列，绑定 spring中直接在配置类中使用@Bean注入类对象即可 rabbitmq Tamplate 消息模板，提供了丰富的发送消息的方法 @Bean注入RabbitTemplate spring封装的属性消息类：MessageProperties，消息类Message MessagePostProcessor类：消息发送前的统一处理（前置，后置都有），重写postProcessorMessage()方法 simpleMessagelistenerContainer 简单消息监听容器，可以动态设置属性，运行中动态配置 @Bean注入，注入后设置监听容器属性，例如消费者数量等… MessagelistenerAdapter 消息监听适配器，适配器设计模式 消息监听类ChannelAwareMessageListener，消息监听容器设置监听类的时候，可以直接把消息监听类ChannelAwareMessageListener设置进去，也可以利用设计模式将消息监听适配器设置进去 MessagelistenerAdapter实例化的时候传入一个参数，这个参数就是自定义的消息设置类 自定义的消息设置类可以实现消息发送的方法名，消息类型转换MessageConvert等 可以设置队列和方法进行绑定，指定特定方法接受处理指定队列中的消息 MessageConvert 消息转换器接口，默认消息方法接受参数byte[] 简单消息监听容器simpleMessagelistenerContainer设置消息监听适配器MessagelistenerAdapter，消息监听适配器MessagelistenerAdapter设置消息转换器MessageConvert； Jackson2JsonMessageConvert:转json转换器，json格式对应java中map对象 messageproperties消息属性中设置消息类型conextType(“application/json”) DefaultMessageConvert:转Java对象转换器，必须使用下面的固定格式 messageproperties.setHandler(“TypeId“,”Java对象类的全路径”) 转多个Java对象转换器：用了一个map来标记标签和Java对象类的全路径之间的对应关系，然后就可以使用标签来替代Java对象类的全路径实现消息转换 ContentTypeDelegatingMessageConver全局消息转换器，可以设置多个消息转换器，根据不同的contentType自动转换成对应的消息格式（图片，pdf，文本…） rabbitmq整合springboot- RabbitTemplate.confirmCallback：消息发送确认 - RabbitTemplate.returnCallbeak：消息不可达返回 - CorrelationData：消息id规则自定义（必须保证全局唯一） - 配置手工确认模式 - 消费端监听：@RabbitListener（原生的时候我们使用while循环来实现消费端监听，整合spring后我们可以自定义消费端监听类），组合注解；配合注解@RabbitHandler使用，用在消费端接受消息方法上 - AMQPHeader常量类 - @PayLoad注解，@Headers：spring提供的注解来标记消息体和消息header；用在消费端接受消息方法上 rabbitmq整合springcloud spring cloud stream：可以对接kafka，rabbitmq；但是定位方向与kafka类似，为提供高性能的消息服务，所以提供的消息不能保证百分之百的可靠性投递 @output注解，定义消息输出通道 @input注解，定义消息接受通道 @streamlistener(参数为@input)：监听消息接受通道，处理消息 配置文件中配置好交换机，队列，绑定关系 可以实现异构，生产端用rabbitmq，消费端用kafka rabbitmq集群架构 主备模式，简称warren（兔子窝）模式 haproxy：tcp级别的代理，负责协调主备的切换 远程模式：可以实现双活的一种模式，简称shovel模式 远程复制，如果本区域的mq集群压力过大，则会将消息转发到其他地域压力不大的mq集群上，然后在进行消息的消费 将消息的进行不同数据中心的复制，实现跨地域的两个mq集群互联 镜像模式（mirror模式） 保证百分之百数据不丢失 主要就是实现数据同步（一般三个节点就可以实现100%数据不丢失） haproxy实现负载均衡 多活模式 异地复制的主流模式 依赖于federation插件实现数据同步复制 双中心，多中心；两套或者多套mq集群 搭建一个高可用mq服务集群 利用rabbitmq，haproxy，keepalived等 互联网大厂set架构 set：单元化架构，即不同的业务线使用不同的架构集群，集群拆分 IDC 同城双活（多活）架构 多中心，多个架构集群互为主备，主从，实现流量的切换等 但是多中心会涉及到跨机房写，有延迟问题 两地三中心架构 基于灾备思想 在同城双活基础上，异地构建一套灾备数据中心，每个中心都具有完整的数据 同城AB数据同步，异地中心冷备 set架构 业务扩展，容灾是主要考虑目标 一条完整的业务线作为一个集群，例如下单整个完整的业务线部署到同一个机房的一个集群上，在把非核心（出错不影响主业务线的进行）抽象出来单独部署到一个非核心集群上 实现不同的业务线出错后不会影响整个服务，不同业务线之间互不影响，同一业务线上非核心步骤不会影响主流程的进行 中心集群（非核心），单元化集群 set化架构策略 中间件（rpc，kv，mq） rpc：对于set服务，调用封闭在set内，对于非set服务，沿用现有路由逻辑 kv：支持分set的数据产生和查询 mq：支持分set的消息生产和消费 set落地原则 对业务透明 切分：业务维度划分，地域划分 部署原则：最好一个中心，一个机房内，也可以跨地域机房 rabbitmq set架构实现 federation插件实现集群之间的数据同步 federation可以通过broker之间数据同步，而不用通过cluster set架构核心思想 每个单元化集群只负责单元内的流量，实现流量拆分 每个单元化集群只存储单元内的交易数据，后续在做数据同步 rabbitmq实现思路与架构设计方案 基础组件封装 消息高性能的序列化转化，异步化发送消息 生产端消费端实例连接池 可靠性消息投递，保证消息百分之百不丢失 消费端幂等操作，避免重复消费 迅速消息，延迟消息，事务消息，顺序消息 消息补偿，重试，异常定位 集群负载均衡，消息路由策略 迅速消息发送（高性能，不可靠） 在提到JMS时，我们通常会说到一些术语，解释如下： 消息中间件（JMS Provider) ： 指提供了对JMS协议的第三方组件，比如ActiveMQ就是一个消息中间件，另外比较知名的还有KFA, Rabbit MQ等。 消息模式：分为点对点（Point to Point，即P2P）和发布/订阅（Pub/Sub)，对应的数据结构分别是队列（Queue)和主题（Topic) 消息（Message): 通信内容的载体，其结构主要分为消息头，属性和消息体，并且根据存储结构的不同分为好几种，后面会详细提到。 消息生产者：产生消息的一方，在P2P模式下，指消息发送者(Sender)，在P/S模式下指消息发布者(Publisher) 消息消费者：接收消息的一方，对应于两种模式分别是消息接收者（Receiver）和消息订阅者(Subscriber)]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>RabbitMq</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从Java打包出发，目的地未知]]></title>
    <url>%2F2019%2F12%2F14%2F%E4%BB%8EJava%E6%89%93%E5%8C%85%E5%87%BA%E5%8F%91%2F</url>
    <content type="text"><![CDATA[从Java打包出发，目的地未知 Java原生如何打包 jar命令 打包后的目录结构 war命令 打包后的目录结构 springboot打包 自定义maven打包插件 自定义类加载器 如何打破双亲委派模型 如何内嵌tomcat容器 目录结构有什么变化 待续 javac -cp dependency.jar */.java -d target：编译目录下所有java文件到指定目录target下 Java原生如何打包jar命令 用法: jar {ctxui}[vfmn0PMe] [jar-file] [manifest-file] [entry-point] [-C dir] files … 选项: -c 创建新档案 -t 列出档案目录 -x 从档案中提取指定的 (或所有) 文件 -u 更新现有档案 -v 在标准输出中生成详细输出 -f 指定档案文件名 -m 包含指定清单文件中的清单信息 -n 创建新档案后执行 Pack200 规范化 -e 为捆绑到可执行 jar 文件的独立应用程序指定应用程序入口点 -0 仅存储; 不使用任何 ZIP 压缩 -P 保留文件名中的前导 ‘/‘ (绝对路径) 和 “..” (父目录) 组件 -M 不创建条目的清单文件 -i 为指定的 jar 文件生成索引信息 -C 更改为指定的目录并包含以下文件 如果任何文件为目录, 则对其进行递归处理。清单文件名, 档案文件名和入口点名称的指定顺序与 ‘m’, ‘f’ 和 ‘e’ 标记的指定顺序相同。 打包样例 示例 1: 将两个类文件归档到一个名为 classes.jar 的档案中:jar cvf classes.jar Foo.class Bar.class 示例 2: 使用现有的清单文件 ‘mymanifest’ 并将 foo/ 目录中的所有文件归档到 ‘classes.jar’ 中:jar cvfm classes.jar mymanifest -C foo/ jar打包后的目录结构 命名空间目录（package关键字后面的目录结构） META-INF目录 MANIFEST.MF（清单文件） services（） Manifest文件规格要求 Manifest-Version：表示版本号，一般由IDE工具（如eclipse）自动生成 Main-Class：是jar文件的主类，程序的入口 Class-Path：指定需要的jar，多个jar必须要在一行上，多个jar之间以空格隔开，如果引用的jar在当前目录的子目录下，windows下使用\来分割，linux下用/分割，文件的冒号后面必须要空一个空格，否则会出错，文件的最后一行必须是一个回车换行符，否则也会出错 jar命令打包时默认会在jar包中添加清单(manifest)文件，如果不想添加，手动指定-M选项 如果要生成可以运行的jar包，需要指定jar包的应用程序入口点，用-e选项 注意 在清单文件中指定CLASSPATH 在运行java命令的时候，如果指定了-jar选项，那么环境变量CLASSPATH和在命令行中指定的所有类路径都被JVM所忽略。这时，如果一个jar包引用了其它的jar包，解决方案有两个： java -cp lib\log4j-1.2.14.jar;hello.jar（手动指定依赖的jar包） com.dhn.Hello （com.dhn.Hello为主类） 在windows下多个jar之间以分号（;）隔开,最后还需要指定运行jar文件中的完整的主类名。 java -jar hello.jar 这种，需要修改hello.jar中的MANIFEST.MF，通过MANIFEST.MF中的Class-Path 来指定运行时需要用到的其他jar，其他jar可以是当前路径也可以是当前路径下的子目录。多个jar文件之间以空格隔开。样例如下： 延申ServiceLoader SPI，全称Service Provider Interfaces，服务提供接口。是Java提供的一套供第三方实现或扩展使用的技术体系。主要通过解耦服务具体实现以及服务使用，使得程序的可扩展性大大增强，甚至可插拔。基于服务的注册与发现机制，服务提供者向系统注册服务，服务使用者通过查找发现服务，可以达到服务的提供与使用的分离，甚至完成对服务的管理。 JDK中，基于SPI的思想，提供了默认具体的实现，ServiceLoader。利用JDK自带的ServiceLoader，可以轻松实现面向服务的注册与发现，完成服务提供与使用的解耦。 完成分离后的服务，使得服务提供方的修改或替换，不会给服务使用方带来代码上的修改，基于面向接口的服务约定，提供方和使用方各自直接面向接口编程，而不用关注对方的具体实现。同时，服务使用方使用到服务时，也才会真正意义上去发现服务，以完成服务的初始化，形成了服务的动态加载。 META-INF/services/，是ServiceLoader中约定的接口与实现类的关系配置目录，文件名是接口全限定类名，内容是接口对应的具体实现类，如果有多个实现类，分别将不同的实现类都分别作为每一行去配置 war命令 用于 web applicaiton 项目打包; servlets主要负责处理网络请求并回传响应，是java体系中网络交互的一套标准 JSP是包含了前端页面处理展示和servlets war打包后的目录结构 servlets JSPS JSP static html file WEB-INF classes(项目代码) lib(依赖包) web.xml(deployment descriptor) springboot打包 使用spring-boot-maven-plugin来完成所有的打包工作 该插件属于自定义插件，Maven的自定义插件 其中springboot自定义了类加载器，打破双亲委派模型]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>Jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式缓存]]></title>
    <url>%2F2019%2F12%2F14%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[分布式缓存 多级缓存层次结构 分布式缓存数据拆分 如何设计缓存的key-value 分布式节点数据交互：序列化 缓存调优 扩展：redis客户端/服务端交互 多级缓存层次结构 浏览器缓存 前端nginx缓存 redis集群等中间件缓存 tomcat集群（应用集群）缓存 数据库缓存 分布式缓存数据拆分分布式数据拆分方案 映射算法：f（key）=i节点 hash算法 范围取值算法 分布式缓存数据拆分后会有那些问题 跨实例数据读取，合并结果 跨实例原子读写依赖请求（涉及到分布式事务） 分布式缓存数据拆分后存在问题的解决方案 数据拆分算法：根据key 的一部分（例如公共命名空间）作为算法的入参，这样可以使得相关数据落在同一实例上，可以解决一部分跨实例原子读写依赖请求 缓存的热点数据和冷数据，存储方式不同，热点数据存ram，冷数据存硬盘 如何设计缓存的key-value？ 确定最频繁访问的查询操作是什么 确定查询操作的条件是single-key还是multiple-key（设计缓存key的关键） 估计各种上限值 最频繁访问的商品详情页的个数 数据最大值多大/KB 考虑时间单位，几乎所有的查询都会涉及到时间因素 redis（或者缓存框架）支持的单key存贮的value值上限 分布式节点数据交互：序列化 网络传输：数据的序列化至关重要 序列化之后的包的大小 序列化时间 对cpu的影响 对GC的影响 可以根据不同的数据类型采用不同的序列化方式提升序列化性能 转义会降低反序列的效率 对大数据采用压缩策略（将timemilles做36-base编码保证字母序关系不变），是否需要数据压缩，取决于数据序列化后的大小，会有一个阈值限制，该阈值综合cpu和网络消耗而定。因为压缩解压都是消耗cpu的操作，虽然压缩可以减少网络的传输，但是压缩需要申请的地址空间可能会影响GC 缓存调优浏览器缓存 页面缓存静态元素，cdn加速 浏览器缓存是根据一套和服务器约定的规则进行的 http1.0提供了基本的缓存特性，服务器设置expires的http请求头告诉客户端缓存过期失效期限，期限内客户端不会去访问服务器，直接拿缓存使用。expired到期后，客户端通过使用if-modified-since-文件最初现在时间请求服务器，如果文件未改变，返回304-not modified应答 http1.1有了新的改进，提供了实体标签e-tag，来标识每一个唯一的文件或者对象，但是使用e-tag每次都会去访问服务器，如果访问资源没有发生变化，返回304-not modified，并提供正确的e-tag。expired的使用优先级高于e-tag的优先级 web代理服务器缓存-正向代理：客户端向代理服务器发送一个请求，同时指定访问目标服务器，代理拿到请求和目标地址，拿请求访问目标地址得到响应，返回给客户端，代理可以缓存目标服务器的响应（客户端需要一定设置才能使用正向代理） 反向代理：客户端不需要进行设置，直接向代理发送普通请求，由代理决定向那个目标服务器发送请求，得到响应再返回客户端 mysql查询缓存—query cache query_cache_size:设置resultset的内存大小 query_cache_type:设置在那种场景下使用 0：off 完全不使用query cache 1：on 除显示要求不使用query cache的select，都使用query cache 2：demand 只用显示要求才会使用query cache 校验query cache的合理性 show varilables like ‘%query_cache%’ show status like ‘%Qcache%’查看缓存使用情况 Qcache hits：标识缓存命中次数 Qcache inserts:标识缓存未命中次数 以上这两个参数值可以计算缓存命中率，从而决定是否开启缓存 Qcache lowmen prunes：内存不足而清理的查询数 Qcache free blocks：缓存碎片数 以上这两个可以查看缓存空间大小设置的是否合理 innodb存储引擎的缓存 innodb_buffer_pool_size:(性能影响最关键的一个参数)innodb索引和数据块缓存，查询使用到的所有索引以及返回结果的数据都会在这个区域查询一遍，所以该区域大小越大越好；类似于myisam中的key_buffer_size 该区域缓存命中率计算公式：(innodb_buffer_pool_read_requests - innodb_buffer_pool_reads)/innodb_buffer_pool_read_requests * 100%；根据该结果调整innodb_buffer_pool_size的大小 mysql 参数table_cache 该参数限制缓存表的数量，每个客户端访问数据库的其中一张表时，会检查是否存在缓存中，存在直接使用，不存在，添加到缓存中，但是需要判定缓存表的数量是否超过table_cache，有一定的缓存淘汰策略 扩展redis客户端与服务器的交互客户端/服务器协议（规定如何交互）协议分为两部分 网络模型：数据交互的组织方式 redis协议位于TCP层之上，客户端和redis实例保持双工连接（即一个连接上，数据有来有返（对照全双工通道）） 序列化协议：数据本身如何序列化 客户端服务器交互的是序列化后的协议数据，在redis中，协议数据分为不同的类型，每种类型均以\r\n结束，通过首字符区分协议数据类型 inline command 表示redis命令 首字符为命令名的字符 simple string 首字符为+ 不能包含\r和\n 不包含转义，因此反序列效率较高（转义会降低反序列的效率） bulk string 特殊string（包含\r和\n的string） 使用长度自描述方式进行处理 首字符为$]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QRCode]]></title>
    <url>%2F2019%2F08%2F11%2FQRCode%2F</url>
    <content type="text"><![CDATA[二维码 説白了就是把信息存儲在圖片二維碼當中，儅二維碼被掃描時，根據統一規約去解析的到相應的信息 條形碼：一維圖形，可支持數據範圍較小，最大20位 使用lua来生成条形码 二維碼：二維圖形，可支持數據範圍大，最大7089位；可全方位掃描識別（二維碼中有三個位置標識來幫助全方位掃描識別）；容錯性，數據部分包含大量的冗餘數據來包幫助實現容錯識別 詳細信息到官方網頁查看詳情：https://www.qrcode.com/en/index.html 身份码 付款码 收款码 乘车码 小程序入口码 离线码 登陆二维码 現實應用身份碼/付款嗎/收款碼 身份二维码 支付宝/微信身份二维码 http://weixin.qq.com/r/L-rg_G-EbIITrZub0097 https://qr.alipay.com/apa2uu7j3tpjyxlr00 身份二维码实际上有用的信息就是指定的URL后面的一个串号。这个串号具有如下特点： 一直固定不变 无法通过此串号获取用户信息 仅能被自己的app识别其深层含义（自家app查询自家数据库），客户app扫码后，将弹出相应的显示详细身份或者加好友的界面 收款二维码 支付寶/微信收款二維碼 https://wx.tenpay.com/f2f?t=AQAAAEBfhXKNRIQUrs6fy4XO8p879 https://d.alipay.com/i/index.htm?b=RECEIVE_AC&amp;u=mGnPJ/rNBfKKKKKDcQlNGn1mthWAVDa7vw00ow5sM4o= 换了一个API，同时后面带上一串和用户账号无关串号。此串号具有如下特点： 一直固定不变 无法通过此串号获取用户信息 仅能被自己的app识别其深层含义（自家app查询自家数据库），被客户app扫描后，客户app直接调出向对方账号付款的界面 付款二維碼 在付款二维码上，微信和支付宝是差不多的，都是一串每分钟就会变一次的一串数字： 284308793673642130 付款码的前两位是用来区分具体是支付宝的付款码还是微信支付的付款码 核心是要识别付款方二維碼所代表的那个18位的数字 此二维码信息具有如下特点： 是一串不带API的纯数字串 每分钟变一次(一分钟强制变一次;能且只能被使用一次) 通过指定的SDK以此数字为参数进行接口调用可以完成扣款 安全風險 对申请扣款资格主体身份进行严格审核 限额。将这种扣款方式进行限定，将其局限在小额场景 離綫支付 我们手机上面的付款码其实只是一个加密后的UserID，用普通的扫码枪就能扫描获取付款码上面的数字，然后把这个加密后的UserID和收银员输入的付款金额一起发送到支付宝的服务器即可完成付款，这也解释了为什么支付宝的付款码支持离线支付，只要收款方没有断网就行 离线二维码的技术原型是在行业中广泛使用的一次性口令(OTP, One-time Password) 18位數字原理 方法很多，比如这样： 每个用户登录的时候会生成一对公私钥，公钥发给客户端存起来，可能可以做一些定时刷新之类的事情 支付码=版本信息+userId+rsa_encypt(userId+nounce+ts, pubKey) 服务端收到支付码，用userId取来私钥，解开密文，验一下ts就好。服务端记录nounce，每个只能支付一次。 需要一个风控系统，ip爆破封ip，用户爆破封用户，谁爆破封谁就行了。具体实现有很多变数 app上的扫码所对应的场景众多，必须要做一定的区分，所以带上API名称 条码枪对应的场景单一，仅仅只是扣款，所以二维码只需要对参数进行编码即可 易通行二維碼 歸根到底是一種匹配碼，如何做到進站/出戰的匹配，然後進行路程金額的計算，最後直接三方支付接口的調用扣款 動態的實時變化，也是每分鐘一次，進可用一次 小程序二維碼 僅僅是用來存儲一些固定信息，如店鋪網址存入二維碼中做分享碼 離綫二維碼 粗淺设计思路 客戶端登陸，服务器生成唯一token，通过加密方式(如https)传递到客户端 打开付款码时，本地生成一段含有token与当前时时间戳的哈希值，如sha1(token+UnixTimestamp)，转换为byte[]并截取指定长度后转换为int变量otp 將支付用户账号(手机号)为int变量id 设otp在[0,n]中，通过code=id*n+otp，即可将OTP与ID合并在同一个数字里，成为最终的条形码/二维码，并每间隔指定时间更新一次 通过商家扫码枪扫描，服务端获取了code，通过(int)(code/n)就得到了id，通过code%n就得到了otp 通过id找到token，通过当前时间戳与前后若干个相同间隔的时间戳以步骤2相同的方法生成对应的一组otps[]，用于容许客户端和服务端之间的时间差 将从客户端得到的otp与otps[]中的元素逐一比对，如有相同项，则为验证通过。 离线二维码安全，核心就是在token的保密 传输：token的传输经过加密，可防止传递过程中数据包被截取。 保存：token保存在app的独立空间中可能会被恶意程序获取到，这个问题理论上仅存在于已开放root权限的手机中。在产品安全的角度，只能限制root手机用户使用，解决办法可以是当客户端获知用户的手机root过以后通知服务端降低该用户的消费限额。 二维码登陆 移动端的登陆的会携带设备id（唯一）等信息，服务端生成的token会保存在移动端本地，所以后台退出/关机等都操作后仍然可以直接登陆成功 浏览器/客户端向服务器发送请求获取二维码，同时服务端生成唯一标识id返回给客户端（二维码信息中包含唯一标识id），唯一标识id存储在redis中，设置一定的过期时间 浏览器/客户端显示登陆二维码，同时轮询请求登陆验证接口，时间间隔自定义，taobao网页不到一秒，知乎网页3秒 根据每次的请求结果可以知晓当前的状态（待扫描，已扫瞄待确认，已确认） 超过指定时间不扫描二维码过期 如果结果是已确认后，会从服务端可以获取到用户登录的token； 移动端已登陆用户扫码请求服务端 服务端解析，获取到唯一标识id，接口类型（是否是登陆接口请求） 将服务端redis中唯一标识id的状态由待扫描变更为已扫瞄待确认 同时生成临时token（用来标识后续的确认登陆请求和扫描请求的关联性）返回给浏览器/客户端 浏览器/客户端使用临时token确认登陆请求 将服务端redis中唯一标识id的状态由已扫瞄待确认变更为已确认 服务端收到确认后，根据二维码ID绑定的设备信息与账号信息，生成用户PC端登录的token； 登陆成功，浏览器/客户端根据服务端生成的toekn进行交互]]></content>
      <categories>
        <category>QRCode</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>QRCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javadoc]]></title>
    <url>%2F2019%2F04%2F28%2FJavadoc%2F</url>
    <content type="text"><![CDATA[Javadoc 注释 用法 @author @author name-text；标识作者 {@code} {@code text}；将文本标记为code代码，避免被解析为html标签或者javadoc标签 {@docRoot} 标识生成doc文档的根目录 注释 用法 @author @author name-text；标识作者 {@code} {@code text}；将文本标记为code代码，避免被解析为html标签或者javadoc标签 {@docRoot} 标识生成doc文档的根目录 @deprecated 标识已弃用；用法样例：/* @deprecated As of JDK 1.1, replaced by {@link #setBounds(int,int,int,int)} / @exception @exception class-name description；描述异常，和@throws搭配使用 {@inheritDoc} 继承文档内容，把基类的注释继承下来 {@link} {@link package.class#member label}；【包名.类名#方法名(参数类型) 标签】标识一个类或者方法的链接，可直接点击实现跳转 {@linkplain} 与{@link}相同，但链接的标签label以纯文本显示，而不是代码字体。标签是纯文本时很有用 {@literal} {@literal text}；展示test文本不被解析为html标签和javadoc标签，即可以使用尖括号等字符而不必使用转义字符&lt; and &gt; @param @param parameter-name description；参数说明 @return @return description；返回值说明 @see @see reference；标识相关内容引用；例如 @see @see “string” @see @see label @see @see package.class#member label @see @see Typical forms for @see package.class#member @see Referencing a member of the current class @see @see #field @see @see #method(Type, Type,…) @see @see #method(Type argname, Type argname,…) @see @see #constructor(Type, Type,…) @see @see #constructor(Type argname, Type argname,…) @see @see Referencing another class in the current or imported packages @see @see Class#field @see @see Class#method(Type, Type,…) @see @see Class#method(Type argname, Type argname,…) @see @see Class#constructor(Type, Type,…) @see @see Class#constructor(Type argname, Type argname,…) @see @see Class.NestedClass @see @see Class @see @see Referencing an element in another package (fully qualified) @see @see package.Class#field @see @see package.Class#method(Type, Type,…) @see @see package.Class#method(Type argname, Type argname,…) @see @see package.Class#constructor(Type, Type,…) @see @see package.Class#constructor(Type argname, Type argname,…) @see @see package.Class.NestedClass @see @see package.Class @see @see package @serial @serial field-description [ include ][ exclude ]；标识是否参与序列化，类级别覆盖包级别 @serialData @serialData data-description；数据描述记录了序列化形式的数据类型和顺序。 具体来说，此数据包括writeObject方法写入的可选数据以及Externalizable.writeExternal方法写入的所有数据（包括基类）。 @serialData标记可以在writeObject，readObject，writeExternal，readExternal，writeReplace和readResolve方法的doc注释中使用。 @serialField @serialField field-name field-type field-description；标识序列化字段 @since @since since-text；表示代码的支持时间或者版本 @throws @throws class-name description；说明异常抛出 {@value} {@value package.class#field}；1.不加任何参数使用在常量字段上时，表示常量的值；2.加参数使用在任何地方，表示使用的是参数那个指定常量值 @version @version version-text；代码版本号]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Javadoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql Function]]></title>
    <url>%2F2019%2F04%2F21%2FMySql%20Function%2F</url>
    <content type="text"><![CDATA[MySql Function LAST_INSERT_ID GROUP_CONCAT CONCAT_WS FIND_IN_SET batch update LAST_INSERT_ID mysql 插入数据后返回自增 ID GROUP_CONCAT mysql分组连接函数—纵向同一个字段的多个值拼接查询输出 group_concat([DISTINCT] 要连接的字段 [Order BY ASC/DESC 排序字段] [Separator ‘分隔符’]) eg：select userId,group_concat(role_name,’;’) from role group by userId; 按USERID分组后，再将同组的role_name进行字符串连接就OVER。 CONCAT_WS mysql横向多字段拼接查询输出 eg：select CONCAT_WS(“—“,ppr.full_price,ppr.purchase_price) from b2c_purchase_price_rule as ppr; FIND_IN_SET Returns a value in the range of 1 to N if the string str is in the string list strlist consisting of N substrings. A string list is a string composed of substrings separated by , characters. If the first argument is a constant string and the second is a column of type SET, the FIND_IN_SET() function is optimized to use bit arithmetic. Returns 0 if str is not in strlist or if strlist is the empty string. Returns NULL if either argument is NULL. This function does not work properly if the first argument contains a comma (,) character. mysql&gt; SELECT FIND_IN_SET(‘b’,’a,b,c,d’); -&gt; 2 FIELD Returns the index (position) of str in the str1, str2, str3, … list. Returns 0 if str is not found.If all arguments to FIELD() are strings, all arguments are compared as strings. If all arguments are numbers, they are compared as numbers. Otherwise, the arguments are compared as double.If str is NULL, the return value is 0 because NULL fails equality comparison with any value. FIELD() is the complement of ELT(). mysql&gt; SELECT FIELD(‘Bb’, ‘Aa’, ‘Bb’, ‘Cc’, ‘Dd’, ‘Ff’); -&gt; 2 利用jooq中现有函数构造CONCAT_WS函数123456789101112131415161718/** * mysql CONCAT_WS(separator,str1,str2...)函数 * * @paramseparator分隔符 * @paramfields分割字段 * @return组合后的String类型字段 */public static Field&lt;String&gt; concatWs(String separator, Field&lt;?&gt;... fields) &#123; if (fields.length == 0) &#123; return null; &#125; Field&lt;String&gt; head = cast(fields[0], String.class); head = Arrays.stream(fields).skip(1).reduce(head, (field1, field2) -&gt; concatHandler(field1, field2, separator)).cast(String.class); return head;&#125;private static Field&lt;String&gt; concatHandler(Field&lt;?&gt; head, Field&lt;?&gt; next, String separator) &#123; return concat(concat(cast(head, String.class), separator), cast(next, String.class));&#125; Mysql批量更新实现方式 update table_name set columns = values where id in (1,2,3,4,5,6…….) INSERT into table (id, fruit) VALUES (1, ‘apple’), (2, ‘orange’), (3, ‘peach’) ON DUPLICATE KEY UPDATE fruit = VALUES(fruit); UPDATE table SET column2 = (CASE column1 WHEN 1 THEN ‘val1’ WHEN 2 THEN ‘val2’ WHEN 3 THEN ‘val3’ END) WHERE column1 IN(1, 2 ,3);（相当于某一列基于另一列而条件更新）]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Date]]></title>
    <url>%2F2019%2F04%2F14%2FNew%20Date%2F</url>
    <content type="text"><![CDATA[java8 Date新特性各个日期时间工具类的输出格式12345678910111213141516Date utilDate = new Date();java.sql.Date sqlDate = new java.sql.Date(System.currentTimeMillis());Time sqlTime = new Time(System.nanoTime());Timestamp sqlTimestamp = new Timestamp(System.currentTimeMillis());Calendar calendar = Calendar.getInstance();System.out.println(&quot;utilDate：&quot; + utilDate.toString());System.out.println(&quot;sqlDate：&quot; + sqlDate.toString());System.out.println(&quot;sqlTime：&quot; + sqlTime.toString());System.out.println(&quot;sqlTimestamp：&quot; + sqlTimestamp.toString());System.out.println(&quot;currentTimeMillis：&quot; + System.currentTimeMillis());System.out.println(&quot;nanoTime：&quot; + System.nanoTime());System.out.println(&quot;---------------before java8----------------------&quot;);System.out.println(&quot;LocalDate：&quot; + LocalDate.now().toString());System.out.println(&quot;LocalTime：&quot; + LocalTime.now().toString());System.out.println(&quot;LocalDateTime：&quot; + LocalDateTime.now().toString());System.out.println(&quot;Instant：&quot; + Instant.now().toString()); 工具类 输出格式 utilDate Sun Sep 01 09:19:39 CST 2019 sqlDate 2019-09-01 sqlTime 04:51:33 sqlTimestamp 2019-09-01 09:19:39.082 currentTimeMillis 1567300779105 nanoTime 30748304283600 LocalDate 2019-09-01 LocalTime 09:19:39.274 LocalDateTime 2019-09-01T09:19:39.276 Instant 2019-09-01T01:19:39.276Z LocalDateTime工具类是设计为使用者（人）阅读使用；而Instant工具类是设计为机器阅读使用，其建模格式为unix元年开始经历的秒数 util包下面的Date是Java设计为Java程序所使用的，既包含日期，又包含时间。但是其展示格式易读性较差。并且不能直接的格式化为其他的表现形式，必须借助格式化工具类才能实现；而sql包下面的Date（继承自util包的Date）、Time、Timestamp是专门设计为契合数据库中日期时间格式所设计的，所以其表现形式和数据库格式保持一致，可读性也良好。同时将日期拆分到Date中，时间拆分到Time中，日期时间集中到Timestamp中。并且含有相应的静态方法和实例方法来进行格式转换。新的日期时间工具类 LocalDate，日期，不可变类final //获取当前日期 LocalDate localDate = LocalDate.now(); //构造某一天的日期 LocalDate localDate = LocalDate.of(2019,8,4); //获取日期的年，月，日，星期等相对信息 localDate.getYear() localDate.getDayOfMonth() localDate.getDayOfWeek() localDate.getMonth() localDate.getDayOfYear() LocalTime，时间，不可变类final //获取当前时间 LocalTime localTime = LocalTime.now(); //构造某一时刻的时间 LocalTime localTime = LocalTime.of(12,8,4); //获取时间的时，分，秒，纳秒等相对信息 localTime.getHour() localTime.getMinute() localTime.getSecond() localTime.getNano() localTime.toSecondOfDay()//当前时间兑换成一天中的秒 -LocalDateTime ，日期时间，不可变类final //获取当前时间 LocalTime localTime = LocalTime.now(); //构造某一时刻的时间 LocalTime localTime = LocalTime.of(12,8,4); //获取时间的时，分，秒，纳秒等相对信息 localTime.getHour() localTime.getMinute() localTime.getSecond() localTime.getNano() localTime.toSecondOfDay()//当前时间兑换成一天中的秒 格式转化格式化日期时间工具类SimpleDateFormat util.Date工具类本身不具备格式化转换的能力，必须依赖于格式化工具类SimpleDateFormat来实现格式转化。因此util.Date并不常用。 SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;); util.Date转字符串 String stringDate = (new SimpleDateFormat(“yyyy-MM-dd hh:mm:ss”)).format(new util.Date()) 字符串转util.Date Date parseDate = format.parse(“2019-09-01”); 由于sql包下工具类的表现形式的易读性，所以直接调用toString()方法即可实现字符串格式转化。但是当遇到特殊格式的时候（例如年月2019-09）还是需要借助格式化工具类SimpleDateFormat来实现；并且sql包下的日期时间工具类新增了与Java8新日期时间工具类的转化方法 sql.Date转字符串 sqlDate.toString()（实例方法） 字符串转sql.Date sql.Date.valueOf(“2019-09-01”)（静态方法） sql.Time转字符串 sqlTime.toString()（实例方法） 字符串转sql.Time sql.Time.valueOf(“12:12:12”)（静态方法） Timestamp转字符串 timestamp.toString()（实例方法） 字符串转Timestamp Timestamp.valueOf(“2019-09-01 12:12:12”)（静态方法） 由于sql.Date继承自util.Date，所以sql.Date可以直接向上转型为util.Date，但是util.Date不能直接转为sql.Date util.Date转sql.Date sqlDate = new java.sql.Date(utilDate.getTime()) sql.Date转util.Date utilDate = sqlDate（向上转型） 借助中间状态String字符串来实现Timestamp和Date的相互转化 TimeStamp转Date sql.Date.valueOf(timestamp.toString()) Date转Timestamp Timestamp timestamp = Timestamp.valueOf(sqlDate.toString()) Java8新增的日期时间工具类兼容了对旧的工具类的转化方法 旧工具新增方法 LocalDate localDate = sqlDate.toLocalDate();（实例方法将旧工具类转为新工具类） java.sql.Date sqlDate = java.sql.Date.valueOf(LocalDate.now());（静态方法将新工具类转为旧工具类） Date，Time，Timestamp同理如上 LocalDateTime：日期时间 通过以下方法可以随时转日期，或者时间 toLocalDate():转日期 toLocalTime():转时间 LocalDate：日期 LocalTime：时间 字符串转日期时间（parse）静态方法 LocalDate date = LocalDate.parse(“2019-08-30”); LocalTime time = LocalTime.parse(“12:34:23”); 日期时间的格式为：the text to parse such as “2007-12-03T10:15:30” LocalDateTime dateTime = LocalDateTime.parse(“2019-08-30T12:34:23”); 日期时间转字符串（format）实例方法 localTime.format(DateTimeFormatter.ofPattern(“hh”)) localDateTime.format(DateTimeFormatter.ofPattern(“yy-MM-dd hh:mm:ss”)) localDateTime.format(DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL)) 借助DateTimeFormatter格式化工具类，设置指定格式 ofLocalizedDateTime方法显示格式不是常规的格式 DateTimeFormatter.ofLocalizedDateTime(FormatStyle.FULL) DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL) ofPattern方法可以自定义任意格式 DateTimeFormatter.ofPattern(“yy-MM-dd hh:mm:ss”) 常用的工具方法 plusXXX()：加法，时间，日期，日期时间的任意加法 minusXXX()：减法，时间，日期，日期时间的任意加法 withXXX()：修改时间日期方法 date.withYear(2000)：将日期的年份修改为2000，其他保持不变，返回修改后的新日期 isAfter()：比较函数 isBefore()：比较函数 isEquels()：比较函数 高级复杂日期时间操作 java8之前可以借助Calendar工具类来实现复杂的日期时间操作 calendar = Calendar.getInstance(); Duration和Period Duration和Period都可以用来计算日期时间间隔，以及时间的加减法等操作，但是Duration主要以秒和纳秒衡量时间长短，也就是Duration不能操控LocalDate；使用Duration计算的间隔可以是秒，纳秒，小时，天；而Period可以操控LocalDate，并且Period计算的间隔可以是年，月，日。各司其职吧！ Duration Duration duration = Duration.between(localDateTime1,localDateTime); duration.toDays() Period Period period = Period.between(localDate,localDate1); period.getYears() TemporalAdjusters 常用工具方法中我们知道了withXXX()方法可以修改给定的时间，但是当我们想要获取基于当前时间的前一周，前一个月，本月的第一天等操作时，就需要额外的辅助工具类来实现了，那就是TemporalAdjusters工具类，它提供了众多的静态方法，来作为withxxx(TemporalAdjusters tem)方法的入参，以此来实现复杂的日期时间修改操作。 LocalDateTime.now().with(TemporalAdjusters.firstDayOfNextMonth());]]></content>
      <categories>
        <category>Date</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高级模糊查询]]></title>
    <url>%2F2019%2F04%2F07%2F%E9%AB%98%E7%BA%A7%E6%A8%A1%E7%B3%8A%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[高级模糊查询 LIKE REGEXP LIKE/NOT LIKE String Expressions字符串表达式匹配规则 like是我们常用的模糊查询关键字，其支持的通配符有 %，_,escape %：匹配任意数量（包括0）的字符 _：匹配具体确定的一个字符 escape：指定使用某个字符作为转义符，然后加在匹配表达式中 select MAX_DATA_LENGTH from tables where MAX_DATA_LENGTH like ‘28,%’ ESCAPE ‘,’;//指定使用逗号作为转义字符 转义字符（默认为反斜杠\）可以把通配符变成普通字符 \% 表示一个%字符，没有通配符的作用 _ 表示一个_字符，没有通配符的作用 REGEXP Regular Expressions正则表达式匹配规则 LIKE支持的通配符有限，所以查询结果也就比较受限制，而REGEXP字段支持更灵活的通配符，具有正则表达式一样的功能 LIKE和REGEXP所支持的通配符相互隔离，不能调换使用 Regular Expressions有哪些 NOT REGEXP：REGEXP的反向匹配 REGEXP：整个字符串匹配表达式 REGEXP_INSTR()：从字符串指定开始索引出开始匹配表达式 REGEXP_LIKE()：等价于REGEXP REGEXP_REPLACE()：替换匹配到表达式的子串 REGEXP_SUBSTR()：返回匹配到表达式的子串 RLIKE：等价于REGEXP Regular Expressions用法 expr NOT REGEXP pat 等价于 expr NOT RLIKE pat 等价于 NOT (expr REGEXP pat)：查找没匹配到的 expr REGEXP pat 等价于 expr RLIKE pat：查找匹配到的 REGEXP_INSTR(expr, pat[, pos[, occurrence[, return_option[, match_type]]]]) pos: 匹配的起始位置，默认是1 occurrence: Which occurrence of a match to search for. If omitted, the default is 1. return_option: 返回类型，1表示返回匹配的子串的首字母位置，0表示返回匹配到的子串 match_type: A string that specifies how to perform matching. The meaning is as described for REGEXP_LIKE(). REGEXP_LIKE(expr, pat[, match_type]) match_type：匹配类型 c：大小写敏感 i：大小写不敏感 REGEXP_REPLACE(expr, pat, repl[, pos[, occurrence[, match_type]]]) REGEXP_SUBSTR(expr, pat[, pos[, occurrence[, match_type]]]) Regular Expression 表达式语法 ^：^foo表示匹配以foo开头的所有字符串 $：ed$表示匹配以ed结尾的所有字符串 .：匹配任意一个字符 a*：匹配任意多个（包括0）a字符===等价于 a{0,} a+：匹配一个或者多个a字符===等价于 a{1,} a?：匹配零个或者一个a字符===等价于 a{0,1} a|b：匹配a字符或者b字符 a{n}： 匹配明确n个a字符. a{n,}： 匹配&gt;=n个a字符 a{m,n}： 匹配m到n个a字符 [0-9]：匹配任意一个一位数数字字符 [^0-9]：匹配非数字字符 （^可以取反） 扩展COLLATE 排序的规则。对于mysql中那些字符类型的列，如VARCHAR，CHAR，TEXT类型的列，都需要有一个COLLATE类型来告知mysql如何对该列进行排序和比较。简而言之，COLLATE会影响到ORDER BY语句的顺序，会影响到WHERE条件中大于小于号筛选出来的结果，会影响DISTINCT、GROUP BY、HAVING语句的查询结果。另外，mysql建索引的时候，如果索引列是字符类型，也会影响索引创建，只不过这种影响我们感知不到。总之，凡是涉及到字符类型比较或排序的地方，都会和COLLATE有关。 COLLATE通常是和数据编码（CHARSET）相关的，一般来说每种CHARSET都有多种它所支持的COLLATE，并且每种CHARSET都指定一种COLLATE为默认值。例如Latin1编码的默认COLLATE为latin1_swedish_ci，GBK编码的默认COLLATE为gbk_chinese_ci，utf8mb4编码的默认值为utf8mb4_general_ci。 很多COLLATE都带有_ci字样，这是Case Insensitive的缩写，即大小写无关，也就是说”A”和”a”在排序和比较的时候是一视同仁的。selection * from table1 where field1=”a”同样可以把field1为”A”的值选出来。与此同时，对于那些_cs后缀的COLLATE，则是Case Sensitive，即大小写敏感的。 show collation指令可以查看到mysql所支持的所有COLLATE 字符串函数 LOCATE]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>LIKE</tag>
        <tag>REGEXP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Transaction]]></title>
    <url>%2F2019%2F03%2F31%2FTransaction%2F</url>
    <content type="text"><![CDATA[Transaction 数据库事务 Spring事务 Redis事务 分布式事务 事务 所有的事务，无论是数据库层面的，还是应用层面的均可以理解为是我有多个操作需要全部执行成功或者不成功，我如何保证这多个操作全部执行成功，或者有一个失败后，其余全部回滚 实现思路： 我有一个统计操作执行结果的一个管理器，每一个操作执行成功后均会给这个管理器发送一个成功的消息，当收到所有操作的成功执行结果，表示这个事务内所有操作均成功，事务成功，如果其中有一个操作执行失败发送给管理器一个失败的消息（操作执行失败或者是因为某原因卡住且规定时间内未能执行完成也算失败，操作直接自行回滚到初始状态然后发送给管理器失败消息）则管理器立马下放通知给各个操作此次事务执行失败，各操作自行回滚 什么是回滚：其实就是反向操作，每一个insert语句对应一条delete语句，每一个update对应一个反向的update 数据库事务 简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。 如果应用系统是单一的数据库，那么这个很好保证，利用数据库的事务特性来满足事务的一致性，这时候的一致性是强一致性的。对于java应用系统来讲，很少直接通过事务的start和commit以及rollback来硬编码，大多通过spring的事务模板或者声明式事务来保证。 ACID 原子性(Atomicity ) 一致性( Consistency ) 隔离性或独立性( Isolation) 持久性(Durabilily) 事务的持久性就体现在，一旦事务被提交，那么数据一定会被写入到数据库中并持久存储起来。 隔离性或独立性( Isolation) 在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable）show variables like ‘transaction_isolation’; 读未提交（read uncommitted） 未提交的事务（事务中的更新操作）可以被其他事务看到（读取到其他事务中更新后但是未提交的值） 读提交（read committed） 未提交的事务（事务中的更新操作）不可以被其他事务看到，之后提交之后才能看到（读取不到其他事务中更新后但是未提交的值） 每个sql执行时才创建视图 可重复读（repeatable read） 事务执行期间所有读取到数据的值必须保证前后一致 事务开始的时候创建一个视图，所有数据结果均以视图中为准 串行化（serializable） 事务a完成后事务b才能进行 隔离性的实现 数据库的每一条更新语句都伴随着一条回滚操作，记录在回滚日志（undo log）中。 mysql通过undo log日志记录事务中操作的所有反向操作，并且undo日志优先数据持久化（保证数据库在崩溃情况下恢复重启后可以继续回滚执行undo日志将数据库回滚至之前的初始状态，如果数据优先undo日志持久化会出现崩溃恢复重启后无法通过undo日志回滚数据的情况） undo log都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据。 MVCC 数据库可以允许事务在数据被其他事务更新时对旧版本的数据进行读取，很多数据库都对这一机制进行了实现；因为所有的读操作不再需要等待写锁的释放，所以能够显著地提升读的性能，MySQL 和 PostgreSQL 都对这一机制进行自己的实现，也就是 MVCC。 保证多并发情况下数据一致性 单一线程，串行化，请求总是顺序执行，也就不存在数据不一致的情况，因为任何时刻请求拿到的数据都是最新的数据 多线程，并行化场景下由于同一时刻访问数据的请求不止一个，尤其是写请求的并发导致数据可能出现不一致的情况 解决多线程，多并发场景的方案便是锁，数据加锁，资源加锁，使得同一时刻只能有一个写请求操作数据，资源，也就是让所有的写请求串行化，回归到最简单的模式 单线程，串行化处理请求速度慢，因此出现了多线程，并行化，可以同一时刻处理多个请求，但任何进步都会伴随的一些副作用，数据的不一致性便是，因此只好寻得两者的一个平衡点，那便是所有的读请求可以并行（不会出现数据不一致性的问题），但是写或者读写仍需要通过加锁的方式来回归到串行化 MVCC方案多版本并发控制，update with condition，更新带条件，这也是在系统设计的时候，合理的选择乐观锁，通过version或者其他条件，来做乐观锁，这样保证更新及时在并发的情况下，也不会有太大的问题。例如update tablexxx set name=#name#,version=version+1 where version=#version# ,或者是 update tablexxx set quality=quality-#subQuality# where quality-#subQuality# &gt;= 0 。 MVCC是如何工作的： InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现。这两个列一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动新增。事务开始时刻的系统版本号会作为事务的版本号，用来查询到每行记录的版本号进行比较。 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列 MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：• 创建版本号：创建一行数据时，将当前系统版本号作为创建版本号赋值。• 删除版本号：删除一行数据时，将当前系统版本号作为删除版本号赋值。如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 REPEATABLE READ（可重复读）隔离级别下MVCC如何工作： 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。 SELECT InnoDB会根据以下条件检查每一行记录：a. InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行要么是在开始事务之前已经存在要么是事务自身插入或者修改过的，在事务开始之后才插入的行，事务不会看到。b. 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除，在事务开始之前就已经过期的数据行，该事务也不会看到。 只有符合上述两个条件的才会被查询出来 INSERT 将当前系统版本号作为数据行快照的创建版本号。 DELETE 将当前系统版本号作为数据行快照的删除版本号。 UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。保存这两个版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且能保证只会读取到复合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。 MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。 可以认为MVCC是行级锁一个变种，但是他很多情况下避免了加锁操作，开销更低。虽然不同数据库的实现机制有所不同，但大都实现了非阻塞的读操作（读不用加锁，且能避免出现不可重复读和幻读），写操作也只锁定必要的行（写必须加锁，否则不同事务并发写会导致数据不一致）。快照读与当前读 在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，不是数据库最新的数据。这种读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库最新版本数据的方式，叫当前读 (current read)。 快照读 当执行select操作是innodb默认会执行快照读，会记录下这次select后的结果，之后select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前select的数据，这就实现了可重复读了。快照的生成当在第一次执行select的时候，也就是说假设当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据。之后无论再有其他事务commit都没有关系，因为快照已经生成了，后面的select都是根据快照来的。 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 select * from table …; 当前读 对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。 读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert; update; delete; 如何解决幻读 很明显可重复读的隔离级别没有办法彻底的解决幻读的问题，如果需要解决幻读的话也有两个办法： • 使用串行化读的隔离级别 • MVCC+next-key locks：next-key locks由record locks(索引加锁) 和 gap locks(间隙锁，每次锁住的不光是需要使用的数据，还会锁住这些数据附近的数据) SELECT FROM t1 WHERE c1 = (SELECT c1 FROM t2) FOR UPDATE;锁不生效SELECT FROM t1 WHERE c1 = (SELECT c1 FROM t2 FOR UPDATE) FOR UPDATE;锁生效 日志系统-两阶段提交 WAL技术：Write-Ahead Logging，先写日志，在写磁盘；也就是mysql会先写redo log，然后更新内存，最后适当的时候（redo log写满的时候或者空闲的时候）在写磁盘；这种能力称之为crash-safe。 redo log：Innodb存储引擎特有的日志 物理日志，记录这个数据页做了什么修改 binlog：server层日志 原始逻辑日志，记录这一行数据的某个字段执行什么操作 事务的执行流程 先写入redolog，然后置于prepare阶段 写binlog 提交事务 事务传播机制串行事务，并行事务（多个事务的依赖性，会导致级联回滚） 1. 串行事务等待时间较长，但是并行事务又会导致一些问题，因此又需要折中方案 2. 事务可以并行，但是需要一定的隔离性 Spring事务 声明式事务：就是通过配置的方式省去很多代码，从而让Spring来帮你管理事务。本质上就是配置一个Around方式的AOP，在执行方法之前，用TransactionInterceptor截取，然后调用PlatformTransactionManager的某个实现做一些事务开始前的事情，然后在方法执行后，调用PlatformTransactionManager的某个实现做commit或rollback. 如何使用 使用注解@Transactional(readOnly = true) value，在有多个事务管理器存在的情况下，用于标识使用哪个事务管理器 isolation，事务的隔离级别，默认是Isolation.DEFAULT，这个DEFAULT是和具体使用的数据库相关的。关于隔离级别，可以参考MySQL事务学习总结 readOnly, 是否只读，如果配置了true，但是方法里使用了update，insert语句，会报错。对于只读的事务，配置为true有助于提高性能。 rollbackFor, noRollbackFor. Spring的声明式事务的默认行为是如果方法抛出RuntimeException或者Error,则事务会回滚，对于其他的checked类型的异常，不会回滚。如果想改变这种默认行为，可以通过这几个属性来配置。 propagation, 事务传播机制 12345&lt;!--事务管理器--&gt;&lt;tx:annotation-driven transaction-manager=&quot;txManager&quot;/&gt;&lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt; Propagation（事务传播机制） PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是 最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行 PROPAGATION_MANDATOR 使用当前的事务，如果当前没有事务，就抛出异常 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作 实现原理 基于AOP，动态代理加反射 限制局限 就是在一个Service内部，事务方法之间的嵌套调用，普通方法和事务方法之间的嵌套调用，都不会开启新的事务！ @Service public class MysqlTest01 { @Autowired private JdbcTemplate jdbcTemplate; @Transactional public void test01() { jdbcTemplate.execute(&quot;update test set money = &apos;501&apos; where id = 3&quot;); test02(); } @Transactional public void test02() { jdbcTemplate.execute(&quot;update test set money = &apos;501&apos; where id = 5&quot;); } } 动态代理最终都是要调用原始对象的，而原始对象在去调用方法时，是不会再触发代理了！ 那么如何解决呢？ 避免在一个Service内部进行事务方法的嵌套调用！（因为动态代理导致这种场景事务失效了。） Redis事务 关系型数据库中，用户先向数据库发送一个begin，然后执行各个相互一致的consistent的写/读操作，最后，向数据库发送commit提交，或者发送rollback回滚 事务执行流程 发送multi命令开启事务 发送执行命令，入队列，暂不执行，等待事务结束命令 发送exec命令结束事务，但是发送exec命令前不会执行任何实际操作 延迟执行事务有助于提升性能：一次性发送多个命令，等会所有回复的做法称之为流水线；流水线可以减少客户端和服务器的网络通信次数来提升执行多个命令的性能 加锁策略 关系型数据库的加锁策略都是悲观锁，Redis的加锁策略是乐观锁，可以提升性能 流水线 pipeline流水线命令 pipeline(true)参数为true时使用事务前有multi，后有exec pipeline(false)参数为false时不使用事务，但依旧是收集所有命令然后一起发送给服务器 分布式事务 XA协议是X/Open组织定义的一套分布式事务的标准，这个标准提出了使用二阶段提交(2PC – Two-Phase-Commit)来保证分布式事务的完整性。 本地事务 不用事务的编程框架来管理事务，直接使用资源管理器来控制事务。典型的就是java.sql.Connection 中的 setAutoCommit、commit、rollback方法。 分布式事务解决方案 基于XA协议的2PC（基于数据库的两阶段提交）强一致性解决方案 prepare阶段 commit提交/rollback回滚 zk广播写事务：leader发送给follow写事件，然后follow会送给leader一个ack，若leader收到一般以上的ack则下放提交通知，各个follow提交事件写入磁盘，leader同时也提交； 3PC 基于TCC 的最终一致性解决方案（tcc-transaction—github） Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 alibaba的GTC(Gloabel Trasaction Service)分布式事务解决方案 基于消息队列的最终一致性方案 本地事务 异步回调机制的引入 A应用调用B，在同步调用的返回结果中，B返回成功给到A，一般情况下，这时候就结束了，其实在99.99%的情况是没问题的，但是有时候为了确保100%，记住最起码在系统设计中100%，这时候B系统再回调A一下，告诉A，你调用我的逻辑，确实成功了。其实这个逻辑，非常类似TCP协议中的三次握手。上图中的B流程。 类似double check机制的确认机制还是上图中异步回调的过程，A在同步调用B，B返回成功了。这次调用结束了，但是A为了确保，在过一段时间，这个时间可以是几秒，也可以是每天定时处理，再调用B一次，查询一下之前的那次调用是否成功。例如A调用B更新订单状态，这时候成功了，延迟几秒后，A查询B，确认一下状态是否是自己刚刚期望的。上图中的D流程。 XA分布式事务实现原理(待完善) Java原生sql事务接口 最开始连接方式是驱动加载连接 a. Java.sql.connection/Driver/等在java.sql 包下 后来有了连接池，使用datasource获取connection（同时有了分布式事务的支持） a. Javax.sql.Datasource/XADatasource 等在javax.sql 包下 Mysql驱动包提供了对应的接口实现 MysqlXADataSource，MysqlXAConnection，MysqlXid Spring提供的事务封装 对原生sql事务的封装，不管是本地事务还是分布式事务（单独讨论） Javax.jta事务包—提供了事务操作的基本接口 Spring.tx事务包实现类 transtations-jta.事务包实现类（Atomikos.icatch.jta事务包实现类） JTA规范 JTA(基于XA协议建模的java标准事务抽象)+XA(XA事务协议)，常见的JTA实现框架有Atomikos、Bitronix Mysql服务端提供的XA命令 a. XA {START|BEGIN} xid [JOIN|RESUME] —————对应MysqlXAConnection 中的 start 方法 b. XA END xid [SUSPEND [FOR MIGRATE]] —————对应MysqlXAConnection 中的 end方法 c. XA PREPARE xid —————对应MysqlXAConnection 中的 perpare方法 d. XA COMMIT xid [ONE PHASE] —————对应MysqlXAConnection 中的 commit方法 e. XA ROLLBACK xid —————对应MysqlXAConnection 中的 rollback方法 f. XA RECOVER [CONVERT XID] —————对应MysqlXAConnection 中的 recover方法 Mysql客户端驱动包中的XA实现类 a. MysqlXADataSource，MysqlXAConnection，MysqlXid b. 基于java包中的标准接口XADatasource ，XAConnection，Javax.transaction.api包—-定义了java事务管理和部分分布式事务的标准接口Xid，由具体实现方实现细节 c. Atmoikos如何基于客户端实现类构建多数据源的分布式事务 a. UserTransactionImp 来开启事务关闭事务 b. UserTransactionImp utx = new UserTransactionImp(); c. AtomikosDataSourceBean dataSource = new AtomikosDataSourceBean(); d. 看不同具体实现，找不到怎么控制多数据原两阶段的代码 将事务绑定到当前线程是为了什么？ a. // 检查当前线程是否有分布式事务 b. if(tx != null){ c. 在分布式事务内，通过 tx 对象判断当前数据连接是否已经被包含在事务中，如果不是那么将此连接加入到事务中 Xid 包含三个元素：formatID、gtrid（全局事务标识符）和 bqual（分支修饰词标识符） a. gtrid 和 bqual 分别包含 64 个字节二进制码来分别标识全局事务和分支事务， 唯一的要求是 gtrid 和 bqual 必须是全局唯一的。]]></content>
      <categories>
        <category>Transaction</category>
      </categories>
      <tags>
        <tag>Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法总结]]></title>
    <url>%2F2019%2F03%2F24%2F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[算法总结 矩阵加减乘 线性/非线性方程组求解（线性代数） 约瑟夫环（简单，难） 符号匹配（栈） 完全数（6，28，496，8128，33550336） 真因子（不包括本身）之和等于该自然数； 真因子（不包括本身）之和大于该自然数叫盈数； 真因子（不包括本身）之和小于该自然数叫亏数； 目前共发现47个，均以6或者8结尾 均为调和数（例如6，1/1+1/2+1/3+1/6=2(是整数，则为调和数)） 亲密数：a因子（本身除外）之和=b因子之和，a！=b 水仙花数：153=1^3+5^3+3^3 1634=1^4+6^4+3^4+4^4 三位水仙花数——4个 四位水仙花数——3个 五位水仙花数——2个 六位水仙花数——1个 七位水仙花数——4个 八位水仙花数——3个 九位水仙花数——2个 十位水仙花数——1个 自守数：a平方的末尾几位=a（算法有技巧） 5^2=25 376^2=141376 最大公约数（欧几里得），最小公倍数 碾转相除法；(除法代价太大，改用减法) Stein算法； 扩展欧几里得 Ax+By=gcd（A,B），求解x，y 素数 回文数 分解质因数（第一个因数一定是质因数） 百钱买百鸡 五家共井 鸡兔同笼 猴子吃桃 舍罕王赏麦（级数求和） 汉诺塔 背包问题/窃贼问题（最优问题——动态规划） 马踏棋盘（日字走法踏遍8*8棋盘）递归 八皇后问题（92种8*8棋盘中） 天平找假币 青蛙过河（队列） 三色旗 爱因斯坦的阶梯 兔子产仔=斐波那契数列=跳台阶问题（一次跳一个或者两个） 长胜将军（谁取到最后一根火柴棍谁就输） 排列组合问题 十点半算法（扑克牌类） 生命游戏 密码学：换位（行列调换） 替换（ascii码同时移动n位） 位加密（异或） 一次一密加密 压缩解压缩算法 一百盏灯（只有平方数的约数个数才是奇数） 十二只球（称量三次找出重量不同于其他球的那只(4+4+4)） 时针/分针/秒针重合问题 20块钱可以喝多少瓶水（一块钱一瓶，两个空瓶换一瓶） 字符串的匹配 数字拆解种数 巧妙过桥问题 大数运算问题（加减乘除）数组/链表实现 进制转换 黑白棋 迷宫问题（回溯法） 农夫过河（狼，羊，白菜） 动态和规划问题（记录重叠 子问题的解，避免下次遇到相同的子问题重复计算）： 斐波那契数列（递归写法——自顶向下） 数塔问题（递推写法——自底向上） 最大连续子序列和 最长不下降（非递减）子序列（LIS）可以不连续 最长公共子序列（LCS） 最长回文子串manacher算法 DAG最长路 背包问题 字符串的编辑距离 格子取数问题 最长递增子序列 股票买卖（最多两次交易求最大利润） 二维数组最小路径和 爬楼梯 单词的编辑距离 数组问题 寻找最小的k个数（最小堆） 和为定值的K个数（k=2排序夹逼，首尾两个指针 k=n时简化为排列组合问题） 奇数偶数排序 荷兰国旗（白红蓝三色旗） 出现次数最多的数（标志位count记录个数，从第一个开始，相同加一，不同减一，为零更换） 位图排序 Hash散列 位运算 双指针技巧 字符翻转问题 素数相乘解决字符包含问题（字母赋予唯一一个素数值，然后字符串用素数乘积表示） 中心扩展思想 数学 N元一次方程组求结集（换成矩阵形式求解） A三B(mod n)表示Ab对模n的余数相同（三，或表示为恒等于） 原根？ 素数的筛选与判定 分解质因数（从根号下N开始） Molius函数 数值积分 高阶代数方程求解（n次方程） ——求导求其导函数零点（递归直到n=1直接返回），导函数领点之间函数必为单调，且最多只有一个零点，二分求零点 快速幂 格雷码序列 分数的加减乘除 点在多边形内还是外 多边形的重心（利用三角形重心即为三点坐标平均值） N阶幻方 费马点（三角形内一点到三定点的距离之和最小） 数组 两数之和（哈希map返回下标，排序双指针不返回下标） 三数之和，扩展自两数之和，一般扩展问题可以通过一些转化还原为原来的问题求解。A+b+c=0转换为a+b=-c 四数之和（转换成（a+b）+（c+d）） N数之和（排列组合） topK（快排分区） topK（找出和不小于k的数目最少的子数组） 两有序数组的第k个值（二分操作） 两有序数组的中值 第一个不重复的字符 数组中只出现一次的数字（k^k=0,k^0=k）位操作异或 一个for循环实现二维数组的遍历 数组的判重（i位置的数字j放置到位置j上） 链表 单链表注意需追踪头指针（尤其是在修改链表时） 遍历首尾边界验证，哨兵 单链表的删除/添加，在不可知其前项引用时，可用交换技术来实现删除、添加 倒数第m个元素（双指针法） 链表的循环判定（双指针法-套圈王） 链表的反转（递归，非递归），去重 两链表的交点 快速定位链表位置（使用双指针快速定位几分之几处，定位中间节点） 树/图 最小公共祖先 路径之和 镜像判断（两队列分别装入左右子树） 字符串 判重（utf-8还是ASCII） 分词 双指针法 有序数组去重（避免了删除操作，只是不断地将非重复元素往前复制） 数组元素之间的最大差值 三色排序 是否能跳跃到数组末尾 数组左右分区 哈希（HashMap） 数组最长连续序列（元素值连续，位置可以不连续） 最长不同字符的子串 经过最多点的直线（两点构成一条直线，找到所有的直线，然后聚合） 柱状图最大面积 排列组合（下一个排列） 位操作 不用加减乘除实现，两数相除，两数之和 小灰的漫画算法 判定链表有环，环的起点，环的长度 遍历有环链表时是个死循环 可以在遍历时判定链表节点是否有重复的（借助额外的空间来降低时间的复杂度） 双指针套圈王 hashmap记录遍历顺序，以此来求解环的起点，环的长度，也可以使用套圈王求出圈的长度 找到栈中的最小值，O（1）复杂度 双栈保存从一个入栈元素以来的较小值 还是空间换时间 最大公约数 判定一个数是否为2的整数幂 全排列的前/后一个数字 中心迁移，以A为主找B，换位思考以B为主找A，倒排索引 红包算法 一百元，10个人抢，每人至少一分钱，所有抢到的和不能大于100 计算的时间点，抢的时候在计算随机值，还是之前就算好放入队列中，抢的时候依次弹出即可 金额=随机区间【一分钱，剩余金额 减去 一分钱】 如何保证红包金额的均匀分布，避免两级分化 二倍均值法：金额=随机区间【0.01，金额/人数*2-0.01】 优化Clone()代替new避免对boolan的不必要等于判定三目操作符（？：）替代if、else实例方法会消耗过多的系统资源，所以常用的工具类可以采用，静态方法代替实例用final锁定无需重载的方法避免使用instanceof局部变量代替全局变量位运算位运算总是需要将全部计算完毕再给出结果，所以在进行布尔判定时不建议使用位运算，而且布尔运算会进行优化提取复杂表达式优化，减少重复计算Java7允许switch语句支持string变长参数的方法调用（如何去除警告信息）集合内部避免返回null，可以减少调用该集合时的判空操作，而是返回大小为0的数组或集合 例如 return Collections.emptyList()/emptyMap() 注意上述方法 返回对象为不可变对象，当实际情况需要改变返回对象时则不可用判断元素是否在数组中：Arrays.asList(T [] array).contains(T obj); ArrayList.toArray(T [] array)Lamda表达式Java7异常捕获catch字句（一个可捕获多个异常）数组代替switch语句，数组的随机访问更快数组复制本地方法system.arraycopy();Finally里面释放关闭资源占用Java7中新增了改进快速排序的类（两个枢纽分三份）java.util.DualPivotQuicksort.classNIO(new input/output)Redis数据库]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inner Class]]></title>
    <url>%2F2019%2F03%2F17%2FInner%20Class%2F</url>
    <content type="text"><![CDATA[Inner Class 内部类使得可以将一些逻辑相关的类组织在一起，并可以控内部类的可见性，隐藏实现细节；而外部类一般不会设置private或者protected 内部类的实例化需要用到外部类的实例：OuterClassName.InnerClassName = outerClassName.new InnerClassName(); 内部类拥有外部类的所有元素的访问权 匿名内部类 当内部类声明为static时称为嵌套类 嵌套类的创建不需要外部类对象 并且不能访问外部类中非static的对象 接口内部的类 接口内部的类自动public和static 可以作为所有实现类的公共部分 java8新添加了接口默认方法可以有实现，作用可以媲美接口内部的类 内部类使得多重继承变得完整]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode BinarySearch]]></title>
    <url>%2F2019%2F03%2F10%2FLintCode%20BinarySearch%2F</url>
    <content type="text"><![CDATA[LintCode 二分查找 X的平方根 搜索插入位置 搜索二维矩阵 二分查找 寻找旋转排序数组中的最小值 寻找峰值 第一个错误的代码版本 搜索旋转排序数组搜索区间 木材加工 X的平方根 实现 int sqrt(int x) 函数，计算并返回 x 的平方根。返回对x开根号后向下取整的结果。 思路：二分查找，从x/2开始，计算(x/2)^2和x的值，比x大往左找，反之往右找进阶：牛顿迭代法快速寻找平方根—我们仅仅是不断用(x,f(x))的切线来逼近方程x^2-a=0的根。根号a实际上就是x^2-a=0的一个正实根，这个函数的导数是2x。也就是说，函数上任一点(x,f(x))处的切线斜率是2x。那么，x-f(x)/(2x)就是一个比x更接近的近似值。代入 f(x)=x^2-a得到x-(x^2-a)/(2x)，也就是(x+a/x)/2。大神：原理还是牛顿迭代法,用x-f(x)/f’(x)来不断的逼近f(x)=a的根。一般的求平方根都是这么循环迭代算的但是卡马克(quake3作者)真正牛B的地方是他选择了一个神秘的常数0x5f3759df 来计算那个猜测值，就是我们加注释的那一行，那一行算出的值非常接近1/sqrt(n)，这样我们只需要2次牛顿迭代就可以达到我们所需要的精度。12345678910111213141516171819202122//进阶float SqrtByNewton(float x)&#123; float val = x;//最终 float last;//保存上一个计算的值 do &#123; last = val; val =(val + x/val) / 2; &#125;while(abs(val-last) &gt; eps); return val;&#125;//大神float InvSqrt(float x)&#123; float xhalf = 0.5f*x; int i = *(int*)&amp;x; // get bits for floating VALUE i = 0x5f375a86- (i&gt;&gt;1); // gives initial guess y0 x = *(float*)&amp;i; // convert bits BACK to float x = x*(1.5f-xhalf*x*x); // Newton step, repeating increases accuracy return x;&#125; 搜索插入位置 给定一个排序数组和一个目标值，如果在数组中找到目标值则返回索引。如果没有，返回到它将会被按顺序插入的位置。你可以假设在数组中无重复元素。 思路：二分查找搜索二维矩阵 写出一个高效的算法来搜索 m × n矩阵中的值。这个矩阵具有以下特性：每行中的整数从左到右是排序的。每行的第一个数大于上一行的最后一个整数。 思路：将矩阵拉成一条一位数组来进行二分查找二分查找 给定一个排序的整数数组（升序）和一个要查找的整数target，用O(logn)的时间查找到target第一次出现的下标（从0开始），如果target不存在于数组中，返回-1。 思路：二分查找，但是有出现次数的限制，也就是查找停止点要靠左寻找旋转排序数组中的最小值 假设一个排好序的数组在其某一未知点发生了旋转（比如0 1 2 4 5 6 7 可能变成4 5 6 7 0 1 2）。你需要找到其中最小的元素。 思路：直接遍历，找到第一个非排序的数字就是最小值寻找峰值 你给出一个整数数组(size为n)，其具有以下特点： 相邻位置的数字是不同的 A[0] &lt; A[1] 并且 A[n 2] &gt; A[n 1] 假定P是峰值的位置则满足A[P] &gt; A[P-1]且A[P] &gt; A[P+1]，返回数组中任意一个峰值的位置。 思路：直接遍历，二分个人感觉这种场景没啥优势第一个错误的代码版本 代码库的版本号是从 1 到 n 的整数。某一天，有人提交了错误版本的代码，因此造成自身及之后版本的代码在单元测试中均出错。请找出第一个错误的版本号。 你可以通过 isBadVersion 的接口来判断版本号 version 是否在单元测试中出错，具体接口详情和调用方法请见代码的注释部分。 二分查找，从中间位置开始，若正确说明之前的都正确，指针移到后半段继续二分搜索旋转排序数组 假设有一个排序的按未知的旋转轴旋转的数组(比如，0 1 2 4 5 6 7 可能成为4 5 6 7 0 1 2)。给定一个目标值进行搜索，如果在数组中找到目标值返回数组中的索引位置，否则返回-1。你可以假设数组中不存在重复的元素。 思路：根据旋转后的特性，由目标值和数组首尾两个元素的比较结果判定从哪个方向开始遍历搜索区间 给定一个包含 n 个整数的排序数组，找出给定目标值 target 的起始和结束位置。如果目标值不在数组中，则返回[-1, -1] 思路：因为是排序数组，所以使用二分找到第一次出现的位置后继续向右找到最后一次出现的位置木材加工 有一些原木，现在想把这些木头切割成一些长度相同的小段木头，需要得到的小段的数目至少为 k。当然，我们希望得到的小段越长越好，你需要计算能够得到的小段木头的最大长度。 木头长度的单位是厘米。原木的长度都是正整数，我们要求切割得到的小段木头的长度也要求是整数。无法切出要求至少 k 段的,则返回 0 即可。 思路：所有原木的长度相加/需要的分段数=结果A，从这个得到的结果A开始递减遍历，每一段原木长度/结果A的结果相加是否满足需要的分段数，满足返回]]></content>
      <categories>
        <category>LintCode</category>
      </categories>
      <tags>
        <tag>LintCode</tag>
        <tag>BinarySearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Enum]]></title>
    <url>%2F2019%2F03%2F03%2FEnum%2F</url>
    <content type="text"><![CDATA[Enum枚举 枚举基本特性 枚举实现责任链模式 多路分发 枚举基本特性12345enum LogEnum&#123; DEBUG, ERROR, INFO&#125; 所有的枚举类都继承自Enum类，由于java只支持单继承，所以你的枚举类不能再继承任何其他类，但是可以实现任意数量的接口 valueOf方法：LOGGING.valueOf(“DEBUG”)根据字符村获取枚举的值（作用有点不太明确） values方法：Arrays.asList(LOGGING.values()).forEach(System.out::println);方法values返回所有枚举元素，顺序严格按照定义顺序返回 values()方法：Enum类中并没有，是由编译器添加的静态方法 LogRecord.class.getEnumConstants();类class同样提供了一个方法getEnumConstants可以返回枚举类的所有元素 使用静态导入impot static LogEnum.*;之后可以在类中直接使用枚举类的元素DEBUG等，无需在使用前缀LogEnum.DEBUG 枚举类中定义方法：枚举类只是多了一些限制，其他方面和普通类没什么区别 方法只能定义在枚举元素之后，并且以分号 ； 隔离枚举元素和方法定义 获取枚举元素默认返回的是元素的toString()方法返回的值；我们可以通过重写toString()方法来实现自定义返回元素值 ordinal方法：LOGGING.ERROR.ordinal()：方法ordinal返回枚举元素的顺序号（从0开始，严格按照定义顺序排序） switch语句中的枚举 枚举元素的随机选取 使用接口组织枚举，实现枚举的子类化和元素扩展分组分类 枚举嵌套 每个枚举类常量元素可以定义多个方法来赋予每个元素不同的行为；前提是需要定义一个或者多个抽象方法，然后交给各个枚举元素实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public enum LOGGING &#123; DEBUG,//不加描述的枚举元素定义 ERROR, INFO; //重写toString()方法来实现自定义返回元素值 @Override public String toString() &#123; String id = name(); char[] idChar = id.toCharArray(); idChar[0] +=32; return String.valueOf(idChar); &#125;&#125;//增强版枚举类public enum LOGGING &#123; DEBUG(&quot;debug&quot;),//加描述的枚举元素定义，前提是有变量description，get方法，构造方法（带参数变量description） ERROR(&quot;error&quot;), INFO(&quot;info&quot;); /** 添加枚举元素的解释描述，并添加get方法获取元素的描述 */ String description; LOGGING(String decription)&#123; this.description = decription; &#125; private String getDescription()&#123; return description; &#125; @Override public String toString() &#123; String id = name(); char[] idChar = id.toCharArray(); idChar[0] +=32; return String.valueOf(idChar); &#125; public static void main(String[] args)&#123; Arrays.asList(LOGGING.values()).forEach((e)-&gt;System.out.println(e + &quot;---&quot; + e.getDescription())); &#125;&#125;//实现不调用枚举任何方法（特质values方法）而实现随机选取枚举元素public class Enums &#123; private static Random random = new Random(47); public static &lt;T extends Enum&lt;T&gt;&gt; T random(Class&lt;T&gt; ec)&#123; return random(ec.getEnumConstants()); &#125; public static &lt;T&gt; T random(T[] arrays)&#123; return arrays[random.nextInt(arrays.length)]; &#125;&#125;//使用接口组织枚举，实现枚举的子类化和元素扩展分组分类public interface Food &#123; enum Vegetables implements Food&#123; 菠菜,油麦菜,白菜 &#125; enum Fruit implements Food&#123; APPLE,PAREL,ORIGANE &#125; enum Meat implements Food&#123; BEEF,PORK,MUTTON &#125;&#125;//枚举元素实现抽象方法定义属于自己的行为public enum LOGGING &#123; DEBUG(&quot;debug&quot;)&#123; @Override String getInfo() &#123; return DateFormat.getInstance().format(new Date()); &#125; &#125;, ERROR(&quot;error&quot;)&#123; @Override String getInfo() &#123; return System.getenv(&quot;CLASSPATH&quot;); &#125; &#125;, INFO(&quot;info&quot;)&#123; @Override String getInfo() &#123; return System.getProperty(&quot;java.version&quot;); &#125; &#125;; //定义一个抽象方法供枚举元素实现各自的行为 abstract String getInfo(); /** 添加枚举元素的解释描述，并添加get方法获取元素的描述 */ String description; LOGGING(String decription)&#123; this.description = decription; &#125; private String getDescription()&#123; return description; &#125; @Override public String toString() &#123; String id = name(); char[] idChar = id.toCharArray(); idChar[0] +=32; return String.valueOf(idChar); &#125; public static void main(String[] args)&#123; Arrays.asList(LOGGING.values()).forEach((e)-&gt;System.out.println(e + &quot;---&quot; + e.getDescription() + &quot;----&quot; + e.getInfo())); &#125;&#125; EnumSet 内部使用long数组，实现位操作，性能极高 枚举实现责任链模式123456789101112131415161718192021222324252627282930313233343536public enum LOGGING &#123; LEVEL1(&quot;一级处理&quot;)&#123; @Override boolean handle(Object o) &#123; System.out.println(&quot;一级处理完成！&quot;); return true; &#125; &#125;, LEVEL2(&quot;二级处理&quot;)&#123; @Override boolean handle(Object o) &#123; System.out.println(&quot;二级处理完成！&quot;); return true; &#125; &#125;, LEVEL3(&quot;三级处理&quot;)&#123; @Override boolean handle(Object o) &#123; System.out.println(&quot;三级处理完成！&quot;); return true; &#125; &#125;; //定义一个抽象方法供枚举元素实现各自的行为 abstract boolean handle(Object o); /** 添加枚举元素的解释描述，并添加get方法获取元素的描述 */ String description; LOGGING(String decription)&#123; this.description = decription; &#125; private String getDescription()&#123; return description; &#125; public static void main(String[] args)&#123; Arrays.asList(LOGGING.values()).forEach((e)-&gt;System.out.println(e + &quot;---&quot; + e.getDescription() + &quot;----&quot; + e.handle(new Object()))); &#125;&#125; 使用枚举创建状态机多路分发 分派的类型 一个方法所属的对象叫做方法的接收者，方法的接收者与方法的参量统称做方法的宗量。 根据分派可以基于多少种宗量，可以将面向对象的语言划分为单分派语言和多分派语言。单元分派语言根据一个宗量的类型（真实类型）进行对方法的选择,多分派语言根据多于一个的宗量的类型对方法进行选择。C++和Java以及Smaltalk都是单分派语言；多分派语言的例子包括CLOS和Cecil。按照这样的区分，C++和Java就是动态的单分派语言，因为这两种语言的动态分派仅仅会考虑到方法的接收者的类型，同时又是静态的多分派语言，因为这两种语言对重载方法的分派会考虑到方法的接收者的类型和方法所有参量的类型。 在一个支持动态单分派的语言里面，有两个条件决定了一个请求会调用哪一个操作：一是请求的名字，二是接收者的真实类型。单分派限制了方法的选择过程，使得只有一个宗量可以被考虑到，这个宗量通常就是方法的接收者。在JAVA语言里面，如果一个操作是作用于某个类型不明的对象上面的。那么这个对象的真实类型测试仅会发生一次。这个就是动态的单分派的特征。 一言以蔽之，JAVA语言支持静态的多分派和动态的单分派。 双重分派 一个方法根据两个宗量的类型来决定执行不同的代码，这就是“双分派”或者“多重分派”。Java不支持动态的多分派。但可以通过使用设计模式，在Java语言里面实现动态的双重分派（ps：就是“伪双重分派”是由两次的单分派组成）。 多路分发的不同实现方式 在方法里使用instanceof判断真实类型，根据实际类型对应执行不同的行为操作 使用访问者模式 实际就是A接口方法a(B)中参数为另一个接口B，而在接口A的实现类中a方法又调用了B接口中定义的方法；这样在发生a方法调用时，a的调用可能是A的任意一个实现类，并且a方法中的参数B也可能是任意一个实现类 实际上就是a.method(b)模型，a和b都是接口的未知具体实现类；a和b可以是同一接口的实现类，也可以是不同接口的实现类 使用枚举 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157//使用访问者模式实现public interface Acceptor &#123; String accept(Visitor v); String getName();&#125;public class AcceptorOne implements Acceptor&#123; @Override public String accept(Visitor v) &#123; System.out.println(&quot;来者是谁：&quot; + v.getName()); return v.handle(this); &#125; @Override public String getName() &#123; return &quot;AcceptorOne&quot;; &#125;&#125;public class AcceptorTwo implements Acceptor&#123; @Override public String accept(Visitor v) &#123; System.out.println(&quot;来者是谁：&quot; + v.getName()); return v.handle(this); &#125; @Override public String getName() &#123; return &quot;AcceptorTwo&quot;; &#125;&#125;public interface Visitor &#123; String handle(Acceptor accept); String getName();&#125;public class VisitorOne implements Visitor &#123; @Override public String handle(Acceptor accept) &#123; return &quot;我是访问者，我访问的是：&quot; + accept.getName(); &#125; @Override public String getName() &#123; return &quot;VisitorOne&quot;; &#125;&#125;public class VisitorTwo implements Visitor &#123; @Override public String handle(Acceptor accept) &#123; return &quot;我是访问者，我访问的是：&quot; + accept.getName(); &#125; @Override public String getName() &#123; return &quot;VisitorTwo&quot;; &#125;&#125;public class VisitorPatternTest &#123; public static void main(String[] args)&#123; Acceptor acceptorOne = new AcceptorOne(); Acceptor acceptorTwo = new AcceptorTwo(); Visitor visitorOne = new VisitorOne(); Visitor visitorTwo = new VisitorTwo(); System.out.println(acceptorOne.accept(visitorOne)); System.out.println(acceptorOne.accept(visitorTwo)); &#125;&#125;//使用枚举的描述特性实现public enum OutCome &#123; DRAW, WIN, LOSE&#125;public interface Competitor&lt;T&gt; &#123; OutCome compete(T competitor);&#125;public class RoShamBoTest &#123; public static &lt;T extends Competitor&lt;T&gt;&gt; void match(T a,T b)&#123; System.out.println(a + &quot; vs &quot; + b + &quot;: &quot; + a.compete(b)); &#125; //T 继承自枚举类Enum和接口Competitor public static &lt;T extends Enum&lt;T&gt; &amp; Competitor&lt;T&gt;&gt; void play(Class&lt;T&gt; clazz,int size)&#123; for (int i = 0;i &lt; size;i++)&#123; match(Enums.random(clazz),Enums.random(clazz)); &#125; &#125;&#125;//枚举类元素的描述跟在元素后的括号内（样例：ENUM(描述...)），描述可以有多个，并且需要定义相应的私有属性变量，同时描述顺序和私有变量顺序保持一致；最后使用私有属性变量构造有参构造方法public enum RoShamBo implements Competitor&lt;RoShamBo&gt; &#123; PAPER(DRAW,LOSE,WIN), SCISSORS(WIN,DRAW,LOSE), ROCK(LOSE,WIN,DRAW); private OutCome vPAPER,vSCISSORS,vROCK; RoShamBo(OutCome paper,OutCome scissors,OutCome rock)&#123; this.vPAPER = paper; this.vSCISSORS = scissors; this.vROCK = rock; &#125; public OutCome compete(RoShamBo it)&#123; switch (it)&#123; case ROCK: return vROCK; case PAPER: return vPAPER; case SCISSORS: return vSCISSORS; default: &#125; return null; &#125; public static void main(String[] args)&#123; RoShamBoTest.play(RoShamBo.class,20); &#125;&#125;//使用枚举的元素常量方法实现public enum RoShamBo2 implements Competitor&lt;RoShamBo2&gt; &#123; PAPER&#123; @Override public OutCome compete(RoShamBo2 competitor) &#123; switch (competitor)&#123; case SCISSORS: return LOSE; case PAPER: return DRAW; case ROCK: return WIN; &#125; return null; &#125; &#125;, SCISSORS&#123; @Override public OutCome compete(RoShamBo2 competitor) &#123; switch (competitor)&#123; case ROCK: return LOSE; case PAPER: return WIN; case SCISSORS: return DRAW; &#125; return null; &#125; &#125;, ROCK&#123; @Override public OutCome compete(RoShamBo2 competitor) &#123; switch (competitor)&#123; case SCISSORS: return WIN; case PAPER: return LOSE; case ROCK: return DRAW; &#125; return null; &#125; &#125;; public abstract OutCome compete(RoShamBo2 competitor); public static void main(String[] args)&#123; RoShamBoTest.play(RoShamBo2.class,20); &#125;&#125;//使用枚举EnumMap实现，实际上是建立了一个a和b以及a操作b后的结果三者之间的关系public enum RoShamBo3 implements Competitor&lt;RoShamBo3&gt; &#123; PAPER,SCISSORS,ROCK; static EnumMap&lt;RoShamBo3,EnumMap&lt;RoShamBo3,OutCome&gt;&gt; map = new EnumMap&lt;RoShamBo3,EnumMap&lt;RoShamBo3,OutCome&gt;&gt;(RoShamBo3.class); ...//利用嵌套集合构建复杂多者行为之间的关系 @Override public OutCome compete(RoShamBo3 competitor) &#123; return null; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2019%2F02%2F24%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[动态代理 什么是代理 本质 用途 场景 静态代理 实现方式 短板所在 动态代理 jdk动态代理 深入思考 有哪些局限性 cglib动态代理 fastclass机制 权限/安全 扩展 @CallerSensitive注解 附录 jdk动态代理生成的代理类class文件内容样例 什么是代理代理的本质 在目标对象前构建起一座城墙，通过过滤，安全，校验，增强等来丰富目标对象 代理模式的用途 归根结底就是丰富弥补目标对象所缺失的 代理模式的应用场景 面向切面编程aop 增强源码 自动生成静态代理 xa-jta的具体实现厂商-atomikos-构造数据源的时候使用了接口Reapable，通过动态代理和java.sql.Connection接口建立联系 静态代理实现方式 直接将目标对象的实例注入到代理proxy类中即可实现目标类的所有的属性/方法代理 基于接口的方式实现，代理类实现和目标类同样的接口类 基于继承方式实现，代理类继承自目标对象类，从而对可见性的属性/方法进行代理 java版静态代理 抽象主题（Subject）：一个接口 实际主题（RealSubject）：实现了抽象主题接口的类 代理(Proxy)：实现了抽象主题接口的类，含有抽象主题声明的变量，来存放实际主题的实例的引用 应用场景：代理的实例用来控制对他所包含的实际主题的实例的访问，即控制他所代理对象的访问权限 案例demo123456789101112131415161718192021222324252627//Subjectpublic interface Employee&#123; public String hearPhone();&#125;//RealSubjectpublic class Boss implements Employee&#123; public String hearPhone()&#123; return "面谈吧"; &#125;&#125;//Proxypublic class Secretary implements Employee&#123; Employee boss; Secretary()&#123; boss = new Boss(); &#125; public String hearPhone()&#123; return "我们老板说："+boss.hearPhone(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Secretary s = new Secretary(); System.out.println(s.hearPhone()); &#125;&#125; 静态代理的短板所在 最大局限性就是所有的目标类必须明确的给出，且每一个都需要手动完成代理过程，在批量代理的诉求下就显得无计可施，从而触发了动态代理的出现 动态代理jdk动态代理实现原理 通过Proxy.newProxyInstance()方法将目标类的类加载器和实现接口以及暴露给上层用户实现具体增强的invokehandler 类加载器可以加载生成的代理类，实现接口用于代理类实现，从而代理所有接口方法 代理实现接口的所有方法最总都引导向了invokehandler的invoke方法，而invoke方法对外暴露给了上层开发者自定义增强功能 生层的代理类具体内容样例见附录 代码演示具体实现1234567891011121314151617181920212223// 1. 首先实现一个InvocationHandler接口，方法调用会被转发到该类的invoke()方法。class LogInvocationHandler implements InvocationHandler &#123; private Hello hello; public LogInvocationHandler(Hello hello) &#123; this.hello = hello; &#125; @Override /** 对代理对象的所有接口方法调用都会转发到InvocationHandler.invoke()方法，在invoke()方法里我们可以加入任何逻辑，比如修改方法参数，加入日志功能、安全检查功能等；之后我们通过某种方式执行真正的方法体，示例中通过反射调用了Hello对象的相应方法，还可以通过RPC调用远程方法。*/ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if(&quot;sayHello&quot;.equals(method.getName())) &#123;// logger.info(&quot;You said: &quot; + Arrays.toString(args)); &#125; return method.invoke(hello, args); &#125;&#125;public void display()&#123; // 2. 然后在需要使用Hello的时候，通过JDK动态代理获取Hello的代理对象。 Hello hello = (Hello)Proxy.newProxyInstance( getClass().getClassLoader(), // 1. 类加载器 new Class&lt;?&gt;[] &#123;Hello.class&#125;, // 2. 代理需要实现的接口，可以有多个 new LogInvocationHandler(new HelloImp()));// 3. 方法调用的实际处理者 System.out.println(hello.sayHello(&quot;I love you!&quot;));&#125; 深入思考 生成的代理类是个什么样子，可以见附录 默认不生成具体的代理类class文件，直接加载到内容中使用，可以使用参数生成具体的class文件 在main方法最前面增加System.getProperties().put(“sun.misc.ProxyGenerator.saveGeneratedFiles”,”true”); jdk版本不同，ProxyGenerator类的位置目录可能不一样，可以直接搜索类名，具体看下即可 代理class的生成路径是在项目根目录下的 com\sun\proxy 目录中，和正常编译后的class文件不在一个地方 生成的类名：$Proxy+数字，例如$Proxy0.class 生成的代理类不仅实现了目标类的所有的接口，同时还继承了Proxy类，因为invokehandler的实例是在Proxy类中的 InvocationHandler接口存在的意思 就是将目标接口方法的调用动作暴露出来给上层用户，应为上层用户需要做一些前置，后置等自定义操作 类似模版模型，流程的编排已经由顶层逻辑封装实现，具体的细节流程上层用户去自定义 局限性 基于接口，也就受限于接口，对于没有接口的目标对象就没发使用jdk动态代理 基于反射调用目标对象的方法，消耗较大 是否可以借鉴cglib的fastclass机制，改造jdk动态代理，将反射改为直接调用目标对象方法 Java动态代理为我们提供了非常灵活的代理机制，但Java动态代理是基于接口的，如果对象没有实现接口我们该如何代理呢？CGLIB登场。 CGLIB动态代理 cglib：是一个强大的，高性能，高质量的Code生成类库，它可以在运行期扩展Java类与实现Java接口。 代理为控制要访问的目标对象提供了一种途径。当访问对象时，它引入了一个间接的层。JDK自从1.3版本开始，就引入了动态代理，并且经常被用来动态地创建代理。JDK的动态代理用起来非常简单，但它有一个限制，就是使用动态代理的对象必须实现一个或多个接口。如果想代理没有实现接口的继承的类，该怎么办？现在我们可以使用CGLIB包。 CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。除了CGLIB包，脚本语言例如Groovy和BeanShell，也是使用ASM来生成java的字节码。当然不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 Javassist是一个开源的分析、编辑和创建Java字节码的类库。关于java字节码的处理，目前有很多工具，如bcel，asm。不过这些都需要直接跟虚拟机指令打交道。如果你不想了解虚拟机指令，可以采用javassist。javassist是jboss的一个子项目，其主要的优点，在于简单，而且快速。直接使用java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构，或者动态生成类。 fastclass机制 简单说就是 cglib 不使用反射而直接调用目标方法 首先设置输出代理类到指定路径，便于后面分析System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, “/users/admin”); 其次cglib动态代理会生成了三个文件，一个代理类文件，两个FastClass文件 代理类文件是调用Enhancer.create的时候生成的，而两个FastClass文件是第一次调用MethodProxy.invokeSuper的时候才生成 核心思想就是基于目标对象的方法建立索引体系，通过方法名直接调用目标对象的方法 代码演示具体实现1234567891011121314151617181920//无需使用接口public class HelloImpl&#123; public void sayHello()&#123;&#125;&#125;// 1. 首先实现一个MethodInterceptor，方法调用会被转发到该类的intercept()方法。class MyMethodInterceptor implements MethodInterceptor&#123; ... @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; logger.info(&quot;You said: &quot; + Arrays.toString(args)); // 注意，这里要调用proxy.invokeSuper，而不是method.invoke，不然会出现栈溢出等问题 return proxy.invokeSuper(obj, args); &#125;&#125;// 2. 然后在需要使用HelloImpl的时候，通过CGLIB动态代理获取代理对象。Enhancer enhancer = new Enhancer();enhancer.setSuperclass(HelloImpl.class);enhancer.setCallback(new MyMethodInterceptor());HelloImpl hello = (HelloImpl)enhancer.create();System.out.println(hello.sayHello(&quot;I love you!&quot;)); 权限/安全 代码的权限和安全问题其实体现在方方面面，对于代理模式而言，个人认为需要注意以下几点底层基础代码是否应该暴露出来给上层开发者代理的机会那些可以暴露出来提供代理增强，那些不应该或者不想被暴露如何避免被迫暴露，例如，被public修饰但是并不想被代理java9的模块系统对这类问题提出了较好的解决方案 扩展@CallerSensitive注解 总结就是说 jdk内有些方法，jvm的开发者认为这些方法危险，不希望开发者调用，就把这种危险的方法用 @CallerSensitive修饰，并在“jvm”级别检查。 如Reflection.getCallerClass()方法规定，调用它的对象，必须有 @CallerSensitive 注解，否则 报异常 @CallerSensitive 有个特殊之处，必须由 启动类classloader加载（如rt.jar ），才可以被识别。 所以rt.jar下面的注解可以正常使用。开发者自己写的@CallerSensitive 不可以被识别。 但是，可以利用jvm参数 -Xbootclasspath/a: path 假装自己的程序是启动类 利用jvm参数 -Xbootclasspath/a: path 假装自己的程序是启动类。 -Xbootclasspath:bootclasspath ：让jvm从指定的路径中加载bootclass，用来替换jdk的rt.jar。一般不会用到。 -Xbootclasspath/a: path ： 被指定的文件追加到默认的bootstrap路径中。 -Xbootclasspath/p: path ： 让jvm优先于默认的bootstrap去加载path中指定的class。 启动类加载器Bootstrap ClassLoader:加载JRE_HOME/lib下的核心包，该类加载器是用c++写的 扩展类加载器Extension ClassLoader:加载JRE_HOME/lib/ext目录下的扩展包,也可以通过启动参数-Djava.ext.dirs指定，该类用java编写。对应ExtClassLoader类 应用类加载器Application ClassLoader:应用类加载器，加载classpath下的字节码文件，用java编写，对应AppClassLoader这个类，可以通过ClassLoader类的静态方法getSystemClassLoader()获得，所以又叫系统类加载器 自定义类加载器：自定义的类加载器，通过直接或者间接继承抽象的ClassLoader类 说到底就是代码的一个权限调用问题，由于jvm内部其他类同样需要调用，有时只能声明为public，但是又不想让开发者去调用，所以用这个注解来实现此功能，但是java9之后，模块化的出现使得可以直接限制package包级别的访问权限，也就是说jvm内部包中的类，只要没有export给指定包，你就没发访问该包下的所有类，也就起到了权限隔离的作用。 附录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100//// Source code recreated from a .class file by IntelliJ IDEA// (powered by FernFlower decompiler)//package com.sun.proxy;import com.huice.middleware.distributor.util.TargetInterface;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements TargetInterface &#123; private static Method m1; private static Method m3; private static Method m2; private static Method m4; private static Method m5; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final void function2() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void function3() throws &#123; try &#123; super.h.invoke(this, m4, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void function1(String var1) throws &#123; try &#123; super.h.invoke(this, m5, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m3 = Class.forName(&quot;com.huice.middleware.distributor.util.TargetInterface&quot;).getMethod(&quot;function2&quot;); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;); m4 = Class.forName(&quot;com.huice.middleware.distributor.util.TargetInterface&quot;).getMethod(&quot;function3&quot;); m5 = Class.forName(&quot;com.huice.middleware.distributor.util.TargetInterface&quot;).getMethod(&quot;function1&quot;, Class.forName(&quot;java.lang.String&quot;)); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo]]></title>
    <url>%2F2019%2F02%2F17%2FDubbo%2F</url>
    <content type="text"><![CDATA[Dubbo 核心点 dubbo本地缓存注册中心服务列表 配置加载流程 dubbo的一次完整服务调用过程 Dubbo外部化配置 服务失效踢出 配置案例 Dubbo的局限性 核心点 协议 Dubbo协议 Stable 采用NIO复用单一长连接，并使用线程池并发处理请求，减少握手和加大并发效率，性能较好（推荐使用） 在大文件传输时，单一连接会成为瓶颈 可用于生产环境 Alibaba Rmi协议 Stable 可与原生RMI互操作，基于TCP协议 偶尔会连接失败，需重建Stub 可用于生产环境 Alibaba Hessian协议 Stable 可与原生Hessian互操作，基于HTTP协议 需hessian.jar支持，http短连接的开销大 可用于生产环境 NIO异步文件传输流 Netty Transporter Stable JBoss的NIO框架，性能较好（推荐使用） 一次请求派发两种事件，需屏蔽无用事件 可用于生产环境 Alibaba Mina Transporter Stable 老牌NIO框架，稳定 待发送消息队列派发不及时，大压力下，会出现FullGC 可用于生产环境 Alibaba Grizzly Transporter Tested Sun的NIO框架，应用于GlassFish服务器中 线程池不可扩展，Filter不能拦截下一Filter 试用 序列化 Hessian Serialization Stable 性能较好，多语言支持（推荐使用） Hessian的各版本兼容性不好，可能和应用使用的Hessian冲突，Dubbo内嵌了hessian3.2.1的源码 可用于生产环境 Alibaba Dubbo Serialization Tested 通过不传送POJO的类元信息，在大量POJO传输时，性能较好 当参数对象增加字段时，需外部文件声明 试用 Json Serialization Tested 纯文本，可跨语言解析，缺省采用FastJson解析 性能较差 试用 Java Serialization Stable Java原生支持 性能较差 可用于生产环境 动态代理工厂 Javassist ProxyFactory Stable 通过字节码生成代替反射，性能比较好（推荐使用） 依赖于javassist.jar包，占用JVM的Perm内存，Perm可能要设大一些：java -XX:PermSize=128m 可用于生产环境 Alibaba Jdk ProxyFactory Stable JDK原生支持 性能较差 可用于生产环境 服务调用策略（容错策略） Failover Cluster Stable 失败自动切换，当出现失败，重试其它服务器，通常用于读操作（推荐使用） 重试会带来更长延迟 可用于生产环境 Alibaba Failfast Cluster Stable 快速失败，只发起一次调用，失败立即报错,通常用于非幂等性的写操作 如果有机器正在重启，可能会出现调用失败 可用于生产环境 Alibaba Failsafe Cluster Stable 失败安全，出现异常时，直接忽略，通常用于写入审计日志等操作 调用信息丢失 可用于生产环境 Monitor Failback Cluster Tested 失败自动恢复，后台记录失败请求，定时重发，通常用于消息通知操作 不可靠，重启丢失 可用于生产环境 Registry Forking Cluster Tested 并行调用多个服务器，只要一个成功即返回，通常用于实时性要求较高的读操作 需要浪费更多服务资源 可用于生产环境 Broadcast Cluster Tested 广播调用所有提供者，逐个调用，任意一台报错则报错，通常用于更新提供方本地状态 速度慢，任意一台报错则报错 可用于生产环境 负载均衡策略 Random LoadBalance Stable 随机，按权重设置随机概率（推荐使用） 在一个截面上碰撞的概率高，重试时，可能出现瞬间压力不均 可用于生产环境 Alibaba RoundRobin LoadBalance Stable 轮询，按公约后的权重设置轮询比率 存在慢的机器累积请求问题，极端情况可能产生雪崩 可用于生产环境 LeastActive LoadBalance Stable 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差，使慢的机器收到更少请求 不支持权重，在容量规划时，不能通过权重把压力导向一台机器压测容量 可用于生产环境 ConsistentHash LoadBalance Stable 一致性Hash，相同参数的请求总是发到同一提供者，当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动 压力分摊不均 可用于生产环境 路由规则 条件路由规则 Stable 基于条件表达式的路由规则，功能简单易用 有些复杂多分支条件情况，规则很难描述 可用于生产环境 Alibaba 脚本路由规则 Tested 基于脚本引擎的路由规则，功能强大 没有运行沙箱，脚本能力过于强大，可能成为后门 试用 服务路由包含一条路由规则，路由规则决定了服务消费者的调用目标，即规定了服务消费者可调用哪些服务提供者。Dubbo 目前提供了三种服务路由实现，分别为条件路由 ConditionRouter、脚本路由 ScriptRouter 和标签路由 TagRouter。 内置容器 Spring Container Stable 自动加载META-INF/spring目录下的所有Spring配置 可用于生产环境 Alibaba Jetty Container Stable 启动一个内嵌Jetty，用于汇报状态 大量访问页面时，会影响服务器的线程和内存 可用于生产环境 Alibaba Log4j Container Stable 自动配置log4j的配置，在多进程启动时，自动给日志文件按进程分目录 用户不能控制log4j的配置，不灵活 可用于生产环境 Alibaba dubbo本地缓存注册中心服务列表 Dubbo通过注册中心发现服务，发现的服务Dubbo同时也会保存到本地缓存一份，缓存的好处有很多，比如不需要每次使用的时候都通过注册中心获取，注册中心不可用了，不影响消费端的调用，因为本地缓存了一份服务提供者列表。- - Dubbo本地缓存默认采用的文件，会根据注册中心自动在当前用户目录下生成一个缓存文件，类似/home/newad/.dubbo/dubbo-registry-....cache，星号表示注册中心的IP地址 如果有变更，注册中心将基于长连接推送变更数据给消费者。 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外，注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者 配置Dubbo缓存文件 123456789101112131415161718public AbstractRegistry(URL url) &#123; setUrl(url); //此处用于配置是否将提供者缓存到本地，如果不配置，则默认为false syncSaveFile = url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); String filename = url.getParameter(Constants.FILE_KEY, System.getProperty(&quot;user.home&quot;) + &quot;/.dubbo/dubbo-registry-&quot; + url.getParameter(Constants.APPLICATION_KEY) + &quot;-&quot; + url.getAddress() + &quot;.cache&quot;); File file = null; if (ConfigUtils.isNotEmpty(filename)) &#123; file = new File(filename); if (!file.exists() &amp;&amp; file.getParentFile() != null &amp;&amp; !file.getParentFile().exists()) &#123; if (!file.getParentFile().mkdirs()) &#123; throw new IllegalArgumentException(&quot;Invalid registry store file &quot; + file + &quot;, cause: Failed to create directory &quot; + file.getParentFile() + &quot;!&quot;); &#125; &#125; &#125; this.file = file; loadProperties(); notify(url.getBackupUrls());&#125; 配置加载流程 应用启动阶段，Dubbo框架如何将所需要的配置采集起来（包括应用配置、注册中心配置、服务配置等），以完成服务的暴露和引用流程。 根据驱动方式的不同（比如Spring或裸API编程）配置形式上肯定会有所差异，具体请参考XML配置、Annotation配置、API配置三篇文档。除了外围驱动方式上的差异，Dubbo的配置读取总体上遵循了以下几个原则： Dubbo支持了多层级的配置，并按预定优先级自动实现配置间的覆盖，最终所有配置汇总到数据总线URL后驱动后续的服务暴露、引用等流程。 ApplicationConfig、ServiceConfig、ReferenceConfig可以被理解成配置来源的一种，是直接面向用户编程的配置采集方式。 配置格式以Properties为主，在配置内容上遵循约定的path-based的命名规范配置来源（从上往下，优先级越来越低，即从上往下覆盖配置） JVM System Properties，-D参数 Externalized Configuration，外部化配置 ServiceConfig、ReferenceConfig等编程接口采集的配置 本地配置文件dubbo.properties dubbo的一次完整服务调用过程总体概括为：接口-代理-服务降级-客户端-编解码-序列化-网络传输-服务端-过滤链-线程池-实现类 调用方式以同步为例 调用服务接口API Dubbo 默认使用 Javassist 框架为服务接口生成动态代理类执行Invoker方法 InvokerInvocationHandler 中的 invoker 成员变量类型为 MockClusterInvoker，MockClusterInvoker 内部封装了服务降级逻辑。 可以直接进行服务降级处理，也可以等执行完了对应的cluster在进行服务降级处理 服务降级是在客户端进行的 根据Dubbo协议（协议其实就是不同的数据包格式）编解码，不同位代表不同的含义进行解析（其中header一共占用了96位） 魔数是否与规定的魔数相等，提前拦截掉非常规数据包 事件类型，心跳事件用于判定服务的可用性 消息体body进行序列化 netty进行nio网络传输 服务端解码，反序列化 线程派发模型 Dubbo 将底层通信框架中接收请求的线程称为 IO 线程。如果一些事件处理逻辑可以很快执行完，比如只在内存打一个标记，此时直接在 IO 线程上执行该段逻辑即可。但如果事件的处理逻辑比较耗时，比如该段逻辑会发起数据库查询或者 HTTP 请求。此时我们就不应该让事件处理逻辑在 IO 线程上执行，而是应该派发到线程池中去执行。原因也很简单，IO 线程主要用于接收请求，如果 IO 线程被占满，将导致它不能接收新的请求。 Dubbo 支持 5 种不同的线程派发策略 all 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件等 direct 所有消息都不派发到线程池，全部在 IO 线程上直接执行 message 只有请求和响应消息派发到线程池，其它消息均在 IO 线程上执行 execution 只有请求消息派发到线程池，不含响应。其它消息均在 IO 线程上执行 connection 在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池 调用实现类并返回结果 Dubbo外部化配置 外部化配置dubbo.properties 作用域：外部化配置有全局和应用两个级别，全局配置是所有应用共享的，应用级配置是由每个应用自己维护且只对自身可见的。 /dubbo/config节点下一个全局配置节点，一个应用配置节点，各自保存自己的.properties文件 自己加载外部化配置 所谓Dubbo对配置中心的支持，本质上就是把.properties从远程拉取到本地，然后和本地的配置做一次融合。理论上只要Dubbo框架能拿到需要的配置就可以正常的启动，它并不关心这些配置是自己加载到的还是应用直接塞给它的，所以Dubbo还提供了以下API，让用户将自己组织好的配置塞给Dubbo框架（配置加载的过程是用户要完成的），这样Dubbo框架就不再直接和Apollo或Zookeeper做读取配置交互。 12345678// 应用自行加载配置Map&lt;String, String&gt; dubboConfigurations = new HashMap&lt;&gt;();dubboConfigurations.put(&quot;dubbo.registry.address&quot;, &quot;zookeeper://127.0.0.1:2181&quot;);dubboConfigurations.put(&quot;dubbo.registry.simplified&quot;, &quot;true&quot;);//将组织好的配置塞给Dubbo框架ConfigCenterConfig configCenter = new ConfigCenterConfig();configCenter.setExternalConfig(dubboConfigurations); 服务治理 /dubbo/config/dubbo节点下configurators，覆盖规则tag-router，标签路由condition-router，条件路由 怎么判断zookeeper中的机器是否可用（服务失效踢出基于 Zookeeper 的临时节点原理） 在分布式系统中,我们常常需要知道某个机器是否可用,传统的开发中,可以通过Ping某个主机来实现,Ping得通说明对方是可用的,相反是不可用的,因为zookeeper是一个树形结构.ZK 中我们让所有的机器都注册一个临时节点,我们判断一个机器是否可用,我们只需要判断这个节点在ZK中是否存在就可以了,不需要直接去连接需要检查的机器,降低系统的复杂度 临时节点的生命周期和客户端会话绑定,也就是说,如果客户端会话失效,那么这个节点就会自动被清除掉 本地暴露于远程暴露的区别: 本地暴露是暴露在本机JVM中,调用本地服务不需要网络通信. 远程暴露是将ip,端口等信息暴露给远程客户端,调用远程服务时需要网络通信. dubbo通信协议dubbo协议为什么要消费者比提供者个数多：因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit=128MByte)，根据测试经验数据每条连接最多只能压满7MByte(不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。 dubbo通信协议dubbo协议为什么采用异步单一长连接：因为服务的现状大都是服务提供者少，通常只有几台机器，而服务的消费者多，可能整个网站都在访问该服务，比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，如果采用常规的hessian服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用异步IO，复用线程池，防止C10K问题。 dubbo使用范围Dubbo 缺省协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用 dubbo 协议传输大文件或超大字符串。传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。 配置案例 启动时检查：check=”true” ：关闭所有服务的启动时检查 (没有提供者时报错) ：关闭注册中心启动时检查 (注册订阅失败时报错) ：关闭某个服务的启动时检查 (没有提供者时报错) 集群容错：缺省为 failover 重试 Failover Cluster：失败自动切换，当出现失败，重试其它服务器 。通常用于读操作 ：设置重试次数 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小 Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。 负载均衡：缺省为 random 随机调用， Random LoadBalance：随机 RoundRobin LoadBalance：轮询 存在慢的提供者累积请求的问题 LeastActive LoadBalance：最少活跃次数 ConsistentHash LoadBalance：一致性hash（相同参数的请求总是发到同一提供者。） 缺省只对第一个参数 Hash，如果要修改，请配置 缺省用 160 份虚拟节点，如果要修改，请配置 线程派发策略 直连提供者 只订阅不注册服务 只注册不订阅服务 多协议 123456789&lt;dubbo:registry id=&quot;registry&quot; address=&quot;10.20.141.150:9090&quot; username=&quot;admin&quot; password=&quot;hello1234&quot; /&gt;&lt;!-- 多协议配置 --&gt;&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;&lt;dubbo:protocol name=&quot;rmi&quot; port=&quot;1099&quot; /&gt;&lt;!-- 使用dubbo协议暴露服务 --&gt;&lt;dubbo:service interface=&quot;com.alibaba.hello.api.HelloService&quot; version=&quot;1.0.0&quot; ref=&quot;helloService&quot; protocol=&quot;dubbo&quot; /&gt;&lt;!-- 使用rmi协议暴露服务 --&gt;&lt;dubbo:service interface=&quot;com.alibaba.hello.api.DemoService&quot; version=&quot;1.0.0&quot; ref=&quot;demoService&quot; protocol=&quot;rmi&quot; /&gt; //或者使用 &lt;dubbo:... protocol=&quot;dubbo,hessian&quot; /&gt; 多注册中心（类似多协议） 服务分组：一个接口多个实现 多版本 在低压力时间段，先升级一半提供者为新版本 再将所有消费者升级为新版本 然后将剩下的一半提供者升级为新版本 分组聚合：合并结果返回，聚合菜单项 指定某些方法合并，某些不合并 结果缓存：声明式缓存， lru 基于最近最少使用原则删除多余缓存，保持最热的数据被缓存。 threadlocal 当前线程缓存，比如一个页面渲染，用到很多 portal，每个 portal 都要去查用户信息，通过线程缓存，可以减少这种多余访问。 jcache 与 JSR107 集成，可以桥接各种缓存实现。 服务降级（使用本地伪装来实现服务降级） mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。 不同的版本支持不同的用法，具体参照官网文档使用 Dubbo 和 Spring Cloud 有什么区别？多版本兼容dubbo和配置中心通讯方式Dubbo 服务暴露的过程画一画服务注册与发现的流程图SPI (Service Provide Interface) 是给扩展者用的C10K问题]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP]]></title>
    <url>%2F2019%2F02%2F10%2FHTTP%2F</url>
    <content type="text"><![CDATA[HTTP 什么是HTTP HTTP为什么无状态，如何解决 HTTP的实际应用 HTTP优化 HTTP HTTP/2 提供了连接复用、双向流、服务器推送、请求优先级、首部压缩等机制，所以在通信过程中可以节省带宽、降低 TCP 连接次数、节省 CPU，尤其对于移动端应用来说，可以帮助延长电池寿命。 什么是HTTP 底层实现还是TCP，只是对TCP的封装 HTTP：应用层协议，主要负责数据的包装；本质为请求-应答，因此服务端不能主动推送任何消息。 对于HTTP协议来说，服务端给一次响应后整个请求就结束了（服务器发送响应消息后断开连接，下次访问Web 服 务器的时候，再重新建立TCP连接 。因此，在Web 服务器看来，每一次 HTTP访问都是相互独立的，无法判断是否和之前的请求相关），这是HTTP请求最大的特点，也是由于这个特点，HTTP请求无法做到的是服务端向客户端主动推送数据。 HTTP无状态协议，是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 HTTP为什么无状态，如何解决 为什么无状态 Web 服务器最早并不是用来运行 CGI程序的，而是主要用来提供静态文件的，而静态文件不需要判断请求之间的相关性，因此最早设计HTTP规格的时候，就有意省略了请求之间 相关性的判断。 解决方案 客户端与服务器进行动态交互的Web应用程序出现之后，HTTP无状态的特性严重阻碍了这些应用程序的实现，毕竟交互是需要承前启后的，简单的购物车程序也要知道用户到底在之前选择了什么商品。于是，两种用于保持HTTP连接状态的技术就应运而生了，一个是Cookie，而另一个则是Session。HTTP本身是一个无状态的连接协议，为了支持客户端与服务器之间的交互，我们就需要通过不同的技术为交互存储状态，而这些不同的技术就是Cookie和Session了。 Cookie是通过客户端保持状态的解决方案。从定义上来说，Cookie就是由服务器发给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息。让我们说得更具体一些：当用户使用浏览器访问一个支持Cookie的网站的时候，用户会提供包括用户名在内的个人信息并且提交至服务器；接着，服务器在向客户端回传相应的超文本的同时也会发回这些个人信息，当然这些信息并不是存放在HTTP响应体（Response Body）中的，而是存放于HTTP响应头（Response Header）；当客户端浏览器接收到来自服务器的响应之后，浏览器会将这些信息存放在一个统一的位置，对于Windows操作系统而言，我们可以从： [系统盘]:\Documents and Settings[用户名]\Cookies目录中找到存储的Cookie；自此，客户端再向服务器发送请求的时候，都会把相应的Cookie再次发回至服务器。而这次，Cookie信息则存放在HTTP请求头（Request Header）了。 HTTP的实际应用 几种基于HTTP协议的实时数据获取方法 轮询访问 短轮询（客户端轮询）：客户端定时发送请求，直到server返回client想要的数据 简单粗暴，无效请求太多，浪费带宽和服务器资源 高并发下，可能导致服务器压力瞬间过大宕机 适用于数据变化比较频繁，或者是预期数据在短时间内可能发生变化 请求的上限次数要做好控制，一定次数没得到的结果便可结束请求，换另一种方式查看 长轮询（服务器轮询）：sever接收到client请求后挂起，然后启动监听，监听数据的变动（也是轮询），一旦有变更返回给client 减少了大量客户端无效的请求 客户端需设置等待超时时间，超时重发请求 server会挂起大量的请求占用资源 服务器对http并发请求数量有限 注意：轮询方式的存在问题 轮询其实是伪实时，因为无论再短的轮询都会存在一定的延时； 所有的请求，只要没有重要数据返回，都是对计算资源的一种浪费 http协议较重，因为每次请求都必须带有http的首部和head头部，但真正有用的其实只有BODY，多余数据是对带宽的一种浪费 WebSocket：一种基于http协议的新协议（可以实现服务端主动推送数据变更） 实时 大量节省带宽 分布式环境下数据同步代价较高uri和url URI，是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。 Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的URI一般由三部组成： ①访问资源的命名机制 ②存放资源的主机名 ③资源自身的名称，由路径表示，着重强调于资源。 URL是uniform resource locator，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。 一次完整HTTP请求 建立tcp连接 发送请求 接收请求，回传响应，然后关闭tcp连接 接收响应 HTTP优化 TCP复用：TCP连接复用是将多个客户端的HTTP请求复用到一个服务器端TCP连接上，而HTTP复用则是一个客户端的多个HTTP请求通过一个TCP连接进行处理。前者是负载均衡设备的独特功能；而后者是HTTP 1.1协议所支持的新功能，目前被大多数浏览器所支持。 Connection:keep-alive保持服务端tcp连接不中断 内容缓存：将经常用到的内容进行缓存起来，那么客户端就可以直接在内存中获取相应的数据了。 压缩：将文本数据进行压缩，减少带宽]]></content>
      <categories>
        <category>Protocol</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode Array]]></title>
    <url>%2F2019%2F02%2F03%2FLintCode%20Array%2F</url>
    <content type="text"><![CDATA[LintCode 数组相关 删除元素 子数组之和 删除排序数组中重复数字 合并排序数组 两数之和 数组剔除元素后的乘积 丢失的第一个正整数 最接近的三数之和 三数之和 数组划分 删除元素 给定一个数组和一个值，在原地删除与值相同的数字，返回新数组的长度。元素的顺序可以改变，并且对新的数组不会有影响。 思路：原地删除意思是不能借助额外数组，只能在这个数组上操作，边校验边删除边移动1234567891011121314public int removeElement(int[] A, int elem) &#123; // write your code here int j = 0; int a[] = new int[A.length]; for(int i = 0;i &lt; A.length;i++)&#123; if(A[i]!=elem) a[j++] = A[i]; &#125; for(int i = 0;i &lt; j;i++)&#123; A[i] = a[i]; &#125; A = new int[j]; return A.length;&#125; 子数组之和 给定一个整数数组，找到和为零的子数组。你的代码应该返回满足要求的子数组的起始位置和结束位置 思路：两层嵌套循环1234567891011121314151617181920212223public ArrayList&lt;Integer&gt; subarraySum(int[] nums) &#123; // write your code here ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int i = 0;i &lt; nums.length;i++)&#123; int sum = nums[i]; if(sum==0)&#123; list.add(i); list.add(i); break; &#125; for(int j = i+1;j &lt; nums.length;j++)&#123; sum +=nums[j]; if(sum==0)&#123; list.add(i); list.add(j); break; &#125; &#125; if(sum==0) break; &#125; return list;&#125; 删除排序数组中重复数字 给定一个排序数组，在原数组中“删除”重复出现的数字，使得每个元素只出现一次，并且返回“新”数组的长度。不要使用额外的数组空间，必须在不使用额外空间的条件下原地完成。 思路：同样是原地完成，双指针，一个指向实际数组位置，一个指向无重复位置12345678910111213141516171819202122232425262728public int removeDuplicates(int[] nums) &#123; // write your code here if(nums.length &lt; 2) return nums.length; else&#123; int result = 0; int temp = 0; for(int i = 0;i &lt; nums.length-1;i=temp)&#123; for(int j = i+1;j &lt; nums.length;j++)&#123; if(nums[i]==nums[j])&#123; if(j &lt; nums.length-1) continue; else &#123; temp = j; break; &#125; &#125; else&#123; nums[++result] = nums[j]; temp = j; break; &#125; &#125; &#125; nums = new int[result+1]; return nums.length; &#125;&#125; 合并排序数组 合并两个排序的整数数组A和B变成一个新的数组。 思路：新建一个数组存放结果，两数组一次比较往新数组中存放两数之和 给一个整数数组，找到两个数使得他们的和等于一个给定的数 target。你需要实现的函数twoSum需要返回这两个数的下标, 并且第一个下标小于第二个下标。注意这里下标的范围是 0 到 n-1。 思路：1. 双层嵌套循环 2. 使用hashmap123456789101112131415public int[] twoSum(int[] numbers, int target) &#123; // write your code here int result[] = new int[2]; int re[][] = new int[numbers.length][numbers.length]; for(int i = 0;i &lt; numbers.length;i++)&#123; for(int j = i;j &lt; numbers.length;j++)&#123; re[i][j] = numbers[i] + numbers[j]; if(re[i][j]==target&amp;&amp;i!=j)&#123; result[0] = i+1; result[1] = j+1; &#125; &#125; &#125; return result;&#125; 数组剔除元素后的乘积 给定一个整数数组A。定义B[i] = A[0] … A[i-1] A[i+1] … * A[n-1]， 计算B的时候请不要使用除法。请输出B。 思路：嵌套循环1234567891011121314151617public ArrayList&lt;Long&gt; productExcludeItself(ArrayList&lt;Integer&gt; A) &#123; // write your code int j = 0; ArrayList&lt;Long&gt; list = new ArrayList&lt;Long&gt;(); while(j &lt; A.size())&#123; long sum = 1; for(int i = 0;i &lt; A.size();i++)&#123; if(i!=j) sum *=A.get(i); else continue; &#125; list.add(sum); j++; &#125; return list;&#125; 丢失的第一个正整数 给出一个无序的整数数组，找出其中没有出现的最小正整数。 思路：1. 排序查找 2. 存入位后判存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public int firstMissingPositive(int[] A) &#123; // write your code here int result = 1; if(A.length!=0)&#123; Arrays.sort(A); int index = binarySerach(A); int j = 1; for(int i = index;i &lt; A.length;i++)&#123; if(A[i] &lt;=0) continue; else&#123; if(A[i]==j)&#123; j++; continue; &#125; else if(A[i]==j-1) continue; else&#123; result = j; break; &#125; &#125; &#125; if(--j==A[A.length-1]) return (++j); else return result; &#125; else return result;&#125;public static int binarySerach(int A[])&#123; int zero = 0; int begin = 0; int end = A.length; while(begin!=end)&#123; zero = (begin+end)/2; if(A[zero] &lt; 0)&#123; if(zero==A.length-1||A[zero+1] &gt; 0)&#123; return zero; &#125; else&#123; begin = zero; continue; &#125; &#125; else if(A[zero] &gt; 0)&#123; if(zero==0||A[zero-1] &lt; 0)&#123; return zero; &#125; else&#123; end = zero; continue; &#125; &#125; else return zero; &#125; return zero;&#125; 最接近的三数之和 给一个包含 n 个整数的数组 S, 找到和与给定整数 target 最接近的三元组，返回这三个数的和。 思路：拆解一个数出来之后就变成了两数之和123456789101112131415161718192021222324252627public int result = 0;public int MIN = Integer.MAX_VALUE;public int threeSumClosest(int[] numbers, int target) &#123; // write your code here int temp[] = new int[3]; return combine(numbers.length,3,numbers,temp,target);&#125;public int combine(int n,int m,int N[],int temp[],int target)&#123; if(m==0)&#123; int sum = 0; for(int i = 0;i &lt; temp.length;i++)&#123; sum += temp[i]; &#125; if(MIN &gt; Math.abs(sum-target))&#123; MIN = Math.abs(sum-target); result = sum; &#125; &#125; else if(n &lt; m) return 0; else&#123; combine(n-1,m,N,temp,target); temp[m-1] = N[n-1]; combine(n-1,m-1,N,temp,target); &#125; return result;&#125; 三数之和 给出一个有n个整数的数组S，在S中找到三个整数a, b, c，找到所有使得a + b + c = 0的三元组。 思路：a+b+c=0等价于a+b=-c又转化为了两数之和1234567891011121314151617181920212223242526272829303132public int a = 0;public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; list = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;();public Map&lt;Integer,ArrayList&lt;Integer&gt;&gt; map = new HashMap&lt;Integer,ArrayList&lt;Integer&gt;&gt;();public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; threeSum(int[] numbers) &#123; // write your code here Arrays.sort(numbers); int temp[] = new int[3]; combine(numbers.length,3,numbers,temp); return list;&#125;public void combine(int n,int m,int N[],int temp[])&#123; if(m==0)&#123; Arrays.sort(temp); if(temp[0]+temp[1]+temp[2]==0)&#123; ArrayList&lt;Integer&gt; templist = new ArrayList&lt;Integer&gt;(); templist.add(temp[0]); templist.add(temp[1]); templist.add(temp[2]); if(!map.containsValue(templist))&#123; map.put(a++, templist); list.add(templist); &#125; &#125; &#125; else if(n &lt; m) return; else&#123; combine(n-1,m,N,temp); temp[m-1] = N[n-1]; combine(n-1,m-1,N,temp); &#125;&#125; 数组划分 给出一个整数数组 nums 和一个整数 k。划分数组（即移动数组 nums 中的元素），使得： 所有小于k的元素移到左边 所有大于等于k的元素移到右边 返回数组划分的位置，即数组中第一个位置 i，满足 nums[i] 大于等于 k。 思路：双指针，一前一后，局部有序12345678910111213141516171819public int partitionArray(int[] nums, int k) &#123; //write your code here int result = 0; if(nums.length!=0)&#123; Arrays.sort(nums); for(int i = 0;i &lt; nums.length;i++)&#123; if(nums[i] &gt;=k)&#123; result = i; break; &#125; &#125; if(result==0&amp;&amp;k &gt; nums[nums.length-1]) return nums.length; else return result; &#125; else return result;&#125;]]></content>
      <categories>
        <category>LintCode</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LintCode</tag>
        <tag>Array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode String]]></title>
    <url>%2F2019%2F01%2F27%2FLintCode%20String%2F</url>
    <content type="text"><![CDATA[LintCode 字符串相关 两个字符串是变位词 比较字符串 字符串查找 乱序字符串 最长公共子串 最长公共前缀 两个字符串是变位词 写出一个函数 anagram(s, t) 判断两个字符串是否可以通过改变字母的顺序变成一样的字符串。 思路：将所有字母排序后判定是否相等12345678910111213public boolean anagram(String s, String t) &#123; // write your code here char a[] = s.toCharArray(); char b[] = t.toCharArray(); Arrays.sort(a); Arrays.sort(b); String a1 = new String(a); String b1 = new String(b); if(a1.equals(b1)) return true; else return false;&#125; 比较字符串 比较两个字符串A和B，确定A中是否包含B中所有的字符。字符串A和B中的字符都是 大写字母 思路：理解包含的具体含义，是否允许重复；拆分b到a中判存123456789101112131415161718public boolean compareStrings(String A, String B) &#123; // write your code here if(A.length() &lt; B.length()) return false; else&#123; boolean flag = true; char[] c = B.toCharArray(); for(int i = 0;i &lt; c.length;i++)&#123; if(A.indexOf(c[i])!=-1)&#123; String s = String.valueOf(c[i]); A = A.replaceFirst(s, &quot;&quot;); &#125; else flag = false; &#125; return flag; &#125;&#125; 字符串查找 对于一个给定的 source 字符串和一个 target 字符串，你应该在 source 字符串中找出 target 字符串出现的第一个位置(从0开始)。如果不存在，则返回 -1。 思路：KMP算法 KMP算法的关键是利用匹配失败后的信息，尽量减少模式串与主串的匹配次数以达到快速匹配的目的。具体实现就是实现一个next()函数，函数本身包含了模式串的局部匹配信息。时间复杂度O(m+n)。 123456789101112void getNext(string W)&#123; for(int i=1; i&lt;m; i++)&#123; int j=i; while(j&gt;0)&#123; j=next[j]; if(W[j]==W[i])&#123; next[i+1]=j+1; break; &#125; &#125; &#125;&#125; 乱序字符串 给出一个字符串数组S，找到其中所有的乱序字符串(Anagram)。如果一个字符串是乱序字符串，那么他存在一个字母集合相同，但顺序不同的字符串也在S中。 思路：数组中每个字符串排序后放入hashmap中判重，重说明为乱序字符串，放入结果list中1234567891011121314151617181920212223242526public List&lt;String&gt; anagrams(String[] strs) &#123; // write your code here if(null==strs||0==strs.length) return null; HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); List&lt;String&gt; res = new ArrayList&lt;&gt;(); for(int i=0;i&lt;strs.length;i++)&#123; String tmp = strsort(strs[i]); if(!map.containsKey(tmp))&#123; map.put(tmp, i); &#125;else&#123; int loc = map.get(tmp); if(loc!=-1)&#123; res.add(strs[loc]); &#125; res.add(strs[i]); map.put(tmp, -1); &#125; &#125; return res; &#125; public String strsort(String str) &#123; char chars[] = str.toCharArray(); Arrays.sort(chars); String res = new String(chars); return res; &#125; 最长公共子串 给出两个字符串，找到最长公共子串，并返回其长度。 思路：动态规划，两个字符串分别作为行和列构造一个矩阵，每行每列比较值，相等为1，否为0，这样最长公共字串就是对角线连续为1的最大值123456789101112131415161718192021public int longestCommonSubstring(String A, String B) &#123; // write your code here char a[] = A.toCharArray(); char b[] = B.toCharArray(); int c[][] = new int[a.length+1][b.length+1]; int max = 0; for (int i = 1;i &lt;= a.length;i++)&#123; for (int j = 1;j &lt;= b.length;j++)&#123; if(a[i-1]==b[j-1])&#123; c[i][j] = c[i-1][j-1] + 1; if(c[i][j] &gt; max)&#123; max = c[i][j]; &#125; &#125; else&#123; c[i][j] = 0; &#125; &#125; &#125; return max;&#125; 最长公共前缀 给k个字符串，求出他们的最长公共前缀(LCP) 思路：循环每个字符串判定，时间复杂度取决于数组个数*（公共前缀个数+1）12345678910111213141516171819202122232425262728public String longestCommonPrefix(String[] strs) &#123; // write your code here if(strs.length==0) return &quot;&quot;; else if(strs.length==1) return strs[0]; else&#123; boolean boo = true; int j = 0; StringBuilder result = new StringBuilder(); char str[] = strs[0].toCharArray(); while(boo&amp;&amp;j &lt; str.length)&#123; for(int i = 0;i &lt; strs.length;i++)&#123; if(strs[i].length() &lt; j+1||str[j]!=strs[i].charAt(j))&#123; boo = false; break; &#125; &#125; if(boo)&#123; result.append(str[j]); j++; &#125; else break; &#125; return result.toString(); &#125;&#125;]]></content>
      <categories>
        <category>LintCode</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LintCode</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rate Limit]]></title>
    <url>%2F2019%2F01%2F20%2FRate%20Limit%2F</url>
    <content type="text"><![CDATA[限流算法 基于计数器的限流算法 基于滑动窗口的限流算法 漏桶算法 令牌桶算范 基于计数器的限流算法 定义每秒或者每分钟可以通过的请求数量，用一个变量来记录；超过该请求数量的直接丢弃，然后每秒/分钟重置该变量 这种算法是最简单的，就是定义了单位时间内允许的流量。 危险的边界值 这种算法实现起来很简单，但是对于边界值的处理很危险 假设定义一分钟内允许通过的流量为1000，一个用户在59.98秒的时候发了1000个请求（该一分钟内除了此用户没有其他用户流量），这1000个请求按照计数器算法合理通过给到服务器，然后此用户又在60.01秒（也就是上一分钟刚刚结束，下一分钟刚刚开始的时候）再次发送了1000个请求，根据计数器算法依然合理通过给到服务器，这个时候相当于服务器在1秒内接受到了2000个请求，如果2000这个值大于服务器的承受能力，则会造成服务器的故障甚至宕机。 基于滑动窗口的限流算法 由于计数器算法会存在危险的边界值问题，所以出现了加强版算法基于滑动窗口的限流算法 基于滑动窗口的限流算法将定义的一个时间单位会分成若干个小的窗口，单位时间内的流量限制不变，只不过变成各个小窗口的和；这样时间移动过程中，每次滑动一个小窗口； 安全的边界值 假设定义一分钟内允许通过的流量为1000，窗口个数为10个（编号1到10），一个用户在59.98秒的时候，也就是第10个窗口发了1000个请求（该一分钟内除了此用户没有其他用户流量且其他窗口也没有流量），这1000个请求按照算法合理通过给到服务器，然后此用户又在60.01秒（也就是上一分钟刚刚结束，下一分钟刚刚开始的时候；这个时候1号窗口移动到了10号窗口的后面，其他窗口不变；）再次发送了1000个请求，根据算法这个时间限制内请求已经达到上限（10个窗口之和），所以请求会被拒绝丢弃掉。这个时候相当于服务器在1秒内接受到了1000个请求，避免了请求瞬间翻倍的情况。 漏桶算法 采用一个固定容量的桶来存放请求（实际中使用消息队列），存放速率不做任何限制，但是当桶满了之后就不能再存放请求，这个时候请求被丢弃；一边没有限制的存放请求，一边我们定义一个固定的速率去拿取请求； 该算法对于服务器来说比较友好，因为始终以一种固定的速率给服务器发送请求，服务器不会面对突发流量（因为都被挡在桶中） 不存在边界值问题，因为发往服务器的请求均以一定的速率返送，而该速率的制定一定是服务器承受范围之内的。 令牌桶算法 令牌桶算法与漏桶算法思路相反，限制往桶中存放请求的速率，而不限制从桶中拿取请求的速率； 同样采用一个固定容量的桶来存放请求，以一定的速率往桶中存放请求；实际该速率值可能较大，正常流量较少时，往桶中存放的请求也就相对较少，这时发往服务器的请求也就相对较少（拿取时可以直接将桶中请求全部拿走发给服务器，因为没有限制）；当有突发流量时，桶中请求也会瞬间猛增，这时发往服务器的请求也会骤增，相当于面对突发流量） 安全的边界值 虽然从桶中拿取的速率不做限制，但是桶中得有请求才行，所以从桶中拿取的速率其实是受限于桶中请求的存放速率，如果桶中一秒中可以积累100个请求，则从桶中拿取的速率就是100个请求/s，但是实际桶中请求的数量需要一定时间的积累，所以当上一秒拿取速率特别大时（存放积累好久的请求），下一秒往往不会很大（积累的请求都被上一秒拿走了），也就不会存在边界值翻倍的情况。]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2F2019%2F01%2F13%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁 悲观锁 重量级锁 自旋锁 自适应自旋锁 独占锁 乐观锁 轻量级锁 偏向锁 共享锁 可重入锁 公平/非公平锁 共享锁和独占锁 分段锁 java中的锁 如何优化锁 悲观锁 悲观锁以一种悲观的心态看待所有的程序调用，认为只要发生调用就会发生数据改动，所以一旦调用就会加锁，防止其他线程来改动数据；适用于写多读少的情况。 重量级锁 线程判定资源是否可用，可用加锁使用，使用完释放锁；若不可用则直接进入阻塞状态，等待锁释放唤醒重新抢夺锁资源；这种一旦判定资源可用就将资源加锁锁定不允许其他线程访问的我们称之为重量级锁。 线程进入阻塞状态和加锁操作都是一个很耗时的过程，会涉及到上下文保存，线程用户态，核心态的切换等，所以称之为重量级锁。 自旋锁 由于重量级锁线程每次都要经历进出阻塞状态这个耗时的过程，但是有时候可能线程等待锁资源释放的时间要比进出阻塞状态所耗费的时间少，所以出现自旋锁。 自旋锁当线程判定资源不可用时，并不是直接进入阻塞状态，而是挂起等待一定时间，即自旋（类似空循环一样）；若是自旋结束后锁也释放则直接抢夺锁资源，否则线程进入阻塞状态。 自适应自旋锁 自旋锁的关键就是自旋时间的长短，太长太短都不合适，并且不同情况自旋时间也大不相同，所以采用相同的自旋时间明显不合适，因此出现了自适应自旋锁。 自适应自旋锁的自旋时间由系统本身去判定，根据线程获取到锁的概率去定制不同的自旋时间。 乐观锁 乐观锁以一种乐观的心态看待所有的程序调用，认为所有的调用均不会发生数据改动，所以发生调用的时候并不会加锁（而是做一个标记，标记次调用有人在执行，采用CAS操作执行），而是等到真正发生数据改动的时候才进行加锁；适用于读多写少的情况。 乐观锁的实现 以对某一张表执行更新操作为例，表中添加一个version字段作为乐观锁标记字段，类型为timestamp not null default current_timestamp on update current_time update之前我们进行select将version字段取出作为乐观锁的标记 然后执行update的时候将之前取出的version值作为where条件加到update语句中，以此来作为乐观锁标记 如果在执行select语句到update语句之间数据没有没其他线程改动过，则version字段值不会发生变动，update语句也可以执行成功，否则标记字段发生变动，update语句执行失败，重新从select开始执行 轻量级锁 对于资源竞争激烈，即同一时间还有多个线程来访问资源，我们使用重量级锁（悲观锁）是应该的，但是并不是所有的时候都会有那么多的线程竞争，所以如果当线程很少或者说是根本没有竞争存在，那么加锁就变得冗余了，因此出现了轻量级锁来应对线程竞争不是很激烈的情况或者是线程总是交错执行的情况。 轻量级锁每次线程判定资源可用时，不会加锁，而是添加一个标识，标识该资源有人在使用了（该标识的改变使用CAS操作完成），使用完成后再将其标识更改为无人使用； 如果就是没有竞争的发生，我们可能认为标识位可有可无，因为没有用到，那么标识位什么时候用到呢；当出现竞争的时候标识位就有用了，他会告知当前线程有人来抢资源了，这时资源就必须要加锁了，也就是轻量级锁必须升级为重量级锁了，不然就会出现数据被其他线程改动的情况。 偏向锁 偏向锁直接认为资源不会发生竞争，所以和轻量级锁一样在进入资源的时候会添加一个标识，同时比轻量级锁多添加一个当前线程id。而当离开资源的时候也不会去更改资源标识，这样当下次再次访问该资源的时候，如果判定标识为已有人使用，同时线程id是自己的话，直接进入避免执行CAS操作。这样，偏向锁可以使的线程更快的进入资源执行操作； 偏向锁适用于线程竞争几乎不存在的情况，相当于单线程； 当资源竞争发生时，线程判定资源标识为又人使用，但是却不是自己的id时，偏向锁就升级为轻量级锁了。 可重入锁 可重入锁，也叫 做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受 影响。 公平/非公平锁 公平锁 加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得 非公平锁 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待 非公平锁性能比公平锁高5~10倍，因为公平锁需要在多核的情况下维护一个队列 Java中的synchronized是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。 共享锁和独占锁 独占锁 独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。 独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线 程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 共享锁 共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种 乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 分段锁 分段锁也并非一种实际的锁，而是一种思想。ConcurrentHashMap是学习分段锁的最好实践 java中的锁Synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁，同时属于可重入锁，非公平锁。 由操作系统Mutex Lock实现。 ReentrantLock 由jdk实现；提供公平/非公平锁，条件锁，响应中断锁；属于重入锁，独占锁，乐观锁 Semaphore 基于计数器实现；提供公平/非公平锁，基本可以完成ReentrantLock的所有工作 AtomicInteger 原子类，为i++专门提供的原子类，性能比手动加锁高很多 ReadWriteLock 读写锁：java专门为提供读写性能提供的锁 读锁 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 写锁 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上 读锁，写的时候上写锁！ 如何优化锁 减少锁持有时间 减少锁的粒度（分段锁） 锁分离（读写锁分离） 锁粗化 当一个线程对资源操作时间较长时，出于减少锁持有时间的考虑，会造成该线程对锁资源不停的进行持有和释放操作，其本身也会浪费大量的性能]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Limits on MySql]]></title>
    <url>%2F2019%2F01%2F06%2FLimits%20on%20MySql%2F</url>
    <content type="text"><![CDATA[Limits on MySql 以下所有内容基于存储引擎为InnoDB mysql没有数据库数量的限制和表数量的限制，InnoDB允许多达40亿个表。 数据文件大小（数据文件，索引文件）取决于操作系统磁盘空间 mysql硬性限制一张表最多4096个字段，实际情况肯定小于此值 mysql限制表中每行记录大小最大为65535个字节（text类型的字段除外，也就是说含有text类型字段的表中每行记录大小可以突破65535字节的限制） mysql存储可变参数时，不仅要空间保存其value值，还要保存其length长度，例如：varchar(N)在编码格式为utf8mb3下，长度需要占2个字节，所以该字段长度为N+2，计算行大小时要注意把长度也算在内。 MyISAM存储引擎下，字段非空的时候需要额外的空间去保存该值是否为空，所以计算每行大小时也要计算在内。 ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBs InnoDB限制一张表最多含有1017个字段（mysql5.6.9之前为1000） InnoDB限制一张表最多含有64个耳机索引 InnoDB：默认索引前缀长度限制为767个字节，当编码格式为utf8mb3时，varchar(n)类型或者text(n)类型字段一个字符占3字节，所以其上限为255个字符；当配置选项 innodb_large_prefix开启后，使用dynamic或者compressed行格式的表索引前缀上限可以提升至3072个字节； InnoDB一个page的默认大小是 16 k。由于是Btree组织，要求叶子节点上一个page至少包含两条记录（否则就退化链表了）。所以一个记录最多不能超过 8 k。又由于InnoDB的聚簇索引结构，一个二级索引要包含主键索引，因此每个单个索引不能超过 4 k（极端情况，pk和某个二级索引都达到这个限制）。由于需要预留和辅助空间，扣掉后不能超过 3500 ，取个“整数”就是(1024*3)。主要字符集的计算方式： latin1 = 1 byte = 1 character uft8 = 3 byte = 1 character gbk = 2 byte = 1 character varchar最大有效长度是 65532 字节，在 varchar 存字符串的时候，第一个字节是空的，不存任何的数据，然后还需要两个字节来存放字符串的长度。所以有效长度就是 65535 - 1 - 2= 65532 由字符集来确定，字符集分单字节和多字节 Latin1 一个字符占一个字节，最多能存放 65532 个字符 GBK 一个字符占两个字节， 最多能存 32766 个字符 UTF8 一个字符占三个字节， 最多能存 21844 个字符 InnoDB限制一个索引最多包含16个字段 InnoDB限制，除了可变长度列（VARBINARY，VARCHAR，BLOB和TEXT）之外，最大行长度略小于页面的一半；配置参数 innodb_page_size=16K时，每行记录最大长度为8000个字节，8K时为4000个字节，4K时为2000个字节 尽管InnoDB在内部支持大于65,535字节的行大小，但MySQL本身对所有列的组合大小施加了行大小限制65,535： 当表空间太大时，建议将其分为多个小文件 log日志文件大小最大512GB 最小表空间大小10M，最大表空间大小取决于page size的设置 InnoDB Page Size Maximum Tablespace Size 4KB 16TB 8KB 32TB 16KB 64TB 参数max_allowed_packet：Mysql 对语句的长度有限制 bulk_insert_buffer_size：insert语句缓存大小 Net_buffer_length general_log和general_log_file：sql操作日志开关和目录 useServerPrepStmts：默认使用PreparedStatement是不能执行预编译的，这需要在url中给出useServerPrepStmts=true参数（MySQL Server 4.1之前的版本是不支持预编译的，而Connector/J在5.0.5以后的版本，默认是没有开启预编译功能的）。这样才能保证mysql驱动会先把SQL语句发送给服务器进行预编译，然后在执行executeQuery()时只是把参数发送给服务器。 cachePrepStmts：当使用不同的PreparedStatement对象来执行相同的SQL语句时，还是会出现编译两次的现象，这是因为驱动没有缓存编译后的函数key，导致二次编译。如果希望缓存编译后函数的key，那么就要设置cachePrepStmts参数为true。例如：jdbc:mysql://localhost:3306/test?useServerPrepStmts=true&amp;cachePrepStmts=true rewriteBatchedStatements：MySQL的批处理也需要通过参数来打开 innodb_open_files=4000 #设置同时最大打开表个数]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Reference]]></title>
    <url>%2F2018%2F12%2F30%2FJava%20Reference%2F</url>
    <content type="text"><![CDATA[Java Reference FinalReference WeakReference SoftReference PhantomReference FinalReference强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 ps：强引用其实也就是我们平时A a = new A()这个意思。 WeakReference如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存（下文给出示例）。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 SoftReference弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 PhantomReference“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。 应用场景缓存]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Replication]]></title>
    <url>%2F2018%2F12%2F23%2FMySQL%20Replication%2F</url>
    <content type="text"><![CDATA[Replication Principle Implement And Configuration Problems In The Process PrincipleBinary Logging File 二进制日志文件：数据库实例操作master将更新和变动以event的形式写入二进制日志文件中，slave配置读取master的二进制日志问文件在本地执行以实现数据同步（slave可以自行决定执行文件的哪些部分，还是全部执行），slave同时保存二进制日志文件的文件名和读取位置以便于下次增量读取同步数据 mysql配置文件中’binlog = /日志文件位置’开启master同步，配置文件修改后记得重启mysql master的binary logging一定要处于开启状态，但是slave并不需要，因此建议关闭，除非遇到A-&gt;B-&gt;C这种主从关系 server-id master和slave均必须配置唯一ID（范围[1,2^32-1]，master配置id为0不允许任何slave连接，slave配置id为0不会连接任何master Replication Exclusive User master可以创建replication的专属用户设置 mysql&gt; CREATE USER &apos;repl&apos;@&apos;%.example.com&apos; IDENTIFIED BY &apos;password&apos;; mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;%.example.com&apos;; Implement And Configuration master配置 log-bin开启 配置唯一server-id 最好使用innodb引擎，并配置如下参数 innodb_flush_log_at_trx_commit=1 sync_binlog=1 确保 skip-networking未开启，否则没有网络，主从无法通信 slave配置 配置唯一server-id slave中log-bin没必要开启，除非slave下还有slave挂载，该情况下还需要开启–log-slave-updates（默认开启）以实现将master传送过来的写更新操作通过sql线程更新到自己的log-bin中，以实现数据向下同步 –skip-log-bin 和–skip-log-slave-updates 参数可关闭slave的log-bin和log-slave-updates 创建同步专属用户 Replication Exclusive User 获取master同步二进制文件坐标position 使用 FLUSH TABLES WITH READ LOCK, 操作（刷新所有表数据，获取读锁，阻断写操作）会阻断所有在 InnoDB 引擎的下表操作的提交 如果要shutdown主机拷贝数据，则不需要再获取master同步二进制文件坐标position，因为主机重启后会创建新的二进制文件 在master的一个客户端session连接中执行FLUSH TABLES WITH READ LOCK;命令，该命令在该客户端session连接保持内有效，若该客户端session连接关闭，该命令失效 在另一个客户端session连接中执行show master status，查看主机状态信息，记录同步日志文件名和位置 master含有原始数据，保持读锁，执行数据拷贝（转向步骤5） master没有原始数据，slave也是新机器（转向步骤6） 选择数据快照方式 mysqldump方式（推荐方式） 命令mysqldump –all-databases –master-data &gt; dbdump.sql将所有的数据库数据和结构dump到的比dbdump.sql中，并包含–master-data选项，该选项自动附加从站上所需的CHANGE MASTER TO语句以启动复制过程： 如果不使用–master-data，则需要手动锁定单独会话中的所有表 参数–ignore-table排除不想同步的表 参数–databases指定同步数据库 若数据存储在便携式二进制文件中，可以拷贝行数据文件实现数据拷贝（不做过多介绍） 设置复制从属 master解锁 UNLOCK TABLES; 如果有原始数据需要引入slave中 启动slave，并使用参数–skip-slave-start 避免复制同步开始 向slave中导入master原始数据 slave配置master信息 start slave开启复制同步 没有原始数据需要引入slave， 启动slave slave配置master信息 start salve开启复制同步 在slave中配置master主机信息123456mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST='master_host_name', -&gt; MASTER_USER='replication_user_name', -&gt; MASTER_PASSWORD='replication_password', -&gt; MASTER_LOG_FILE='recorded_log_file_name', -&gt; MASTER_LOG_POS=recorded_log_position; 在已有的主从环境中添加slave 停止已有的slave并记录状态信息 mysql&gt; STOP SLAVE; mysql&gt; SHOW SLAVE STATUS\G shutdown已有slave 由已有slave向新slave拷贝数据，包括log文件和relay log文件 拷贝完成，重启已有slave 配置新slave（注：唯一id） 启动新slave使用参数 –skip-slave-start ，查看状态信息是否正确 SHOW SLAVE STATUS 启动复制过程mysql&gt; START SLAVE; Problems In The Process 服务器之间ping通但是telnet不通解决方案： 清防火墙sudo iptables -F 开通防火墙响应端口（centos6常用的防火墙文件路径是/etc/sysconfig/iptables）1234开通防火墙端口22-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT开通防火墙端口3306-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT mysql配置文件位置：/etc/my.cnf（有些配置内容写在mysqld下生效，mysql_safe下无效） Error reading packet from server: Slave can not handle replication events with the checksum that master is configured to log; the first event ‘localhost-bin.000002’ at 123, the last event read from ‘./localhost-bin.000002’ at 123, the last byte read from ‘./localhost-bin.000002’ at 123. ( server_errno=1236) 这是由于 master 用的 mysql5.6 , binlog_checksum 默认设置的是 crc32。 如果slave用的 5.5 或者更早的版本，请将master的 binlog_checksum设置为 none。（binlog_checksum=none） mysqldump命令 1234mysqldump -u用户名 -p 数据库名 &gt; 导出的文件名.sqlmysqldump -u用户名 -p 数据库名 表名&gt; 导出的文件名.sqlmysqldump -u用户名 -p -d（只导出表结构参数） 数据库名 表名&gt; 导出的文件名.sql导入文件命令：mysql&gt;source d:wcnc_db.sql mysql数据库容量和表容量大小磁盘占用查看 查看该实例下各个库大小 123select table_schema, sum(data_length+index_length)/1024/1024 as total_mb, sum(data_length)/1024/1024 as data_mb, sum(index_length)/1024/1024 as index_mb, count(*) as tables, curdate() as today from information_schema.tables group by table_schema order by 2 desc; 查看单库下所有表的状态 123select table_name, (data_length/1024/1024) as data_mb , (index_length/1024/1024) as index_mb, ((data_length+index_length)/1024/1024) as all_mb, table_rows from information_schema.tables where table_schema = &apos;ifp&apos;; 或者在mysql数据文件物理路径下(/var/lib/mysql/)执行命令du -h查看各个数据文件所占空间大小 Could not initialize master info structure; more error messages can be found in the MySQL error log+Failed to open the relay log ‘./localhost-relay-bin.000001’ (relay_log_pos 4) 由于之前配置过，生成了一些relay文件，使得再次配置无法生成，删除掉之前生成的文件就可以。 mysql数据导入导出 导出使用mysqldump 较快，10分钟/亿级别 导入使用source命令时，在innodb引擎下较慢，可以将主键，索引先删除，引擎更改为myisam，之后完成数据导入后再添加主键，索引，更换引擎 采用直接拷贝数据文件来实现数据迁移，但是innodb的表，直接复制文件是无法使用的，会提示表不存在，在复制的时候，应将数据目录下的ibdata1文件一并复制过去，并且删除ib_logfile0，ib_logfile1等文件 mysql的root用户密码忘记了怎么办？ 进入配置文件：/etc/mysql/目录下 配置文件my.conf中可以直接配置，亦可以引入配置，例如如下12!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 添加skip-grant-tables 重新启动mysql即可进入 查看mysql库中user表root的相关信息，密码字段为authentication_string，内容为加密后的，可以直接将其设置为空，保存退出mysql， 修改配置文件将刚才添加的一行去掉，重启mysql登录]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>Replication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2018%2F12%2F16%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 什么是ThreadLocal 使用指南 实现原理 应用场景 Magic Number 0x61c88647 为甚么使用weakReference 为什么会发生内存泄漏 InheritThreadLocal（子线程传递） FastThreadLocal（Netty） InternalThreadLocal（Dubbo） ##什么是ThreadLocal 早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。 ThreadLocal很容易让人望文生义，想当然地认为是一个“本地线程”。其实，ThreadLocal并不是一个Thread，而是Thread的局部变量，也许把它命名为ThreadLocalVariable更容易让人理解一些。 值得一提的是，在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal，之前为ThreadLocal。 使用样例 ThreadLocal一般声明为public static. 12345678910111213141516171819202122232425262728public class ThreadLocalTest &#123; public static ThreadLocal&lt;SimpleDateFormat&gt; dateFormat = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); &#125; &#125;; public static void main(String[] args)&#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-mm-dd&quot;); for (int i = 0;i &lt; 100;i++) &#123; printDate(); new Thread() &#123; @Override public void run() &#123; super.run(); alterAndpPrintDate(); &#125; &#125;.start(); &#125; &#125; public static void printDate()&#123; System.out.println(&quot;thread 1 :&quot; + threadLocal.get().format(new Date())); &#125; public static void alterAndpPrintDate()&#123; threadLocal.set(new SimpleDateFormat(&quot;yyyy-mm&quot;)); System.out.println(&quot;thread 2 :&quot; + threadLocal.get().format(new Date())); &#125;&#125; 实现原理 从下面的源码中可以看出：具体的ThreadLocalMap实例并不是ThreadLocal保持，而是每个Thread持有，且不同的Thread持有不同的ThreadLocalMap实例, 因此它们是不存在线程竞争的； ThreadLocalMap为ThreadLocal的一个内部类，用于保存线程共享变量的副本值 哈希冲突解决方案：开放定址法：碰撞时,会从当前位置开始向后环型遍历,找到一个空位置,这方法我们可以称之为线性探测法. hash 冲突的解决方案1.开放定址法。2.链式地址法。3.再哈希法。4.建立公共溢出区。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261//获取共享变量副本过程如下public T get() &#123; Thread t = Thread.currentThread();//获取当前线程对象 /** 获取线程持有的ThreadLocalMap实例，该实例用来保存每个线程的共享变量副本 */ ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125;//从ThreadLocalMap实例中获取当前线程保存的变量副本，无则返回初始化值 return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;public class Thread&#123; /** ThreadLocal values pertaining to this thread. This map is maintained by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null;&#125;//设置共享变量副本过程如下public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;//ThreadLocal内部类ThreadLocalMapstatic class ThreadLocalMap &#123;//存储共享变量数据的Entry节点，继承自弱引用，随时可能被GC回收 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;//初始容量16，底层实现数组，扩容点默认0，设置规则为数组长度的2/3 private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int threshold; // Default to 0 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; //以一个初始值构造ThreadLocalMap ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; //以一个现成的ThreadLocalMap构造ThreadLocalMap private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125; //根据key值取value private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1);//根据哈希值计算key在数组中的位置 Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else //若是第一次没有取到值，可能是哈希冲突，也可能是弱引用key已经被GC回收，走下面这个方法处理 return getEntryAfterMiss(key, i, e); &#125; private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; //由于第一次哈希值对应数组位置中没能找到对应的key，则可能由于哈希冲突导致key遵循线性探测法解决冲突，因此从当前位置向后循环判定是否key向后移动了，同时清除key为null的value值，避免内存泄漏 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key)//若找到对应的key，直接返回 return e; if (k == null)//若key为null，怎清理过期值 expungeStaleEntry(i); else i = nextIndex(i, len);//向后移动数组继续判定 e = tab[i]; &#125; return null; &#125; private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //往里存数据时，避免哈希冲突，循环判定所处位置是否已经有值存在，是则数组索引后移，直到有一个空位置可以存放新值，如果期间找到了已经存在的旧值，即意味着要更新旧key的值，旧key不为null，直接覆盖其value值，否，将为null的key替换掉。 for (Entry e = tab[i];e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125; &#125; //替换过期数据 private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len);(e = tab[i]) != null;i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; for (int i = nextIndex(staleSlot, len);(e = tab[i]) != null;i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; //清除过期数据 private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i; &#125; private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed; &#125; //扩容必然导致重新哈希计算数组中的位置索引 private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize(); &#125; //扩容 private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab; &#125; private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125; &#125; &#125; 应用场景 ThreadLocal和其它同步机制相比有什么优势呢？ThreadLocal和其它所有的同步机制都是为了解决多线程中的对同一变量的访问冲突，在普通的同步机制中，是通过对象加锁来实现多个线 程对同一变量的安全访问的。这时该变量是多个线程共享的，使用这种同步机制需要很细致地分析在什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放该对象的锁等等很多。所有这些都是因为多个线程共享了资源造成的。ThreadLocal就从另一个角度来解决多线程的并发访问，ThreadLocal会为每一个线程维护一个和该线程绑定的变量的副本，从而隔离了多个线程的数据，每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的整个变量封装进ThreadLocal，或者把该对象的特定于线程的状态封装进ThreadLocal。 当然ThreadLocal并不能替代同步机制，两者面向的问题领域不同。同步机制是为了同步多个线程对相同资源的并发访问，是为了多个线程之间进行通信的有效方式；而ThreadLocal是隔离多个线程的数据共享，从根本上就不在多个线程之间共享资源（变量），这样当然不需要对多个线程进行同步了。所以，如果你需要进行多个线程之间进行通信，则使用同步机制；如果需要隔离多个线程之间的共享冲突，可以使用ThreadLocal，这将极大地简化我们的程序，使程序更加易读、简洁。ThreadLocal类为各线程提供了存放局部变量的场所。 应用 一：将request请求中的数据放入ThreadLocal中可以使得入参在整个请求流程中作为全局上下文使用（因为每一请求都会是一个独立的线程处理）应用二：用ThreadLocal保存session的值 每个线程访问数据库都应当是一个独立的Session会话，如果多个线程共享同一个Session会话，有可能其他线程关闭连接了，当前线程再执行提交时就会出现会话已关闭的异常，导致系统异常。此方式能避免线程争抢Session，提高并发下的安全性。 应用三：线程不安全的类在多线程中使用，如 SimpleDateFormat；在一个线程中修改不影响其他线程的使用。 java里面的变量的作用范围，有的是局部变量，有的是成员变量。局部变量永远不存在线程安全问题，成员变量是所有的线程所共享的，ThreadLocal的出现就弥补了这两种范围的一个不足，它比局部变量的范围要大，不仅仅是局限于一个方法块，但是又比成员变量的范围要小，因为它不会被多个线程共享，是线程独占的。 Magic Number 0x61c88647(32进制) ThreadLocal用到了map，就一定会存在冲突。而魔法数字0x61c88647的作用就是减少冲突并且增强数据的均匀分布性。 123456789101112/** 源码中线程局部变量哈希值通过原子类AtomicInteger每次加魔法数字0x61c88647而生成，为的就是让哈希码能均匀的分布在2的N次方的数组里 */private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;/** 底层数组扩容每次右移一位，保证数组大小始终为2的N次方；而哈希值和数组长度减一后的值进行与操作相当于取模操作，将变量存入指定数组位置中 */int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);int h = key.threadLocalHashCode &amp; (len - 1);int i = key.threadLocalHashCode &amp; (table.length - 1);&#125; 为甚么使用weakReference 不影响key的正常gc回收，否则会一直存在一个强引用指向key对象，导致即使没有其他对象强引用后也不能正常gc回收 弱应用的实际用法 threadlocal的采用了Entity继承WeakReference&lt;&gt;的方式来继承引用父类的弱引用对象，避免了采用组合的方式，还得单独在Entity中定义一个弱应用属性；较为方便 12345678910111213141516171819202122232425262728293031// 测试弱引用WeakReference&lt;String&gt; r = new WeakReference&lt;String&gt;(new String(&quot;I&apos;m here&quot;));WeakReference&lt;String&gt; sr = new WeakReference&lt;String&gt;(&quot;I&apos;m here&quot;);System.out.println(&quot;before gc: r=&quot; + r.get() + &quot;, static=&quot; + sr.get());System.gc();Thread.sleep(100);// only r.get() becomes nullSystem.out.println(&quot;after gc: r=&quot; + r.get() + &quot;, static=&quot; + sr.get());// 实际使用样例//（建议使用）static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;//（不建议使用）static class Entry &#123; WeakReference&lt;ThreadLocal&lt;?&gt;&gt; key; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; key = new WeakReference&lt;k&gt;; value = v; &#125;&#125; 为什么会发生内存泄漏 首先Threadlocal类中有内部类Treadlocalmap，Treadlocalmap中还有内部类Entity，Entity继承了WeakReference]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Sentinel]]></title>
    <url>%2F2018%2F12%2F09%2FRedis%20Sentinel%2F</url>
    <content type="text"><![CDATA[Redis Sentinel 哨兵能干什么？ 什么是哨兵模式？ 如何启动redis以哨兵模式？ 如何配置哨兵？ 部署哨兵模式需要注意什么？ 哨兵API 如何添加或者移除哨兵？ 订阅/发布消息 哨兵能干什么？ 监控：监控主从实例是否正常运行 通知：通知系统管理员、编程人员，运行实例出错了 自动失败策略：当master实例不在正常运行时，自动将其中一个slave上升为master，其他slave重新配置新的master，应用使用redis服务器通知的新master地址进行连接 配置提供者：哨兵作为客户端连接的权限关卡，所有的客户端连接哨兵索要master的连接地址，当master宕机时，哨兵会报告新master地址 什么是哨兵模式？ 哨兵模式是一种分布式系统 哨兵本身设计被运行在多个哨兵进程协同工作的环境中 保证master停止工作判定的正确性，多个哨兵同意方能确认该master真正停止工作 拥有故障转移系统本身就是一个单一的故障点并不是一件好事。 如何启动redis以哨兵模式？ redis-sentinel /path/to/sentinel.conf redis-server /path/to/sentinel.conf –sentinel 均需要配置文件sentinel.conf 哨兵模式启动默认端口TCP：26379，确保该端口开启保证哨兵之间的通话和决策，否则故障转移功能将无法奏效 注意： 至少三个哨兵实例保证 三个哨兵实例之间不能存在失败依赖关系，即将其放置到不同的物理服务器上或者不同的可用空间 由于Redis使用异步复制，因此不保证在失败期间保留已确认的写入，但是可以将写入丢失控制在一定时间内 并不是所有的客户端都会被哨兵模式支持，比较的流行的会 开发环境的多次测试才能换来生产环境的高可用安全 哨兵和docker混合使用时，要注意地址转换和端口匹配 如何配置哨兵？ 配置文件 sentinel monitor &lt;master-group-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; quorum参数：决策master不可达的哨兵数量 该参数仅仅用来检测master不可达，真正实际执行失败策略需要得到哨兵集群中大部分哨兵的决策同意，也就是说，当检测master不可达的哨兵数量达到quorum参数设置值的时候，检测不可达的其中一台哨兵可以尝试执行失败策略，但是如果该数量并没有到达哨兵集群数量的大多数，则失败策略实际并不会执行；只有当集群数量中大多数均认为该master不可达才会被授权真正实行失败策略。 sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt; down-after-milliseconds：认为该master不可达的时间限制，单位毫秒 parallel-syncs：失败策略执行后，同一时间可以重新配置新master地址的salve个数，该值设置越小，失败策略完成的越慢； 所有配置均可在运行时通过sentinel set命令设置 12345678910//只要mastername命名不同，哨兵即可配置多个master（可含有任意数量的slave）sentinel monitor mastername 127.0.0.1 6379 2sentinel down-after-milliseconds mastername 60000sentinel failover-timeout mastername 180000sentinel parallel-syncs mastername 1sentinel monitor mastername1 127.0.0.1 6379 2sentinel down-after-milliseconds mastername1 60000sentinel failover-timeout mastername1 180000sentinel parallel-syncs mastername1 1 部署哨兵模式需要注意什么？ 请至少部署三个哨兵实例在不同的物理机上（满足分布式的高可用） 当master不可达后，失败策略完成之前，连接该master的客户端上的所有写操作将会永久性丢失 解决方案：设置master被检测到不可同步写记录到指定数量的slave，然后指定时间后不再接受写操作 min-slaves-to-write 1（数量） min-slaves-max-lag 10（时间/s） 当服务器资源无法承载哨兵模式的最小数量3，可以将哨兵和客户端放置在一起 docker的端口映射：不同应用的同一端口会被docker映射成不同的端口暴露出去 端口和ip的映射可能对哨兵模式造成的影响 哨兵之间的自动发现是基于发送接收hello message给他们所监听的端口和ip，重要的是他们不知道啥叫ip、端口映射。 当展示master下的slave时，所有的slave会被列出在master的输出上，其中信息时通过tcp连接获得，而端口是在tcp三次握手时得到，映射操作可能会造成端口有误 实战指南 三个哨兵实例配置 文件如下： 123456789101112131415port 5000sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1port 5001sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1port 5002sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1 redis-cli -p 5000：客户端登录哨兵实例1 sentinel master mymaster：查看被监控master信息 flags：表示master状态，master表示正常， s_down or o_down 表示异常 SENTINEL slaves mymaster：查看slave信息 SENTINEL sentinels mymaster：查看哨兵信息 SENTINEL get-master-addr-by-name mymaster：获取当前master的ip信息 redis-cli -p 6379 DEBUG sleep 30：手动测试失败策略，之后可查看master的ip信息已变更 哨兵API PING：连通性检测 SENTINEL CKQUORUM ：检查当前的Sentinel配置是否能够达到对主机进行故障转移所需的仲裁，以及对授权故障转移所需的多数进行仲裁。在监视系统中应使用此命令来检查Sentinel部署是否正常 SENTINEL INFO-CACHE（&gt; = 3.2）：从主服务器和副本服务器返回缓存的INFO输出。 sentinel masters：显示多有被监视的master列表和其状态 sentinel master ：显示指定master状态 sentinel slaves ：显示指定master下所有的slave的状态信息 sentinel sentinels ：显示指定master的哨兵列表信息状态 sentinel get-master-addr-by-name ：返回指定master的ip和端口 sentinel reset pattern&gt;：重置所有匹配到的master状态，清空所有目前的数据 sentinel failover ：如果master不可达，强制启动失败策略，不经过哨兵的同意 sentinel flushconfig：强制哨兵重写磁盘配置文件，包括当前哨兵状态 SENTINEL REPLICAS （&gt; = 5.0）：显示此主副本的副本及其状态的列表。 重新配置哨兵在运行时 哨兵订阅命令可以使得哨兵实例的配置更新变得自动化，避免人为手动每个实例去更改 sentinel monitor ：根据所给信息重新配置哨兵的监控master sentinel remove ：移除指定master sentinel set ：更改指定master的配置参数 支持的额外命令：acl, info, shutdown(关闭当前实例), ping, hello, command, client, auth 如何添加或者移除哨兵？ 基于哨兵的自动发现机制，只需要启动一台配置好当前活跃的master的哨兵实例即可，10秒中便内便会自动被其他哨兵发现并添加到哨兵列表中 若需要一次性添加多台哨兵实例，建议一台一台添加，等待其他所有的哨兵已经知晓被添加的第一台实例后再添加第二台 由于哨兵永远不会忘记已经见过的其他哨兵，所以哨兵的移除有些复杂 停止想要移除的哨兵实例进程 发送sentinel reset * 命令给所有其他哨兵实例，每个哨兵实例发送命令的时间间隔至少30秒 检查所有哨兵是否同意当前活跃哨兵实例个数（sentinel master mastername） 移除旧master或者不可达的slave 哨兵不会忘记所给master的所有的slave，即使他们不可达很长一段时间 发送命令sentinel reset mastername 给所有的哨兵，未来10秒哨兵会刷新slave列表，仅仅添加当前正在从master同步信息的slave 订阅/发布消息 客户端可以使用Sentinel，因为它是Redis兼容的发布/订阅服务器（但您不能使用PUBLISH），以便SUBSCRIBE或PSUBSCRIBE到频道并获得有关特定事件的通知。 频道名称和事件名称一致 PSUBSCRIBE *可以订阅所有频道得到所有信息 +reset-master ：订阅master重置reset信息 == @ 更多订阅信息命令请看：Redis–Pub/Sub Messages salve由优先级 redis有一个配置参数叫做slave-priority 哨兵根据这个信息来选出失败策略后新的master slave优先级设置为0,表示永远不可能晋升为master 优先级数字越小，越有可能晋升为master 权限问题 如果master配置需要客户端登录密码，则slave连接master同样需要该密码 requirepass：在master中，设置密码校验跳过对于那些无需验证的客户端 masterauth：在slave中，设置被master已认证，便于进行主从同步 哨兵连接配置了requirepass的master时需要使用一下命令 sentinel auth-pass 哨兵实例权限配置（redis5.0.1之后支持） requirepass “your_password_here”配置后所有的客户端连接均需要密码，哨兵之间的通讯也需要该密码 意味着所有的哨兵实例中配置同样的密码 哨兵模式的细节实现 自动发现机制 哨兵实例之间通过订阅/发布机制来互通信交换信息检测对方状态 该特性的实现通过往名为sentinel:hello的频道发送hello消息 每一个哨兵发布一条消息到它所监控的每一个master和slave发布/订阅频道sentinel:hello上，每两秒，公布他们目前的ip，port和运行id 每个哨兵订阅了每一个master和slave和频道sentinel:hello，去寻找未知的哨兵，一旦发现，加入本master的哨兵列表 hello信息包括当前master的完整配置信息，以供哨兵更新旧的配置信息 新哨兵加入之前总要检测目前列表中是否已存在同样runid的哨兵实例，确保移除添加互不冲突 Sentinel是一个系统，其中每个进程将始终尝试将最后一个逻辑配置强制应用于受监视实例集。 slave选举和优先级 衡量标准严格按照以下顺序进行 和master失连时间（超过10次master配置的超时时间，取消选举资格） salve优先级设置（优先级数字设置低的优先） 同步进度（同步进度快的优先） 运行id（小的运行id优先） epochs配置 标记配置版本信息，每一次失败策略触发更换master均会导致配置版本信息的迭代 更多实现细节待补充。。。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql插入去重]]></title>
    <url>%2F2018%2F12%2F02%2FMySql%E6%8F%92%E5%85%A5%E5%8E%BB%E9%87%8D%2F</url>
    <content type="text"><![CDATA[MySql插入去重 insert ignore… Replace into… insert into … ON DUPLICATE KEY UPDATE … 最近碰到一个数据迁移的需求： 基础环境为分库分表（四个分片库，1024张表），mysql数据库 需求为将某个表中的几个字段值抽取出来迁移到新的表中（新旧表之后会共存） 数据量约为2000万 应用服务器12台（8C，12G） 解决方案 业务代码改动，单写改双写，同时向新旧表写数据 业务代码改动上线后，旧表为全量数据，新表只有增量数据，需要将存量数据批量导入新表中 这个地方思维陷入了死胡同，好长一段时间僵持在找不到存量和增量数据的临界点在哪 单库单表向分库分表进行数据迁移的方案通常我们可以定一个MAX(自增主键)来区分存量和增量数据，或者其他可以代表全局唯一性的字段来作为临界点的参考对象，例如流水号，客户号，时间戳等 分库分表环境下，MAX(自增主键)明显不好使了，而且旧表中唯一能作为全局唯一性参考的字段只有客户号，但是由于业务原因，客户号无法作为临界点对象 在没有办法找到明显存量和增量数据的分界点时，我们怎么实现数据的迁移？ 存量和增量数据区分的本质是什么？—去重 之前考虑为题的方向是：拿取数据的时候就完成去重操作，之后直接插入新表即可。这种思路下必须找到新旧数据的分界点。 抛弃固有思维，我们可以将去重这个动作放到拿到数据之后再来完成，一种情况可以放到代码中来实现去重（受项目环境限制，实现较为复杂，考虑因素较多），另一种情况可以在插入新表的时候去完成去重操作（由数据库完成，操作简单） MySql INSERT语法官方文档地址 1234567891011121314151617181920212223242526272829INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ... [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] SET assignment_list [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] SELECT ... [ON DUPLICATE KEY UPDATE assignment_list]value: &#123;expr | DEFAULT&#125;value_list: value [, value] ...assignment: col_name = valueassignment_list: assignment [, assignment] ... IGNORE ：忽略由UNIQUE index or PRIMARY KEY造成的错误，可以理解为插入操作执行时，若发现表中已有该数据，则不执行该操作 insert ignore into table_name () vlaues() ON DUPLICATE KEY UPDATE：插入时若造成UNIQUE index or PRIMARY KEY冲突，更新指定字段的值 insert into table_name () values() on duplicate key update cloumn_name=cloumn_values,… MySql REPLACE语法12345678910111213141516171819202122232425262728REPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ...REPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] SET assignment_listREPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] SELECT ...value: &#123;expr | DEFAULT&#125;value_list: value [, value] ...assignment: col_name = valueassignment_list: assignment [, assignment] ... 当检测到PRIMARY KEY or a UNIQUE index冲突时，删除旧数据，插入新数据（必须同时拥有插入，删除权限） replace into table_name () values();]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Idempotency]]></title>
    <url>%2F2018%2F11%2F25%2FIdempotency%2F</url>
    <content type="text"><![CDATA[Idempotency 何为幂等性 幂等实现方式 何为幂等性 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 应用场景 分布式环境下，我们经常会用到远程调用。但是远程调用不像本地调用，本地调用后的结果只有成功，失败两种情况。分布式环境中的远程调用多了一种超时的情况，超时本身又是不确定的一种状态，可能包含多种情况（调用成功但是返回中断，调用中断等等）。由此引出了幂等性验证。 何为幂等操作 幂等操作：update tab1 set col1 = 1 where id = 2（这样的更新语句，无论执行多少次结果都是不受影响的，所以是幂等的） 非幂等操作：update tab1 set col1 = col1 + 1 where id = 2http中幂等/非幂等方法 幂等方法 OPTIONS GET HEAD PUT DELETE 非幂等方法 POST PATCH 幂等实现方式 排重表dup_forbidden校验 好多业务表本身就具有排重表的功能（基于业务存在唯一的业务编号来设计实现的） 利用交易流水在数据库表里面设置的唯一约束来实现（可以在很长的时间范围内实现幂等控制） 123456begin transaction;count = insert ignore dup_forbidden (...biz_id...) value(...biz_id...)if (count &gt; 0) &#123; f(biz_id)&#125; commit; API层面的幂等 这里有一个场景，API层面的幂等，例如提交数据，如何控制重复提交，这里可以在提交数据的form表单或者客户端软件，增加一个唯一标示，然后服务端，根据这个UUID来进行去重，这样就能比较好的做到API层面的唯一标示。 状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Idempotency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识分库分表]]></title>
    <url>%2F2018%2F11%2F18%2F%E5%88%9D%E8%AF%86%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[分库分表 分库分表 解决方案 部署上线 数据库拆分方案案例 引发问题 分库分表 分库 集群通过读写分离缓解了数据库的读取压力，但是由于master只能有一个且所有的写压力全部在master上，所以当单台资源无法承受海量的写压力时，便需要进行分库操作，将数据分摊在不同的分片资源机器上，写压力随即均分缓解。 分表 水平分表：将表中数据分配到多个表中存储，缓解单表量级 垂直分表：将表中字段分配到多个表中，缓解单表字段太多造成的读写压力 任何数据的切分均不是任意而为之，均需根据实际业务需要来操作，例如：数据有冷热之分，新旧之分，常用之分，渠道之分，来源之分，等等（字段同理），均可以作为切分维度，实际项目中需要根据业务需求做出相应的抉择。 不同维度的数据存储模式也不尽相同。例如： 热数据：存储于mysql中，操作实时性高 冷数据1：不经常使用，可以使用es存储，定期将部分数据降级为冷数据2 冷数据2：基本不会使用，可用使用hive存储，一旦使用到及升级为冷数据1 ##解决方案 分库分表必然需要中间件来做这一层工作，而且希望对于客户端是透明的，但是目前还没有一个一统江湖的中间件，列举一些大公司的解决方案供大家参考： 阿里 TDDL DRDS (基于阿里云的RDS 做分库分表的中间件) 开源 sharding-jdbc Atlas(Qihoo 360) alibaba.cobar(是阿里巴巴（B2B）部门开发) MyCAT（基于阿里开源的Cobar产品而研发） Oceanus(58同城数据库中间件) OneProxy(支付宝首席架构师楼方鑫开发) vitess（谷歌开发的数据库中间件） 部署上线分库分表后如何进行项目的部署上线 停机部署（常规做法） 取决于公司产品性质，如非电商公司产品，不具有海量的流量，尤其是夜间，几乎没有，所以可以选择夜间时间点停机部署 提前发布停机维护公告（夜间00:00-06:00） 数据迁移程序上线，开始数据迁移 将旧库数据通过中间件迁入新库 数据迁入完成，验证迁移前后数据的一致性 迁移程序下线 切换业务到新库，全面验证业务正确性 双写部署法（无需停机，会侵入业务代码） 统计计算历史数据（记录某一时刻的max（主键），然后将小于该max（主键）的称为历史数据，大于max（主键）的称为增量数据，历史数据直接由旧库迁往新库，增量数据动态写入消息队列中，随后再写入新库。（如何区分历史数据和增量数据除了用max（主键），还可以用时间字段排序等） 业务代码中新增往消息队列中发送操作sql的代码，只发送写sql操作，作为增量数据 迁移程序上线，迁移历史数据（通过中间件） 订阅程序上线，将消息队列中增量数据通过中间件写入新库 验证数据一致性，下线双写代码 切换业务至新库 历史数据发生变动怎么办：delete操作，update操作主要是，迁移之前执行的操作没有影响，迁移之后发生的操作会被记录在消息队列中作为增量数据更新掉发生变动的原始数据 数据一致性验证 全量验证，逐条数据验证 抽样验证，验证关键字段（例如：一次取出若干条数据拼接成字符串，然后md5 加密，最后比较字符串的一致性） 数据库拆分方案案例背景介绍 两个应用独立部署，资源独立，但是数据库共享，现需要将其中一个应用数据拆分到新的数据库资源机器上。 环境资源 测试环境：一主一从一备，四分片，12 台机器 生产环境：一主两从三备，四分片，24台机器 拆分方案步骤 从资源集群中摘下备库，拷贝其数据，注意：方案为直接拷贝mysql数据目录，而不是导出insert.sql语句，拷贝完成后将备库再挂上去（备库摘下与挂上的两个阶段前后均需一段平稳的交易模拟压测，查看两个步骤对旧系统交易的影响有多大） 将拷贝好的数据目录拷贝到新资源集群的所有机器中（新集群中主从备关系已经搭建好，但是未开启同步），然后再次开启压测 紧接着将新集群中master挂载到旧集群中的master下作为该从库进行增量数据的同步，压测持续监测数据同步对旧系统交易的影响 新集群master挂载好了之后便逐个开启新集群中主从备的同步，加大了同步压力（相当于将一整个主从备的集群挂载到了旧集群master下），压测持续监测旧系统的交易TPS变化，当数据同步完成后即可开始将应用切换至新数据库资源集群 数据同步完成后，旧系统中关闭要拆出的那个应用的所有写交易开关，只留下读交易 然后切断新集群中master与旧集群中master的主从连接， 测试版一组接入新数据库资源进行测试，测试版读写交易均可进行 通过后将正式版二组切换至新数据库资源测试 二组测试通过上第三组，否回退 开启写交易开关验证写交易 切换正式版一组 开始全面业务验证 引发问题 水平拆分后的count() 操作： count相加，单个count在相加，效率慢 更新记录数表，写压力增大，容易不一致 定时更新记录数表（前两者结合） 跨库事务难以实现 要避免在一个事务中同时修改数据库db0和数据库db1中的表，因为操作起来很复杂 切分维度导致的查询问题： 聚合分片查询结果：查询排序分页—使用到了归并排序—最大分页限制 冗余多份数据：全局表，冗余表，字段冗余]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型无处不在]]></title>
    <url>%2F2018%2F11%2F04%2F%E6%B3%9B%E5%9E%8B%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%2F</url>
    <content type="text"><![CDATA[Generic 泛型的使用 泛型的实现 泛型的改进 泛型的使用&lt;\T&gt; 类型参数T：用来表示不确定的某种类型；基本类型无法作为类型参数，但是Java5以后具有了自动组包拆包的功能。 泛型接口 创建对象时必须指定类型参数的值，一旦类型指定就不能在改变了 public interface Demo{ T t;} 泛型方法 泛型方法优先级高于泛型接口，即优先考虑使用泛型方法，再使用泛型接口 泛型方法由于类型参数推断能力，每次调用都相当于重新判定其类型参数的值 public void display(T t){} 可变参数和泛型方法 1234567891011121314151617181920212223public &lt;T&gt; List&lt;T&gt; display(T... args)&#123; List&lt;T&gt; list = new LinkedList&lt;&gt;(); for(T item : args)&#123; list.add(item); &#125; return list;&#125;//生成器Generatorclass BaseGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; private Class&lt;T&gt; type; public BaseGenerator(Class&lt;T&gt; type)&#123; this.type = type; &#125; public T next()&#123; try &#123; return type.newInstance(); &#125;catch(Exception e)&#123;e.printStackTrace();&#125; return null; &#125; public &lt;T&gt; Generator&lt;T&gt; create(Class&lt;T&gt; type)&#123; return new BaseGenerator&lt;T&gt;(type); &#125;&#125; Set泛型工具类(瞅瞅enmuset的用法) 1234567891011121314151617181920class Sets&#123; public static &lt;T&gt; Set&lt;T&gt; union(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a);//不改变原参数，复制一个新值 result.addAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; intersction(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a); result.retainAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; differences(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a); result.removeAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; complements(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; return differences(union(a,b),intersction(a,b)); &#125;&#125; 匿名内部类和泛型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647泛型前interface Animal&#123; void next();&#125;class Dog implements Animal&#123; public void next()&#123;&#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal animal1 = new Animal() &#123; @Override public void next() &#123; &#125; &#125;;&#125;泛型后interface Animal&lt;T&gt;&#123; void next(T t);&#125;class Dog&lt;T&gt; implements Animal&lt;T&gt;&#123; public void next(T t)&#123;&#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal&lt;T&gt; animal1 = new Animal&lt;T&gt;() &#123; @Override public void next(T t) &#123; &#125; &#125;;&#125;lambda表达式与泛型interface Animal&lt;T&gt;&#123; void next(T t);&#125;class Dog&lt;T&gt; implements Animal&lt;T&gt;&#123; public void next(T t)&#123; System.out.println(t.toString()); &#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal&lt;T&gt; animal1 = (T t)-&gt;&#123; System.out.println(t.toString()); &#125;;&#125; 泛型+元组 可用于一次方法调用返回多个对象的应用需求 12345678910111213public class Twotuple&lt;A,B&gt;&#123; public static A a; public static B b; public Twotuple(A a,B b)&#123; this.a = a; this.b = b; &#125;&#125;public class Tuple&#123; public static &lt;A,B&gt; TwoTuple&lt;A,B&gt; tuple(A a,B b)&#123; return new TwoTuple&lt;A,B&gt;(a,b); &#125;&#125; 泛型的实现 类型擦除 java泛型的实现是通过擦除来实现，由于不是从语言诞生一开始就引入的特性，所以具有一定的局限性 类型擦除：顾名思义任何具体的类型信息都被擦除了，我们将无法获取这些信息 由于类型信息的擦除，参数T将丧失某些操作能力，如转型，instanceof操作，new表达式等操作，但是针对各个缺失均由相应的补偿措施 边界 在泛型的参数类型上设置限制条件成为泛型的边界设置 关键字extends（多个继承关系存在时，类在前，接口在后） ,, 泛型参数无法设置超类边界 可用于扩展复杂结构层次 通配符 通配符的作用是用来修饰、限制泛型参数类型的，其含义相当于Object的作用 有界通配符 &lt;? extends Class&gt; &lt;? super Class&gt;、&lt;? super T&gt; 无界通配符 &lt;?&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//擦除导致泛型所缺失的操作能力如下class Erased&lt;T&gt;&#123; public void f(Object arg)&#123; if (arg instanceof T)&#123;&#125;//error1无法类型判断 T var = new T();//error2（C++中该操作相当正确）无法实例化 T[] array = new T[5];//error3无法创建泛型数组 T[] arrayO = (T[]) new Object[5];//unchecked warning泛型转型警告 &#125;&#125;//error1的补偿实现：引入类型标签（其实就是将obj instanceof class改为了class.isInstance(obj)）class Erased&lt;T&gt;&#123; Class&lt;T&gt; type; Erased(Class&lt;T&gt; type)&#123; this.type = type; &#125; public boolean f(Object arg)&#123; return type.isInstance(arg); &#125;&#125;//error2的补偿实现：传入一个工厂对象，例如Class对象，使用newInstance()来创建泛型类型对象class Erased&lt;T&gt;&#123; T t; public void f(Class&lt;T&gt; type)throws Exception&#123; t = type.newInstance(); &#125;&#125;//自己编写一个显示的工厂类public class Main &#123; public static void main(String[] agrs)&#123; FactoryA factoryA = new FactoryInteger(); new FactoryProxy(factoryA); &#125; interface FactoryA&lt;T&gt;&#123; T create(); &#125; static class FactoryProxy&#123; &lt;F extends FactoryA&lt;T&gt;&gt; FactoryProxy(F factory)&#123; factory.create(); &#125; &#125; static class FactoryInteger implements FactoryA&lt;Integer&gt;&#123; @Override public Integer create() &#123; return new Integer(10); &#125; &#125; class FactoryString implements FactoryA&lt;String&gt;&#123; @Override public String create() &#123; return new String(&quot;hello&quot;); &#125; &#125;&#125;//error3补偿实现方式：使用ArrayList代替数组List&lt;T&gt; list = new ArrayList&lt;T&gt;(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//样例1：java编译无法通过（C++编译器却可以通过）class Hasf&#123; public void display()&#123;&#125;&#125;class Manipulator&lt;T&gt;&#123; T obj; Manipulator(T t)&#123; this.obj = t; &#125; public void manipulator()&#123; obj.display();//编译器无法知道参数类型具体到底是谁，所以无法进行方法调用 &#125;&#125;public void check()&#123; Hasf hasf = new Hasf(); Manipulator&lt;Hasf&gt; manipulator = new Manipulator&lt;&gt;(hasf); manipulator.manipulator();&#125;//样例2：将类型参数值加上边界java编译即可通过class Hasf&#123; public void display()&#123;&#125;&#125;class Manipulator&lt;T extends Hasf&gt;&#123;//指定参数类型的边界后，类型擦除实际上是将T擦除到了Hasf类型，等价于class Manipulator&lt;Hasf&gt; T obj; Manipulator(T t)&#123; this.obj = t; &#125; public void manipulator()&#123; obj.display();//由于指定了类型边界，编译器便可以知道具体类型 &#125;&#125;public void check()&#123; Hasf hasf = new Hasf(); Manipulator&lt;Hasf&gt; manipulator = new Manipulator&lt;&gt;(hasf); manipulator.manipulator();&#125;//样例3：使用泛型&lt;T extends Hasf&gt;比直接使用&lt;Hasf&gt;的好处在于：当一个类有一个返回T的方式时，该方法可以返回具体确切的类型class Manipulator&lt;T extends Hasf&gt;&#123; T obj; public T getManipultor()&#123; return obj; &#125; &#125;//样例4：instanceof验证public &lt;T&gt; void checkBaseType(T t)&#123; if(t instanceof String)&#123;//这种写法是可行的，但是var instanceof T这种是不可行的 System.out.println(&quot;T 类型为字符串类型&quot;); &#125; if(t instanceof Integer)&#123; System.out.println(&quot;T 类型为整型类型&quot;); &#125; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125;&#125;//等价于public void checkBaseType(Object t)&#123; if(t instanceof String)&#123; System.out.println(&quot;T 类型为字符串类型&quot;); &#125; if(t instanceof Integer)&#123; System.out.println(&quot;T 类型为整型类型&quot;); &#125; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125;&#125;//样例4.1public &lt;T extends Hasf&gt; void checkBaseType(T t)&#123; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125; if(t instanceof HasfB)&#123; System.out.println(&quot;T 类型为HasfB类型&quot;); &#125;&#125;等价于public void checkBaseType(Hasf t)&#123; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125; if(t instanceof HasfB)&#123; System.out.println(&quot;T 类型为HasfB类型&quot;); &#125;&#125;//样例5：转型验证 public class Main &#123; public static void main(String[] agrs)&#123; String[] str = create(String.class,5); Arrays.fill(str,&quot;hello&quot;); System.out.println(Arrays.toString(str)); &#125; public static &lt;T&gt; T[] create(Class&lt;T&gt; type,int size)&#123; T[] array = (T[])Array.newInstance(type,size); return array; &#125;&#125; 泛型的改进 类型参数推断 从泛型参数列表中一个参数推断出另一个参数（编译器从8开始支持） Map map = new HashMap();—之前，为了避免重复性的代码，可以使用工具类New Map map = new HashMap&lt;&gt;();—之后 任何基本类型不能作为类型参数（自动组包拆包解决了该问题） 一个类不能实现同一个泛型接口的两种变体（由于擦除原因会被认为是两个相同的接口） 方法的重载（由于擦除原因会被认为是两个相同的方法） java5泛型之前，我们存入容器中的内容均被向上转型为object，当取出时，必须向下转型为具体的类型 123456789101112class New&#123; public static &lt;K,V&gt; Map&lt;K,V&gt; map()&#123; return new HashMap&lt;K,V&gt;(); &#125; public static &lt;K&gt; List&lt;K&gt; list()&#123; return new LinkedList&lt;K&gt;(); &#125; public static &lt;K&gt; Set&lt;K&gt; set()&#123; return new HashSet&lt;K&gt;(); &#125;&#125;Map&lt;String,String&gt; map = New.map(); 12Map map = new HashMap()//不采用泛型，可存放任意类型的键值对Map&lt;String,String&gt; map = new HashMap&lt;&gt;();//采用泛型指定参数类型只能存放字符串类型的键值对]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Generic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introspector]]></title>
    <url>%2F2018%2F10%2F28%2FJAVA_%E5%86%85%E7%9C%81%2F</url>
    <content type="text"><![CDATA[Introspector 内省(Introspector) 是Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”。方法比较少。这些信息储存在类的私有变量中，通过set()、get()获得。 反射就是运行时获取一个类的所有信息，可以获取到.class的任何定义的信息（包括成员 变量，成员方法，构造器等）可以操纵类的字段、方法、构造器等部分。 内省基于反射实现，主要用于操作JavaBean，通过内省 可以获取bean的getter/setter 生活中 反射就像我们照镜子，照镜子时候 你的所有信息会毫无出错毫无保留的反射到镜子中，而java中反射就像是运行时用一把镜子去照.class字节码 将这个类的所有信息照出来，‘照’出的结果是客观的，是正确的； 内省就像我们反省自己，通常我们是针对犯错而进行反省，根据所犯错误反省总结出结论，这个结论是主观的，不一定正确的，有时候你觉得你自己做错了，但可能事实上自己无可厚非。java中内省，是针对javaBean进行的，目的是为了找出bean的getter和setter以便操作这个bean。只要看到有getter或者setter 就认为这个类有那么一个字段，比如看到getName() 内省就会认为这个类中有name字段，但事实上并不一定会有name； 注意： 第一种方式最后会得到包括父类在内的属性信息（即是说第二种有过滤作用） 方式一：BeanInfo beanInfo = Introspector.getBeanInfo(Person.class) 方式二：BeanInfo beanInfo = Introspector.getBeanInfo(Person.class,Object.class); 应用：将map转换成object bean对象123456789101112131415161718192021222324252627282930313233343536373839404142public &lt;T&gt; T mapToBean(Map map, Class&lt;T&gt; tClass) &#123; if (map == null) &#123; return null; &#125; else &#123; Object object = null; try &#123; object = tClass.newInstance(); BeanInfo beanInfo = Introspector.getBeanInfo(tClass); PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); PropertyDescriptor[] arr$ = propertyDescriptors; int len$ = propertyDescriptors.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; PropertyDescriptor propertyDescriptor = arr$[i$]; if (propertyDescriptor.getReadMethod() != null &amp;&amp; propertyDescriptor.getWriteMethod() != null) &#123; String propertyTypeName = propertyDescriptor.g Object value = map.get(JsonUtils.convertUpperCase(propertyTypeName)); if (value != null) &#123; if (propertyDescriptor.getPropertyType() != Long.class &amp;&amp; propertyDescriptor.getPropertyType() != Long.TYPE) &#123; if (propertyDescriptor.getPropertyType() != Double.TYPE &amp;&amp; propertyDescriptor.getPropertyType() != Double.class) &#123; if (propertyDescriptor.getPropertyType() != Integer.TYPE &amp;&amp; propertyDescriptor.getPropertyType() != Integer.class) &#123; propertyDescriptor.getWriteMethod().invoke(object, value); &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseInt(value)); &#125; &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseDouble(value)); &#125; &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseLong(value)); &#125; &#125; &#125; &#125; &#125; catch (Exception var12) &#123; ; &#125; return object; &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Introspector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC BATCH]]></title>
    <url>%2F2018%2F10%2F21%2FJDBC_Batch%2F</url>
    <content type="text"><![CDATA[JDBC BATCH JDBC基础知识复盘 JDBC BATCH 批处理执行sql JDBC基础知识复盘 复盘（使用jdbc增删改查） 12345678910111213141516171819202122232425//1. 引入对应数据库的驱动jar包//2. 加载数据库驱动Class.forName(&quot;sun.jdbc.odbc.JdbcOdbcDriver&quot;);//3. 与数据库建立连接Connection con = DriverManager.getConnection(&quot;jdbc:odbc:wombat&quot;,&quot;login&quot;,&quot;password&quot;);//4. 编写执行sqlString sql = &quot;INSERT INTO TABLEX VALUES(?, ?)&quot;;//5.1 预编译sql，防止sql注入（PreparedStatement extends Statement）PreparedStatement stmt = con.prepareStatement(sql); //5.2 设置sql语句的参数实际值stmt.setInt(1, 1);stmt.setString(2, &quot;Cujo&quot;); /** 或者使用非预编译方式（不推荐使用）：Statement stmt = con.createStatement(); *///6. 执行sql返回结果/** executeQuery执行查询类sql，返回结果集ResultSet * executeUpdate执行维护类sql，返回行数int * execute执行所给sql，返回boolean，适用于动态执行sql，返回结果有多种的情况 */ResultSet rs = stmt.executeQuery(sql);//ResultSet rs = stmt.executeUpdate(sql);while (rs.next()) &#123; int x = rs.getInt(&quot;a&quot;); String s = rs.getString(&quot;b&quot;); float f = rs.getFloat(&quot;c&quot;);&#125; Tip！！！ 为了避免像以下这种情况（单一重复性的工作，将数据库表对象的记录值存放到java对象中）的出现，衍生了数据库表和javaBean对象之间的映射关系框架123456789101112&gt; String selectSql = &quot;SELECT * FROM employees&quot;; ResultSet resultSet = stmt.executeQuery(selectSql); List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); while (resultSet.next()) &#123; Employee emp = new Employee(); emp.setId(resultSet.getInt(&quot;emp_id&quot;)); emp.setName(resultSet.getString(&quot;name&quot;)); emp.setPosition(resultSet.getString(&quot;position&quot;)); emp.setSalary(resultSet.getDouble(&quot;salary&quot;)); employees.add(emp); &#125;&gt; 盲区 使用jdbc调用存储过程 123456789101112//调用存储过程String preparedSql = &quot;&#123;call insertEmployee(?,?,?,?)&#125;&quot;;CallableStatement cstmt = con.prepareCall(preparedSql);//设置入参cstmt.setString(2, &quot;ana&quot;);cstmt.setString(3, &quot;tester&quot;);cstmt.setDouble(4, 2000);//设置出参cstmt.registerOutParameter(1, Types.INTEGER);//执行存储过程，获取出参cstmt.execute();int new_id = cstmt.getInt(1); 修改ResultSet 12345678Statement updatableStmt = con.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_UPDATABLE);ResultSet updatableResultSet = updatableStmt.executeQuery(selectSql);updatableResultSet.moveToInsertRow();updatableResultSet.updateString(&quot;name&quot;, &quot;mark&quot;);updatableResultSet.updateString(&quot;position&quot;, &quot;analyst&quot;);updatableResultSet.updateDouble(&quot;salary&quot;, 2000);updatableResultSet.insertRow(); 获取数据库表信息 123456DatabaseMetaData dbmd = con.getMetaData();//getTables该方法返回TABLE_TYPE, TABLE_SCHEM TABLE_NAME这几个表描述信息，其他信息可参考源码ResultSet tablesResultSet = dbmd.getTables(null, null, &quot;%&quot;, null);while (tablesResultSet.next()) &#123; LOG.info(tablesResultSet.getString(&quot;TABLE_NAME&quot;));&#125; 获取ResultSet中的列总数和列名 123456789ResultSetMetaData rsmd = rs.getMetaData();int nrColumns = rsmd.getColumnCount();IntStream.range(1, nrColumns).forEach(i -&gt; &#123; try &#123; LOG.info(rsmd.getColumnName(i)); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;&#125;); Transactions事务操作 12345678910111213141516171819202122232425//操作一String updatePositionSql = &quot;UPDATE employees SET position=? WHERE emp_id=?&quot;;PreparedStatement pstmt = con.prepareStatement(updatePositionSql);pstmt.setString(1, &quot;lead developer&quot;);pstmt.setInt(2, 1);//操作二 String updateSalarySql = &quot;UPDATE employees SET salary=? WHERE emp_id=?&quot;;PreparedStatement pstmt2 = con.prepareStatement(updateSalarySql);pstmt.setDouble(1, 3000);pstmt.setInt(2, 1);//获取当前连接自动提交状态，true或者falseboolean autoCommit = con.getAutoCommit();try &#123; //取消默认每执行一条sql语句就自动提交，改为手动提交状态 con.setAutoCommit(false); pstmt.executeUpdate(); pstmt2.executeUpdate(); //手动提交，操作一，操作二作为一整个原子操作执行 con.commit();&#125; catch (SQLException exc) &#123; con.rollback();&#125; finally &#123; //还原默认提交状态 con.setAutoCommit(autoCommit);&#125; JDBC BATCH 批处理执行sql Batch Processing Using Statement 123456789Statement statement = connection.createStatement();statement.addBatch(&quot;INSERT INTO EMPLOYEE(ID, NAME, DESIGNATION) &quot; + &quot;VALUES (&apos;1&apos;,&apos;EmployeeName&apos;,&apos;Designation&apos;)&quot;);statement.addBatch(&quot;INSERT INTO EMP_ADDRESS(ID, EMP_ID, ADDRESS) &quot; + &quot;VALUES (&apos;10&apos;,&apos;1&apos;,&apos;Address&apos;)&quot;);statement.executeBatch();``` - ### Batch Processing Using PreparedStatement String[] EMPLOYEES = new String[]{“Zuck”,”Mike”,”Larry”,”Musk”,”Steve”};String[] DESIGNATIONS = new String[]{“CFO”,”CSO”,”CTO”,”CEO”,”CMO”};String insertEmployeeSQL = “INSERT INTO EMPLOYEE(ID, NAME, DESIGNATION) “ “VALUES (?,?,?)”;PreparedStatement employeeStmt = connection.prepareStatement(insertEmployeeSQL);for(int i = 0; i &lt; EMPLOYEES.length; i++){ String employeeId = UUID.randomUUID().toString(); employeeStmt.setString(1,employeeId); employeeStmt.setString(2,EMPLOYEES[i]); employeeStmt.setString(3,DESIGNATIONS[i]); employeeStmt.addBatch();}employeeStmt.executeBatch();```]]></content>
      <categories>
        <category>JDBC</category>
      </categories>
      <tags>
        <tag>JDBC</tag>
        <tag>BATCH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux File Transfer]]></title>
    <url>%2F2018%2F10%2F21%2FLinux%20File%20Transfer%2F</url>
    <content type="text"><![CDATA[Linux File Transfer scp rsync nc ssh SCPNAMEscp - secure copy (remote file copy program) SYNOPSISscp [-1246BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2 DESCRIPTION 使用ssh协议进行数据传输 不像rcp，ssh协议要求密码或秘钥如果需要认证 目标文件如果已存在，直接覆盖 常用参数 -B 批处理模式，避免询问密码或秘钥 -C 开启压缩模式，可加快传输速度 -P port 连接远程主机端口号 -p 保留源文件的修改时间，访问时间，和模式 -q 安静模式：禁用进度表以及警告和来自ssh（1）的诊断消息。 -r 整个文件夹传输，包含当前文件夹（默认为文件夹下的所有内容，不包含文件夹本身） -v 打印过程日志，便于debug EXAMPLE 将本地文件拷贝到远程服务器： scp -P port ufile user@host:~/ufile 将远程服务器中的文件拷贝到本地的用法： scp -P port user@host:~/ufile ufile 将本机sql文件传输到192.168.184.132主机的/home/liufein/mysql路径下 scp -C ifp_table.sql root@192.168.184.132:/home/liufein/mysql 将本机文件夹test传输到192.168.184.132主机的/home/liufein路径下 scp -r -C test root@192.168.184.132:/home/liufein RSYNCNAMErsync -- a fast, versatile, remote (and local) file-copying tool SYNOPSISLocal: rsync [OPTION...] SRC... [DEST] Access via remote shell: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST Access via rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST COMMON PARAMETERS -q, 安静模式，只打印错误信息 -c, 跳过基于checknum的检测 -r, 递归目录 -R, 使用相对路径名 -d, 传输目录而不递归 -p, 保留权限 -z, 传输过程压缩文件 -f, –filter=RULE 添加文件过滤规则 -v, 增加传输过程中的信息显示 -a, 递归保留所有的内容 EXAMPLE rsync with ssh(通过SSH通道传输数据) rsync使用SSH通道传输数据时，配置比较简单，只要配置好了SSH，就直接可用，不需要额外的操作，正是这个原因，很多人更喜欢使用这种方式来使用rsync。与直接使用SSH传输数据时间基本一样。 本地到远程：rsync -zav --rsh=&apos;ssh -p 22&apos; ufile user@host:path 远程到本地：rsync -zav --rsh=&apos;ssh -p 22&apos; user@host:path ufile rsync with daemon(通过与服务器的rsync守护者(daemon)进程建立连接来传输数据) 不同于SCP和SFTP，rsync是一套独立的软件，除了通过SSH通道传输数据以外，还可以通过rsync的守护者进程进行数据传输。（该命令实现较为复杂，需配置配置文件，这里不做详细介绍，只是简单介绍一下执行命令） rsync -avz ufile user@host::module_name NCNAMEnc - arbitrary TCP and UDP connections and listens SYNOPSISnc [-46DdhklnrStUuvzC] [-i interval] [-p source_port] [-s source_ip_address] [-T ToS] [-w timeout] [-X proxy_protocol] [-x proxy_address[:port]] [hostname] [port[s]] COMMON PARAMETERS -D 允许debug -d 不从stdin中读取内容 -i interval 内容传输的时间间隔 -k 当前连接结束后强制监听另一连接 -n Do not do any DNS or service lookups on any specified addresses, hostnames or ports. -p source_port端口 -r 随机选择端口 -S Enables the RFC 2385 TCP MD5 signature option. -s source_ip_address源IP地址 -u 使用udp而不是默认的tcp -v 更详细的日志输出 -w timeout超时 -z 只监听，不发送数据 -l 用于指定nc应侦听传入连接，而不是启动与远程主机的连接。 DATA TRANSFER The example in the previous section can be expanded to build a basic data transfer model. Any information input into one end of the connection will be output to the other end, and input and output can be easily captured in order to emulate file transfer. Start by using nc to listen on a specific port, with output captured into a file: $ nc -l 1234 &gt; filename.out Using a second machine, connect to the listening nc process, feeding it the file which is to be transferred: $ nc host.example.com 1234 &lt; filename.in After the file has been transferred, the connection will close automatically. EXAMPLES首先在数据接收方的机器上侦听指定端口 在本机8210端口侦听TCP连接，将收到的数据写入文本文件 nc -l -p 8210 &gt; demo.txt 在本机8210端口侦听TCP连接，将收到的数据写成压缩文件 nc -l -p 8210 &gt; demo.tar.bz2 然后在数据发送方机器上向指定地址(ip+port)以TCP方式发送数据 向ip为dest_ip的机器的8210端口发送demo.txt文件 nc dest_ip 8210 &lt; demo.txt 压缩后发送 nc dest_ip 8210 &lt; $(tar -jcvf demo.tar.bz2 demo.txt) SSH 将本地的数据传输到远程服务器的用法： gzip -c ufile | ssh -p port user@host &#39;gunzip &gt;ufile&#39; 将远程服务器传输到本地的用法 ssh -p port user@host &quot;gzip -c ufile&quot; | gunzip -c &gt; ufile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SCP</tag>
        <tag>NC</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java SizeOf]]></title>
    <url>%2F2018%2F10%2F14%2FJAVA_SizeOf%2F</url>
    <content type="text"><![CDATA[Java SizeOf 计算java中对象所占内存空间大小 Java对象结构 内存对齐 Jvm中对象字段的排列顺序 Instrumentation的getObjectSize()方法获取对象的大小 Java对象结构普通对象的结构如下（按64位机器的长度计算） 对象头(_mark)， 8个字节 Oop指针，如果是32G内存以下的，默认开启对象指针压缩，4个字节 数据区 Padding(内存对齐)，按照8的倍数对齐，每8个字节为一组 数组对象结构如下 对象头(_mark)， 8个字节 Oop指针，如果是32G内存以下的，默认开启对象指针压缩，4个字节 数组长度，4个字节 数据区 Padding(内存对齐)，按照8的倍数对齐，每8个字节为一组 对象属性中根据基本类型算，将结果相加，但要考虑引用指针占用的空间（64位 JVM 压缩指针，不压缩） 当JVM最大内存小于32GB时，自动打开压缩指针特性 内存对齐 为什么需要内存对齐？32位cpu一次性可以读取32bit的数据（也就是四个字节），64位cpu一次性可以读取64bit的数据（也就是8个字节），如果不采用内存对齐，本来可以一次性就读取完成的数据可能需要两次读取才能完成，所以为了提高cpu读取数据性能，提出了内存对齐的概念。 内存对齐算法 初级算法: 1234567//n为起始地址，align为字节对齐数unsigned int calc_align(unsigned int n,unsigned align) &#123; if ( n / align * align == n) return n; return (n / align + 1) * align; &#125; 大神算法： 12345678910111213141516171819202122232425262728293031323334unsigned int calc_align(unsigned int n,unsigned align) &#123; return ((n + align - 1) &amp; (~(align - 1))); &#125; ``` &gt; ### 大神思路是这样的：&gt; 2字节对齐，要求地址位为2,4,6,8...，要求二进制位最后一位为0（2的1次方）4字节对齐，要求地址位为4,8,12,16...，要求二进制位最后两位为0（2的2次方）8字节对齐，要求地址位为8,16,24,32...，要求二进制位最后三位为0（2的3次方）16字节对齐，要求地址位为16,32,48,64...，要求二进制位最后四位为0（2的4次方）...由此可见，我们只要对数据补齐对齐所需最少数据，然后将补齐位置0就可以实现对齐计算。（1）(align-1)，表示对齐所需的对齐位，如：2字节对齐为1，4字节为11，8字节为111，16字节为1111...（2）(x+(align-1))，表示x补齐对齐所需数据 （3）&amp;~(align-1)，表示去除由于补齐造成的多余数据（4） (x+(align-1))&amp;~(align-1)，表示对齐后的数据## Jvm中对象字段的排列顺序- 默认的顺序如下：从长到短排列，引用排最后: long/double –&gt; int/float –&gt; short/char –&gt; byte/boolean –&gt; Reference- 这个顺序可以使用JVM参数: -XX:FieldsAllocationSylte=0(默认是1)来改变。（直接按照实际顺序排列）## Instrumentation的getObjectSize()方法获取对象的大小- Shallow Size，即遇到引用时，只计算引用的长度，不计算所引用的对象的实际大小。如果要计算所引用对象的实际大小，可以通过递归的方式去计算- Instrumentation的实例必须通过指定javaagent的方式才能获得 - 1. 定义一个类，提供一个premain方法: public static void premain(String agentArgs, Instrumentation instP) 2. 创建META-INF/MANIFEST.MF文件，内容是指定PreMain的类是哪个： Premain-Class: sizeof.ObjectShallowSize 3. 把这个类打成jar，然后使用jvm参数 -javaagent java-agent-sizeof.jar 启动main类 4. 在idea中引入java-agent-sizeof.jar包，然后编写启动类，设置启动jvm参数如下，运行 4. -javaagent:D:\Administrator\Tools\maven\repository\dcits\liufein\java-agent-sizeof.jar&gt; jar打包命令：jar cvfm java-agent-sizeof.jar META-INF/MANIFEST.MF - 三方工具开源的sizeOf.jar （实现原理就是Instrumentation的getObjectSize）可直接使用 ### 具体类编写如下 //jvm启动参数jar包中的类，用于使用Instrumentationpackage sizeof;import java.lang.instrument.Instrumentation;public class ObjectShallowSize { private static Instrumentation inst; public ObjectShallowSize() { } public static void premain(String agentArgs, Instrumentation instP) { inst = instP; } public static long sizeOf(Object obj) { return inst.getObjectSize(obj); }}//jvm启动参数jar包中的配置文件MANIFEST.MF内容Premain-Class: sizeof.ObjectShallowSize//实际启动类（实际需要调用Instrumentation方法getObjectSize的类）public static void main(String [] args){ System.out.println(sizeof.ObjectShallowSize.sizeOf(new ObjectA())); }``` 扩展 使用Runtime不精确计算对象占用内存空间 Runtime run = Runtime.getRuntime(); run.totalMemory()-run.freeMemory()) Runtime.getRuntime().gc();手动GC 通过sun.misc.Unsafe对象的objectFieldOffset(field)等方法结合反射来定位对象字段排列顺序 通过反射获取到对象的field 然后通过unsafe的objectFieldOffset(field)方法获取每个field的offset（偏移量，可以定位field的排列顺序）-javaagent 参数 这个参数是 JDK5 引入的，可以通过 java -h 查看其帮助信息 通过使用 -javaagent 参数，用户可以在执行 main 函数前执行指定 javaagent 包中的特定代码，甚至可以动态的修改替换类中代码。 javaagent 的代码与你的 main 方法在同一个 JVM 中运行，并被同一个 system classloader 装载，被同一的安全策略（security policy） 和上下文（context）所管理。 noverify 参数 通过使用 -noverify 参数，关闭 Java 字节码的校验功能。 当 ClassLoader 加载的Java 字节码时，字节码首先接受校验器（verifier）的校验。校验器负责检查那些指令无法执行的明显的破坏性的操作。校验器执行的检查操作： 变量要在使用之前进行初始化。 方法调用与对象应用类型之间要匹配。 访问私有数据和方法的规则没有被违反。 对本地变量的访问都在运行时堆栈内。 运行时堆栈没有溢处。 manifest（MANIFEST.MF）是什么配置文件？ 这个 manifest 文件定义了与扩展和包相关的数据，例如： 一般属性 应用程序相关属性 小程序(Applet)相关属性 扩展标识属性 包扩展属性 签名相关属性 自定义属性 ### Java中无论是汉字还是英文字母都是用Unicode编码来表示的，一个Unicode码是16位，每字节是8位，所以一个Unicode码占两字节，英文字母比较特殊，源自于8位（1字节）的ASCII码。 Java——————-MySql byte：1字节———–TINYINT 1 short：2字节———-SMALLINT 2 MEDIUMINT 3 int：4字节————-INT 4 long：8字节———–BIGINT 8 float：4字节———-FLOAT(M,D) double：8字节——–DOUBLE(M,D) char/String———–CHAR()/VARCHAR()]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SizeOf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell Learning]]></title>
    <url>%2F2018%2F10%2F07%2FShell%20Learning%2F</url>
    <content type="text"><![CDATA[Shell Learning linux常用命令 输入输出重定向 管道符 | 编写shell脚本 定时任务 周期任务 /dev/zero和/dev/null linux常用命令 man ls：查看ls命令详解（/aaa搜索文档，？aaa模糊搜索文档，n查看下一个匹配项，N产看上一个匹配项，q退出文档） echo 字符串、$变量：输出到终端命令 date：日期命令，常用与将其与备份文件命名相结合，使其文件名清晰明了 reboot、poweroff：重启、关机 wget 参数（-P指定目录） 下载地址：下载网络文件 ps命令 用于报告当前系统的进程状态。可以搭配kill指令随时中断、删除不必要的程序 top：查看系统负载情况（cup，内存。。。） pidof service：查看service的pid值 kill 2456：杀死指定服务进程 killall service：杀死指定服务所有进程 ifconfig：查看网络状态信息 uname -a：查看系统内核版本信息 uptime：查看系统负载情况 free：查看当前内存使用量 who、last、history：当前用户信息、上一次登录信息、历史命令 pwd、cd、ls、 cat：查看纯文本内容（内容较少） more：查看纯文本（内容较多） head：查看文本前几行 tail：查看文本后几行（-f参数实时更新） tr source target：替换文本字符（支持正则表达式[a-z]） wc：统计文本行数-l，单词数-w，字节数-c stat filename：查看文件的存储信息和时间等 cut 参数 文本：按列提取文字符（-d:参数-d以：为间隔符，-f2 按列搜索两列） diff 参数 fileA fileB：比较文件AB的不同（–brief显示对比结果是否相同，-c显示具体的不同） touch：创建空白文件，修改设置文件时间（-a修改读取时间atime，-修改修改时间mtime，-d同时修改atime和mtime） mkdir：创建空白目录（-p递归创建） cp 参数 source target：复制文件（target是目录复制到目录中，是文件覆盖询问，不存在直接执行） mv 参数 source target：剪贴文件 rm：删除文件、目录（-f强制删除，-r删除目录） dd：按照指定大小和个数复制或转换文件（if=输入文件名，of=输出文件名，bs=块的大小，count=块的个数） dd if=/dev/zero of=560_file bs=560M count=2 tar：打包命令（-c创建压缩文件，-x解开压缩文件，-t查看压缩包内有哪些文件，-z用Gzip压缩或者解压，-j用bzip压缩或者解压，-v显示压缩解压过程，-f目标文件名，-P保留原始属性权限，-p使用绝对路径来压缩，-C指定解压目录） tar -czvf etc.tar.gz /etc 压缩文件夹etc下的内容 tar -xzvf etc.tar.gz -C /root/liufei 解压文件etc.tar.gz到文件夹/root/liufei grep：文本内容搜索（-b将可执行文件当做文本文件搜索，-c仅显示找到的行数，-i忽略大小写，-n显示行号，-v反向匹配找到没有关键字的行，-A10匹配的后十行，-B10前十行） find：文件搜索** netstat -anop，端口占用查看，列出所有端口的情况 netstat -anop|findstr “49157” 精确查询端口情况，查看被占用端口对应的PID（windows下） netstat -anop|grep 21666 精确查询端口情况，查看被占用端口详情（linux下） kill pid 根据pid杀掉进程（linux下） tasklist|findstr “102760” 根据pid查询占用服务（windows下） taskkill /f /t /im Tencentdl.exe：结束占用进程（windows下） w：该命令显示的信息很丰富，第一行从左至右显示的信息一次为：时间、系统运行时间、登录用户数、平均负载，这些数据里最应该关注当为load average后的3个数值。第一个数值表示1分钟内系统的平均负载值，第二个数值表示为5分钟内系统的平均负载值，第三个表示15分钟内系统的平均负载值。这里着重看第一个值，它表示单位时间段内使用CPU的活动进程数，值越大就说明服务器压力越大，一般情况下只要这个值不超过服务器的CPU数量就没有关系。如果服务器CPU数量为8，那么值小于8就说明当前服务器没有压力，否则就要关注一下。 cat /proc/cpuinfo：查看服务器有几个CPU vmstat：查看当前系统具体是哪里有压力，显示的结果共分为六部分：procs、memory、swap、io、system、cpu。（vmstat 1每隔一秒输出一次；vmstat 1 5每隔一秒输出一次，共五次） sar：（yum install -y sysstat安装命令）可以监控系统几乎所有资源的状态 sar -n DEV：查看网卡流量输入输出重定向 标准输入重定向：stdin 0标准输出重定向：stdout 1错误输出重定向：stderr 2 重定向符号的使用 命令 &lt; 文件：文件作为命令的标准输入 命令 &lt;&lt; 分界符：从标准输入中读取，知道遇到分界符 命令 &lt; 文件1 &gt; 文件2：文件1作为命令的标准输入，并将标准输出到文件2 命令 &gt; 文件：标准输出到文件，覆盖 命令 2&gt; 文件：错误输出到文件，覆盖 命令 &gt;&gt; 文件：标准输出到文件，追加 命令 2&gt;&gt; 文件：错误输出到文件，追加 命令 &amp;&gt;&gt; 文件：错误和标准输出到文件，追加 管道符 |将前一个命令的标准输出到后一个命令的标准的输入 ls /liufein | wc -l 配置主机名称：/etc/hostname配置网卡信息：ifconfig+cd /etc/sysconfig/network-scripts/+vi+ service network restart/systemctl restart network shell脚本的编写 接收用户参数：./example.sh 参数1 参数2 参数3 … vi example.sh $0对应脚本名称 $#对应总参数个数 $*对应所有的参数值 $1,$2…对应第n个参数 条件表达式：[空格+表达式+空格] 测试参数 -d：是否为目录 -e：文件是否存在 -f：是否为一般文件 -r、w、x：是否拥有可读、可写、可执行权限 -eq：是否等于 -ne：是否不等于 -gt：是否大于 -lt：是否小于 -ge：是否大于等于 -le：是否小于等于 123456789101112131415161718192021222324252627282930313233343536373839# 单条件 if [空格+表达式+空格] then 。。。 else 。。。fi# 多条件if [空格+表达式+空格] then 。。。elif [空格+表达式+空格] then ...else ...fi# for循环for user in usersdo ...done# while循环while [空格+表达式+空格]do ...done# case条件case 变量 in模式1) .... ;;模式2) .... ;;...*) 默认执行esac 定时任务命令 at 时间点 Ctrl+d结束定时任务编写 at -l：查看所有定时任务 atrm 序号：删除定时任务 周期任务命令（分，时，日，月，星期（0和7均表示周日），命令） crontab -e：创建周期任务 crontab -l：查看周期任务 crontab -r：删除周期任务 crontab -u：root用户可修改其他人的周期任务 *星号表示占位符，没有具体值，逗号分割表示多个值-连字符表示一段连续值/n表示每隔n执行一次分不能为空或*，日和星期不能同时使用命令一定要使用绝对路径，使用whereis 命令查看 /dev/null 在类Unix系统中，/dev/null，或称空设备，是一个特殊的设备文件，它丢弃一切写入其中的数据（但报告写入操作成功），读取它则会立即得到一个EOF。 在程序员行话，尤其是Unix行话中，/dev/null 被称为位桶(bit bucket)或者黑洞(black hole)。空设备通常被用于丢弃不需要的输出流，或作为用于输入流的空文件。当你读它的时候，它会提供无限的空字符(NULL, ASCII NUL, 0x00)。 /dev/zero 像/dev/null一样，/dev/zero也是一个伪文件，但它实际上产生连续不断的null的流（二进制的零流，而不是ASCII型的）。写入它的输出会丢失不见，/dev/zero主要的用处是用来创建一个指定长度用于初始化的空文件，像临时交换文件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DECODE]]></title>
    <url>%2F2018%2F09%2F30%2FDECODE%20Function%2F</url>
    <content type="text"><![CDATA[DECODE FUNCTION Oracle 中的decode()函数，用来替代sql语句中的if-else逻辑 Oracle DECODE() function语法：DECODE (e , s1, r1[, s2, r2], ...,[,sn,rn] [, d]); 实例SELECT DECODE(1, 1, &apos;One&apos;) FROM table_a; //等价于 SELECT (IF 1 = 1 THEN RETURN &apos;One&apos;; END IF) FROM table_a; 目标值与单个值的比较DECODE(var1, var2, value)：如果var1=var2，返回value，否返回nullDECODE(var1, var2, value1,value2)：如果var1=var2，返回value1，否返回value2 SELECT DECODE(2,1,&apos;ONE&apos;,2,&apos;NOT ONE&apos;) FROM table_a; SELECT (IF 2 = 1 THEN RETURN &apos;ONE&apos;; ELSEIF 2 = 2 THEN RETURN &apos;NOT ONE&apos;; END IF) FROM table_a; 目标值与多个值的比较DECODE(var1, var2, value2,var3,value3…)：如果var1 = var2，返回value2，如果var1 = var3，返回value3…以此类推DECODE(var1, var2, value2,var3,value3…,defaultValue)：如果var1 = var2，返回value2，如果var1 = var3，返回value3…以此类推，如果没有一个匹配上，则返回默认值defaultValue]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle DECODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Executor]]></title>
    <url>%2F2018%2F09%2F23%2FExecutor%2F</url>
    <content type="text"><![CDATA[ExecutorExecutor接口 接口只有一个execute(Runnable command)方法来执行所给线程 ExecutorService接口 继承自接口Executor 提供了管理线程生命周期的方法，运行 关闭和终止三种状态。 AbstractExecutorService抽象类 实现了接口ExecutorService 新增了两个newTaskFor方法来实现父接口的submit等线程执行方法 调用execute方法执行线程 将其结果返回到Future中 ForkJoinPool 继承自抽象类AbstractExecutorService 内部类WorkQueue（工作队列） 其实就是维护了一个ForkJoinTask类型的数组 ForkJoinWorkerThread的run方法负责去执行WorkQueue中的ForkJoinTask任务 两个主要的执行任务的抽象类。RecursiveAction与RecursiveTask (继承自ForkJoinTask(实现了Futrue))。 RecursiveAction ：没有返回值的接口。 RecursiveTask ：带有返回值的接口。 ForkJoinTask fork方法负责分解创建子任务（将创建的子任务ForkJoinTask扔进WorkQueue中的数组中，再由ForkJoinWorkerThread线程取出执行） join方法负责阻塞等待子任务结果 invokeAll方法避免了当任务众多时逐一去调用fork和join，将多任务作为参数传入统一执行，同时invokeAll方法可以充分利用当前线程去处理任务，减少一个task放入WorkQueue，再由ForkJoinWorkerThread取出执行的时间，效率更高一些（等效于当有两个任务时，1.fork；2.doInvoke；1.join；按照这样的顺序执行效率最高） 核心思想就是分治。Fork分解任务，Join收集数据。 ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。 实现原理：将一个大的任务分解为多个小的任务（默认cpu核数），这样一个线程负责一个任务的执行，每一个小的任务还可以继续细分为多个task，就相当于一个线程负责若干个task的执行，每个线程拥有一个双向队列数据结构来承载各自的task，该双向队列只有三个操作，从队列头取出一个task供线程执行，当队列中task又细分出另外的task时，将该task放入队列头中（注意不是放入队列尾），相当于该双向队列的队列头是一个栈的作用，而当其他线程提前将自己的task全部执行完成后，会去帮助其他还未完成的线程，从其双向队列的队尾取出一个task帮助其完成（注意：从其他线程的队列尾取出task操作需要加锁，避免多个线程同时去执行取task这个操作）。 应用场景：适用于基于event的异步消息处理执行框架 注意：选择合适的子任务粒度 ThreadPoolExecutor（核心类） 继承自抽象类AbstractExecutorService 重点负责线程池的创建和管理 负责线程生命周期的管理，线程的执行，线程执行结果的返回 内部类Worker继承了AbstractQueuedSynchronizer（用于构建锁或者其他相关同步装置的基础框架）实现了runnable接口 构造方法构造线程池，submit方法提交执行线程任务 ScheduledExecutorService接口 继承自接口ExecutorService 新增基于时间计划的线程执行方法 结果返回在ScheduledFuture&lt;?&gt;中 ScheduledThreadPoolExecutor实现类 继承自ThreadPoolExecutor 实现了接口ScheduledExecutorService System.nanoTime()返回纳秒 Executors 调用ThreadPoolExecutor，ForkJoinPool，ScheduledThreadPoolExecutor三个核心类来创建指定的线程池 newFixedThreadPool(int nThreads) 创建一个指定线程数量的线程池 ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); newWorkStealingPool() 创建一个可以偷其他线程task执行的线程池（1.8新增） ForkJoinPool(Runtime.getRuntime().availableProcessors(),ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); newSingleThreadExecutor() 创建一个单一工作线程的executor new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue())); newCachedThreadPool() 创建一个缓存线程池，线程可复用 ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,new SynchronousQueue()); newScheduledThreadPool创建一个时间计划线程池 newSingleThreadScheduledExecutor创建一个基于时间计划的单一工作线程的executor ForkJoinWorkerThread（ForkJoin工作线程） 继承自Thread 负责执行ForkJoinPool中队列里面的任务task 最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目 实战演练环节123ForkJoinPool一个线程一个任务，该任务必须是可切分的，切分后的task均被放入自己的所属线程的队列中去JVM可用的处理器个数Runtime.getRuntime().availableProcessors()=当前设备的CPU个数 批量文件量太大，分部读入处理，放入集合中内容不能太多]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Executor</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CompletableFuture]]></title>
    <url>%2F2018%2F09%2F16%2FCompletableFuture%2F</url>
    <content type="text"><![CDATA[CompletableFuture Callable/Runnable Future FutureTask CompletionStage CompletableFuture Appendix Callable/Runnable The Callable interface is similar to Runnable, in that both are designed for classes whose instances are potentially executed by another thread. A Runnable, however, does not return a result and cannot throw a checked exception. callable和runnable的实例都是设计用来被其他线程所执行的，区别在于runnable没有返回值，也不能抛出错误 callable和runnable都是接口，只会构造出一个另外的线程实例，但不会去自己执行，需要一个调度器excuter来提交执行或者一个实现了该接口的实例类去自己调用run/call方法来启动线程。Thread有自己的start方法来自我启动 12public interface Callable&lt;V&gt;（V为返回值的类型）public interface Runnable Future 承载线程执行结果的接口，定义了以下方法 cancel()取消线程执行操作 get()获取线程执行结果返回值 get(long timeout, TimeUnit unit)规定时间内返回结果（完成返回值，未完成报错超时） isCancelled()线程执行操作是否取消 isDone()线程是否执行完成 Future的弊端 只能通过阻塞或者轮询的方式得到任务的结果 很难直接表述多个Future 结果之间的依赖性 将多个异步计算的结果合并成一个 等待Future集合中的所有异步任务都完成 Future完成事件（即，异步任务完成以后触发执行动作） 应用举例12345678使用Future获取异步操作结果ExecutorService executor = Executors.newSingleThreadExecutor(); Future&lt;String&gt; future = executor.submit(()-&gt;&#123; System.out.println(&quot;异步操作执行 &quot;); return &quot;hello&quot;; &#125;); System.out.println(&quot;原交易正常执行 &quot;); System.out.println(&quot;获取异步操作返回值&quot; + future.get()); FutureTaskRunnableFuture 该接口继承了runnable和future，FutureTask又是该接口的唯一实现类，因此FutureTask不仅可以获取线程执行的结果，还拥有了启动线程执行的能力。 FutureTask A FutureTask can be used to wrap a Callable or Runnable object.一个FutureTask能包裹一个callable或者runnable对象（构造方法实现） 没有无参构造方法 可以提交至executor执行，也可以调用自己的run方法执行 由于实现了runnale接口，构造方法参数又有runnable/callable，所以可以启动两个线程，自身线程和入参线程 FutureTask代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void futureTaskDisplay()&#123; //使用匿名内部类书写 executor.submit(new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;); //使用lambda表达式书写 executor.submit(new FutureTask&lt;String&gt;(()-&gt; &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(()-&gt; &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;; futureTask.run(); System.out.println(&quot;是否完成&quot; + futureTask.isDone()); System.out.println(&quot;是否取消&quot; + futureTask.isCancelled()); try &#123; System.out.println(futureTask.get()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;catch (ExecutionException e)&#123; e.printStackTrace(); &#125; &#125; CompletableFuture 1.8新增功能类 实现了接口CompletionStage和Future 只有无参构造方法CompletableFuture() 典型应用 1.acceptEither(2,3) 1.applyToEither(2,3) 1.handle(2) 1.runAfterBoth(2,3) 1.runAfterBoth(2,3) Appendix CompletionStage接口所有方法解读 CompletableFuture acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 1.acceptEither(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动 CompletableFuture acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 1.acceptEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动（以1默认异步执行工具执行） CompletableFuture acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor) 1.acceptEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动（用提供的executor去执行） static CompletableFuture allOf(CompletableFuture&lt;?&gt;… cfs) 1.allOf(2,3,4….)：当234等所有的CompletableFuture全部完成，返回完成的1 static CompletableFuture anyOf(CompletableFuture&lt;?&gt;… cfs) 1.anyOf(2,3,4….)：当234等任意的一个CompletableFuture完成，就可以返回完成的1 CompletableFuture applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 1.applyToEither(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动 CompletableFuture applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 1.applyToEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动（以1默认异步执行工具执行） CompletableFuture applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor) 1.applyToEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动（用提供的executor去执行） boolean cancel(boolean mayInterruptIfRunning) 取消异步操作 boolean complete(T value) 如果调用时未完成，设置value作为完成结果对接其他 static CompletableFuture completedFuture(U value) 返回一个已完成的CompletableFuture，结果设置为value boolean completeExceptionally(Throwable ex) 若异步操作未完成中，调用get方法或者其他相关方法，抛出该错误 CompletableFuture exceptionally(Function fn) T get() 获取异步操作的结果值 T get(long timeout, TimeUnit unit) 指定时间内获取异步操作的结果值 T getNow(T valueIfAbsent) 立刻获取异步操作的结果值，已完成直接返回其结果，未完成返回所给参数值 int getNumberOfDependents() 获取其他已完成的但是在等待此CompletableFuture的数量 CompletableFuture handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2 CompletableFuture handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2（以1默认的异步工具执行） CompletableFuture handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2（用所给的executor执行） boolean isCancelled() boolean isCompletedExceptionally() boolean isDone() T join() 正常完成，返回结果值，异常，抛错 void obtrudeException(Throwable ex) void obtrudeValue(T value) CompletableFuture runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3 CompletableFuture runAfterBothAsync(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3（以1默认的异步工具执行） CompletableFuture runAfterBothAsync(CompletionStage&lt;?&gt; other, Runnable action, Executor executor) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3（用所给的executor执行） CompletableFuture runAfterEither(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2有一个正常完成后，执行3 CompletableFuture runAfterEitherAsync(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2有一个正常正常完成后，执行3（以1默认的异步工具执行） CompletableFuture runAfterEitherAsync(CompletionStage&lt;?&gt; other, Runnable action, Executor executor) 1.runAfterBoth(2,3)：当1和2有一个正常正常完成后，执行3（用所给的executor执行） static CompletableFuture runAsync(Runnable runnable) 1.runAsync(2)：当 ForkJoinPool.commonPool()中1的task完成后异步的执行2 static CompletableFuture runAsync(Runnable runnable, Executor executor) 1.runAsync(2,3)：当 3中1的task完成后异步的执行2 static CompletableFuture supplyAsync(Supplier supplier) 返回由ForkJoinPool.commonPool（）中运行的任务异步完成的新CompletableFuture，其中包含通过调用给定供应商获得的值。 static CompletableFuture supplyAsync(Supplier supplier, Executor executor) 返回由executor运行的任务异步完成的新CompletableFuture，其中包含通过调用给定供应商获得的值。 CompletableFuture thenAccept(Consumer&lt;? super T&gt; action) 1.thenAccept(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenAcceptAsync(Consumer&lt;? super T&gt; action) 1.thenAcceptAsync(2)：1正常完成后，2以1的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor) 1.thenAcceptAsync(2)：1正常完成后，2以1的结果为入参执行（用所给的executor执行） CompletableFuture thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行 CompletableFuture thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action, Executor executor) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行（用所给的executor执行） CompletableFuture thenApply(Function&lt;? super T,? extends U&gt; fn) 1.thenApply(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenApplyAsync(Function&lt;? super T,? extends U&gt; fn) 1.thenApplyAsync(2)：1正常完成后，2以1的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 1.thenApplyAsync(2)：1正常完成后，2以1的结果为入参执行（用所给的executor执行） CompletableFuture thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) 1.thenCombine(2,3)：12都正常完成后，3以12的结果为入参执行 CompletableFuture thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) CompletableFuture thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor) CompletableFuture thenCompose(Function&lt;? super T,? extends CompletionStage&gt; fn) 1.thenCompose(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenComposeAsync(Function&lt;? super T,? extends CompletionStage&gt; fn) CompletableFuture thenComposeAsync(Function&lt;? super T,? extends CompletionStage&gt; fn, Executor executor) CompletableFuture thenRun(Runnable action) 1.thenRun(2)：1正常完成后，2执行 CompletableFuture thenRunAsync(Runnable action) CompletableFuture thenRunAsync(Runnable action, Executor executor) CompletableFuture toCompletableFuture() 返回这个CompletableFuture CompletableFuture whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action) 1.whenComplete(2)：1完成后（正常或者报错），2执行 CompletableFuture whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action) CompletableFuture whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)]]></content>
      <categories>
        <category>Asynchronous</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>Asynchronous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BlockingQueue]]></title>
    <url>%2F2018%2F09%2F09%2FBlockingQueue%2F</url>
    <content type="text"><![CDATA[BlockingQueue 阻塞队列源于队列，先把队列数据结构熟悉后再来了解阻塞队列事半功倍 所有方法均类似的会涉及到一个指定时间计划的参数 队列的存取实际就是基于生产者消费者的最基本模型 公平锁/非公平锁也就是可否抢夺资源 生产者/消费者公用一把锁还是各用一把锁 队列的有界/无界性其实就是对生产者的一种限制，避免无限生产导致资源耗尽 阻塞队列类分析 接口BlockingQueue 继承自接口 Queue add方法添加元素，成功返回true，若队列已满抛错 offer方法添加元素，成功返回true，若队列已满返回false put方法添加元素，若队列已满，等待队列腾出空间后插入 take取出队列头元素，若无可取元素，等待直到有元素进入将其取出 drainTo方法将队列中元素抽取到所给的集合中去 ArrayBlockingQueue 有界队列 数组模拟循环队列，当队尾达到数组边界时，索引index返回数组下标为0的地方 使用Object[]数组盛放队列元素 ReentrantLock加锁执行每一次元素的存取 内部类Itr实现了Iterator接口，迭代遍历元素使用 内部类Itrs维护了多个Iterator在链表中，作用不懂？ LinkedBlockingQueue 有界队列（默认Integer.MAX_VALUE） 使用链表节点node承载队列元素 双向链表，有头结点也有尾节点 入队列在链表尾，出队列取链表头 ReentrantLock加锁执行每一次元素的存取 内部类Itr实现了Iterator接口，迭代遍历元素使用 PriorityBlockingQueue（优先阻塞队列） 无界队列（注意：当生产者速度远大于消费者时，会导致队列的无限扩容，最终耗尽空间资源） 使用Object[]数组承载队列元素，用数组实现的堆heap来实现优先级 默认初始数组空间为11 数组扩容oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : (oldCap &gt;&gt; 1)); 优先级实现原理参照优先队列 DelayQueue（延迟队列） 实现延迟获取的无界队列 创建元素时，指定延迟一定时间才能从队列中获取该元素 内部使用非线程安全的优先队列 采用了leader/follower模式 若干个线程组成线程池来处理大量的事件 有一个线程作为领导者leader，等待事件的发生；其他的线程作为追随者follower，仅仅是睡眠。 假如有事件需要处理，领导者会从追随者中指定一个新的领导者，自己去处理事件，状态变为processer。 唤醒的追随者作为新的领导者等待事件的发生。 处理事件的线程处理完毕以后，就会成为追随者的一员，直到被唤醒成为领导者。 假如需要处理的事件太多，而线程数量不够(能够动态创建线程处理另当别论)，则有的事件可能会得不到处理。 应用场景 缓存有效期：将某个缓存的有效期存入延迟队列中，使用一线程轮训访问该延迟队列，一旦能取出该有效期，则表示有效期到了 定时任务调度：一旦可以从延迟队列中取出该任务时，就开始执行 SynchronousQueue（同步队列） 队列中不存储元素 每一个值插入的操作必将等待一个取值操作，否则不能插入元素 Executors.newCachedThreadPool()使用了SynchronousQueue LinkedBlockingDeque 有界队列 使用链表节点node承载队列元素 双向链表，有头结点也有尾节点 链表双向均可插入取出元素 实战演练环节12]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Queue</tag>
        <tag>BlockingQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[F5]]></title>
    <url>%2F2018%2F09%2F02%2FF5%2F</url>
    <content type="text"><![CDATA[F5F5 Networks(纳斯达克: FFIV) ，全球领先的应用交付网络（ADN）领域的厂商，F5是个公司的名称！ 引言 工作以后耳边总会时不时的响起一些生疏的代名词，今天这个叫F5。这次词已经不止一次的进入到的我的耳朵里，但每次总是一闪而过，并伴随着硬件负载均衡器这个解释。直到前段时间这个词真正出现在了我面前，忍不住查阅了一翻资料才发现之前的认知有多么的草率。 正文 F5为什么会被叫做硬件负载均衡器？ 真正的硬件负载均衡器是谁？ 负载均衡的功能包括哪些？ F5公司的介绍和该公司的产品介绍可自行google了解，官网地址如下：https://www.f5.com/ F5为什么会被叫做硬件负载均衡器 1996年，F5 Networks创立。1997年，F5 推出的第一款产品是BIG-IP 负载均衡器 。1999年，F5在美国NASDAQ成功上市，掀起了应用交付网络的强劲龙卷风。 F5是负载均衡产品的一个品牌，除了F5以外，Radware、Array、A10、Cisco、深信服等都是负载均衡的牌子，但由于F5在这类产品中影响最大，所以经常说F5负载均衡。 真正的硬件负载均衡器是谁F5公司旗下的产品众多，包括 BIG-IP平台 F5 BIG-IP本地流量管理器(LTM)：一款出色的应用流量管理系统，可提供业内最智能、最具适应性的解决方案来保护、优化和交付应用，从而确保企业能够在保持高效运营的同时提高其竞争力。 F5 BIG-IP应用安全管理器(ASM)：一个先进的Web应用防火墙，可显著减少和控制数据、知识产权和Web应用丢失或损坏的风险。BIG-IP ASM通过一个将应用交付与网络和应用加速及优化结合在一起的平台，提供了无与匹敌的应用和网站防护、完整的攻击专家系统，并且可以满足关键的法规要求。 F5 BIG-IP链路控制器(LC)：无缝地监控多条WAN ISP连接的可用性与性能，以智能地管理到某站点的双向流量，从而提供出色的容错性和优化的互联网访问。 BIG-IP iSeries平台：全新F5 BIG-IP iSeries硬件平台具备可编程性、广泛的生态系统集成编排功能、以及创纪录的软件定义硬件性能。 VIPRION威普龙平台：一款独立且功能强大的应用交付控制器，它采用模块化高性能板卡，且插拔模块板卡时不会中断应用运行。 F5 BIG-IP 企业管理器… F5 ⅥPRION威普龙应用交付控制器… BIG-IP虚拟版本（VE）… F5 Advanced WAF(API安全 - 新一代WAF)… BIG-IP Cloud Edition（BIG-IP云版本）… F5 WANJet广域网加速器… F5 BIG-IP Web应用加速器(Web Accelerator)… F5 BIG-IP安全接入管理器(SAM)… F5 BIG-IP广域流量管理器(GTM)… 硬件负载均衡器==F5 BIG-IP LTM（本地流量管理器） F5 BIG-IP LTM（本地流量管理器）是一台对流量和内容进行管理分配的设备。它提供12种灵活的算法将数据流有效地转发到它所连接的服务器群。而面对用户，只是一台虚拟服务器。用户此时只需访问定义于BIG-IP LTM上的一台服务器，即虚拟服务器（Virtual Server）。但他们的数据流却被BIG-IP灵活地均衡到所有的物理服务器。BIG-IP LTM可以通过多种负载均衡算法对流量进行分配。 负载均衡的功能包括哪些？ 降低服务器负载方面 内容转换 OneConnect 高速缓存 SSL加速和卸载 应用优化方面 智能应用交换 智能压缩 灵活的第7层速率整形 TCPExpress iSessions WAN优化模块(插件模块) 安全的应用方面 资源隐藏和内容安全 定制的应用攻击过滤 基础防火墙功能—数据包过滤 隔离协议攻击 网络攻击防护 有选择的加密 Cookie加密 高级SSL加密标准 先进的客户端验证模块(插件模块) 垃圾邮件过滤模块(插件模块) 协议安全模块(插件模块)]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Load Balance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DMZ]]></title>
    <url>%2F2018%2F08%2F26%2FDMZ%2F</url>
    <content type="text"><![CDATA[DMZ 什么是DMZ？ 有哪些用途？ 什么是DMZ？两个防火墙之间的空间被称为DMZ。 DMZ是英文“demilitarized zone”的缩写，中文名称为“隔离区”，也称“非军事化区”。它是为了解决安装防火墙后外部网络的访问用户不能访问内部网络服务器的问题，而设立的一个非安全系统与安全系统之间的缓冲区。该缓冲区位于企业内部网络和外部网络之间的小网络区域内。在这个小网络区域内可以放置一些必须公开的服务器设施，如企业Web服务器、FTP服务器和论坛等。另一方面，通过这样一个DMZ区域，更加有效地保护了内部网络。因为这种网络部署，比起一般的防火墙方案，对来自外网的攻击者来说又多了一道关卡。 外网—&gt;外网防火墙—&gt;DMZ—&gt;内网防火墙—&gt;内网DMZ空间中包含堡垒主机，modem池，公共服务器 堡垒主机：堡垒主机是一种被强化的可以防御进攻的计算机，作为进入内部网络的一个检查点，以达到把整个网络的安全问题集中在某个主机上解决，从而省时省力，不用考虑其它主机的安全的目的。堡垒主机是网络中最容易受到侵害的主机，所以堡垒主机也必须是自身保护最完善的主机。一个堡垒主机使用两块网卡，每个网卡连接不同的网络。一块网卡连接你公司的内部网络用来管理、控制和保护，而另一块连接另一个网络，通常是公网也就是Internet。堡垒主机经常配置网关服务。网关服务是一个进程来提供对从公网到私有网络的特殊协议路由，反之亦然。 modem池：调制解调器，是一种计算机硬件，它能把计算机的数字信号翻译成可沿普通电话线传送的模拟信号，而这些模拟信号又可被线路另一端的另一个调制解调器接收，并译成计算机可懂的语言。这一简单过程完成了两台计算机间的通信 公共服务器：如web，ftp，mail等公司必须对外开放的一些公共服务器，无敏感数据，代理数据访问的主机服务器 有哪些用途？ 三层保护，攻击者如果想要进入到内网，将通过外网防火墙，DMZ区域，内网防火墙三层关卡，内网数据安全性更高 防火墙来完成外网到DMZ，DMZ到内网的地址转换工作，即NAT，以保证隐藏服务器真实网络地址 解决安装防火墙后外部网络的访问用户不能访问内部网络服务器的问题，而设立的一个非安全系统与安全系统之间的缓冲区。]]></content>
      <categories>
        <category>NetWork</category>
      </categories>
      <tags>
        <tag>DMZ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSO原理]]></title>
    <url>%2F2018%2F08%2F19%2FSSO%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[SSO原理 需求缘起 实现原理 什么是Cookie？ 什么是session？ 什么是Token？ 需求缘起Web应用系统演变史 从单一功能到多功能 从单一系统到多系统 Web互联网应用逐渐发展为多系统共同支持的应用群 不同系统间功能相对独立，但又存在着联系 用户眼中只有应用群一个概念，群内的各个系统应该对用户保持透明 如何保证用户信息在各个系统间的一致性，也就是说在应用群内一处验证，随处可用 单Web应用系统如何实现登录登出 Web应用，系统采用B/S架构，Browser和Server之间的通信协议是http协议 http协议为无状态协议，即每个http请求都是单一独立的，不考虑是否源自同一会话 用户登陆应用到登出的之间这一段称之为一次会话交互 要想实现http请求的会话识别可以通过传递参数或者cookie两种方式 推荐cookie方式，服务器端http响应设置好后，浏览器以后每次请求会自动带上cookie返回给服务端进行是否同一会话验证 Web应用服务器一般俊辉提供这种会话基础服务，如tomcat的session机制，避免了开发人员的手动cookie创建维护删除管理 cookie作用域，由属性Domain和Path共同决定，path是访问路径，可以设置为/根路径使其作用于所有路径，但是Domain我们不能定义顶级域名，最大只能定义到二级域名，所以当应用群中存在多个二级域名时便会出现cookie失效情况 当请求超过cookie作用域时，请求不会携带cookie 服务器session机制只适用于单一应用范围内 不同系统之间的异构性会导致session实现机制不尽相同 共享session机制会对原系统侵入性很大 一次完整的用户和系统间http交互过程 用户发出登录请求 系统验证用户信息，信息无误，授权用户相关权限，登录成功响应，设置会话id-cookie 登录成功后继续请求，携带会话id-cookie 系统验证会话id-cookie，返回请求资源 用户请求登出 系统取消会话id-cookie 实现原理大致思路 抽象每个单Web应用系统中的用户登录验证阶段成一个独立的认证中心系统 将浏览器对应用系统的用户登录请求重定向到认证中心系统 认证中心认证完成后再将请求重定向回应用系统 应用系统检测到认证成功予以登录，授权用户后续操作 存在问题及解决方案 登录信息传递：认证中心认证通过后如何将消息回传给应用系统，由于cookie不能跨域，所以只能传递参数；可以将认证通过消息制作成令牌token传递。 令牌token正确性验证：应用系统如何判别令牌是从认证中心发出，且有效正确。因此需要应用系统和认证系统之间进行通信验证令牌 登录状态判断：首次登录验证成功后用户浏览器和认证中心建立起了会话，但是应用系统与用户之间没有，所以登录成功后的每次请求验证均需通过认证中心，导致效率低下。因此可以在应用系统和用户之间也建立会话，称之为局部会话（与认证中心之间的称之为全局会话），局部会话依附于全局会话而存在。 登出状态判定：当用户在其中一个应用系统登出之后，该应用系统局部会话销毁，认证中心的全局会话销毁，同时认证中心下放通知各个应用系统销毁该用户的局部会话 什么是Cookie？ cookie指的就是浏览器里面能永久存储数据的一种数据存储功能。 cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的cookie数量是有限的。 当用户访问同一个 Web 服务器时，浏览器首先要检查本地的Cookies，并将其原样发送给 Web 服务器。 Cookie有什么功能特点呢？在同一个页面中设置 Cookie，实际上是按从后往前的顺序进行的。如果要先删除一个 Cookie，再写入一个 Cookie，则必须先写写入语句，再写删除语句，否则会出现错误 。 Cookie是面向路径的。缺省路径 (path) 属性时，Web 服务器页会自动传递当前路径给浏览器，指定路径强制服务器使用设置的路径。在一个目录页面里设置的 Cookie 在另一个目录的页面里是看不到的 。 Cookie 必须在 HTML 文件的内容输出之前设置；不同的浏览器 (Netscape Navigator、Internet Explorer) 对 Cookie 的处理不一致，使用时一定要考虑；客户端用户如果设置禁止 Cookie，则 Cookie 不能建立。 并且在客户端，一个浏览器能创建的 Cookie 数量最多为 300 个，并且每个不能超过 4KB，每个 Web 站点能设置的 Cookie 总数不能超过 20 个 。 Cookie的生命周期呢？：Cookie可以保持登录信息到用户下次与服务器的会话，换句话说，下次访问同一网站时，用户会发现不必输入用户名和密码就已经登录了（当然，不排除用户手工删除Cookie）。而还有一些Cookie在用户退出会话的时候就被删除了，这样可以有效保护个人隐私。Cookie在生成时就会被指定一个Expire值，这就是Cookie的生存周期，在这个周期内Cookie有效，超出周期Cookie就会被清除。有些页面将Cookie的生存周期设置为“0”或负值，这样在关闭浏览器时，就马上清除Cookie，不会记录用户信息，更加安全。 建议开发人员在向客户端 Cookie 输出敏感的内容时（譬如：该内容能识别用户身份）： 设置该 Cookie 不能被脚本读取，这样在一定程度上解决上述问题。 对 Cookie 内容进行加密，在加密前嵌入时间戳，保证每次加密后的密文都不一样（并且可以防止消息重放）。 客户端请求时，每次或定时更新 Cookie 内容（即：基于第2小条，重新加密） 每次向 Cookie 写入时间戳，数据库需要记录最后一次时间戳（防止 Cookie 篡改，或重放攻击）。 客户端提交 Cookie 时，先解密然后校验时间戳，时间戳若小于数据数据库中记录，即意味发生攻击。 基于上述建议，即使 Cookie 被窃取，却因 Cookie 被随机更新，且内容无规律性，攻击者无法加以利用。另外利用了时间戳另一大好处就是防止 Cookie 篡改或重放。 什么是session？ session就是会话。这个就类似于你和一个人交谈，你怎么知道当前和你交谈的是张三而不是李四呢？对方肯定有某种特征（长相等）表明他就是张三。 session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识sessionID”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识sessionID”，服务器就知道这个请求来自于谁了。至于客户端怎么保存这个“身份标识sessionID”，可以有很多种方式，对于浏览器客户端，大家都默认采用 cookie 的方式。 服务器使用session把用户的信息临时保存在了服务器上，用户离开网站后session会被销毁。这种用户信息存储方式相对cookie来说更安全，可是session有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。 JSP使用一个叫HttpSession的对象实现同样的功能。HTTPSession 是一个建立在cookies 和URL-rewriting上的高质量的界面。Session的信息保存在服务器端，Session的id保存在客户机的cookie中。事实上，在许多服务器上，如果浏览器支持的话它们就使用cookies，但是如果不支持或废除了的话就自动转化为URL-rewriting，session自动为每个流程提供了方便地存储信息的方法。 什么是Token？ Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。 使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。流程是这样的： 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>SSO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Annotation]]></title>
    <url>%2F2018%2F08%2F12%2FJava%20Annotation%2F</url>
    <content type="text"><![CDATA[Annotation 基本语法 编写注解处理器 使用apt处理注解 基于观察者模式的apt 基本语法内置 注解 @Override：当前方法覆盖超类方法 @Deprecated：表示不应该再使用的方法，使用会发出警告信息 @SuppressWarnings：关闭不当的编译器警告信息 all 关闭所有警告 boxing 关闭装箱拆箱警告 cast 关闭类型转换警告 dep-ann 关闭弃用注解警告 deprecation 关闭弃用警告 fallthrough 关闭switch中缺失breaks的警告 finally 关闭finally中不能正常返回的警告 hiding to suppress warnings relative to locals that hide variable incomplete-switch to suppress warnings relative to missing entries in a switch statement (enum case) nls to suppress warnings relative to non-nls string literals null to suppress warnings relative to null analysis rawtypes to suppress warnings relative to un-specific types when using generics on class params restriction to suppress warnings relative to usage of discouraged or forbidden references serial to suppress warnings relative to missing serialVersionUID field for a serializable class static-access o suppress warnings relative to incorrect static access synthetic-access to suppress warnings relative to unoptimized access from inner classes unchecked to suppress warnings relative to unchecked operations unqualified-field-access to suppress warnings relative to field access unqualified unused to suppress warnings relative to unused code 注解定义 @Target(ElementType.METHOD)：注解可用位置 CONSTRUCTOR：构造器 FIELD：域（属性） LOCAL_VARIABLE：局部变量 METHOD：方法 PACKAGE：包 PARAMETER：参数 TYPE：类，接口，注解，enum @Retention(RetentionPolicy.RUNTIME)：注解保留级别 SOURCE：注解在原文件中可用，会被编译器丢失 CLASS：注解在class文件中可用，会被VM丢失 RUNTIME：VM将在运行期也保留注解，可通过反射机制读取 @Documented：将此注解包含在javadoc中 @Inherited：允许子类继承父类的注解 注解元素 类似方法定义 可用类型：所有基本类型，String，Class，enum，annotation，以上类型数组 元素值必须确定，要么默认值，要么提供值 自定义默认值负数或者空字符串以表示某个不存在的元素 注解不支持继承 每一个自定义的注解都需要自己的处理器代码样例123456789/** 代码样例 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface MyAnnotation &#123; int id() default -1; String description() default &quot;annotation&quot;;&#125; 编写注解处理器基于反射的运行时注解处理器 由于反射提供了对注解的相关操作，所以我们可以通过反射遍历所有的类文件来判定哪些类文件标注了具体哪些注解，然后根据实际情况做相应的决策，最简单粗暴的注解处理器由此而来。 12345678910111213public class MyReflection &#123; public static void main(String [] args)throws Exception&#123; Class clazz = Class.forName(&quot;dcits.liufein.springboot.java.simple.MyService&quot;); MyService myService = (MyService) clazz.newInstance(); for (Method method : clazz.getMethods())&#123; MyAnnotation annotation = method.getAnnotation(MyAnnotation.class); if(annotation!=null)&#123; System.out.println(annotation.id() + &quot;---&quot; + annotation.description()); method.invoke(myService,null); &#125; &#125; &#125;&#125; ### 使用apt处理注解（编译时注解处理器） apt设计为操作java源文件，而不是编译后的文件，默认apt会在处理完成源文件后同一编译；实际上，apt还会检测有没有新的源文件生成（由注解处理器生成），经过一轮又一轮的检测，知道没有新的源文件生成，然后同一编译。 通过AnnotationProcessorFactory，apt能够为每一个发现的注解生成一个正确的处理器 apt生成注解处理器时，我们无法使用java的反射机制，因为我们操作的是源代码，而不是编译后的类文件 mirror API能够在未编译的源代码中查看方法，域，以及类型 apt-mirror-api-0.1.jar 基于观察者模式的apt扩展 Generating Your Own Metadata by Using the Annotation Processor https://docs.spring.io/spring-boot/docs/2.1.4.RELEASE/reference/html/configuration-metadata.html#configuration-metadata-annotation-processor]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql DROP DATABASE Syntax]]></title>
    <url>%2F2018%2F08%2F05%2FMySql%20DROP%20DATABASE%20Syntax%2F</url>
    <content type="text"><![CDATA[MySql DROP DATABASE Syntax DROP DATABASE Syntax TRUNCATE TABLE Syntax DDL/DML/DCL/TCL DROP DATABASE Syntax https://dev.mysql.com/doc/refman/8.0/en/drop-database.html DROP {DATABASE | SCHEMA} [IF EXISTS] db_name 当数据库drop掉的时候，其库的权限不会自动删除，需要手动drop删除 If you use DROP DATABASE on a symbolically linked database, both the link and the original database are deleted.使用drop的时候，如果该库含有同步连接数据库，即存在主从关系（集群），连接库以及原始库都将删除 drop命令执行返回的是所删除的表的总数 drop命令删除库的相关文件和文件夹，其中包括（.BAK.DAT.HSH.MRG.MYD.MYI.cfg.db.ibd.ndb），如果出了这些文件还有其他文件存在，执行drop命令后数据库文件夹不能被删除，除非手动删除文件夹内文件后才能删除 drop命令不会删除临时表，临时表在session连接结束后自动删除 TRUNCATE TABLE SyntaxTRUNCATE [TABLE] tbl_name 该命令等同于delete所有行数据，等同于drop table + create table 跳过DML方法，不会触发在delete上的触发器 Innodb存储引擎下的表如果存在外键关系，则无法执行，且不能信箱DML 操作那样执行回退 truncate使用原子DDL支持存储引擎实现全部成功提交或者失败全部回滚 不同于delete 速度比delete快，尤其体现在海量数据 不可回退 当连接持有活动状态的表锁时不能执行 innodb下有外键时不能执行 不返回有意义的值 只要表结构定义正确，即使数据文件或者索引文件损坏，truncate操作完成后也能创建空表 自增值重置为原始值， MyISAM and InnoDB均是 不会触发delete触发器 支持操作损坏的innodb 表 与分区表一起使用时，TRUNCATE TABLE保留分区; 也就是说，数据和索引文件被删除并重新创建，而分区定义不受影响。 DDL/DML/DCL/TCLDDL(Data Definition Language) 数据定义语言, 用于定义/修改/删除数据对象(如表)的数据结构。DDL语言操作的对象是数据库中的对象而非对象所包含的数据。 DDL用于操作对象和对象的属性，这种对象包括数据库本身，以及数据库对象，像：表、视图等等，DDL对这些对象和属性的管理和定义具体表现在Create、Drop和Alter上。特别注意：DDL操作的“对象”的概念，”对象“包括对象及对象的属性，而且对象最小也比记录大个层次。以表举例：Create创建数据表，Alter可以更改该表的字段，Drop可以删除这个表。 DDL包含以下语句： CREATE : 在数据库中创建新的数据对象 ALTER : 修改数据库中对象的数据结构 DROP : 删除数据库中的对象（可以删除数据表、索引、触发程序、条件约束以及数据表的权限等） DISABLE/ENABLE TRIGGER : 修改触发器的状态 UPDATE STATISTIC : 更新表/视图统计信息 TRUNCATE TABLE : 清空表中数据 COMMENT : 给数据对象添加注释 RENAME : 更改数据对象名称 唯一需要注意的是TRUNCATE，尽管从功能上看相当于DELETE表中所有数据，但由于它所操作的对象是table这个级别而非row（如由于某种原因不能立即删除表数据时，TRUNCATE会锁定整张表，而DELETE锁定的则是row)，所以归在DDL中。 DML(Data Manipulation Language) 数据操作语言，用于添加/修改/查询数据库中数据。 DML用于操作数据库对象中包含的数据，也就是说操作的单位是记录。 DML包含以下语句： - INSERT ：将数据插入到表或视图 DELETE ：从表或视图删除数据 SELECT ：从表或视图中获取数据 UPDATE ：更新表或视图中的数据 MERGE ： 对数据进行合并操作(插入/更新/删除) DCL(Data Control Language) DCL用来向用户赋予/取消对数据对象的控制权限。 DCL包含以下语句： GRANT : 赋予用户某种控制权限 REVOKE ：取消用户某种控制权限 TCL(Transaction Control Language) 事务控制语句，用来对事务进行管理。 TCL包含以下语句： COMMIT : 保存已完成事务动作结果 SAVEPOINT : 保存事务相关数据和状态用以可能的回滚操作 ROLLBACK : 恢复事务相关数据至上一次COMMIT操作之后 SET TRANSACTION : 设置事务选项 DQL]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>DROP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Distributed Tracing Design and Architecture]]></title>
    <url>%2F2018%2F07%2F29%2F%E8%B0%83%E7%94%A8%E9%93%BE%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[调用链实现原理 调用链的产生 调用链跟踪原理 调用链系统设计与实现 调用链的产生 简单来说：微服务架构中系统众多，系统间的交互复杂，调用关系错综复杂，导致在特殊情况下难以快速定位和解决问题，因此，调用链应用而生。 举个简单的例子：客户反馈问题，开发和运维人员从服务A开始查起，确定服务A没有问题，然后将问题传递到服务B中开始排查，确认服务B没有问题后，又将问题传到服务C排查…以此类推，知道排查出问题所在。如果问题出在A服务，我们可以很快的定位到问题并解决问题，但是如果问题在最后一个被调用的服务，那么我们需要将之前所有的服务全部排查一遍才能定位到问题，不仅浪费时间，而且做了很多的无用功。倘若有了调用链，我们可以直接定位到问题所在的服务，节省时间又避免无用功的发生。 调用链跟踪原理每一个微服务架构系统即使再复杂都会有一个入口，而这个入口我们可以将其看作一棵树的树根root，之后所发生的所有调用关系我们可以看作是由树根衍生出来的树干与树枝，这样所有的系统调用关系就被抽象成了一颗复杂的树，而基于树 的特性，我们可以沿着某一分叉找到一条完整的调用关系，因此我们可以给每个不同的分叉定义不用的唯一标识来区分不同的调用链，这样每一条的完整的调用链关系就被我们抽象了出来，但是调用链内的各个服务调用顺序还没有明确，虽然有些服务的调用顺序并不会对最终结果造成影响，但是有些却会产生对系统致命的影响，所以我们再次利用树的层次特性来给同一分支中不同节点定义先后顺序。这样，复杂的微服务系统之间的调用关系就变得一目了然。 谷歌dapper为例：采用http协议头携带标记信息（信息包含调用链唯一流水id=traceID（用于找寻所有属于同一请求的调用点放入同一集合中），调用层次spanID，调用顺序parentSpanID（用于将处在同一调用链中的不同点分层和记录调用顺序）；最后形成完整的树形调用链供可视化，同时便于记录出错节点和各个节点详细信息） spanID=64位整型值：产生策略 随机数[-2^63,2^63-1] 分布式全局唯一流水号（发号器） spanID携带所有父类节点时会携带太多的冗余信息 调用链系统设计与实现调用链系统的构成 采集器：从业务系统中将远程服务的调用信息收集并发送给处理器 处理器；接受从采集器传递过来的服务调用信息并聚合调用链，将其存储到分布式数据存储中，以及对调用链进行分析输出给监控和报警系统。 分布式存储系统：存储海量的调用链数据，并支持灵活的查询和搜索的功能。 调用链展示系统：查询展示调用链信息 traceID，spanID的传递： java应用内：本地线程传递 服务间：通信协议中传递，restful风格使用http头传递，rpc使用序列化协议上增加定制化字段 主子线程，非核心链路异步处理，创建子线程时，traceID和spanID一同传递下去 消息队列传递：调用链跟踪失效，采用更改队列底层协议或者业务侵入手动增加字段实现 缓存数据库：将调用链traceID和spanID与访问数据关联 调用链信息的采集（将traceID，spanID等信息传到采集器处理）： 侵入业务代码，代码中编写（不推荐） AOP推送，同样侵入了业务代码，但是AOP可独立开发 javaAgent字节码增强（虚拟机级别支持的AOP实现方式） 调用信息随日志推送到日志中心然后再处理 采集器数据的推送 采集器收集的数据必须从业务系统中推送到调用链的处理器上，并且推送过程中必须保证不能影响业务系统的正常运行，及绝对不能直接使用业务线程来发送调用信息，一般采用异步线程池发送，同时异步线程池与处理器之间必须采用有界队列做缓冲，避免出现数据积压后导致应用内存耗光的情况。 kafka消息队列（处于采集器和处理器中间，面对大流量高峰采集信息起到消峰作用） UDP推送：无连接传输层协议，效率比tcp或之上的协议高得多 不同的调用链组成业务链（多个请求建立连接（例如，下单，支付，退款），多个树形调用链组成森林业务链）]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed Tracing</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Commands]]></title>
    <url>%2F2018%2F07%2F22%2FRedis%20Commands%2F</url>
    <content type="text"><![CDATA[Redis Commands APPEND key value：若key存在，在其value（必须为string类型）后面追加字符串 AUTH password：服务器访问权限设置，在配置文件redis.conf中配置requirepass 字段的值即可实现服务器的加密操作，客户端需使用命令auth password来获取权限才能执行命令 BGREWRITEAOF BGSAVE BITCOUNT key [start end]：计算key中位为1的数量 * BITFIELD：* BITOP：按位操作，与，或，异或，非 BITOP AND destkey srckey1 srckey2 srckey3 … srckeyN BITOP OR destkey srckey1 srckey2 srckey3 … srckeyN BITOP XOR destkey srckey1 srckey2 srckey3 … srckeyN BITOP NOT destkey srckey BITPOS key bit [start] [end]：返回key中第一位为1或者0的位置（可自定义范围） BLPOP key [key …] timeout：返回非空list（key）的第一个元素 BRPOP key [key …] timeout：返回非空list（key）的最后一个元素 BRPOPLPUSH source destination timeout：source非空时，等效于命令RPOPLPUSH source destination，source为空时，阻断连接至超时 RPOPLPUSH source destination：将source的最后一个元素移除放置到destination的第一元素位置 BZPOPMIN key [key …] timeout：从第一个非空排序sets（key）中返回并移除最小值 BZPOPMAX key [key …] timeout：从第一个非空排序sets（key）中返回并移除最大值 CLIENT ID：返回当前客户端id CLIENT KILL [ip:port] [ID client-id] [TYPE normal|master|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]：关闭指定客户端连接 CLIENT LIST [TYPE normal|master|replica|pubsub]：获取客户端连接列表 CLIENT GETNAME：获取当前连接名 CLIENT PAUSE timeout：暂停客户端一段时间 CLIENT REPLY ON|OFF|SKIP：设置服务器对客户端的响应 CLIENT SETNAME connection-name：设置当前连接的客户端名称 CLIENT UNBLOCK client-id [TIMEOUT|ERROR]： CLUSTER ADDSLOTS slot [slot …]：集群模式下，将slot槽位分配给客户端节点 CLUSTER COUNT-FAILURE-REPORTS node-id：统计集群中，节点失败报告的次数，用来判定该节点是否不可达 CLUSTER COUNTKEYSINSLOT slot：统计某一槽位slot中key的数量 CLUSTER DELSLOTS slot [slot …]：删除集群中节点对应服务器的槽位 CLUSTER FAILOVER [FORCE|TAKEOVER]：该命令只能发送给集群中的复制节点来手动故障转移moster主节点 CLUSTER FORGET node-id：从集群节点表中移除该节点，即将该节点从集群中踢出去，由于集群中所有节点都能感知到其他节点的存在，所以想要完全从集群中移除，需要给所有的已存在节点发送该命令 CLUSTER GETKEYSINSLOT slot count：获取指定槽位slot中指定数量count的key值数组集合 CLUSTER INFO：集群节点信息 CLUSTER KEYSLOT key：获取key所在的槽位slot CLUSTER MEET ip port：强制与其他节点连接交互 CLUSTER NODES：获取集群节点配置 CLUSTER REPLICATE node-id：重新配置一个节点作为moster的复制节点 CLUSTER RESET [HARD|SOFT]：重置集群节点，Note that this command does not work for masters if they hold one or more keys CLUSTER SAVECONFIG：强制节点保存节点配置到本地磁盘 CLUSTER SET-CONFIG-EPOCH config-epoch： CLUSTER SETSLOT slot IMPORTING|MIGRATING|STABLE|NODE [node-id]： MIGRATING subcommand: Set a hash slot in migrating state. IMPORTING subcommand: Set a hash slot in importing state. STABLE subcommand: Clear any importing / migrating state from hash slot. NODE subcommand: Bind the hash slot to a different node. CLUSTER SLAVES node-id：列出moster节点的复本节点 CLUSTER REPLICAS node-id：列出moster节点的复本节点 CLUSTER SLOTS：返回集群槽位与redis实例匹配的详细信息 COMMAND：获取命令细节 COMMAND COUNT：统计命令总数 COMMAND GETKEYS：获取命令中的key数组 COMMAND INFO command-name [command-name …]：命令的具体信息 CONFIG GET parameter：获取配置参数的值 CONFIG REWRITE：重新写配置文件 CONFIG SET parameter value：设置配置参数为value CONFIG RESETSTAT：重置配置文件信息 DBSIZE：返回当前所选数据库中key的数量 DEBUG OBJECT key：获取key的debug信息 DEBUG SEGFAULT：让服务器崩溃 DECR key：key的值减一 DECRBY key decrement：key值减少指定值 DEL key [key …]：删除key（可多个） DISCARD：刷新事务中所有先前排队的命令，并将连接状态恢复为正常。 DUMP key：序列化key中的value值以redis特定格式，并将其返回 ECHO message：输出所给的字符串 EVAL script numkeys key [key …] arg [arg …]： EVALSHA sha1 numkeys key [key …] arg [arg …]： EXEC：执行事务中所有先前排队的命令，并将连接状态恢复为正常。 EXISTS key [key …]：判定key是否存在 EXPIRE key seconds：设置key的生存周期 EXPIREAT key timestamp：设置key的生存周期（timestamp表示以unix时间为基准，1970.01.01） FLUSHALL [ASYNC]：移除所有数据库中所有key FLUSHDB [ASYNC]：移除当前数据库中所有key GEOADD key longitude latitude member [longitude latitude member …]： GEOHASH key member [member …]： 。。。 GET key：获取key值 GETBIT key offset：返回偏移后的位值 GETRANGE key start end：获取字串 GETSET key value：设置新值，返回旧值 HDEL key field [field …]：从key中存储的哈希中删除指定的字段 HEXISTS key field：判定key中存储的哈希中是否存在指定的字段 HGET key field：从key中存储的哈希中获取指定的字段 HGETALL key：获取key存储哈希中所有的字段值 HINCRBY key field increment：将key存储的哈希值中给定字段增加给定的数值（integer） HINCRBYFLOAT key field increment：将key存储的哈希值中给定字段增加给定的数值（float） HKEYS key：返回key中存储的哈希值中所有字段的值 HLEN key：获取key中存储的哈希值中的字段数量 HMGET key field [field …]：从key中存储的哈希中获取指定的字段的值 HMSET key field value [field value …]：从key中存储的哈希中设定多个指定的字段以指定的值 HSET key field value：从key中存储的哈希中设定指定的字段以指定的值 HSETNX key field value：从key中存储的哈希中设定指定的字段以指定的值（当且仅当field不存在是成立，否则，不做任何操作） HSTRLEN key field：获取key中存储的哈希中设定指定字段值的长度 HVALS key：获取key中存储的哈希的所有值 INCR key：key值自增加一 INCRBY key increment：key值自增指定值 INCRBYFLOAT key increment：key值自增指定值（float） INFO [section]：获取服务器信息数据 KEYS pattern：找到所有的与所给pattern相匹配的key LASTSAVE：返回最后一次成功保存到磁盘的unix时间戳 LINDEX key index：获取list中第index个元素 LINSERT key BEFORE|AFTER pivot value：在list中某元素前或者后插入元素 LLEN key：获取list的长度 LPOP key：获取并移除list中第一个元素 LPUSH key value [value …]：在list头不插入多个元素 LPUSHX key value：list头中key元素存在时给key赋值value，否则不做任何操作 LRANGE key start stop：获取list中所给范围的值 LREM key count value： count &gt; 0: Remove elements equal to value moving from head to tail. count &lt; 0: Remove elements equal to value moving from tail to head. count = 0: Remove all elements equal to value. LSET key index value：给list中第index个key赋值为value LTRIM key start stop：给list中所给范围内的元素去空格trim操作 MEMORY DOCTOR：报告内存问题及意见 MEMORY HELP：返回描述不同子命令的帮助文档 MEMORY MALLOC-STATS：提供内存分配器的内部统计报告。 MEMORY PURGE：要求内存分配器释放空间 MEMORY STATS：显示内存使用详细内容 MEMORY USAGE key [SAMPLES count]：显示key的内存使用 MGET key [key …]：返回多个key的值 MIGRATE host port key|”” destination-db timeout [COPY] [REPLACE] [KEYS key [key …]]：redis实例之间的转换 MONITOR：实时监听服务器所有的请求 MOVE key db：移动key到另一个数据库 MSET key value [key value …]：设置多个key的值 MSETNX key value [key value …]：设置多个key的值，仅当所有的key都不存在时成立 MULTI：标记事务块的开始 OBJECT subcommand [arguments [arguments …]]： OBJECT REFCOUNT returns the number of references of the value associated with the ecified key. This command is mainly useful for debugging. OBJECT ENCODING returns the kind of internal representation used in order to store the value associated with a key. OBJECT IDLETIME returns the number of seconds since the object stored at the specified key is idle (not requested by read or write operations). While the value is returned in seconds the actual resolution of this timer is 10 seconds, but may vary in future implementations. This subcommand is available when maxmemory-policy is set to an LRU policy or noeviction. OBJECT FREQ returns the logarithmic access frequency counter of the object stored at the specified key. This subcommand is available when maxmemory-policy is set to an LFU policy. OBJECT HELP returns a succint help text. PERSIST key：去除key中含有的timeout设置 PEXPIRE key milliseconds：设置key的timeout，单位milliseconds而不是秒 PEXPIREAT key milliseconds-timestamp：设置key的timeout已unix时间为准，单位milliseconds PFADD key element [element …]：将所有元素参数element添加到存储在指定为第一个参数key的变量名称的HyperLogLog数据结构中。 PFCOUNT key [key …]： PFMERGE destkey sourcekey [sourcekey …]：合并多个hyberloglog为一个 PING [message]：ping通服务器 PSETEX key milliseconds value：设置key的value中和timeout PSUBSCRIBE pattern [pattern …]：监听发布到渠道的消息中与所给格式匹配的消息 PUBSUB subcommand [argument [argument …]]：检测pub、sub子系统的状态 PTTL key：获取key的timeout，单位milliseconds PUBLISH channel message：发布一个消息到渠道 PUNSUBSCRIBE [pattern [pattern …]]：停止监听发布到渠道的消息中与所给格式匹配的消息 QUIT：关闭连接 RANDOMKEY：从当前数据库中随机返回一个key READONLY：允许连接对集群复制节点进行读操作 READWRITE：禁止连接对集群子节点的读操作 RENAME key newkey：重命名key RENAMENX key newkey：重命名key，并且新名字不存在 RESTORE key ttl serialized-value [REPLACE]：创建一个key，其值为从提供的序列化的值 ROLE：返回当前实例的角色 RPOP key：返回并移除list的最后一个元素 RPOPLPUSH source destination：从source list移除最后一个元素放入destination list中，并返回改元素 RPUSH key value [value …]：在list末尾插入多个元素 RPUSHX key value：仅当list存在时，插入元素key SADD key member [member …]：添加一个元素到set中 SAVE：同步保存数据库到本地磁盘 SCARD key：获取set中元素的数量 SCRIPT DEBUG YES|SYNC|NO：对当前执行的脚本设置debug模式 SCRIPT EXISTS sha1 [sha1 …]：在脚本缓存中检测执行脚本的存在性 SCRIPT FLUSH：清空脚本缓存 SCRIPT KILL：停止当前执行的脚本 SCRIPT LOAD script：加载lua脚本到脚本缓存中 SDIFF key [key …]：返回第一个set中元素与其他所有set中的元素不相同的元素set集合 SDIFFSTORE destination key [key …]：将第一个set中元素与其他所有set中的元素不相同的元素放入目标destination key中 SELECT index：切换redis的逻辑数据库 SET key value [expiration EX seconds|PX milliseconds] [NX|XX]：设置key一个string类型的value值 SETBIT key offset value：设置key中所存储的值的特定偏移的位的值 SETEX key seconds value：设置一个key的value值和timeout（单位秒） SETNX key value：设置key的值，仅当key不存在的时候 SETRANGE key offset value：从给定的偏移出开始，覆盖key中的value值 SHUTDOWN [NOSAVE|SAVE]：同步保存数据库到本地磁盘然后停止服务 SINTER key [key …]：返回多个set中公共的元素集合 SINTERSTORE destination key [key …]：返回多个set中的公共元素到指定元素的destination中 SISMEMBER key member：如果member在key中，返回1，否则返回0； SLAVEOF host port： REPLICAOF host port： SLOWLOG subcommand [argument]：管理redis的慢查询日志，读取或者重置。 SMEMBERS key：返回set中所有的元素 SMOVE source destination member：将member从源set移动到目标set SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern …]] [ASC|DESC] [ALPHA] [STORE destination]：排序集合中的元素 SPOP key [count]：从set中随机返回并移除一个或者多个元素 SRANDMEMBER key [count]：获取set中的一个或多个随机元素 SREM key member [member …]：移除一个或多个set中的元素 STRLEN key：获取key中value值的长度 SUBSCRIBE channel [channel …]：监听发布到给定渠道的消息 SUNION key [key …]：合并多个set集合 SUNIONSTORE destination key [key …]：合并多个set集合到指定元素中 SWAPDB index index：交换两个数据库 TIME：返回服务器当前时间 TOUCH key [key …]：修改key的最后一次访问时间，返回修改key的个数 TTL key：获取key的timeout TYPE key：返回key的类型 UNSUBSCRIBE [channel [channel …]]：停止监听发布到给定渠道的消息 UNLINK key [key …]：用不同线程将key从keyspace移除，真正的删除操作最后同步 UNWATCH：清空所有的监听 WAIT numreplicas timeout：暂停当前客户端操作直到所有的写命令成功执行并且被特定数量的复制节点知道 WATCH key [key …]：设置监听 ZADD key [NX|XX] [CH] [INCR] score member [score member …]：添加一个或几个member到排序set中，若已存在key，则更新 ZCARD key：获取排序set中的元素数量 ZCOUNT key min max：统计排序set中key的值在min和max之间的key的数量 ZINCRBY key increment member：给排序set中的member元素的值增加increment ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]： ZLEXCOUNT key min max：当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序，此命令返回键中有序集合中元素的数量，其值介于min和max之间。 ZPOPMAX key [count]：返回并移除排序set中key的值最大的哪一个元素 ZPOPMIN key [count]：返回并移除排序set中key的值最小的哪一个元素 ZRANGE key start stop [WITHSCORES]：返回排序set中给定范围的元素 ZRANGEBYLEX key min max [LIMIT offset count]：返回排序set中给定范围的元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序） ZREVRANGEBYLEX key max min [LIMIT offset count]：返回排序set中给定范围的元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序）顺序从高到低 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]：返回排序set中给定key的score值范围的元素 ZRANK key member：返回排序set中给定元素的index ZREM key member [member …]：从排序set中删除一个或多个元素 ZREMRANGEBYLEX key min max：删除排序set中给定范围的所有元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序） ZREMRANGEBYRANK key start stop：根据index删除排序set中给定范围的元素 ZREMRANGEBYSCORE key min max：根据score值删除排序set中给定范围的元素 ZREVRANGE key start stop [WITHSCORES]：返回按照index给定范围的排序set中元素，score顺序由高到低 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]：返回按照score给定范围的排序set中元素，score顺序由高到低 ZREVRANK key member：返回排序set中按照score由高到低排好序后的给定的member的index ZSCORE key member：返回排序set中元素的score ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]：存储多个排序set到指定destination中 SCAN cursor [MATCH pattern] [COUNT count]：逐步迭代key space元素集合。 SSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代set元素集合。 HSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代hash filed和value。 ZSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代set元素和对应的score值。 XINFO [CONSUMERS key groupname] [GROUPS key] [STREAM key] [HELP]：检索有关流和关联的使用者组的不同信息 XADD key ID field string [field string …]：在已有的key实体流后衔接实体流，key不存在则创建一个新的 XTRIM key MAXLEN [~] count： XDEL key ID [ID …]：从流中删除指定的实体 XRANGE key start end [COUNT count]：返回流中给定范围的元素 XREVRANGE key end start [COUNT count]：返回流中给定范围的元素（逆序） XLEN key：返回流中实体的数量 XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]：从一个或多个流中读取数据，只返回ID大于调用者报告的最后一个接收ID的条目 XGROUP [CREATE key groupname id-or-$] [SETID key groupname id-or-$] [DESTROY key groupname] [DELCONSUMER key groupname consumername]：创建，销毁，管理使用者组 XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]： XACK key group ID [ID …]： XCLAIM key group consumer min-idle-time ID [ID …] [IDLE ms] [TIME ms-unix-time] [RETRYCOUNT count] [FORCE] [JUSTID]： XPENDING key group [start end count] [consumer]：]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式通信]]></title>
    <url>%2F2018%2F07%2F15%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[分布式通信所有的通信过程可以抽象为以下几步 服务端服务，并将其通过某个服务机的端口暴露出去供客户端调用。 客户端程序，客户端通过指定服务所在的主机和端口号、将请求封装并序列化，最终通过网络协议发送到服务端。 服务端解析和反序列化请求，调用服务端上的服务，将结果序列化并返回给客户端。 客户端接收并反序列化服务端返回的结果，反馈给用户。 机器通信，归根到底是网络的通信，网络通信需要做的就是将流从一台计算机传输到另外一台计算机，基于传输协议和网络IO来实现，其中传输协议比较出名的有http、tcp、udp等等，http、tcp、udp都是在基于Socket概念上为某类应用场景而扩展出的传输协议，网络IO，主要有bio、nio、aio三种方式，所有的分布式应用通讯都基于这个原理而实现，只是为了应用的易用性，各种语言通常都会提供一些更为贴近应用易用的应用层协议。 一台计算机发起请求，另外一台机器在接收到请求后进行相应的处理并将结果返回给请求端，将请求转换成流，通过传输协议传输至远端，远端计算机在接收到请求的流后进行处理，处理完毕后将结果转化为流，并通过传输协议返回给调用端。 Socket通信12345678910111213141516171819202122位于Java.net包中服务端：ServerSocket server = new ServerSocket(9091);Socket client = server.accept();BufferedReader input = new BufferedReader(new InputStreamReader(client.getInputStream()));String line = input.readLine();String returnMess = execute(line);PrintWriter output = new PrintWriter(client.getOutputStream(), true);output.println(returnMess);客户端：Socket client = new Socket("127.0.0.1", 9091);//通过ip:port与服务器建立连接PrintWriter output = new PrintWriter(client.getOutputStream(), true);//创建输出流，给服务器发送消息output.println(jsonString);output.flush();//刷新缓冲区client.shutdownOutput();//关闭输出流BufferedReader input = new BufferedReader(new InputStreamReader(client.getInputStream()));//创建输入流，接收服务器发送的消息String line = input.readLine();/*while(line!=null)&#123;System.out.println(line);line = input.readLine();&#125;*/client.close(); RPC（Remote Procedure Call Protocol） RPC是在Socket的基础上实现的。 RMI（底层实现还是socket） Stub和Skeleton：这两个的身份是一致的，都是作为代理的存在。客户端的称作Stub，服务端的称作Skeleton。要做到对程序员屏蔽远程方法调用的细节，这两个代理是必不可少的，包括网络连接等细节。 Registry：顾名思义，可以认为Registry是一个“注册所”，提供了服务名到服务的映射。如果没有它，意味着客户端需要记住每个服务所在的端口号，这种设计显然是不优雅的。 RMI 采用stubs 和 skeletons 来进行远程对象(remote object)的通讯。stub 充当远程对象的客户端代理，有着和远程对象相同的远程接口，远程对象的调用实际是通过调用该对象的客户端代理对象stub来完成的，通过该机制RMI就好比它是本地工作，采用tcp/ip协议，客户端直接调用服务端上的一些方法。优点是强类型，编译期可检查错误，缺点是只能基于JAVA语言，客户机与服务器紧耦合； 1234567891011121314151617181920创建远程接口-直接或间接继承java.rmi.Remote接口；-接口中的所有方法声明抛出java.rmi.RemoteException异常或父异常。创建远程实现类，实现远程接口；-继承java.rmi.server.UnicastRemoteObject类，构造器必须抛出java.rmi.RemoteException异常。-或者使用UnicastRemoteObject.exportObject(this/实现类对象实例, 0);创建服务器程序，在rmiregistry注册表中注册远程对象；LocateRegistry.createRegistry(1099);//定义暴露服务接口HelloService service = new HelloServiceImpl("service");//实例化服务实现类Naming.bind("rmi://localhost:1099/HelloService", service);//绑定实现类在服务器上对应的接口-bind(String name, Object obj): 注册对象，把对象与服务名绑定。如果该服务名已与其他对象绑定，则会抛出NameAlreadyBoundException异常。-rebind(String name, Object obj): 注册对象，把对象与服务名绑定。如果该服务名已与其他对象绑定，不会抛异常，而是将新的对象绑定到该服务名上。-lookup(String name): 查找对象，返回与指定名称相同的对象。创建客户端程序，负责定位远程对象，并且调用远程方法。HelloService serv = (HelloService) Naming.lookup(url + "HelloService1");//定位远程服务serv.service(“Hello ”);//调用远程服务客户端和服务端通过Stub和Skeleton建立了socket连接，后面的操作直接通过这个连接完成就结了！ WebService Web Service提供的服务是基于web容器的，底层使用http协议，类似一个远程的服务提供者，就是通过一个servlet，提供服务出去。首先客户端从服务器的到WebService的WSDL，同时在客户端声称一个代理类(Proxy Class) 这个代理类负责与WebService服务器进行Request 和Response 当一个数据（XML格式的）被封装成SOAP格式的数据流发送到服务器端的时候，就会生成一个进程对象并且把接收到这个Request的SOAP包进行解析，然后对事物进行处理，处理结束以后再对这个计算结果进行SOAP包装，然后把这个包作为一个Response发送给客户端的代理类(Proxy Class)，同样地，这个代理类也对这个SOAP包进行解析处理，继而进行后续操作。这就是WebService的一个运行过程。Web Service大体上分为5个层次: Http传输信道 XML的数据格式 SOAP封装格式 WSDL的描述方式 UDDI UDDI是一种目录服务，企业可以使用它对Webservices进行注册和搜索 JMS（Java Messaging Service） Java消息服务是一个与具体平台无关的API（activeMQ是jms的其中一种开源实现类），绝大多数MOM提供商都对JMS提供支持。JMS是Java的消息服务，JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS支持两种消息模型：Point-to-Point（P2P）和Publish/Subscribe（Pub/Sub），即点对点和发布订阅模型。优点：支持异步通信、消息produce和recept松耦合。在JMS编程模型中，JMS客户端使用connectionFactory对象创建一个连接，向消息服务发送消息以及从消息服务接收消息均是通过此连接来进行。Connection是客户端与消息服务的活动连接，创建连接时将分配通信资源以及验证客户端。大多数客户端均使用一个连接来进行所有的消息发送。连接用于创建会话，Session是一个用于生成和使用消息的单线程上下文。它用于创建发送的生产者和接收消息的消费者，并为所发送的消息定义发送顺序，会话通过大量确认选项或通过事务来支持可靠发送。客户端使用 MessageProducer 向指定的物理目标（在 API 中表示为目标身份对象）发送消息。生产者可指定一个默认传送模式（持久性消息与非持久性消息）、优先级和有效期值，以控制生产者向物理目标发送的所有消息。 同样，客户端使用 MessageConsumer 对象从指定的物理目标（在 API 中表示为目标对象）接收消息。消费者可使用消息选择器，借助它，消息服务可以只向消费者发送与选择标准匹配的那些消息。消费者可以支持同步或异步消息接收。异步使用可通过向消费者注册 MessageListener 来实现。当会话线程调用 MessageListener 对象的 onMessage 方法时，客户端将使用消息。 RPC与RMI （1）RPC 跨语言，而 RMI只支持Java。（2）RMI 调用远程对象方法，允许方法返回 Java 对象以及基本数据类型，而RPC 不支持对象的概念，传送到 RPC服务的消息由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。只有由 XDR 定义的数据类型才能被传递， 可以说 RMI 是面向对象方式的 Java RPC 。（3）在方法调用上，RMI中，远程接口使每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口上，那么这个新方法就不能被RMI客户方所调用。在RPC中，当一个请求到达RPC服务器时，这个请求就包含了一个参数集和一个文本值，通常形成“classname.methodname”的形式。这就向RPC服务器表明，被请求的方法在为 “classname”的类中，名叫“methodname”。然后RPC服务器就去搜索与之相匹配的类和方法，并把它作为那种方法参数类型的输入。这里的参数类型是与RPC请求中的类型是匹配的。一旦匹配成功，这个方法就被调用了，其结果被编码后返回客户方。 JMS与RMI JMS 服务，对象是在物理上被异步从网络的某个JVM 上直接移动到另一个JVM 上（是消息通知机制）而RMI 对象是绑定在本地JVM 中，只有函数参数和返回值是通过网络传送的（是请求应答机制）。RMI一般都是同步的，也就是说，当client调用Server的一个方法的时候，需要等到对方的返回，才能继续执行client端，这个过程调用本地方法感觉上是一样的，这也是RMI的一个特点。JMS 一般只是一个点发出一个Message到Message Server,发出之后一般不会关心谁用了这个message。所以，一般RMI的应用是紧耦合，JMS的应用相对来说是松散耦合应用。 JNDI（Java naming and Directory Interface） Java命名与目录接口，包含两个服务，命名服务奖名称和对象联系起来，使得我们可以用名称访问对象，目录服务是一种命名服务，在这种服务里，对象不但有名称，还有属性。使用JNDI，一个J2EE应用程序可以存储和动态获取任何类型的命名Java对象。因为JNDI不依赖于任何特定的执行，应用程序可以使用JNDI访问各种命名目录服务，包括现有的诸如LDAP、NDS、DNS、NIS、COS命名和RMI注册等服务。这使得J2EE应用程序可以和传统的应用程序和系统共存。从JNDI的架构中可以看出，JNDI分为三部分，应用程序编程接口（API）和服务供应商接口（SPI），前者Java应用程序访问各种命名和目录服务，开发上层应用的程序员就不必去关心底层具体的技术细节，后者则是设计来供任意一种服务的供应商（也包括目录服务供应商）使用，这一层一般由供应商去完成。]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>JMS</tag>
        <tag>RMI</tag>
        <tag>Socket</tag>
        <tag>RPC</tag>
        <tag>WebService</tag>
        <tag>EJB</tag>
        <tag>JNDI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper]]></title>
    <url>%2F2018%2F07%2F08%2FZookeeper%2F</url>
    <content type="text"><![CDATA[Zookeeper What is Zookeeper ? Why use Zookeeper ? Theory Leader Election Endurance Deploy How to use ? Command Line API Curator What is Zookeeper ? ZK被多数人认为是一个注册中心，在分布式架构中像服务提供者和服务消费者之间的一个枢纽站，服务提供者将服务注册在注册中心以供服务消费者来获取消费，支持一对一，一对多，多对一，多对多等模式，其原理简单来讲，就是服务提供者在注册中心注册自己的服务地址，并通过一定端口将自己的服务暴露出去，消费者想要使用提供者所提供的服务时，首先需要去注册中心匹配相应的服务以获取该具体服务提供的地址，然后才能去访问该服务提供者以消费该服务，多对多模式中，如果同一时间消费者大量的涌入注册中心去访问同一服务，ZK还具有负载均衡的作用来有效的分配大量的请求流量。 Why use Zookeeper ? 问：为什么不直接用消费者去调用服务提供者，加一层类似中间件的注册中心有什么好处，有哪些实际应用场景，即ZK存在的理由 ? 答：首先明确一点，就是所有的中间件的诞生都是基于将某些公共的，重复的内容抽取出来简化过程，ZK的诞生同样也不例外。 集群的管理：所谓集群管理，无外乎两点，是否有机器加入和退出，选举master，ZK的leader选举规则（此处为超链接）。 公共配置的管理：分布式环境或者是集群环境中，将同一个应用系统部署到多台服务器上，或者一个应用系统需要多台服务器一起运行是非常常见的情况，那么一定会存在大量的配置是公共的，重复性的存在于多台服务器上，一旦配置发生变动，那配置的更改将变得非常繁琐，并且容易出现错误，这时我们就想要将所有的公共的配置全部都提取出来共同维护，ZK将所有的公共配置全部注册到它的服务器上，并且让所有用到该配置的其他服务启用监听，每当ZK服务器上的配置发生变动时，所有监听的服务就会收到ZK的通知，然后监听服务只需要从ZK服务器更新配置文件即可，免去了人工手动更改大量重复配置文件的繁琐操作，同时也降低了错误发生的概率。 共享锁/分布式锁：锁服务可以分为两类，一种是独占锁，一种是时序锁。 在同一个进程中锁往往很容易实现，但是在跨进程和跨服务之间就不容易实现了，因为感知其他进程和服务的锁的使用情况变得复杂，但是Zookeeper 却很容易实现这个功能，因为它可以将各个进程或者服务对锁的使用情况再次变得简单起来 利用节点名称唯一性来实现 思路: 利用名称唯一性，加锁操作时，只需要所有客户端一起创建/test/Lock节点，只有一个创建成功，成功者获得锁。解锁时，只需删除/test/Lock节点，其余客户端再次进入竞争创建节点，直到所有客户端都获得锁。 缺点：会产生“惊群”效应，假如许多客户端在等待一把锁，当锁释放时候所有客户端都被唤醒，仅仅有一个客户端得到锁。 利用临时顺序节点来实现 Zookeeper中有一种节点叫做顺序节点ZooKeeper中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZooKeeper集群断开连接，则该节点自动被删除。 客户端调用create()方法创建名为“locknode/guid-lock-”的节点，需要注意的是，这里节点的创建类型需要设置为EPHEMERAL_SEQUENTIAL。 客户端调用getChildren(“locknode”)方法来获取所有已经创建的子节点，同时在这个节点上注册上子节点变更通知的Watcher。客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。 如果在步骤3中发现自己并非是所有子节点中最小的，说明自己还没有获取到锁，就开始等待，直到下次子节点变更通知的时候，再进行子节点的获取，判断是否获取锁。 临时顺序节点改进 方法2的缺点：客户端接受到过多的和自己不相关的事件通知，这如果在集群规模大的时候，会对Server造成很大的性能影响，并且如果一旦同一时间有多个节点的客户端断开连接，这个时候，服务器就会像其余客户端发送大量的事件通知——这就是所谓的惊群效应。 改进：由原来的监视所有节点变成监视一个节点。 思路：对于加锁操作，可以让所有客户端都去/lock目录下创建临时顺序节点，如果创建的客户端发现自身创建节点序列号是/lock/目录下最小的节点，则获得锁。否则，监视比自己创建节点的序列号小的节点（比自己创建的节点小的最大节点），进入等待。 释放锁很简单，只要删除前面它自己所创建的目录节点就行了。 Theory ZK中的角色定义： server角色 Leader：负责投票的发起和决议，更新系统状态 Flower：接收客户请求并返回结果，在选主过程过程中参与投票 Observe：接收客户端请求，转发给leader，且不参与选主过程，只是同步leader状态。其存在目的是为了扩展系统，提高读取速度。 Client角色 Client：发送请求 工作原理： 我们知道各服务是通过启用监听来保持和ZK服务器上公共配置的一致性，但是ZK内部自己是如何保持在集群状态下的各个leader和flower之间的同步以及leader的产生，即选主。 对应着ZK中两种模式来分别实现，恢复模式：即在集群平衡状态被打破后需要重新选举产生leader并完成选举后的同步；广播模式：即集群在平衡状态下leader与各flower之间的同步。 为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增。 ZXID=32(高位epoch，leader编号)+32（低位proposal事务编号） 这里的事务主要指的是写请求，因为读请求不会导致节点数据更新，即不会引发同步操作，只有当遇到写请求时才会导致同步发生，并且，flower只有处理读请求的权限，当遇到写请求时，flower会将请求转发给leader来处理，然后由leader来发起同步操作更新集群状态。 消息广播 集群正常运转情况下：消息广播协议，当flower接受到数据改动请求，及写请求后，会将其转发给leader，然后leader将其请求以事务 的形式广播发给所有的flower，flower收到后以事务日志的形式存入本地磁盘，成功写入后然后回传给leader一个ack消息，leader收到ack响应后并且响应数量超过半数服务器数量后，便继续广播一个commit提交事务给所有的flower，flower收到后开始提交事务，同时leader也开始提交事务，以此达到数据同步的效果。 崩溃恢复 Leader宕机之后如何恢复并选举出新的leader：首先，leader宕机后或者TCP连接中断后，所有的flower和leader均变成looking状态，即选举leader状态。 从所有的flower中选出ZXID最大的作为新leader，因为新leader上任后需要应对缺失事务proposal补充和多余事务的丢弃，而由于ZXID 为一个全局的唯一ID，ZXID 最大意味着最高事务编号，也就意味着其包含了所有的成功已提交事务，省去了检查事务提交和缺失丢弃的步骤。 Leader选举后的数据同步和数据丢弃 数据同步：leader将那些flower没有的事务proposal通过队列下发给所有的flower，flower将其同步到本地数据库中，成功后leader将其列入可用flower列表中。 数据丢弃：leader根据自己的proposal和flower和proposal比较，结果必然是flower进行回退，丢弃自己的proposal，回退到一个集群中过半数flower提交的最新的事务proposal。 Leader Election 首先明确zookeeper选举规则的先决条件; 可用节点数量 &gt; 总节点数量/2 。注意 是 &gt; , 不是 ≥。 注：为什么规则要求 可用节点数量 &gt; 集群总结点数量/2 ？（为什么集群数量一般为奇数） 如果不这样限制，在集群出现脑裂的时候，可能会出现多个子集群同时服务的情况（即子集群各组选举出自己的leader）， 这样对整个zookeeper集群来说是紊乱的。 换句话说，如果遵守上述规则进行选举，即使出现脑裂，集群最多也只能回出现一个子集群可以提供服务的情况（能满足节点数量&gt; 总结点数量/2 的子集群最多只会有一个）。所以要限制 可用节点数量 &gt; 集群总结点数量/2 。 什么是脑裂？集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，小集群各自选出自己的master节点，导致原有的集群出现多个master节点的情况，这就是脑裂。 官方文档地址：https://zookeeper.apache.org/doc/current/recipes.html 内容如下： Leader ElectionA simple way of doing leader election with ZooKeeper is to use the SEQUENCE|EPHEMERAL flags when creating znodes that represent “proposals” of clients. The idea is to have a znode, say “/election”, such that each znode creates a child znode “/election/n“ with both flags SEQUENCE|EPHEMERAL. With the sequence flag, ZooKeeper automatically appends a sequence number that is greater that any one previously appended to a child of “/election”. The process that created the znode with the smallest appended sequence number is the leader.That’s not all, though. It is important to watch for failures of the leader, so that a new client arises as the new leader in the case the current leader fails. A trivial solution is to have all application processes watching upon the current smallest znode, and checking if they are the new leader when the smallest znode goes away (note that the smallest znode will go away if the leader fails because the node is ephemeral). But this causes a herd effect: upon of failure of the current leader, all other processes receive a notification, and execute getChildren on “/election” to obtain the current list of children of “/election”. If the number of clients is large, it causes a spike on the number of operations that ZooKeeper servers have to process. To avoid the herd effect, it is sufficient to watch for the next znode down on the sequence of znodes. If a client receives a notification that the znode it is watching is gone, then it becomes the new leader in the case that there is no smaller znode. Note that this avoids the herd effect by not having all clients watching the same znode.Here’s the pseudo code:Let ELECTION be a path of choice of the application. To volunteer to be a leader:Create znode z with path “ELECTION/n“ with both SEQUENCE and EPHEMERAL flags;Let C be the children of “ELECTION”, and i be the sequence number of z;Watch for changes on “ELECTION/n_j”, where j is the largest sequence number such that j &lt; i and n_j is a znode in C;Upon receiving a notification of znode deletion:Let C be the new set of children of ELECTION;If z is the smallest node in C, then execute leader procedure;Otherwise, watch for changes on “ELECTION/n_j”, where j is the largest sequence number such that j &lt; i and n_j is a znode in C;Note that the znode having no preceding znode on the list of children does not imply that the creator of this znode is aware that it is the current leader. Applications may consider creating a separate znode to acknowledge that the leader has executed the leader procedure. 大意为：选举的一种简单方式为利用ZK中的临时顺序节点，具体思路为有一个名为/election的节点，然后所有节点开始在该节点下创建子节点/election/n_，类型为临时顺序节点，创建成功后ZK自动在节点后衔接一个顺序号，顺序号最小的即为leader，同时，所有节点启动对/election节点的监视，当该节点发生变动时，检测自己的节点顺序号是否为最小，是则晋升为leader，否则继续监视。 与分布式锁遇到的问题雷同，所有节点监视/election节点，相当于监视所有节点在该节点下的子节点，当该节点发生变动时，所有节点都会接收到通知，但其实只有一个节点晋升为leader，意味着其他节点会接受到大量的无用通知，当服务器数量较为庞大时，便会引起”惊群效应”。改进措施同样与分布式锁解决方案一样，将对/election节点的监视更改为对该节点下顺序号比自己小的最大节点的监视。可对比分布式锁理解。 Endurance 持久化：如何保证数据不丢失 同一个客户端的请求是是放到一个队列中顺序处理的，所以没有所谓的并发问题，但是不同的客户端是通过Map&lt;客户端唯一表示，队列&gt;来实现的，所以不同的客户端请求没发保证顺序性，且会存在并发问题 持久化底层数据结构，Map&lt;节点目录，节点对象&gt; 持久化方式，log文件记录增量，snapshot记录全量快照 Deploy 单机模式： 下载zookeeper到本地（PC端），解压后可看到zookeeper的目录结构，/bin中存放着一些.sh或者.cmd的命令（如启动服务器命令和客户端连接服务器命令等），/conf中存放着配置文件，其中有一个zoo.sample.cfg的配置文件，我们需要将其复制一份命名为zoo.cfg，然后在其中添加两行（官网说默认在日志和数据存放在一个文件中，但是考虑到性能问题，建议还是分开存放） dataDir=../data 用于存放snapshot文件dataLogDir=../log 用于存放日志log文件 客户端端口默认为2181，一般无需修改，除非自己本机出现端口占用问题 。clientPort=2181 我们下载的zookeeper文件夹中有一个zookeeper.jar包，我们可以理解为zookeeper的客户端API，我们可以将该jar包导入工程项目中来连接zookeeper的服务器并对其进行相关操作。 还有一个客户端我们可以使用——Curator（https://curator.apache.org/） 集群模式： 在不同的服务器上分别安装zookeeper，并对其进行相关配置，在zoo.cfg配置文件中我们需要加上相同的几行配置（下面的意思为让zookeeper的集群服务器之间相互知道对方的存在，由于在不同的服务器上，所以端口号无需修改，但是服务器ip一定不能相同） server.1=server.ip1:2888:3888server.2=server.ip2:2888:3888server.3=server.ip3:2888:3888 然后我们还需要在存放snapshot文件的data文件夹中创建myid文件并在其中写入一行配置，即自己的服务器序号，就是配置文件中自己ip前面的服务器序号（server.1的1，其范围是1到255） 伪集群模式： 即在一个物理服务器上搭建多个逻辑上的zookeeper集群，其部署方式与真正集群相似，不同的是在同一个服务器上，所以配置文件中的ip均相同，但是端口号需要改为不同的端口号，其余均与集群配置一致。 server.1=server.ip:2888:3888server.2=server.ip:2889:3889server.3=server.ip:2890:3890 How to use ? 命令行指令 在ZK中，ZK客户端对服务器每一个数据节点的写操作，ZK会认为都是一次完整的事务操作，要么成功，要么失败，保证了数据的原子性。而每次事务都会分配一个唯一的事务id，以标识这次事务操作的数据信息。下面详细理解一下节点状态各个字段的含义：cZxid：创建节点的事务idctime：创建节点的时间mZxid：修改节点的事务idmtime：修改节点的时间pZxid：子节点列表最后一次修改的事务id。删除或添加子节点，不包含修改子节点的数据。cversion：子节点的版本号，删除或添加子节点，版本号会自增dataVersion：节点数据版本号，数据写入操作，版本号会递增aclVersion：节点ACL权限版本，权限写入操作，版本号会递增ephemeralOwner：临时节点创建时的事务id，如果节点是永久节点，则它的值为0dataLength：节点数据长度（单位：byte），中文占3个bytenumChildren：子节点数量 服务器启动命令：./zkServer.sh start 服务器检测状态：./zkServer.sh status 客户端连接本地服务器：./zkCli.sh -server 127.0.0.1:2181 显示节点：ls /（或者ls2 /） 创建节点：create /liufein（节点名） liufei（节点值） 获取节点信息：get /liufein 设置节点信息：set /liufein stefan（节点新值）【信息中数据版本字段会随着数据更改次数而自增】 删除节点信息：delete /liufein（子节点不为空不能删除）删除节点命令，此命令与delete命令不同的是delete不可删除有子节点的节点，但是rmr命令可以删除，注意路径为绝对路径。该命令现在也可执行，但会有提示使用deleteall命令来替代 查看节点状态信息。如stat /zookeeper 显示配额：如listquota /zookeeper 查看节点权限Acl：如getAcl /zookeeper/node1 SetAcl命令，设置权限 （ACL权限控制:注意:删除权限的作用范围为其子节点，而非其本身，意味着当你给某一节点设置了删除权限后，你依然可以随意的删除该节点，但是其子节点不能。） acl由三部分组成：1为scheme，2为user，3为permission，一般情况下表示为scheme:id:permissions。 world: 它下面只有一个id, 叫anyone, world:anyone代表任何人，zookeeper中对所有人有权限的结点就是属于world:anyone的 auth: 它不需要id, 只要是通过authentication的user都有权限（zookeeper支持通过kerberos来进行authencation, 也支持username/password形式的authentication) digest: 它对应的id为username:BASE64(SHA1(password))，它需要先通过username:password形式的authentication。（由于使用digest时，密码会经过SHA1和BASE64的两层编码转换，所以我们可以使用命令：echo -n lf:lf | openssl dgst -binary -sha1 | openssl base64用于输出密码所对应的BASE64(SHA1(password))编码之后的值，然后使用该值进行权限的设置，这样在我们使用授权的时候就可以直接使用编码前的字符，避免使用编码后的复杂难记忆的字符，例如setAcl /liufein digest:lf:shTM7tNH6fVkpZWS9MbSN6xaJEM=:rwdca设置授权命令，addauth digest lf:lf添加权限命令） ip: 它对应的id为客户机的IP地址，设置的时候可以设置一个ip段，比如ip:192.168.1.0/16, 表示匹配前16个bit的IP段 super: 在这种scheme情况下，对应的id拥有超级权限，可以做任何事情(cdrwa) Permissions CREATE(c): 创建权限，可以在在当前node下创建child node DELETE(d): 删除权限，可以删除当前的node READ(r): 读权限，可以获取当前node的数据，可以list当前node所有的child nodes WRITE(w): 写权限，可以向当前node写数据 ADMIN(a): 管理权限，可以设置当前node的permission 综上，一个简单使用setAcl命令，则可以为：setAcl/zookeeper/node1 world:anyone:cdrw Digest:先设置权限，其中密码使用的是编码的格式setAcl /zookeeper digest:username:BASE64(SHA1(password)):rwadc然后添加访问权限，此时密码使用的明文字符addauth digest lf:lf添加权限后才能进行相关操作 Auth：先添加权限，密码为明文addauth digest username:password然后设置权限，密码同样为明文setAcl /zookeeper auth:username:passeword:rwadc 可以添加监听watajch的命令有(即可以使用以下命令来设置watch) Stat path [watch] Ls path [watch] Ls2 path [watch] Get path [watch] API使用指南 API官方地址：https://zookeeper.apache.org/doc/r3.4.6/api/org/apache/zookeeper/ZooKeeper.html Zk中为我们提供了一个原生的jar包来供我们依赖使用，其位置就在/zookeeper/下 我们在开发环境中，新建工程，将其导入即可使用其来操作zk服务器中节点数据，如下为简单的一些实际操作 连接zk 客户端和zk服务端链接是一个异步的过，当连接成功后后，客户端会收的一个watch通知 参数：connectString：连接服务器的ip字符串，比如: “192.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181”可以是一个ip，也可以是多个ip，一个ip代表单机，多个ip代表集群，也可以在ip后加路径 sessionTimeout：超时时间，心跳收不到了，那就超时 watcher：通知事件，如果有对应的事件触发，则会收到一个通知；如果不需要，那就设置为null canBeReadOnly：可读，当这个物理机节点断开后，还是可以读到数据的，只是不能写，此时数据被读取到的可能是旧数据，此处建议设置为false，不推荐使用 sessionId：会话的id sessionPasswd：会话密码 当会话丢失后，可以依据 sessionId 和 sessionPasswd 重新获取会话 1234ZooKeeper zk = new ZooKeeper(ZK_SERVER_PATH, TIME_OUT, new ZKConnection()); long sessionId = zk.getSessionId(); byte[] sessionPassword = zk.getSessionPasswd(); ZooKeeper zkSession = new ZooKeeper(ZK_SERVER_PATH,TIME_OUT,new ZKConnection(), sessionId,sessionPassword); 节点创建 123456789101112131415161718192021222324252627282930313233/** * 同步或者异步创建节点，都不支持子节点的递归创建，异步有一个callback函数 * 参数： * path：创建的路径 * data：存储的数据的byte[] * acl：控制权限策略 * Ids.OPEN_ACL_UNSAFE --&gt; world:anyone:cdrwa * CREATOR_ALL_ACL --&gt; auth:user:password:cdrwa * createMode：节点类型, 是一个枚举 * PERSISTENT：持久节点 * PERSISTENT_SEQUENTIAL：持久顺序节点 * EPHEMERAL：临时节点 * EPHEMERAL_SEQUENTIAL：临时顺序节点 */ /*同步创建*/ result = zookeeper.create(path, data, acls, CreateMode.PERSISTENT); /*异步创建*/ String ctx = "&#123;'create':'success'&#125;"; zookeeper.create(path, data, acls, CreateMode.PERSISTENT, new CreateCallBack(), ctx); ``` - Callback回调函数： - 通知和回调的区别： - 通知是ZooKeeper中注册了监视点的客户端收到的事件报告消息 - 回调是基于异步思想的,通过回调函数来确定操作的完成情况 &gt; ZK中回调函数均由某些接口定义，我们需要实现该接口，并实现其中的processResult方法，其中接口的实现随功能而定，如以下创建和删除方法中的回调接口便不一致（方法内参数也不同），具体可参考官方API - 参数中有一个Object ctx，该参数为回调信息，类型为Object意味着回调类型可以为任意类型。 ```java create(String path, byte[] data, List&lt;ACL&gt; acl, CreateMode createMode, AsyncCallback.StringCallback cb, Object ctx) delete(String path, int version, AsyncCallback.VoidCallback cb, Object ctx) Watcher通知事件： ZooKeeper中实现对接点的监控,需要实现Watcher接口类,实现其中的process方法 12345public class WatcherDemo implements Watcher&#123; public void process(WatchedEvent event) &#123; 监视事件发生后进行的操作 &#125; &#125; 监视事件的设置，如： 12Zookeeper.exists(String path, Watcher watcher)方法， 具体使用为：Zookeeper.exists("/dubbo", new WatcherDemo() ) 意味着给节点/dubbo实行监视，当他存在即创建时，监视事件WatcherDemo被触发，引发该类的process()方法被执行。其余均类似，可参考官方API中具体有那些方法可以设置通知事件Watcher 权限设置 任何人可以访问： zkServer.createZKNode("/aclimooc", "test".getBytes(), Ids.OPEN_ACL_UNSAFE); 1 自定义用户认证访问： 1234567List&lt;ACL&gt; acls = new ArrayList&lt;ACL&gt;(); Id imooc1 = new Id("digest",DigestAuthenticationProvider.generateDigest("imooc1:123456")); Id imooc2 = new Id("digest",DigestAuthenticationProvider.generateDigest("imooc2:123456")); acls.add(new ACL(Perms.ALL, imooc1)); acls.add(new ACL(Perms.READ, imooc2)); acls.add(new ACL(Perms.DELETE | Perms.CREATE, imooc2)); zkServer.createZKNode("/aclimooc/testdigest", "testdigest".getBytes(), acls); 注册过的用户必须通过addAuthInfo才能操作节点，参考命令行 addauth： 123456zkServer.getZookeeper().addAuthInfo("digest", "imooc1:123456".getBytes()); zkServer.createZKNode("/aclimooc/testdigest/childtest","childtest".getBytes(),Ids.CREATOR_ALL_ACL); Stat stat = new Stat(); byte[] data = zkServer.getZookeeper().getData("/aclimooc/testdigest", false, stat); System.out.println(new String(data)); zkServer.getZookeeper().setData("/aclimooc/testdigest", "now".getBytes(), 1); Ip方式的acl： 1234List&lt;ACL&gt; aclsIP = new ArrayList&lt;ACL&gt;(); Id ipId1 = new Id("ip", "192.168.1.6"); aclsIP.add(new ACL(Perms.ALL, ipId1)); zkServer.createZKNode("/aclimooc/iptest6", "iptest".getBytes(), aclsIP); DigestAuthenticationProvider.generateDigest(id);转码操作，类似于命令行的echo -n lf:lf | openssl dgst -binary -sha1 | openssl base64 Curator客户端使用指南 扩展与思考 注册中心的需求分析和关键设计考量 注册中心是CP还是AP zk基于CP（数据一致性，分区容忍性），nacos基于AP（可用性，分区容忍性） zk集群3机房5节点容灾部署，当某一机房出现网络分区时，该机房的zk节点就成了不可写状态，因为联系不上leader，也就是说该机房的应用服务没办法重新部署，扩容或者缩容；但是如果使用nacos，该机房的注册中心依然可以支持该机房服务的正常重新部署，上下线，虽然注册中心数据出现了不一致，但是并不影响服务的正常使用。 zk的写是不可扩展的（由于要保持整个集群数据的一致性，所有的写操作都是由leader节点来操控，而且会涉及到分布式事务的问题，严重影响效率性能），不能通过增加节点来解决水平扩展性问题。 zk的数据持久化和事务日志。 在服务发现场景中，其最核心的数据-实时的健康的服务的地址列表真的需要数据持久化么？其实不是，因为客户端会缓存一份数据，并且客户端对注册中心一定是一个弱依赖关系，必须仅在服务发布，机器上下线，服务扩缩容等必要时才依赖注册中心。 一个完整的生产可用的注册中心，除了服务的实时地址列表以及实时的健康状态之外，还会存储一些服务的元数据信息，例如服务的版本，分组，所在的数据中心，权重，鉴权策略信息，service label等元信息，这些数据需要持久化存储，并且注册中心应该提供对这些元信息的检索的能力。 服务的健康检测 将服务的健康监测绑定在了 ZooKeeper 对于 Session 的健康监测上，或者说绑定在TCP长链接活性探测上了。 注册中心应该提供更丰富的健康监测方案，服务的健康与否的逻辑应该开放给服务提供方自己定义，而不是一刀切搞成了 TCP 活性检测！ 容灾 客户端中应该有针对注册中心服务完全不可用时做容灾的手段，例如设计客户端缓存数据机制（我们称之为 client snapshot）就是行之有效的手段 ZooKeeper，大数据/分布式协调绝佳伴侣，而交易则/服务发现则不太合适 Zab协议 Zab协议: 全称是 Zookeeper Atomic Broadcast （Zookeeper原子广播） 保证数据一致性的核心算法 基于该协议，zk实现了一种主备模型（即Leader和Follower模型）的系统架构来保证集群中各个副本之间数据的一致性 使用一个单一的主进程（Leader）来接收并处理客户端的事务请求（也就是写请求），并采用了Zab的原子广播协议，将服务器数据的状态变更以 事务proposal （事务提议）的形式广播到所有的副本（Follower）进程上去。 保证一个全局的变更序列被顺序引用。Zookeeper是一个树形结构，很多操作都要先检查才能确定是否可以执行，比如P1的事务t1可能是创建节点”/a”，t2可能是创建节点”/a/bb”，只有先创建了父节点”/a”，才能创建子节点”/a/b”。为了保证这一点，Zab要保证同一个Leader发起的事务要按顺序被apply Paxos算法 Paxos算法: 用来解决分布式系统中，如何就某个值达成一致的算法 Proposer：议案发起者。 Acceptor：决策者，可以批准议案。 Learner：最终决策的学习者。 P0. 当集群中，超过半数的Acceptor接受了一个议案，那我们就可以说这个议案被选定了（Chosen）。P0已经是一个完备的一致性算法，保证了P0也就解决了一致性问题。但是P0的实用性不佳，一个议案想被半数以上的Acceptor接受是一件极其困难的事情！ 算法推算过程太复杂，自行百度 负载均衡算法 zk客户端curator实现连接zk集群服务器的负载均衡算法：拿到集群服务器列表放到List中，然后使用random.nextInt(集群服务器数量)来随机连接一个 分区容忍性 什么是分区容忍性：一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Zookeeper</tag>
        <tag>Provider</tag>
        <tag>Consumer</tag>
        <tag>RegistrationCenter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeanCopy]]></title>
    <url>%2F2018%2F07%2F01%2FBeanCopy%2F</url>
    <content type="text"><![CDATA[Bean类的复制 当bean对象中属性字段较少时，我们通常手动使用置取方法来完成一个bean对象的复制，但是实际项目中往往一个bean类中含有大量的属性字段，所以手动复制变得不太现实，beancopy技术因此应用而生。 Apache的两个版本：（原理：反射机制） org.apache.commons.beanutils.PropertyUtils.copyProperties(Object dest, Object orig) org.apache.commons.beanutils.BeanUtils.copyProperties(Object dest, Object orig)Spring版本：（原理：反射机制） org.springframework.beans.BeanUtils.copyProperties(Object source, Object target, Class editable, String[] ignoreProperties)cglib版本：（原理：字节码+动态代理，效率最高） net.sf.cglib.beans.BeanCopier.copy(Object paramObject1, Object paramObject2, Converter paramConverter) 反射原理我们都很熟，也很常见，字节码可能听着较为生疏，所以这里主要聊一聊cglib版本的beancopy（这是cglib用到的两个jar包：cglib-nodep-3.2.7.jar和asm-4.0.jar） 使用指南：1234SourceBean sourceBean = new SourceBean();TargetBean targetBean = new TargetBean(); BeanCopier copier = BeanCopier.create(SourceBean.class, TargetBean.class, false); copier.copy(sourceBean, targetBean, null); BeanCopier中Create对象过程： 产生sourceClass-》TargetClass的拷贝代理类，放入jvm中，所以创建的代理类的时候比较耗时，最好保证这个对象的单例模式。 创建过程：源代码见jdk：net.sf.cglib.beans.BeanCopier.Generator.generateClass(ClassVisitor) 获取sourceClass的所有public get 方法-》PropertyDescriptor[] getters 获取TargetClass 的所有 public set 方法-》PropertyDescriptor[] setters 遍历setters的每一个属性，执行4和5 按setters的name生成sourceClass的所有setter方法-》PropertyDescriptor getter【不符合javabean规范的类将会可能出现空指针异常】 PropertyDescriptor[] setters-》PropertyDescriptor setter 将setter和getter名字和类型 配对，生成代理类的拷贝方法。 Copy属性过程：调用生成的代理类，代理类的代码和手工操作的代码很类似，效率非常高。 从多字段向少字段（层层筛选）的拷贝，从少字段的向多字段（层层叠加）的拷贝均可实现，其核心都是target.setXXX(source.getXXX()),所以源类的get方法和目标类的set方法不可缺少，否则值将拷贝不过去。 后续延伸 cglib是一款比较底层的操作java字节码的框架CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。除了CGLIB包，脚本语言例如Groovy和BeanShell，也是使用ASM来生成java的字节码。当然不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflection</tag>
        <tag>Bean</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro Integration]]></title>
    <url>%2F2018%2F05%2F20%2FShiro%20Integration%2F</url>
    <content type="text"><![CDATA[Shiro Integration springboot集成shiro（非web应用） springboot集成shiro（web应用） spring集成shiro（web应用） springboot集成shiro（非web应用） shiro-spring-boot-starter包为我们省去了好多设置 编写myrealm（可继承jdbcRealm或者Realm） AuthenticationInfo配置验证 AuthorizationInfo配置授权 可编写多个myrealm，但是会涉及到验证策略 编写配置类 shiroConfig 配置Realm bean 可设置密码加密，加密算法有MD5… 如果有多个realm需要设置验证策略 也可以自定义验证策略，使用自己的策略 缓存设置（否则每个请求都将触发验证查询数据库操作） 记住我设置） 编写CommandLineRunner来设置securityManager启动shiro 编写授权服务，可使用注解对服务进行权限设定 运行测试 springboot集成shiro（web应用） shiro-spring-boot-web-starter依赖引入 测试使用thymeleaf前端，引入thymeleaf和servlet的包 编写myrealm（与非web应用同理） 编写配置类 Realm 加密算法HashedCredentialsMatcher 过滤器链ShiroFilterChainDefinition（url路径权限设置） modelattribute设置（subject）与ui交互 编写控制层controller application.properties参数配置 验证失败重定向url配置 shiro接管session配置 禁止session重写配置 spring集成shiro（javaconfig方式） web配置类（实现WebApplicationInitializer接口，重写onStartUp方法） 获取AnnotationConfigWebApplicationContext实例注册配置文件（包括mvc配置，shiro配置），设置ServletContext DelegatingFilterProxy过滤器注册 springMVC的DispatcherServlet注册 mvc配置 视图层解析配置（jsp、html） 静态资源配置 shiro配置 realm实例 shiro bean生命周期管理实例LifecycleBeanPostProcessor 注解功能开启 shiroFilter过滤器 验证失败重定向url页面配置 未授权重定向url 过滤器链url授权配置 securityManager 缓存ehcache（需要配置缓存xml配置文件） sessionManager cookie记住我管理 simpleCookie]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web.xml]]></title>
    <url>%2F2018%2F05%2F13%2FWeb.xml%2F</url>
    <content type="text"><![CDATA[Web.xml web.xml javaconfig配置 springboot配置web web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot;&gt; &lt;!-- icon元素指出IDE和GUI工具用来表示Web应用的一个和两个图像文件的位置。 --&gt; &lt;icon&gt; &lt;small-icon&gt;/images/small-book.gif&lt;/small-icon&gt; &lt;large-icon&gt;/images/tome.jpg&lt;/large-icon&gt; &lt;/icon&gt; &lt;!-- display-name元素提供GUI工具可能会用来标记这个特定的Web应用的一个名称。 --&gt; &lt;display-name&gt;&lt;/display-name&gt; &lt;!-- description元素给出与此有关的说明性文本。 --&gt; &lt;description&gt;&lt;/description&gt; &lt;!-- context-param元素声明应用范围内的初始化参数，所有servlet全都可以获取使用该参数 --&gt; &lt;context-param&gt; &lt;param-name&gt;support-email&lt;/param-name&gt; &lt;param-value&gt;blackhole@mycompany.com&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- filter 过滤器元素将一个名字与一个实现javax.servlet.Filter接口的类相关联。 --&gt; &lt;filter&gt; &lt;filter-name&gt; &lt;filter-class&gt; &lt;/filter&gt; &lt;!-- filter-mapping 一旦命名了一个过滤器，就要利用filter-mapping元素把它与一个或多个servlet或JSP页面相关联。 --&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;Reporter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; 过滤所有路径 或者 &lt;filter-name&gt;Reporter&lt;/filter-name&gt; &lt;servlet-name&gt;SomeServletName&lt;/servlet-name&gt; 关联servlet &lt;/filter-mapping&gt; &lt;!-- listener 对事件监听程序的支持，事件监听程序在建立、修改和删除会话或servlet环境时得到通知。Listener元素指出事件监听程序类。 --&gt; &lt;listener&gt; &lt;listener-class&gt; &lt;/listener&gt; &lt;!-- servlet 在向servlet或JSP页面制定初始化参数或定制URL时，必须首先命名servlet或JSP页面。Servlet元素就是用来完成此项任务的。 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;Search&lt;/servlet-name&gt; &lt;servlet-class&gt;myPackage.SearchServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; 启动时装载（默认请求时装载，若初始化时消耗时间较长，则可以考虑启动时装载） &lt;init-param&gt; 单个servlet所需要的初始化参数 &lt;param-name&gt;firstName&lt;/param-name&gt; &lt;param-value&gt;Larry&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;!-- servlet-mapping 服务器一般为servlet提供一个缺省的URL：http://host/webAppPrefix/servlet/ServletName。但是，常常会更改这个URL，以便servlet可以访问初始化参数或更容易地处理相对URL。在更改缺省URL时，使用servlet-mapping元素。 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt; PageName &lt;/servlet-name&gt; &lt;url-pattern&gt;/UrlTest2/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- session-config 如果某个会话在一定时间内未被访问，服务器可以抛弃它以节省内存。可通过使用HttpSession的setMaxInactiveInterval方法明确设置单个会话对象的超时值，或者可利用session-config元素制定缺省超时值。 --&gt; &lt;session-config&gt; &lt;session-timeout&gt;180&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;!-- mime-mapping 如果Web应用具有想到特殊的文件，希望能保证给他们分配特定的MIME类型，则mime-mapping元素提供这种保证。 --&gt; &lt;mime-mapping&gt;&lt;/mime-mapping&gt; &lt;!-- welcome-file-list元素指示服务器在收到引用一个目录名而不是文件名的URL时，使用哪个文件。 --&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- error-page元素使得在返回特定HTTP状态代码时，或者特定类型的异常被抛出时，能够制定将要显示的页面。 --&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/errors/servererror.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;!-- resource-env-ref元素声明与资源相关的一个管理对象。 --&gt; &lt;resource-env-ref&gt;&lt;/resource-env-ref&gt; &lt;!-- resource-ref元素声明一个资源工厂使用的外部资源。 --&gt; &lt;resource-ref&gt;&lt;/resource-ref&gt; &lt;!-- security-constraint元素制定应该保护的URL。它与login-config元素联合使用 --&gt; &lt;security-constraint&gt;&lt;/security-constraint&gt; &lt;!-- 用login-config元素来指定服务器应该怎样给试图访问受保护页面的用户授权。它与sercurity-constraint元素联合使用。 --&gt; &lt;login-config&gt;&lt;/login-config&gt; &lt;!-- security-role元素给出安全角色的一个列表，这些角色将出现在servlet元素内的security-role-ref元素的role-name子元素中。分别地声明角色可使高级IDE处理安全信息更为容易。 --&gt; &lt;security-role&gt;&lt;/security-role&gt; &lt;!-- env-entry元素声明Web应用的环境项。 --&gt; &lt;env-entry&gt;&lt;/env-entry&gt; &lt;!-- ejb-ref元素声明一个EJB的主目录的引用。 --&gt; &lt;ejb-ref&gt;&lt;/ejb-ref&gt; &lt;!-- ejb-local-ref元素声明一个EJB的本地主目录的应用。 --&gt; &lt;ejb-local-ref&gt;&lt;/ejb-local-ref&gt;&lt;/web-app&gt; javaconfig配置12345678910111213141516171819202122232425public class WebInitConfig implements WebApplicationInitializer &#123; @Override public void onStartup(ServletContext container) throws ServletException &#123; AnnotationConfigWebApplicationContext appContext = new AnnotationConfigWebApplicationContext(); appContext.register(WebMvcConfig.class); appContext.setServletContext(container); container.setInitParameter(&quot;&quot;,&quot;&quot;);//设置初始化参数 //设置过滤器 FilterRegistration.Dynamic shiroFilter = container.addFilter(&quot;shiroFilter&quot;, DelegatingFilterProxy.class); shiroFilter.setInitParameter(&quot;targetFilterLifecycle&quot;, &quot;true&quot;); shiroFilter.addMappingForUrlPatterns(EnumSet.allOf(DispatcherType.class), false, &quot;/*&quot;); container.addListener(EnvironmentLoaderListener.class); //设置监听器 //设置servlet ServletRegistration.Dynamic dispatcher = container.addServlet(&quot;DispatcherServlet&quot;, new DispatcherServlet(appContext)); dispatcher.setLoadOnStartup(1); dispatcher.addMapping(&quot;/&quot;); container.setSessionTimeout();//设置session超时时间 &#125;&#125; 自定义servlet1234public class InitServlet extends HttpServlet &#123; public void init() &#123;&#125; public void doGet(HttpServletRequest request,HttpServletResponse response)throws ServletException, IOException &#123;&#125; &#125; 自定义过滤器12345public class ReportFilter implements Filter &#123; public void doFilter(ServletRequest request,ServletResponse response,FilterChain chain)throws ServletException, IOException &#123; &#125; public void init(FilterConfig config)throws ServletException &#123;&#125; public void destroy() &#123;&#125; &#125; springboot配置web 注解扫描方式 @WebServlet、@WebListener、@WebFilter @ServletComponentScan(value = “dcits.liufein”) 组建注册方式 123456789101112131415161718@Bean public FilterRegistrationBean getFilterRegistrationBean()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(new DelegatingFilterProxy()); bean.addInitParameter(); bean.addServletNames(); bean.addUrlPatterns(); &#125; @Bean public ServletListenerRegistrationBean getServletListenerRegistrationBean()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(new MySessionActivationListener()); bean.setOrder(1); &#125; @Bean public ServletRegistrationBean getServletRegistrationBean()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new DefaultServlet()); bean.addUrlMappings(&quot;/secondServlet&quot;); return bean; &#125; 部分xml元素使用springboot中application.properties配置文件中配置，例如session超时，context-para初始化参数]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web_Listener]]></title>
    <url>%2F2018%2F05%2F06%2FWeb_Listener%2F</url>
    <content type="text"><![CDATA[Web_Listener Listener实现 基于组合关系的监听器实现 基于观察者模式的监听器实现 基于观察者模式和代理模式的监听器实现 Web Listener javaweb中监听器的分类 实现原理 案例实践 Listener实现 监听器，顾名思义用于监听某一对象（可以是类，方法，数据等）变化的工具，根据变化从而可以做出相对应的措施。 基于组合关系的监听器实现123456789101112131415/** * 监听器listener负责监听类Source中的init方法* 当init方法被调用时触发监听器执行beforeInit方法进行一些初始化操作前的必要操作 */public class Source&#123; /** 被监听方法 */ public void init()&#123; Listener.beforeInit(); ... &#125;&#125;/** 监听类 */public class Listener&#123; public static void beforeInit()&#123;&#125;&#125; 以上代码通过类之间的组合关系实现了监听器的功能，该版本为最初始版本，接下来进行改造优化。（无论多么复杂的代码均是由最简单的代码一步步演化而来） 基于观察者模式的监听器实现123456789101112131415161718192021222324252627282930/** 监听接口 */public interface Listener&#123; void beforeInit();&#125;/** 主题接口 */public interface Source&#123; void addListener(Listener listener);&#125;/** 监听实现 */public class ListenerImpl implements Listener&#123; /** 构造方法中注入主题接口并调用该添加监听方法将自身加入到主题的监听列表中 */ public ListenerImpl(Source source)&#123; source.addListener(this); &#125; public void beforeInit()&#123;&#125;&#125;/** 主题实现 */public class SourceImpl implements Source&#123; List&lt;Listener&gt; listenerList; public void addListener(Listener listener)&#123; listenerList.add(listener); &#125; public void doListeners()&#123; for(Listener listener ：listenerList)&#123;listener.beforeInit();&#125; &#125; public void init()&#123; doListeners(); ... &#125;&#125; 上面代码将监听和主题各自抽象出一个接口以实现多态特性，同时在监听实现注入主题接口以实现监听的开启功能，但是监听和主题之间还存在着一定的耦合，所以我们需要进行解耦优化。 基于观察者模式和代理模式的监听器实现1234567891011121314151617181920212223242526272829303132333435363738394041424344/** 监听接口 */public interface Listener&#123; void beforeInit();&#125;/** 主题接口 */public interface Source&#123; void addListener(Listener listener);&#125;/** 代理接口 */public class Event&#123; private Object source; public Event(Object source)&#123;this.source = source;&#125; public Object getObject()&#123;return source;&#125;&#125;/** 代理实现 */public class EventImpl extends Event&#123; public EventImpl(Source sourcee)&#123;super(source)&#125; public Source getSource()&#123;(Source)super.getObject()&#125;&#125;/** 监听实现 */public class ListenerImpl implements Listener&#123; /** 构造方法中注入主题接口并调用该添加监听方法将自身加入到主题的监听列表中 */ public ListenerImpl(EventImpl eventImpl)&#123; eventImpl.getSource().addListener(this); &#125; public void beforeInit(EventImpl eventImpl)&#123; Source source = eventImpl.getSource(); ... &#125;&#125;/** 主题实现 */public class SourceImpl implements Source&#123; List&lt;Listener&gt; listenerList; public void addListener(Listener listener)&#123; listenerList.add(listener); &#125; public void doListeners()&#123; for(Listener listener ：listenerList)&#123;listener.beforeInit();&#125; &#125; public void init()&#123; doListeners(); ... &#125;&#125; Web Listenerjavaweb中有8个监听器，主要负责监听ServletContext,HttpSession,ServletRequest三个域对象状态，可大致分为三类 一类:监听三个域对象的创建和销毁的监听器 对象类型 对应的监听器 ServletContext ServletContextListener HttpSession HttpSessionListener HttpServletRequest ServletRequestListener 二类:监听三个域对象的属性变更的监听器.(属性添加,属性移除,属性替换) 对象类型 对应的监听器 ServletContext ServletContextAttributeListener HttpServletRequest ServletRequestAttributeListener HttpSession HttpSessionAttributeListener 三类:监听HttpSession对象中的JavaBean的状态的改变.(绑定,解除绑定,钝化和活化)2个 对象类型 对应的监听器 HttpSession HttpSessionBindingListener(绑定,解除绑定) HttpSession HttpSessionActivationListener(序列化和反序列化) HttpSessionBindingListener和HttpSessionListener的区别 所谓对session进行数据绑定，就是调用session.setAttribute()把 HttpSessionBindingListener保存进session中。 HttpSessionListener设置一次就可以监听所有 session HttpSessionBindingListener通常都是一对一的 实现原理（以ServletContextListener为例）12345678910111213141516171819202122232425262728293031323334/** 监听接口，内含域对象初始化和销毁方法 */public interface ServletContextListener implements EventListener&#123; default void contextInitialized(ServletContextEvent sce) &#123;&#125; default void contextDestroyed(ServletContextEvent sce) &#123;&#125;&#125;/** 监听实现，自定义实现方法内容 */public class MySerConListener implements ServletContextListener&#123; void contextInitialized(ServletContextEvent sce) &#123; ... &#125;&#125;/** 监听与被监听之间的代理层，监听程序通过该代理获取被监听实例 */public class ServletContextEvent extends EventObject &#123; public ServletContextEvent(ServletContext source) &#123; super(source); &#125; public ServletContext getServletContext() &#123; return (ServletContext)super.getSource(); &#125;&#125;/** 被监听接口 */public interface ServletContext &#123;&#125;/** 被监听实现 ，内含addListener负责添加自定义监听*/public class ApplicationContext implements ServletContext &#123; public &lt;T extends EventListener&gt; void addListener(T t) &#123;&#125;&#125;/** 监听程序实际被调用的地方 */public class StandardContext extends ... implements ...&#123; public boolean listenerStart() &#123; ... listener.contextInitialized(event); ... &#125;&#125; 案例实践 基于springboot的自定义servletListener实现（相当于web.xml中配置监听） 自定义监听类添加注解@WebListener(第三类不需要使用注解) 启动类添加扫面注解@ServletComponentScan(value = “dcits.liufein”) 详细案例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182//@WebListenerpublic class MyRequestAttributeListener implements ServletRequestAttributeListener &#123; Logger log = LoggerFactory.getLogger(MyRequestAttributeListener.class); @Override public void attributeAdded(ServletRequestAttributeEvent srae) &#123; log.info(&quot;ServletRequestAttributeListener-----&quot; + srae.getName() + &quot;---&quot; + srae.getValue()); &#125; @Override public void attributeRemoved(ServletRequestAttributeEvent srae) &#123; &#125; @Override public void attributeReplaced(ServletRequestAttributeEvent srae) &#123; &#125;&#125;@WebListenerpublic class MyRequestListener implements ServletRequestListener &#123; Logger log = LoggerFactory.getLogger(MyRequestListener.class); @Override public void requestDestroyed(ServletRequestEvent sre) &#123; &#125; @Override public void requestInitialized(ServletRequestEvent sre) &#123; log.info(&quot;ServletRequestListener-----请求初始化前奏&quot;); &#125;&#125;@WebListenerpublic class MyServletAttributeListener implements ServletContextAttributeListener &#123; Logger log = LoggerFactory.getLogger(MyServletAttributeListener.class); @Override public void attributeAdded(ServletContextAttributeEvent scae) &#123; log.info(&quot;ServletContextAttributeListener-----&quot; + scae.getName() + &quot;---&quot; + scae.getValue()); &#125; @Override public void attributeRemoved(ServletContextAttributeEvent scae) &#123; &#125; @Override public void attributeReplaced(ServletContextAttributeEvent scae) &#123; &#125;&#125;@WebListenerpublic class MyServletListener implements ServletContextListener &#123; Logger log = LoggerFactory.getLogger(MyServletListener.class); @Override public void contextInitialized(ServletContextEvent sce) &#123; log.info(&quot;ServletContextListener---初始化前的准备工作&quot;); &#125; @Override public void contextDestroyed(ServletContextEvent sce) &#123; &#125;&#125;public class MySessionActivationListener implements HttpSessionActivationListener,Serializable &#123; Logger log = LoggerFactory.getLogger(MySessionActivationListener.class); @Override public void sessionWillPassivate(HttpSessionEvent se) &#123; log.info(&quot;HttpSessionActivationListener-----session超时序列化到磁盘之前的准备操作&quot;); &#125; @Override public void sessionDidActivate(HttpSessionEvent se) &#123; log.info(&quot;HttpSessionActivationListener-----session反序列化到内存后的第一操作&quot;); &#125;&#125;@WebListenerpublic class MySessionAttributelistener implements HttpSessionAttributeListener &#123; Logger log = LoggerFactory.getLogger(MySessionAttributelistener.class); @Override public void attributeAdded(HttpSessionBindingEvent se) &#123; log.info(&quot;HttpSessionAttributeListener-----&quot; + se.getName() + &quot;---&quot; + se.getValue()); &#125; @Override public void attributeRemoved(HttpSessionBindingEvent se) &#123; &#125; @Override public void attributeReplaced(HttpSessionBindingEvent se) &#123; &#125;&#125;/** * @Description: 将该实例以元素形式设置到session的attribute中 * 例如：session.setAttribute(&quot;userList&quot;,new MySessionBoundListener(&quot;liufein&quot;)); * 即可实现绑定监听，上述例子执行将触发实例中的valueBound方法， * 而该session元素的修改，删除，失效都将触发实例中valueUnbound方法 * 注意：该针对于单一元素的监听与HttpSessionListener针对全部session元素监听两者互不冲突 * 不需要使用@WebListener注解 */public class MySessionBoundListener implements HttpSessionBindingListener &#123; Logger log = LoggerFactory.getLogger(MySessionBoundListener.class); private String sessionUserName; public MySessionBoundListener(String sessionUserName)&#123; this.sessionUserName = sessionUserName; &#125; @Override public void valueBound(HttpSessionBindingEvent event) &#123; ServletContext servletContext = event.getSession().getServletContext(); List&lt;String&gt; onlineUserList = (List&lt;String&gt;)servletContext.getAttribute(&quot;ONLINE_USER_LIST&quot;); onlineUserList = onlineUserList == null ? new LinkedList&lt;&gt;() : onlineUserList; onlineUserList.add(this.sessionUserName); servletContext.setAttribute(&quot;ONLINE_USER_LIST&quot;,onlineUserList); log.info(&quot;HttpSessionBindingListener-----绑定&quot; + event.getName() + &quot;---&quot; + sessionUserName); &#125; @Override public void valueUnbound(HttpSessionBindingEvent event) &#123; ServletContext servletContext = event.getSession().getServletContext(); List&lt;String&gt; onlineUserList = (List&lt;String&gt;)servletContext.getAttribute(&quot;ONLINE_USER_LIST&quot;); onlineUserList.remove(this.sessionUserName); log.info(&quot;HttpSessionBindingListener-----解绑&quot; + event.getName() + &quot;---&quot; + sessionUserName); &#125;&#125;@WebListenerpublic class MySessionListener implements HttpSessionListener &#123; Logger log = LoggerFactory.getLogger(MySessionListener.class); public static int TOTAL_ONLINE_USERS = 0; @Override public void sessionCreated(HttpSessionEvent se) &#123; log.info(&quot;HttpSessionListener-----&quot; + se.getSession().getId()); ServletContext servletContext = se.getSession().getServletContext(); Integer totalOnlineUsers = (Integer) servletContext.getAttribute(&quot;TOTAL_ONLINE_USERS&quot;); if (totalOnlineUsers==null)&#123; totalOnlineUsers = 0; servletContext.setAttribute(&quot;TOTAL_ONLINE_USERS&quot;,totalOnlineUsers); &#125; TOTAL_ONLINE_USERS = totalOnlineUsers; TOTAL_ONLINE_USERS++; servletContext.setAttribute(&quot;TOTAL_ONLINE_USERS&quot;,TOTAL_ONLINE_USERS); log.info(&quot;HttpSessionListener-----当前在线人数为：&quot; + TOTAL_ONLINE_USERS); &#125; @Override public void sessionDestroyed(HttpSessionEvent se) &#123; ServletContext servletContext = se.getSession().getServletContext(); TOTAL_ONLINE_USERS = (Integer) servletContext.getAttribute(&quot;TOTAL_ONLINE_USERS&quot;); if(TOTAL_ONLINE_USERS&gt;0) &#123; TOTAL_ONLINE_USERS--; &#125; servletContext.setAttribute(&quot;TOTAL_ONLINE_USERS&quot;,TOTAL_ONLINE_USERS); log.info(&quot;HttpSessionListener-----一位不知名用户下线&quot;); log.info(&quot;HttpSessionListener-----当前在线人数为：&quot; + TOTAL_ONLINE_USERS); &#125;&#125;@Controllerpublic class WebListenerController &#123; @RequestMapping(&quot;/&quot;) public String index(HttpSession session)&#123; session.setAttribute(&quot;liufein&quot;,&quot;liufein&quot;); session.setAttribute(&quot;userList&quot;,new MySessionBoundListener(&quot;liufein&quot;)); /** * HttpSessionBindingListener验证辅助代码 * session元素的修改会导致之前的绑定解绑，但是发生在新的绑定之后 */ session.setAttribute(&quot;userList&quot;,new MySessionBoundListener(&quot;stefan&quot;)); List&lt;String&gt; list = (List)session.getServletContext().getAttribute(&quot;ONLINE_USER_LIST&quot;); list.forEach((e)-&gt;&#123; System.out.println(e); &#125;); session.removeAttribute(&quot;userList&quot;); /** MySessionActivationListener验证session序列化/反序列化监听 */ session.setAttribute(&quot;MySessionActivationListener&quot;,new MySessionActivationListener()); return &quot;index&quot;; &#125;&#125; springboot设置session持久化不起作用，待解决。。。 ## 附：与监听器相对应的过滤器，servlet配置均相似 springboot配置web.xml中的listener，servlet，filter两种方式 注解扫描方式 @WebServlet、@WebListener、@WebFilter @ServletComponentScan(value = “dcits.liufein”) 组建注册方式 123456789101112131415161718@Bean public FilterRegistrationBean getFilterRegistrationBean()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(new DelegatingFilterProxy()); bean.addInitParameter(); bean.addServletNames(); bean.addUrlPatterns(); &#125; @Bean public ServletListenerRegistrationBean getServletListenerRegistrationBean()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(new MySessionActivationListener()); bean.setOrder(1); &#125; @Bean public ServletRegistrationBean getServletRegistrationBean()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new DefaultServlet()); bean.addUrlMappings(&quot;/secondServlet&quot;); return bean; &#125;]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>Listener</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Json与序列化]]></title>
    <url>%2F2018%2F04%2F29%2FJson%E4%B8%8E%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Json与序列化 序列化：序列化是将对象状态转换为可保持或传输的格式的过程。与序列化相对的是反序列化，它将流转换为对象。这两个过程结合起来，可以轻松地存储和传输数据。 JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。它基于 ECMAScript (欧洲计算机协会制定的js规范)的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。 Json 对象表示为键值对 数据由逗号分隔 花括号保存对象 方括号保存数组 1234String str = JSON.toJSONString(person);JSONObject jObject = JSON.parseObject(str);Person p = JSONObject.toJavaObject(jObject, Person.class);System.out.println(person.getName()); json的实现有很多，这里使用的fastjson，较其速度相对来说是所有实现中最快的，使用json代码较为简洁干练，并且其生成的字符串体积较小，易于传输。 序列化/反序列化 当程序运行时，有关对象的信息就存储在了内存当中，但是当程序终止时，对象将不再继续存在。我们需要一种储存对象信息的方法，使我们的程序关闭之后他还继续存在，当我们再次打开程序时，可以轻易的还原当时的状态。这就是对象序列化的目的。 所谓序列化，就是定义一种格式来与内存中对象信息构造一种一一对应的关系，从而可以把内存中对象信息以某种格式来保存到任意地方；而序列化/反序列化就是对这种格式的解析 java的对象序列化将那些实现了Serializable接口的对象转换成一个字节序列，并且能够在以后将这个字节序列完全恢复为原来的对象，甚至可以通过网络传播。 这意味着序列化机制自动弥补了不同OS之间的差异. 如此，java实现了“轻量级持久性”，为啥是轻量级，因为在java中我们还不能直接通过一个类似public这样的关键字直接使一个对象序列化，并让系统自动维护其他细节问题。因此我们只能在程序中显示地序列化与反序列化 对象序列化不仅保存了对象的“全景图”，而且能够追踪对象内所包含的所有引用，并保存这些对象；接着又能对对象内包含的每个这样的引用进行追踪；以此类推。这种情况有时被称为“对象网”。 如何使用序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*序列化对象到临时性存储介质，如字符串临时变量*/ByteArrayOutputStream byteOut = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteOut);/*序列化对象到永久性存储介质，如本地文件ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream("D:/序列化.txt"));*/objectOutputStream.writeObject(person);System.out.println("序列化后对象的值为："+byteOut.toString());//System.out.println("序列化后对象的值为："+byteOut.toString("ISO-8859-1")); /*从文件反序列化对象ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream("D:/序列化.txt"));*//*从字符串反序列化对象*/ByteArrayInputStream byteIn = new ByteArrayInputStream(byteOut.toString().getBytes()); ObjectInputStream objectInputStream = new ObjectInputStream(byteIn);try &#123; Person readPerson = (Person)objectInputStream.readObject(); System.out.println(readPerson.getName());&#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace();&#125;/** 使用序列化实现加密解密 ，实现Serializable接口的类中添加writeObject()和readObject()可以实现数据的修改和加密解密操作* 因为底层调用的时候会先行检查实现Serializable接口的类中是否含有这两个方法，有则调用，没有直接调用默认方法*/class Person implements Serializable &#123; ... private void writeObject(ObjectOutputStream out) &#123; try &#123; PutField putFields = out.putFields(); password = "encryption";//模拟加密 putFields.put("password", password); out.writeFields(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void readObject(ObjectInputStream in) &#123; try &#123; GetField readFields = in.readFields(); Object object = readFields.get("password", ""); password = "pass";//模拟解密,需要获得本地的密钥 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; serialize后字符串包含了子串的长度，这可能是速度方面的优化 至于两者的速度各有千秋，因不同的场景，不同的条件而定 java序列化底层实现原理 java.io.ObjectOutputStream：表示对象输出流； 它的writeObject(Object obj)方法可以对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中； java.io.ObjectInputStream：表示对象输入流； 它的readObject()方法源输入流中读取字节序列，再把它们反序列化成为一个对象，并将其返回； 被序列化对象必须实现序列化接口Serializable才能被序列化；Serializable接口这是一个标识，告诉程序所有实现了”我”的对象都需要进行序列化 static和transient字段不能被序列化。 当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口 序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。为它赋予明确的值。显式地定义serialVersionUID有两种用途： 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。 java的远程方法调用（RMI），序列化使存活于其他计算机上的对象使用起来就像存活于本机上一样。当远程对象发送消息时，需要通过对象序列化来传输参数和返回值。 Java 序列化机制为了节省磁盘空间，具有特定的存储规则，当写入文件的为同一对象时，并不会再将对象的内容进行存储，而只是再次存储一份引用 序列化写入过程 写入过程会调用底层的字节数据容器 bout = new BlockDataOutputStream(outputStream);（bout表示底层的字节数据容器） 用特定的字节序列的值来表示不同的对象，字段或者等等其他，也就是建立一个字节序列和需要被序列化的内容的一一对应关系； 序列化/反序列化实质就是对字节序列的解析 第一步先写入magic number魔法数字 第二步写入对test类的描述 第三步写入对test父类的描述 第四步写入test父类中定义的字段的数据 第五步写入test类中定义的字段的数据 第六步写入test内部类的描述 第七步写入test内部类中定义的字段的数据 序列化的控制（部分/指定序列化） 通过实现Externalizable接口——代替实现Serializable接口——来对序列化过程进行控制。 可以实现指定字段的序列化（Serializable不能） Externalizable接口继承了Serializable接口，增加了两个方法，writeExternal()和readExternal()，这两个方法会在序列化和反序列化还原的过程中被自动调用。 Externalizable对象，在还原的时候所有普通的默认构造器都会被调用（包括在字段定义时的初始化）(只有这样才能使Externalizable对象产生正确的行为)，然后调用readExternal(). 如果我们从一个Externalizable对象继承，通常需要调用基类版本的writeExternal()和readExternal()来为基类组件提供恰当的存储和恢复功能。 为了正常运行，我们不仅需要在writeExternal()方法中将来自对象的重要信息写入，还必须在readExternal（）中恢复数据 防止对象的敏感部分被序列化，两种方式： 将类实现Externalizable，在writeExternal()内部只对所需部分进行显示的序列化 实现Serializable，用transient(瞬时)关键字（只能和Serializable一起使用）逐个字段的关闭序列化，他的意思：不用麻烦你保存或恢复数据——我自己会处理。 重复对象循环引用 Java 序列化机制为了节省磁盘空间，具有特定的存储规则，当写入文件的为同一对象时，并不会再将对象的内容进行存储，而只是再次存储一份引用 数据加密解密 向实现Serializable接口的类中添加writeObject()和readObject()可以实现数据的修改和加密解密操作 序列化/反序列化版本问题 序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。]]></content>
      <categories>
        <category>Json</category>
      </categories>
      <tags>
        <tag>Json</tag>
        <tag>Serializetion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列化框架]]></title>
    <url>%2F2018%2F04%2F29%2F%E5%BA%8F%E5%88%97%E5%8C%96%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[序列化框架 Hessian Protobuf Kryo FSTSerialize Json Schema，即XML Schema，XSD (XML Schema Definition)，指出如何形式描述XML文档的元素。由于SOAP协议的结构问题会使封装的数据膨胀数倍。当传输数据量比较小时，问题不是那么明显，但是当进行大数据量传输时就会导致Web服务的传输性能在实际运用中降低了很多。这对于经常有大数据量数据交换的应用系统来说是不适用的。所以催生了其他的各种轻量级协议，如Hessian协议（其实就是一个格式，双方达成共识后变成了协议）。 Hessian 序列化格式：二进制，下面是序列化语法（即二进制如何与java对象信息实现一一对应关系）文档地址 Hessian语法 无需额外的schema或者接口定义 版本控制： 无语言依赖性 数据类型 Hessian’s object serialization has 8 primitive types: raw binary data boolean 64-bit millisecond date 64-bit double 32-bit int 64-bit long null UTF8-encoded string It has 3 recursive types: list for lists and arrays map for maps and dictionaries object for objects Finally, it has one special contruct: ref for shared and circular object references. Hessian 2.0 has 3 internal reference maps: An object/list reference map. An class definition reference map. A type (class name) reference map. Hessian 2.0草案规范增加了对Hessian消息周围的包络的支持。 这些信封可以提供其他功能，如压缩，加密和消息签名。 信封还可用于将路由和可靠性信息附加到消息。 由于信封是可嵌套的，因此每个信封可以很简单，并在组合时提供强大的功能。 例如，安全消息传递系统可以压缩，加密然后安全地签名消息。使用信封的API是wrap（）用于编写消息，而unwrap（）用于读取消息。 应用程序序列化代码本身是相同的，因为信封只是在原始流周围创建一个Hessian2Input或Hessian2Output包装器。Hessian采用引用取代重复遇到的对象。使用引用取代重复遇到的对象可以避免对重复对象的编码，而且也减少了编码后的数据量。 Hessian使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Car &#123; private int year; private Model model; private Color color;&#125;public enum Model &#123; CIVIC, EDSEL, MODEL_T,&#125;public enum Color &#123; BLACK, GREEN, BLUE,&#125;//序列化ByteArrayOutputStream bos = new ByteArrayOutputStream();Hessian2Output out = new Hessian2Output(bos);out.startMessage();out.writeInt(2);Car car1 = new Car(Model.EDSEL, Color.GREEN, 1954);out.writeObject(car1);Car car2 = new Car(Model.MODEL_T, Color.BLACK, 1937);out.writeObject(car2);out.completeMessage();out.close();byte []data = bos.toByteArray();//反序列化ByteArrayInputStream bin = new ByteArrayInputStream(data);Hessian2Input in = new Hessian2Input(bin);in.startMessage();ArrayList list = new ArrayList();int length = in.readInt();for (int i = 0; i &lt; length; i++) &#123; list.add(in.readObject());&#125;in.completeMessage();in.close();bin.close();//压缩Deflation envelope = new Deflation();ByteArrayOutputStream bos = new ByteArrayOutputStream();Hessian2Output out = new Hessian2Output(bos);out = out.wrap(out);out.startMessage();Car car1 = new Car(Model.EDSEL, Color.GREEN, 1954);out.writeObject(car1);out.completeMessage();out.close();byte []data = bos.toByteArray();//解压Deflation envelope = new Deflation();ByteArrayInputStream bin = new ByteArrayInputStream(data);Hessian2Input in = new Hessian2Input(bin);in = envelope.unwrap(in);in.startMessage();Object value = in.readObject();in.completeMessage(); Protobuf（Protocol Buffers） 自定义.proto文件来定制序列化格式，需要学习其语法才能编写.proto文件 Protocol Buffer Language Guide：官方文档学习如何编写.proto文件 Java API Reference Java Generated Code Guide Encoding Reference：详细编码规则 拥有自己的编译器protocol buffer compiler 12345678910111213141516//.proto文件样例message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phone = 4;&#125; KryoFSTSerialize使用指南github地址 所需依赖12345&lt;dependency&gt; &lt;groupId&gt;de.ruedigermoeller&lt;/groupId&gt; &lt;artifactId&gt;fst&lt;/artifactId&gt; &lt;version&gt;2.56&lt;/version&gt;&lt;/dependency&gt; 使用样例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//用法一（线程安全）将对象序列化为byte数组，从byte数组反序列化回对象static FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration();// write序列化byte barray[] = conf.asByteArray(mySerializableObject);// read反序列化MyObject object = (MyObject)conf.asObject(barray);/** 为了可以确认反序列化数据的完整性，序列化时先序列化数据的长度，然后是数据本身 */// writebyte barray[] = conf.asByteArray(mySerializableObject);stream.writeInt(barray.length);stream.write(barray);[..flush..]// readint len = stream.readInt();int orglen = len;byte buffer[] = new byte[len]; // this could be reused !while (len &gt; 0) len -= in.read(buffer, buffer.length - len, len);// skipped: check for stream closeObject readObj = conf.getObjectInput(buffer).readObject();//方法二：使用FSTObjectOutput,FSTObjectInput替换ObjectOutputStream, ObjectInputStream；直接从流中反序列化或序列化为流public MyClass myreadMethod( InputStream stream ) throws IOException, ClassNotFoundException &#123; FSTObjectInput in = new FSTObjectInput(stream); MyClass result = (MyClass)in.readObject();//或者MyClass result = in.readObject(MyClass.class); in.close(); // required ! return result;&#125;public void mywriteMethod( OutputStream stream, MyClass toWrite ) throws IOException &#123; FSTObjectOutput out = new FSTObjectOutput(stream); out.writeObject( toWrite );//或者out.writeObject( toWrite, MyClass.class ); out.close(); // required !&#125;//方法三：为了优化对象重用和线程安全，FSTConfiguration 提供了两种简单的方式获取input/outputStream对象实例static FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration();...public MyClass myreadMethod(InputStream stream) throws IOException, ClassNotFoundException&#123; FSTObjectInput in = conf.getObjectInput(stream); MyClass result = in.readObject(MyClass.class); // DON&apos;T: in.close(); here prevents reuse and will result in an exception stream.close(); return result;&#125;public void mywriteMethod( OutputStream stream, MyClass toWrite ) throws IOException &#123; FSTObjectOutput out = conf.getObjectOutput(stream); out.writeObject( toWrite, MyClass.class ); // DON&apos;T out.close() when using factory method; out.flush(); stream.close();&#125;//方法四：将对象序列化为byte数组，或从byte数组反序列化回对象（ 以下DefaultCoder非线程安全，建议使用ThreadLocal&lt;DefaultCoder&gt;）DefaultCoder coder = new DefaultCoder(); // reuse this (per thread)/** 为了提升速度，DefaultCoder可以预注册一些常用的序列化类* DefaultCoder coder =new DefaultCoder(true,* Car.class, CarBench.Engine.class, * CarBench.Model.class,* CarBench.Accel.class, CarBench.PerformanceFigures.class,* CarBench.FueldData.class, CarBench.OptionalExtras.class);* /byte serialized[] = coder.toByteArray( someObject );Object deserialized = coder.toObject( serialized ); FSTConfigurationu解析 在序列化时定义编码解码，一般只需创建一个全局单例 123456public class MyApplication &#123; static FSTConfiguration singletonConf = FSTConfiguration.createDefaultConfiguration(); public static FSTConfiguration getInstance() &#123; return singletonConf; &#125;&#125; 序列化多版本兼容 使用注解@Version(n) Json重复对象的引用问题 fastjson支持循环引用，并且是缺省打开的。 当序列化后的JSON传输到浏览器或者其他语言中，这些json解析器不支持循环引用，从而导致数据丢失。你可以关闭fastjson的循环引用支持。关闭引用检测，还能够提升序列化时的性能。 全局配置关闭 JSON.DEFAULT_GENERATE_FEATURE |= SerializerFeature.DisableCircularReferenceDetect.getMask(); 非全局配置关闭 JSON.toJSONString(obj, SerializerFeature.DisableCircularReferenceDetect); 引用语法语法———————————–描述{“$ref”:”$”}—————————引用根对象{“$ref”:”@”}————————–引用自己{“$ref”:”..”}—————————引用父对象{“$ref”:”../..”}————————-引用父对象的父对象{“$ref”:”$.members[0].reportTo”}—基于路径的引用 序列化/反序列化版本问题部分序列化/指定序列化 JSONField 若属性是私有的，必须有set*方法。否则无法反序列化。 JSONField使用指南 123456789101112public @interface JSONField &#123; // 配置序列化和反序列化的顺序，1.1.42版本之后才支持 int ordinal() default 0; // 指定字段的名称 String name() default &quot;&quot;; // 指定字段的格式，对日期格式有用 String format() default &quot;&quot;; // 是否序列化 boolean serialize() default true; // 是否反序列化 boolean deserialize() default true;&#125; JSONField配置方式 配置在getter/setter上 配置在field上 123456789101112131415//配置在getter/setter上 public class A &#123; private int id; @JSONField(name=&quot;ID&quot;) public int getId() &#123;return id;&#125; @JSONField(name=&quot;ID&quot;) public void setId(int value) &#123;this.id = id;&#125; &#125;//配置在field上 public class A &#123; @JSONField(name=&quot;ID&quot;) private int id; public int getId() &#123;return id;&#125; public void setId(int value) &#123;this.id = id;&#125; &#125; 使用format配置日期格式化 12345public class A &#123; // 配置date序列化和反序列使用yyyyMMdd日期格式 @JSONField(format=&quot;yyyyMMdd&quot;) public Date date; &#125; 使用serialize/deserialize指定字段不序列化 12345678public class A &#123; @JSONField(serialize=false) public Date date; &#125;public class A &#123; @JSONField(deserialize=false) public Date date; &#125; 使用ordinal指定字段的顺序 默认按照字段字母排序 12345678public static class VO &#123; @JSONField(ordinal = 3) private int f0; @JSONField(ordinal = 2) private int f1; @JSONField(ordinal = 1) private int f2;&#125; 使用serializeUsing制定属性的序列化类 在fastjson 1.2.16版本之后，JSONField支持新的定制化配置serializeUsing，可以单独对某一个类的某个属性定制序列化 123456789101112public static class Model &#123; @JSONField(serializeUsing = ModelValueSerializer.class) public int value;&#125;public static class ModelValueSerializer implements ObjectSerializer &#123; @Override public void write(JSONSerializer serializer, Object object, Object fieldName, Type fieldType,int features) throws IOException &#123; Integer value = (Integer) object; String text = value + &quot;元&quot;; serializer.write(text); &#125;&#125;]]></content>
      <categories>
        <category>Json</category>
      </categories>
      <tags>
        <tag>Json</tag>
        <tag>Serializetion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2018%2F04%2F22%2FJVM%2F</url>
    <content type="text"><![CDATA[步入java虚拟机的世界 内存管理 运行时数据区域 内存分配与回收 虚拟机对象 垃圾回收 垃圾回收算法 垃圾收集器 GC日志 class文件 类加载机制 自定义类加载器 建议读者自行了解java的技术体系结构以及java虚拟机的历史发展，这里不做叙述！ 包括一套字节码指令集、一组寄存器、一个栈、 一个垃圾回收，堆 和 一个存储方法 内存管理运行时数据区域 程序计数器(线程私有) PC寄存器（pc计数器） 通过计数器来知道下一条应该执行的指令，精准记录各个线程正在执行的当前字节码指令地址 虚拟机栈（线程私有） 也可以叫做JAVA栈 ，代表了处理逻辑 ，每当启动一个新线程时，JAVA虚拟机就会为他分配一个JAVA栈（以栈帧为单位保存线程的运行状态）。单位为栈帧 （每调用一个方法时，都会创建一个新的栈帧） ，由局部变量表 （存储方法参数和局部变量 ，所需内存空间编译器完成，运行期间不变），操作数栈 ，动态链接 （指向运行时常量池中该栈帧所属方法的引用 ），方法返回值 四部分组成。 本地方法栈（线程私有） 虚拟机执行native方法，hotspot中将本地方法栈和虚拟机栈合二为一，作用类似 java堆（线程共享） 堆 ，代表了数据，运行时动态分配内存 一个JAVA程序在运行时创建的所有的类实例或数组都放在同一个堆里面。 一个JAVA虚拟机实例中只会存在一个堆空间，所有的线程共享这个堆空间。 一个JAVA 程序独占一个JAVA虚拟机实例。 所以每个JAVA程序都有自己的堆空间，彼此互不干扰。 堆中的的分代： YoungGen（新生代，存放新生对象或年龄不大的对象）{Eden(8/10) + From Survivor(1/10) + To Survivor(1/10)}，占堆的1/3 OldGen（老生代，存放大对象或者年龄较大的对象），占堆的2/3 方法区 方法区—编译后代码的存储区，存储了每一个java类的结构信息，逻辑上独立，物理上属于堆的一部分 运行时常量区 运行时常量池—方法区的一部分，用于存放编译器生成的字面量和符号引用 直接内存（主要用于nio） 本地函数库直接分配内存，由堆中一个DirectorByteBuffer指向引用操作 永久代 PermGen 指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被 放入永久区域，它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这 也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。 JAVA8与元数据（metaspace） 在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间 的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用 本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 native memory, 字符串池和类的静态变量放入 java 堆中，这样可以加载多少类的元数据就不再由 MaxPermSize控制（由新增参数-XX:MetaspaceSize=size和-XX:MaxMetaspaceSize=size来控制大小）, 而由系统的实际可用空间来控制。 内存分配与回收 大多数情况下，对象直接在Eden区域分配，如果该区域不够，则虚拟机进行一次minorGC minorGC：新生代GC，由于新生代对象生命周期较短，朝生夕灭，所以minorGC较为频繁，速度较快 以复制算法为例，minorGC一次的全过程如下 eden 、 servicorFrom 复制到 ServicorTo ，年龄 + 1：首先，把Eden和ServivorFrom区域中存活的对象复制到ServicorTo区域（如果有对象的年 龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不 够位置了就放到老年区，这种现象叫做提前晋升，需要根据实际情况调整servicor区域的大）； 清空 eden 、 servicorFrom 然后，清空Eden和ServicorFrom中的对象； ServicorTo和 ServicorFrom互换：最后，ServicorTo和ServicorFrom互换，原ServicorTo成为下一次GC时的ServicorFrom 区。 majorGC：老年代GC，大对象，周期较长，不频繁，速度比minorGC慢十倍左右，一般majorGC的发生总会伴随着至少一次的minorGC 大对象直接在老年代分配（应该尽量避免短命大对象） 对象年龄计数器：在Eden出生经过一次minorGC并且被survivor接收的话（如果survivor不接受则进入老年代），进入survivor后年龄设置为1，然后每熬过一次minorGC，年龄加一，到达一定年龄后进入老年代，默认年龄是15岁进入老年代。 动态年龄判定：survivor中相同年龄的对象大小总和大于survivor空间大小的一半时，所有大于等于该年龄的对象进入老年代 空间分配担保：minorGC前会判断老年代中空闲空间大小是否大于新生代所有对象所占空间总和，大于则绝对安全（即使minorGC后新生代对象所有都进入老年代，也可以容的下），否则需要风险担保，由于具体进入老年代的对象所占空间大小在minorGC之后才能确定，所以在此之前，老年代会采用之前数据的平均值来预估是否可以容下即将进入老年代的所有对象，故存在一定风险导致容不下，而导致发生fullGC（我们的目标是尽量减少fullgc，因为耗时太久）。 虚拟机对象 对象的创建 这里指的是普通对象的创建，即我们最常使用的关键字new创建对象的过程（不包括数组对象和class对象） 首先在常量池中定位该类的符号引用是否存在 存在紧接着判定是否加载过（即经历了加载，解析，初始化三个阶段） 加载过然后堆中分配内存空间，具体大小加载中已计算出来 这里涉及到堆中分配策略：主要有两种，指针碰撞和空闲列表 指针碰撞：堆内存空间规整，已分配/未分配空间区域有明确分界线，这时只需要将指针向一个未分配区域方向移动所需空间大小即可实现对象的堆中内存空间分配 空闲列表：堆内存空间不规整，这样的话就得维护一个列表，负责记录空闲空间，然后从列表中找出一个符合分配对象大小的空间分配给它 堆空间的规整与否，取决于垃圾回收器是否有压缩整理功能 考虑到并发操作的安全性，提出了两种解决方案：1. cas原子性操作，2. 本地线程分配缓冲池TLAB—java堆区域中一块线程私有区域，包含在Eden空间中，用于快速分配策略（每一个线程在堆中的一小块内存空间，操作系统中称为快表，因为线程私有，所以线程安全，只有TLAB分配完后才从共享堆中执行原子性操作分配空间） TlAB分配失败直接在Eden中分配，Eden也失败则执行GC，如果是大对象直接在老年代中分配 内存空间分配好后初始化内存空间 然后设置对象头（对象头用于存放类的各种信息，类比报文头理解） init() 对象访问定位 栈中reference引用数据指向堆中对象(具体访问实现调用由虚拟机实现，因此不同虚拟机实现不同,主流有两种，句柄，直接指针。见下图理解） 句柄实现如下： 直接指针实现如下： 垃圾回收如何判定对象可以进行回收 引用计数法：简而言之就是记录对象的引用数，为零时可回收，但是该方法无法解决对象的循环引用问题 可达性分析算法（简单来说，就是图的根节点如果无法间接相连到该节点，则说明该节点不可达，回收，如下图所示） 引用分类（由于以前引用的定义过于狭隘，而现实中我们想实现一种“空间充足，则对象存在，空间紧迫，则对象回收”的美好愿景，于是引用分类由此而生） 强引用 软引用：有用非必须，内存溢出之前进行回收 弱引用：只能存活到下一次垃圾回收之前 虚引用（依次递减）：无法通过该引用获得实例对象，其存在的唯一目的就是进行垃圾回收时会收到一个系统通知 一个对象的死亡之路： 首先可达性分析—–&gt;不可达—–&gt;第一次标记，筛选（即一次miniorGC过程）——&gt;若没有覆盖finalize()方法/或已执行finalize方法——&gt;否——&gt;执行finalize方法—–&gt;放入F-queue队列中—-&gt;一定时间后执行二次标记（在此之前如果队列中对象可以再次获取引用，则到时候出队列躲过被回收的命运，否则就真的被回收） finalize（claner） 当垃圾回收确定不再有对该对象的引用时，由垃圾回收器在对象上调用。子类覆盖finalize方法以处置系统资源或执行其他清除。 finalize的一般约定是，当Java™虚拟机确定不再有任何手段可以使尚未死亡的任何线程可以访问该对象时（除非是由于操作而导致），调用finalize。由完成的其他一些对象或类的完成确定。 finalize方法可以采取任何措施，包括使该对象可再次用于其他线程。但是，完成的通常目的是在清除对象之前将其清除。例如，代表输入/输出连接的对象的finalize方法可能会执行显式I / O事务，以在永久丢弃该对象之前中断连接。 Object类的finalize方法不执行任何特殊操作；它只是正常返回。 Object的子类可以覆盖此定义。 Java编程语言不能保证哪个线程将为任何给定对象调用finalize方法。但是，可以保证，在调用finalize时，调用finalize的线程将不持有任何用户可见的同步锁。如果finalize方法抛出未捕获的异常，则该异常将被忽略，并且该对象的终结将终止。 在为对象调用finalize方法之后，直到Java虚拟机再次确定不再有任何方法可以由尚未死亡的任何线程访问该对象之后，才采取进一步的措施，包括可能的措施可以通过其他准备完成的对象或类来完成，此时可以丢弃该对象。 对于任何给定的对象，Java虚拟机都不会多次调用finalize方法。 由finalize方法引发的任何异常都将导致此对象的终止终止，但否则将被忽略。 System.gc()与System.runFinalization()方法增加了finalize()方法执行的机会，但不可盲目依赖它们 finalize()方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize()的执行 对象再生问题：finalize()方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的；即：当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后（释放非堆内存资源），GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。 在Java类中实现finalize方法，该方法会在Java对象回收的时候得到调用。这样我们便可以在finalize方法中去释放native对象，让Java资源和native资源在GC过程中同时释放。不过finalize方法有诸多缺陷，最终在JDK 9中被弃用。替代它的是Cleaner类。 垃圾回收算法 标记清除算法：先标记回收对象，然后统一回收，效率较低，导致内存碎片过多，使得内存利用率降低 复制算法：将内存空间对半分为相等的两部分，一半使用，另一半保留，当需要回收时将使用过的那一半中的对象复制到保留未使用的一般中，然后清空那一半空间保留下一次回收时使用。此方法可以避免内存碎片，提高内存利用率。 标记整理算法：先标记，后移动可用空间到一起，然后统一清除剩下的 分代回收算法：按生存周期划分内存空间，不同空间采用不同的回收算法。新生代（复制算法）老年代（对象存活率高，采用标记清除/整理算法） 垃圾收集器：内存回收的具体实现- serial：单线程+stop the world-----新生代收集器（单线程、复制算法） - parnew：多线程版本的serial-----新生代收集器（Serial+多线程） - paralel scavenge：关注点在高吞吐量，提高cpu效率，新生代收集器（多线程复制算法、高效） - seri old：serial的老年代收集器版本，（单线程标记整理算法 ） - paralel old：paralel scavenge的老年代收集器版本，多线程 - cms：（多线程标记清除算法）强调一次GC过程的最短停顿时间，老年代收集器 - g1：最前沿成果，基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 GC日志阅读 GC日志的阅读有助于处理遇到的内存问题，就好比看日志调试bug一样 认识class文件 虚拟机不与包括java在内的所有语言绑定，而是与class文件绑定，意味着和虚拟机打交道的是class文件 首先了解class文件是一组以8位字节为基础单位的二进制流； 其编译原理过程较为复杂，这里不做深究，大致过程为：词法分析（生成Token序列）—语法分析（生成抽象语法树）—语义分析（完善语法树）—生成最终字节码 本章节重点了解class文件的结构组成： （其结构如下图所示） （U1,U2,U4分别表示1，2，4个字节的无符号数）ClassFile表结构是class文件的最外层结构，即class文件的格式 第一项为魔数：CA-FE-BA-BE（cafebabe）（对应的十进制为202-254-186-190），用于判定是否为java-class文件。 第二项是主次版本号（；不同版本的jvm编译下的class文件在其他版本的jvm下不适用） 第三项是常量池（常量池数量+常量池数组），存在于方法区中，由11种基本的常量项（常量表）组成，Java程序的一个类中的所有常量数据都将存储在这里，像类名，方法名，返回类型等等 1234项的通用格式 cp_info&#123; u1 tag； u1 info[]; &#125; 第四项：access_flags 第五项：this_class，记录当前类的全限定名（包名+类名），其值指向常量池中对应的索引值 第六项：supper_class 记录当前类的父类的全限定名， 第七项：interface_count，记录当前类的实现的接口数量 第八项：interface，记录当前类实现的接口 第九项：field_count，记录当前类的定义的变量的总数量 第十项：field 变量详细信息 字段表代码结构如下： 1234567Filed_info&#123; u2 access_flags;（访问权限和基本属性的掩码标志） u2 name_index; u2 descriptor_index; u2 attributes_counts; Attribute_info attributes[attributes_counts]; &#125; 方法表代码结构如下： 1234567method_info&#123; u2 access_flags;（访问权限和基本属性的掩码标志） u2 name_index; u2 descriptor_index; u2 attributes_counts; Attribute_info attributes[attributes_counts]; &#125; 注：类和接口的名称采用全限定形式 ；方法，字段名，局部变量采用非全限定形式 Class文件校验 Class文件加载过程：装载—链接（验证(确保类型格式)—准备(分配内存)—解析(常量池中的符号链接转换为直接引用)）—初始化(赋予初值)方法 注：类型的初始化方法，jvm决定加载某个类型时调用该方法类的构造函数，jvm决定实例化某个类型时调用该方法 类加载机制类加载过程 加载-（验证-准备-解析（只有该阶段执行顺序不一定，可变））统称为连接-初始化-使用-卸载 加载： 通过一个类 的全限定名来获取的此类的二进制字节流 将这字节流所代表的静态存储结构转化为方法区运行时数据结构 在内存中生成一个代表这个类的class对象，作为方法区这个类的各种数据的访问入口 验证：连接第一步，保证class文件中字节流包好信息符合虚拟机要求，其中包括文件格式，元数据验证，字节码验证，符号引用验证 准备：类变量分配内存（包好static，不包含实例变量），初始化变量值 解析：虚拟机将 常量池内符号引用替换为直接引用 符号引用：与虚拟机布局无关，引用目标不一定加载到内存中，class文件中明确规定 直接引用：与虚拟机布局有关，引用目标必然存在于内存中 初始化：执行类构造器方法的过程 方法详解 编译器自动收集类中所有的类变量的赋值动作和静态语句块中语句合并而成（静态语句块中只能访问到定义在静态语句块之前的变量，定义在之后的只能赋值，不能访问） 不同于构造函数（init()函数），它不会显示的调用父类构造器，虚拟机保证在子类的clinit之前父类clinit已经执行完毕，所以虚拟机中第一个执行的肯定是object的clinit 如果一个类或者接口中没有静态语句块，并且没有对变量的赋值操作，编译器可以不生成clinit方法 类加载器 通过一个类的全限定名来获取描述此类的二进制字节流“这个动作在虚拟机外部实现， 同一份class文件，不同的类加载器加载后形成的类不一样 jvm判定两个class是否相同：class的全限定名是否相同；是否同一个classloader加载 启动类加载器：BoostropClassLoader，c++实现，虚拟机自身一部分（负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等） 其他所有类加载器：java实现，虚拟机外部 扩展类加载器（负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar） 应用程序加载器（负责加载应用程序classpath目录下的所有jar和class文件） 自定义加载器（例如：加载网络中的class文件） String rootUrl = “http://localhost:8080/httpweb/classes“; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Object obj1 = clazz1.newInstance(); 双亲委派模型：类加载器收到类加载请求后，将请求委派给父加载器，所有的请求最终被传送到启动类加载器上，只有父加载器自己无法完成加载后，子加载器才会自己加载，这样可以有效防止类的重复加载 Jvm参数生产实例-UCC-server ：选择服务器应用程序运行时优化。 目录服务器将需要更长的时间来启动和“预热”，但将进行更积极的优化以产生更高的吞吐量。-d64 ：仅适用于64位的机器，默认是32位机器-Xmx8g ：jvm最大堆内存空间大小-Xms8g ：jvm最小堆内存空间大小-Xmn1g ：年轻代占内存大小-XX:PermSize=512m 设置永久代大小，避免内存泄露异常java.lang.OutOfMemoryError: PermGen space-Xss2m ：分配给单个线程的空间-XX:+DisableExplicitGC ：防止外部应用程序强制进行昂贵的垃圾收集。 如果使用jstatd或其他基于RMI的应用程序来监视Oracle Unified Directory，则应考虑使用此选项以避免意外暂停。-XX:+UseConcMarkSweepGC ：选择CMS垃圾收集器。 此垃圾收集器设置为低暂停时间。 这将导致Java应用程序具有较低的平均吞吐量，但CPU密集型垃圾收集要短得多。 在具有响应时间限制的环境中，此选项是必需的。-XX:+CMSParallelRemarkEnabled-XX:+UseCMSCompactAtFullCollection-XX:LargePageSizeInBytes=128m-XX:+UseFastAccessorMethods-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=70 ：选择GC开始的级别。 默认值为68％。-XX:+PrintGCDetails ：打印GC细节-XX:+PrintGCTimeStamps ：打印垃圾收集时间戳以帮助调试。-Xloggc:./logs/gc.log-XX:-HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./logs” 生产实例-CMC-server-Xmx8g-Xms8g-Xmn256m-Xss256k-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-Xloggc:./logs/gc.log-XX:-HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./logs” 垃圾收集器参数-XX:+UseSerialGC-XX:+UseParallelGC-XX:+USeParNewGC-XX:+UseG1GC-XX:+UseParallelOldGC ：选择并行的老年代垃圾收集器。 此垃圾收集器设置为高吞吐量。 它将使import-ldif实用程序的平均吞吐量最大化，代价是偶尔停止世界的垃圾收集。 GC日志参数-XX:+UseGCLogFileRotation-XX:NumberOfGCLogFiles=&lt; number of log files &gt;-XX:GCLogFileSize=&lt; file size &gt;[ unit ]-Xloggc:/path/to/gc.log 内存溢出参数-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./java_pid.hprof-XX:OnOutOfMemoryError=”&lt; cmd args &gt;;&lt; cmd args &gt;” -XX:OnOutOfMemoryError=”shutdown -r”-XX:+UseGCOverheadLimit 其他参数-XX:+UseStringDeduplication ：Java 8u20引入了这个JVM参数，通过创建相同String的太多实例来减少不必要的内存使用; 这通过将重复的String值减少到单个全局char []数组来优化堆内存-XX:LargePageSizeInBytes ：设置用于Java堆的大页面大小; 它采用GB / MB / KB的参数; 通过更大的页面大小，我们可以更好地利用虚拟内存硬件资源; 但是，这可能会导致PermGen的空间大小增加，从而可以强制减小Java堆空间的大小-XX:MaxHeapFreeRatio：在GC之后设置堆的最大自由百分比以避免收缩。-XX:MinHeapFreeRatio ：GC后设置堆的最小自由百分比以避免扩展; 监视堆使用情况，您可以使用JDK附带的VisualVM。-XX:SurvivorRatio ：eden/survivor空间大小的比例-XX:+UseStringCache: 字符串缓存-XX:+UseCompressedStrings:压缩字符串 扩展Categories of JVM arguments （Jvm参数分类） Standard Options (-D but not only).These are the most commonly used options that are supported by all implementations of the JVM.You use -D to specify System properties but most of them don’t have any prefix :-verbose, -showversion, and so for… Non-Standard Options (prefixed with -X)These options are general purpose options that are specific to the Java HotSpot Virtual Machine.For example : -Xmssize, -Xmxsize Advanced Runtime Options (prefixed with -XX)These options control the runtime behavior of the Java HotSpot VM. Advanced JIT Compiler Options (prefixed with -XX)These options control the dynamic just-in-time (JIT) compilation performed by the Java HotSpot VM. Advanced Serviceability Options (prefixed with -XX)These options provide the ability to gather system information and perform extensive debugging. Advanced Garbage Collection Options (prefixed with -XX)These options control how garbage collection (GC) is performed by the Java HotSpot VM. 自定义类加载器ClassLoader 继承java.lang.ClassLoader 重写父类的findClass方法 从源获取class文件内容（例如：从网络URL加载class文件（使用inputStream获取class文件的byte[]）） 非自定义类加载器获取class文件通过java本地接口（native）实现 将获取到的class文件内容转换成jvm内的class对象实例 自定义/非自定义类加载器都是通过java本地接口完成转换 注意：因为JDK已经在loadClass方法中帮我们实现了ClassLoader搜索类的算法，当在loadClass方法中搜索不到类时，loadClass方法就会调用findClass方法来搜索类，所以我们只需重写该方法即可。如没有特殊的要求，一般不建议重写loadClass搜索类的算法。 https://gist.github.com/LFstefan/6b1d82511b0bf435c14a01907809827d JDK目录结构解析（JDK1.8目录结构） bin目录：Java工具的可执行文件，包括: java、Java编译器javac、反编译.class文件javap、密钥管理工具keytool、Java文档工具javadoc等。 db目录：Java实现的数据库。 include目录：.h头文件，C语言开发时用到的头文件。比如jni.h是开发jni程序时必须引用的头文件。 lib目录： Java类库，我们经常看到的dt.jar和tools.jar就在这个目录下。 dt.jar包含了Swing包，是运行环境的类库。 tools.jar是工具类库，bin目录下的可执行程序，好多都会用到这个类库。 src.zip文件：Java类库源码，包括了rt.jar库中的关键部分；除了Java类库，还包含了启动器（launcher）的源码（C语言实现）。 jre目录：Java运行环境。后面会展开了讲它的目录结构。 jre目录结构 bin目录：包含了java运行所需要的可执行文件，比如java[.exe] lib目录：包含了运行时依赖的java类库和动态链接库（.so或.dll或.dylib） amd64目录下包含了程序运行所需的动态链接库，在amd64/server目录下，可以找到JVM库：libjvm.so。 rt.jar文件是java运行时类库，是我们用到最多的基础类库，包括java.lang，java.io，java.net，java.util等。 如何打破双亲委派模型 自定义类加载器，基于双亲委派模型自定义类加载顺序模型 javap可视化class文件解读 javap -v xxx.class &gt; output.txt：该命令可以将指定的class文件以可读的格式输出到文本文件中 StackMapTable：在Java 6版本之后JVM在class文件中引入了栈图(StackMapTable)。作用为了提高JVM在类型检查的验证过程的效率。栈图结构位于Code属性（指Classfile的Code属性）的属性表（ attributes table）结构中。在字节码的Code属性中最多包含一个StackMapTable属性。 在Java 7版本之后把栈图作为字节码文件中的强制部分。 本来程序员是不需要关心JVM中的JIT编译器的细节，也不用知道编译原理或者数据流、控制流的细节。但栈图强制了，如果要生成bytecode，必须准确知道每个字节码指令对应的局部变量和操作数栈的类型。这是因为Java7在编译的时期做了一些验证期间要做的事情，那就是类型检查，也就是栈图包含的内容。但是Java的验证在类加载的时候只会运行一次，而占据了大部分时间的操作是IO的消耗，而不是验证过程。即使现在有了栈图，验证过程依然会执行，栈图的存在只是节省了一部分的验证时间。并且JVM的设计者还必须兼容没有栈图的验证的实现，因为Java7以前版本是没有强制栈图这个概念的，然而Java8依然延续了栈图的字节码结构。 Hotspot中java对象的内存布局 每个java对象在内存中都由对象头和对象体组成。 对象头是存放对象的元信息，包括该对象所属类对象Class的引用以及hashcode和monitor的一些信息。 对象体主要存放的是java对象自身的实例域以及从父类继承过来的实例域，并且内部布局满足由下规则： 规则1：任何对象都是8个字节为粒度进行对齐的。 规则2：实例域按照如下优先级进行排列：长整型和双精度类型；整型和浮点型；字符和短整型；字节类型和布尔类型，最后是引用类型。这些实例域都按照各自的单位对齐。 规则3：不同类继承关系中的实例域不能混合排列。首先按照规则2处理父类中的实例域，接着才是子类的实例域。 规则4：当父类中最后一个成员和子类第一个成员的间隔如果不够4个字节的话，就必须扩展到4个字节的基本单位。 规则5：如果子类第一个实例域是一个双精度或者长整型，并且父类并没有用完8个字节，JVM会破坏规则2，按照整形（int），短整型（short），字节型（byte），引用类型（reference）的顺序，向未填满的空间填充。 64位出现给jvm带来的影响 64位字长的出现，导致操作系统内存扩大（原先32位，4G）；64位的jvm也应用而生（增大的java堆），同时也导致了vm内部java对象表示（oops：普通对象指针）由32位增加到了64位，长度增加导致 cpu 高速缓存行中可用的oops减少，降低了cpu缓存的效率；从而导致jvm性能下降了 8～15% ； 解决方案：新版jvm出了压缩指针 -XX:UseCompressedOops 弥补了字长增加导致的性能下降问题，同时还有所提升 64位，意味着同时可以使用更多的寄存器，避免寄存器的卸载发生，（就是变量超过寄存器数量，就会有一部分被存储在内存中，需要时和寄存器中内容交换，类似内存页面交换，这里称之为寄存器卸载） JIT 在部分商用虚拟机中（如HotSpot），Java程序最初是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“热点代码”。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（Just In Time Compiler，下文统称JIT编译器）。 即时编译器并不是虚拟机必须的部分，Java虚拟机规范并没有规定Java虚拟机内必须要有即时编译器存在，更没有限定或指导即时编译器应该如何去实现。但是，即时编译器编译性能的好坏、代码优化程度的高低却是衡量一款商用虚拟机优秀与否的最关键的指标之一，它也是虚拟机中最核心且最能体现虚拟机技术水平的部分。 由于Java虚拟机规范并没有具体的约束规则去限制即使编译器应该如何实现，所以这部分功能完全是与虚拟机具体实现相关的内容，如无特殊说明，我们提到的编译器、即时编译器都是指Hotspot虚拟机内的即时编译器，虚拟机也是特指HotSpot虚拟机。 尽管并不是所有的Java虚拟机都采用解释器与编译器并存的架构，但许多主流的商用虚拟机（如HotSpot），都同时包含解释器和编译器。解释器与编译器两者各有优势： 当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释器执行节约内存，反之可以使用编译执行来提升效率。此外，如果编译后出现“罕见陷阱”，可以通过逆优化退回到解释执行。 注意⚠️：对一般的Java方法而言，编译后代码的大小相对于字节码的大小，膨胀比达到10x是很正常的。同上面说的时间开销一样，这里的空间开销也是，只有对执行频繁的代码才值得编译，如果把所有代码都编译则会显著增加代码所占空间，导致“代码爆炸”。这也就解释了为什么有些JVM会选择不总是做JIT编译，而是选择用解释器+JIT编译器的混合执行引擎。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Heap</tag>
        <tag>Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq Monitor]]></title>
    <url>%2F2018%2F04%2F22%2FRabbitmq%20Monitor%2F</url>
    <content type="text"><![CDATA[Rabbitmq Monitor 监控脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/bin/bashfunction monitor_overview_message_stat()&#123; # 总体消息状态，从接收第一个消息开始 MESSAGE_STAT=$(curl -H &apos;Content-Type: application/json&apos; -G -s -u &apos;root:5gXsq4beBACfNVyq0xMhR&apos; 127.0.0.1:15672/api/overview | /home/eshop/jq .message_stats) ACK=$(echo $MESSAGE_STAT | /home/eshop/jq .ack) ACK_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .ack_details.rate) COMFIRM=$(echo $MESSAGE_STAT | /home/eshop/jq .confirm) COMFIRM_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .confirm_details.rate) DELIVER=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver) DELIVER_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver_details.rate) DELIVER_GET=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver_get) DELIVER_GET_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver_get_details.rate) DELIVER_NO_ACK=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver_no_ack) DELIVER_NO_ACK_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .deliver_no_ack_details.rate) DISK_READ=$(echo $MESSAGE_STAT | /home/eshop/jq .disk_reads) DISK_READ_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .disk_reads_details.rate) DISK_WRITE=$(echo $MESSAGE_STAT | /home/eshop/jq .disk_writes) DISK_WRITE_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .disk_writes_details.rate) PUBLISH=$(echo $MESSAGE_STAT | /home/eshop/jq .publish) PUBLISH_RATE=$(echo $MESSAGE_STAT | /home/eshop/jq .publish_details.rate) printf &quot;%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s\n&quot; &quot;publish&quot; &quot;ack&quot; &quot;confirm&quot; &quot;deliver&quot; &quot;deliver_get&quot; &quot;deliver_no_ack&quot; &quot;disk_reads&quot; &quot;disk_writes&quot; printf &quot;%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s\n&quot; &quot;$PUBLISH / $PUBLISH_RATE&quot; &quot;$ACK / $ACK_RATE&quot; &quot;$COMFIRM / $COMFIRM_RATE&quot; &quot;$DELIVER / $DELIVER_RATE&quot; &quot;$DELIVER_GET / $DELIVER_GET_RATE&quot; &quot;$DELIVER_NO_ACK / $DELIVER_NO_ACK_RATE&quot; &quot;$DISK_READ / $DISK_READ_RATE&quot; &quot;$DISK_WRITE / $DISK_WRITE_RATE&quot; printf &quot;\n&quot;&#125;function monitor_overview_current_data()&#123; OVERVIEW=$(curl -H &apos;Content-Type: application/json&apos; -G -s -u &apos;root:5gXsq4beBACfNVyq0xMhR&apos; 127.0.0.1:15672/api/overview) # 当前实时数据 包含overview下 churn_rates ， queue_totals ， object_totals CHURN_RATE=$(echo $OVERVIEW | /home/eshop/jq .churn_rates) QUEUE_TOTALS=$(echo $OVERVIEW | /home/eshop/jq .queue_totals) OBJECT_TOTALS=$(echo $OVERVIEW | /home/eshop/jq .object_totals) # 通道关闭数量/速率 CHANN_CLO=$(echo $CHURN_RATE | /home/eshop/jq .channel_closed) CHANN_CLO_RATE=$(echo $CHURN_RATE | /home/eshop/jq .channel_closed_details.rate) # 通道创建数量/速率 CHANN_CRE=$(echo $CHURN_RATE | /home/eshop/jq .channel_created) CHANN_CRE_RATE=$(echo $CHURN_RATE | /home/eshop/jq .channel_created_details.rate) # 连接关闭数量/速率 CONN_CLO=$(echo $CHURN_RATE | /home/eshop/jq .connection_closed) CONN_CLO_RATE=$(echo $CHURN_RATE | /home/eshop/jq .connection_closed_details.rate) # 连接创建数量/速率 CONN_CRE=$(echo $CHURN_RATE | /home/eshop/jq .connection_created) CONN_CRE_RATE=$(echo $CHURN_RATE | /home/eshop/jq .connection_created_details.rate) # 当前所有队列消息总数量 MESSAGE=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages) MESSAGE_RATE=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages_details.rate) # 当前所有队列ready状态消息总数量 MESSAGE_READY=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages_ready) MESSAGE_READY_RATE=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages_ready_details.rate) # 当前所有队列unack状态消息总数量 MESSAGE_UNACK=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages_unacknowledged) MESSAGE_UNACK_RATE=$(echo $QUEUE_TOTALS | /home/eshop/jq .messages_unacknowledged_details.rate) # 当前通道数量和连接数量 CHANNELS=$(echo $OBJECT_TOTALS | /home/eshop/jq .channels) CONNECTIONS=$(echo $OBJECT_TOTALS | /home/eshop/jq .connections) printf &quot;%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s\n&quot; &quot;messages&quot; &quot;msg_ready&quot; &quot;msg_unack&quot; &quot;connections&quot; &quot;channels&quot; &quot;conn_created&quot; &quot;conn_closed&quot; &quot;chan_created&quot; &quot;chan_closed&quot; printf &quot;%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s%-20s\n&quot; &quot;$MESSAGE / $MESSAGE_RATE&quot; &quot;$MESSAGE_READY / $MESSAGE_READY_RATE&quot; &quot;$MESSAGE_UNACK / $MESSAGE_UNACK_RATE&quot; &quot;$CONNECTIONS&quot; &quot;$CHANNELS&quot; &quot;$CONN_CRE / $CONN_CRE_RATE&quot; &quot;$CONN_CLO / $CONN_CLO_RATE&quot; &quot;$CHANN_CRE / $CHANN_CRE_RATE&quot; &quot;$CHANN_CLO / $CHANN_CLO_RATE&quot; printf &quot;\n&quot;&#125;# interval timeSLEEP_SECOND=$1while truedo monitor_overview_current_data sleep $SLEEP_SECONDdone]]></content>
      <categories>
        <category>Rabbitmq</category>
      </categories>
      <tags>
        <tag>Rabbitmq</tag>
        <tag>MQ</tag>
        <tag>Monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Compile JDK]]></title>
    <url>%2F2018%2F04%2F15%2FCompile%20JDK%2F</url>
    <content type="text"><![CDATA[动手编译JDK README-builds.html，每一份源码内均存在的编译指南，英语基础好的童鞋可直接参考该文档，比起网络上的资源，官方文档始终应该作为第一选择！ 前言 如果你是linux操作系统小白，上来就想挑战编译jdk，那么你将会遇到重重困难，但是这同时也是一个非常好的学习机会，因为你会突然间接触到非常多的新知识，过程中的每一个坑，每一次失败都将成为你进步的垫脚石，期间需要你非常耐心的去面对和处理每一个问题，分析其原因并总结经验教训，切记不可急躁，你所花费的每一分钟都将会有所收获，急躁只会打乱你的思考，导致考虑问题的轨道产生偏差，从而绕其弯路，文章只会告诉你如何编译jdk，但不会告诉你怎么操作才能看到最后的成功标志，需要你自己去一遍思考一遍了解为何这样做，祝各位旅途愉快，到达成功的终点。（大佬们请自动忽略我的废话，直接找寻你们的目标信息即可） 目录 材料准备 编译jdk 过程总结 涉及知识清单 正文材料准备 linux操作系统 系统中常用的工具及依赖自行安装，如不清楚编译jdk需要哪些依赖及工具可参考附录 系统网络状态正常，因为编译中途会涉及到下载相关依赖 openjdk7，用于后续的jdk编译（这里的jdk不同于后续待编译的jdk，这里jdk是我们平时正常使用的jdk，因为jdk各个组成部分有的是用c/c++写的，有的是用java写的，所以后续编译java代码时需要用到） openjdk源码（此为我们后续编译的jdk源代码，版本自行选择，这里使用的7） 获取 OpenJDK 源码大致有两种方式 通过 Mercurial 代码版本管理工具从 Repository 中直接取得源码，这就需要我们先安装工具Mercurial，安装过程自行查阅资料。 注意：使用Mercrial工具下载源码时，结果可能由于网络原因导致源码文件有所缺失，从而后续命令失败。 从网站上下载： http://download.java.net/openjdk/jdk7/promoted/b147/openjdk-7-fcs-src-b147-27_jun_2011.zip 编译jdk 环境变量配置 编辑环境变量命令：vi /etc/profile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748语言选项,这个必须设置,否则编译好后会出现一个HashTable的NPE错export LANG=CBootstrap JDK的安装路径。必须设置export ALT_BOOTDIR=/usr/local/java/jdk1.8.0_101 允许自动下载依赖export ALLOW_DOWNLOADS=true并行编译的线程数,设置为和CPU内核数量一致即可export HOTSPOT_BUILD_J0BS=6export ALT_PARALLEL_COMPILE_JOBS=6 比较本次build出来的映像与先前版本的差异。这对我们来说没有意义, 必须设置为false,香则sanity检查会报缺少先前版本JDK的映像的错误提示。 如桌已经设置dev或者DEV_ONLY=true,这个不显式设置也行export SKIP_COMPARE_IMAGES=true使用预编译头文件,不加这个编译会更慢一些export USE_PRECOMPILED_HEADER=true要编译的内容export BUILD_LANGTOOLS=trueexport BUILD_JAXP=falseexport BUILD_JAXWS=fa1seexport BUILD_CORBA=falseexport BUILD_HOTSPOT=trueexport BUILD_JDK=true要编译的版本export SKIP_DEBUG_BUILD=falseexport SKIP_FASTDEBUG_BUILD=trueexport DEBUG_NAME=debug把它设置为false可以避开javaws和浏览器Java插件之类的部分的buildBUILD_DEPLOY=false把它设置为false就不会build出安装包。因为安装包里有些奇怪的依赖, 但即便不build出它也已经能得到完整的JDK映像,所以还是别build它好了BUILD_INSTALL=false编译结果所存放的路径export ALT_OUTPUTDIR=/root/openjdk7/build这两个环境变量必须去掉,不然会有很诡异的事情发生（我没有具体查过这些 "诡异的事情” ,Makefile脚本裣查到有这2个变量就会提示警告)unset JAVA_HOMEunset CLASSPATHmake 2&gt;&amp;1 | tee $ALT_OUTPUTDIR/build.log 生效环境变量命：source /etc/profile 编译 编译前的检测：进入到openjdk源码目录下执行命令：make sanity检测编译环境是否可行，出现Sanity check passed.结果表示测试通过可以进行编译，否则根据报错进行修改。 开始编译：在openjdk源码目录下执行命令：make开始编译，过程时间长短由你所配置的环境变量有关，本次时长大约十三分钟，出现以下命令时表示编译成功。 12345678910111213成功标志：-- Build times ----------Target all_product_buildStart 2018-09-14 10:45:08End 2018-09-14 10:57:5400:00:05 corba00:00:05 hotspot00:00:03 jaxp00:00:05 jaxws00:12:25 jdk00:00:03 langtools00:12:46 TOTAL------------------------- 编译结果 进入存放编译结果目录（环境变量已配置）/root/openjdk7/build下的j2sdk-image目录 cd /root/openjdk7/build/j2sdk-image 更换JAVA_HOME路径（j2sdk-image路径下的内容就和我们平时用的jdk内容大致一样） export JAVA_HOME=/root/openjdk7/build/j2sdk-image export PATH=$PATH:$JAVA_HOME/bin 检测编译结果 java -version 出现版本号等信息说明编译成功可用 运行编译后的虚拟机： 进入目录/root/openjdk7/build/hotspot/outputdir/linux_amd64_compiler2/product 修改文件env.sh：vi env.sh LD_LIBRARY_PATH=.:${JAVA_HOME}/jre/lib/amd64/native_threads:${JAVA_HOME}/jre/lib/amd64:（有则不管，无则加入） export LD_LIBRARY_PATH（有则不管，无则加入） 修改JAVA_HOME路径为编译后的jdk，即JAVA_HOME=/root/openjdk7/build/j2sdk-image 运行命令：source ./env.sh和./gamma -version 出现结果如下说明成功1234Using java runtime at: /root/openjdk7/build/j2sdk-image/jreopenjdk version "1.7.0-internal"OpenJDK Runtime Environment (build 1.7.0-internal-openjdk_2017_05_13_11_17-b00)OpenJDK 64-Bit Server VM (build 24.80-b07, mixed mode) 过程总结 首先linux系统一定要够熟练，基本命令的使用，操作系统的了解，包括jvm和jdk的组成生态环境，都对你的整个编译过程有很大的帮助 前面提到过编译过程中会有相关依赖的下载（总共有三个，分别为：jaxp145_01.zip，jdk7-jaxws2_2_4-b03-2011_05_27.zip ，jdk7-jaf-2010_08_19.zip），但是实际上下载会失败，将链接地址拷贝出来到网页是可以下载的，但是编译过程中不行，本次编译实现两种解决方案，一种是将下载链接地址换成其他例如，网盘，七牛云等，一种是自行下载好放入相应文件夹中 方法一需修改配置文件 其一位置为：/root/openjdk7/jaxp/jaxp.properties，其二位置为：/root/openjdk7/jaxws/jaxws.properties 将上述配置文件中jaxws_src.master.bundle.url.base=http://download.java.net/glassfish/components/jax-ws/openjdk/jdk7后面的url地址换成自己的地址即可 方法二将以下三个文件下载后置于OpenJDK解压后根目录下的drop目录下，并在环境变量中加入配置：export ALT_DROPS_DIR=/usr/local/src/openjdk7/drop # 注意目录Path https://netix.dl.sourceforge.net/project/jdk7src/input-archives/jdk7-jaf-2010_08_19.zip http://download.java.net/glassfish/components/jax-ws/openjdk/jdk7/jdk7-jaxws2_2_4-b03-2011_05_27.zip http://download.java.net/jaxp/1.4.5/jaxp145_01.zip 错误：Error: time is more than 10 years from present: 1136059200000 需要修改源码目录中的一个文件，这个文件是/jdk/src/share/classes/java/util/CurrencyData.properties。 我们需要做的是把文件中以下的时间改为10年内的一个时间： 错误：JAVA_HOME must point to a valid JDK/JRE to run gamma 解决：export JAVA_HOME=/root/openjdk7/build/j2sdk-image（使用我们刚刚自己编译的jdk） echo $JAVA_HOME 编译jvmg版本的jdk。 make jvmg jvmg1 2&gt;&amp;1 | tee $ALT_OUTPUTDIR/build.log 上面我的命令只是编译jvmg版的hotspot。所以除了jvmg目录，其他目录下是没有hotspot的。 最后通过gamma启动器来启动hotspot。 知识扩展 MD5 CheckSum：在一些场景中，比如文件传输（如插件、固件升级包等），MD5 CheckSum的作用就是用于检查文件完整性，检测文件是否被恶意篡改。编译过程中的依赖下载就用到了该技术，在配置文件/root/openjdk7/jaxp/jaxp.properties，其二位置为：/root/openjdk7/jaxws/jaxws.properties中可以看到该字段配置 附录编译涉及依赖及工具安装命令： yum install build-essential gawk m4 openjdk-6-jdk libasound2-dev libcups2-dev libxrender-dev xorg-dev xutils-dev xllproto-print-dev binutils libmotif3 libmotif-dev ant 各个依赖工具作用： build-essential：作用是提供编译程序必须软件包的列表信息也就是说 编译程序有了这个软件包它才知道 头文件在哪 才知道库函数在哪还会下载依赖的软件包 最后才组成一个开发环境 gawk (gnu awk) ：linux下查找替换文本工具按行(或者其他文本单元)搜索文件内容,包含一个匹配模式。当有文本行匹配，awk在此行进行特别的操作。Program告诉awk该去做什么; m4 ：将输入拷贝到输出,同时将宏展开. 宏可以是内嵌的也可以是用户定义的. 除了可以展开宏,m4还有一些内建的函数,用来引用文件,执行Unix命令,整数运算,文本操作,循环等. m4既可以作为编译器的前端也可以单独作为一个宏处理器。 libasound2-dev： 这是Advanced Linux Sound Architecture (ALSA)相关的依赖。 libcups2-dev： 这是Common UNIX Printing System (CUPS)相关的依赖。 binutils：GNU binutils是一组二进制工具集。包括：addr2line ar gprof nm objcopy objdump ranlib size strings strip. 本文归纳他们的常用法。ar用于建立、修改、提取档案文件(archive)。archive是一个包含多个被包含文件的单一文件（也称之为库文件），其结构保证了可以从中检索并得到原始的被包含文件（称之为archive中的member）。member的原始文件内容、模式（权限）、时间戳、所有者和组等属性都被保存在 archive中。member被提取后，他们的属性被恢复到初始状态。 待补充。。。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识REST]]></title>
    <url>%2F2018%2F04%2F15%2F%E5%88%9D%E8%AF%86REST%2F</url>
    <content type="text"><![CDATA[初识REST rest是什么，来源，起因，未来 restAPI接口设计 get方法，接口中添加注解@GET，实现类无需再添加注解，安全（读取资源不会对其状态做改动），幂等（外系统对接口的多次访问，得到的资源状态是一致的） 资源命名，面向资源，名词为主（rpc，面向动作，动词为主） head，option方法与get方法类似 put，http写请求方法，用于更新或添加资源，幂等，不安全（凡是涉及写请求的http方法都不是安全的） delete，幂等， post，不幂等，不安全，rpc中所有写请求操作均使用该方法，rest中只用来添加资源 jersey的AOP功能：HK2依赖实现，无需配置，实现接口即可 Providers：jersey支持多种表述类型，其原因为底层实现提providers具备对不同格式的处理能力，其内部提供了丰富的MessageBodyReader和MessageBodyWriter接口实现类来处理不同的格式表述。 MessageBodyReader消息体处理器接口：用于将传输流转换成java类型对象，业务系统启用该实现类有两种方式，一为：使用注解@Provider定义实现类，业务系统启动时自动探测并加载，二为：编码注册到Application类或者其子类中，业务系统启动时加载Application类或其子类时一并加载 MessageBodyReader接口中定义了两个方法，isReadable()判定是否可以反序列化，和readFrom()具体反序列化操作 MessageBodyReader接口，负责将java对象转换为流，即序列化过程，包含方法isWriteable()和wroteTo() 上下文provider：ContextResolver接口的方法getContext()，入参表述对象类型，出参上下文泛型 请求流程：流程角色：用户，rest客户端，rest服务器 用户提交请求，客户端接收请求（客户端请求过滤器） 客户端拦截器，对客户端序列化操作的的拦截 客户端消息体写处理器执行序列化，流程过度到服务器 服务器接收请求，服务器前置请求过滤器 根据请求匹配资源，服务器后置请求过滤器 服务器读拦截器，拦截服务器的反序列化操作 服务器消息体读处理器，对数据流反序列化，执行匹配的资源方法 请求资源处理完毕，服务器响应过滤器 服务器写拦截器，对服务器序列化到客户端的操作进行拦截 服务器消息体写处理器执行序列化，流程返回客户端 客户端接收响应，客户端响应过滤器 客户端响应实例response返回用户一侧，用户执行respinse.readEntity，客户端读拦截器，对客户端反序列化进行拦截 客户端消息体读处理器执行反序列化 rest和rpc的区别rest的web服务提供的方法信息存在http方法中rpc的web服务提供的方法信息存在http信封中 rest和soap的区别Stack Overflow上看到一个回答觉得很到位 SOAP and REST can’t be compared directly, since the first is a protocol (or at least tries to be) and the second is an architectural style. This is probably one of the sources of confusion around it, since people tend to call REST any HTTP API that isn’t SOAP.Pushing things a little and trying to establish a comparison, the main difference between SOAP and REST is the degree of coupling between client and server implementations. A SOAP client works like a custom desktop application, tightly coupled to the server. There’s a rigid contract between client and server, and everything is expected to break if either side changes anything. You need constant updates following any change, but it’s easier to ascertain if the contract is being followed.A REST client is more like a browser. It’s a generic client that knows how to use a protocol and standardized methods, and an application has to fit inside that. You don’t violate the protocol standards by creating extra methods, you leverage on the standard methods and create the actions with them on your media type. If done right, there’s less coupling, and changes can be dealt with more gracefully. A client is supposed to enter a REST service with zero knowledge of the API, except for the entry point and the media type. In SOAP, the client needs previous knowledge on everything it will be using, or it won’t even begin the interaction. Additionally, a REST client can be extended by code-on-demand supplied by the server itself, the classical example being JavaScript code used to drive the interaction with another service on the client-side.I think these are the crucial points to understand what REST is about, and how it differs from SOAP:REST is protocol independent. It’s not coupled to HTTP. Pretty much like you can follow an ftp link on a website, a REST application can use any protocol for which there is a standardized URI scheme.REST is not a mapping of CRUD to HTTP methods. Read this answer for a detailed explanation on that.REST is as standardized as the parts you’re using. Security and authentication in HTTP are standardized, so that’s what you use when doing REST over HTTP.REST is not REST without hypermedia and HATEOAS. This means that a client only knows the entry point URI and the resources are supposed to return links the client should follow. Those fancy documentation generators that give URI patterns for everything you can do in a REST API miss the point completely. They are not only documenting something that’s supposed to be following the standard, but when you do that, you’re coupling the client to one particular moment in the evolution of the API, and any changes on the API have to be documented and applied, or it will break.REST is the architectural style of the web itself. When you enter Stack Overflow, you know what a User, a Question and an Answer are, you know the media types, and the website provides you with the links to them. A REST API has to do the same. If we designed the web the way people think REST should be done, instead of having a home page with links to Questions and Answers, we’d have a static documentation explaining that in order to view a question, you have to take the URI stackoverflow.com/questions/, replace id with the Question.id and paste that on your browser. That’s nonsense, but that’s what many people think REST is.This last point can’t be emphasized enough. If your clients are building URIs from templates in documentation and not getting links in the resource representations, that’s not REST. Roy Fielding, the author of REST, made it clear on this blog post: REST APIs must be hypertext-driven.With the above in mind, you’ll realize that while REST might not be restricted to XML, to do it correctly with any other format you’ll have to design and standardize some format for your links. Hyperlinks are standard in XML, but not in JSON. There are draft standards for JSON, like HAL.Finally, REST isn’t for everyone, and a proof of that is how most people solve their problems very well with the HTTP APIs they mistakenly called REST and never venture beyond that. REST is hard to do sometimes, especially in the beginning, but it pays over time with easier evolution on the server side, and client’s resilience to changes. If you need something done quickly and easily, don’t bother about getting REST right. It’s probably not what you’re looking for. If you need something that will have to stay online for years or even decades, then REST is for you. rest和mvc的区别 rest应用开发demo 实体类 @XmlRootElement定义类，@XmlElementWapper等其他注解 资源路径定义，也就是springMVC中的路径问题 资源类==controller，@Path（”/类路径”）， @Path（”/方法路径”）@GET/@PUT方法类型，@Produce（）返回json需要使用@Produces注解，@Concumer（）接收json，需要使用@Consumes，该注解标注在类上事务，表示该类中所有的方法均遵循该注解配置，一般建议建议将注解标注在接口中，实现显得干净整洁一些 集成spring用的包为jersey-spring 这里的jersey是和spring一起使用的，将jersey的webservice交给spring管理。因此容器这一块，必须选择：com.sun.jersey.spi.spring.container.servlet.SpringServlet而不是org.glassfish.jersey.servlet.ServletContainer 体会心得 jaxp标准：包括dom，sax，stax三种解析xml的技术，各不相同，需要手写解析过程 dom：面向文档，加载进内存，映射为树木和节点 sax：事件驱动的流解析技术，监听注册事件，触发回调实现解析 stax拉式流解析技术，相当于sax的时间驱动推送技术，该读取过程可以主动推进当前xml位置的指针而不是被动获得解析中的xml数据 jsxb标准：利用pojo中的注解来实现xml文件的自动解析，免去了手写程序解析xml的过程]]></content>
      <categories>
        <category>REST</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>REST</tag>
        <tag>Restful</tag>
        <tag>SOAP</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashAlgorithm]]></title>
    <url>%2F2018%2F04%2F08%2FHashAlgorithm%2F</url>
    <content type="text"><![CDATA[hash算法 Murmurhash2 哈希算法 siphash 哈希算法 &lt;- more -&gt;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedisTheory]]></title>
    <url>%2F2018%2F04%2F08%2FRedisTheory%2F</url>
    <content type="text"><![CDATA[Redis底层技术实现与原理 本篇以《Rdeis设计与实现》为阅读基础，总结提炼其中一些知识点 底层数据结构 内存回收机制 对象共享 单机数据库 RDB持久化 AOF持久化 事件 复制 redis集群 &lt;- more -&gt; 基本底层实现SDS动态字符串（redis内部自定义字符串）12345Struct sdshdr&#123; Int len;字符串长度，不包括结束符‘/0’ Int free;字符串剩余空间，同样不包括结束符 Char buf[];字节数组，分配空间时多分配一个为结束符 &#125; 优势： 常数时间获取字符串长度（len） 避免了缓冲区溢出（free，先检测free空间是否充足在执行操作） 减少修改字符串带来的内存重分配次数，采用空间预分配，若修改后的sds.len1MB，则buf的长度等于30MB+1MB+1byte，即len=30MB，free=1MB；同时采用惰性空间释放策略，当缩小字符串长度时，并不是立马释放缩小空间，而是加到free中来供后续为字符串增加长度做准备。 双向链表1234567891011121314Typedef struct listNode&#123; Struct listNode *prev; Struce listNode *next; Void *value; &#125;listNode; Typedef struct list&#123; listNode *head;头节点 listNode *tail;尾节点 Unsigned long len;节点数量 Void *(*dup) (void *ptr);节点值复制函数 Void *(*free) (void *ptr);节点值释放函数 int (*match) (void *ptr ,void *key);节点值对比函数 &#125; 特点： 双向（prev，next），双指针（表头，表尾） 无环，表头的prev和表尾的next均指向null，访问以null为结束 O（1）获取链表长度 可保存不同类型的值 哈希表123456789101112131415161718Typedef struct dictht&#123; dicEntry **table;哈希表数组 Unsigned long size;哈希表大小 Unsigned long sizemask;哈希表大小掩码，用于计算索引值（=size-1） Unsigned long used;哈希表已有节点数量 &#125; Typedef struct dicEntry&#123; void *key;键 Union&#123;值可以有三种类型 Void *val;指针 Uint64_tu64;无符号整数 Int64_ts64;有符号整数 &#125;v; Struct dicEntry *next;下一个哈希表节点，链地址法解决冲突 &#125;dicEntry; 字典123456Typedef struct dict&#123; dictType *type;类型特定函数，为用途不同的字典设置不同的类型特定函数，如复制键函数，复制值函数，计算哈希值函数等 Void *private;为类型特定函数提供参数 Dictht ht[2];哈希表两个，正常只用第一个ht[0]，ht[1]在rehash的时候用 Int rehashidx;rehash状态判定，rehash不在进行时值为-1 &#125;dict; 哈希索引值index = hash &amp; dict-&gt;ht[x].sizemask Rehash操作： rehashidx值置为0，表示rehash工作正式开始，为字典的ht[1]分配空间 如果是扩展操作，ht[1]的大小为第一个大于等于ht[0].used*2的2的n次方幂 如果是收缩操作，ht[1]的大小为第一个大于等于ht[0].used的2的n次方幂 将ht[0]中的内容重新计算哈希值和索引值迁移到ht[1]中，ht[0]变为空表，然后释放ht[0] 将ht[1]更改为ht[0]，重新创建一个新的表空间ht[1]为下次rehash做准备，rehash工作完成，rehashidx值置为-1 当数量较为庞大时，rehash过程为渐进式，而不是一次性，将rehash操作均摊到每一次的字典的增删改查操作上 跳跃表-（有序数据结构，在一个接点中维持有多个指向其他节点的指针，从而实现跳跃性访问节点，可代替平横树）12345678910Typedef struct zskiplistNode&#123; Struct zskiplistLevel&#123; Struct zskiplistNode *forward; Unsigned int span;跨度，节点间的距离 &#125;level[];层，表示一个节点维持有几个指向其他节点的指针，即level数组的个数 Struct zskiplistNode *backward; Double score;保存对象值 Robj *obj;保存对象 &#125;zskiplistNode; 整数集合压缩列表对象-(redis五大基本对象：字符串对象，列表对象，哈希对象，集合对象，有序集合对象)123456Typedef struct redisObject&#123; Unsigned type:4;类型 Undigned encoding:4;编码 Void *ptr;指向底层实现数据结构的指针 … &#125; 字符串对象 编码有三种：int，raw，embatr 当字符串对象存的时整数值，编码为int 当字符串对象存的是长度大于32 的字符串时，编码为raw 当字符串对象存的是小于等于32 的字符串时，编码为embstr embstr编码时专门用来保存短字符串的一种优化编码方式，raw会调用两次内存分配函数来分别创建redisObject和sdshdr，而embstr只会调用一次内存分配函数分配一块连续的空间供redisObject和sdshdr使用，降低了内存分配和释放次数，同时所有数据保存在连续的内存中，能更好的利用缓存带来的优势） 列表对象 编码有两种：ziplist（压缩列表实现底层），linkedlist（双向列表实现底层） 当列表对象保存的所有字符串元素的长度都小于64字节并且元素数量小于512个时，使用ziplist编码，否则使用linkedlist编码 哈希对象 编码有两种：ziplist，hashtable（字典实现底层） 当列表对象保存的所有键值对的键和值的长度都小于64字节并且键值对数量小于512个时，使用ziplist编码（使用ziplist编码时，键值两个节点始终相邻，键节点在前，值节点在后）否则使用linkedlist编码 集合对象 编码有两种：intset（整数集合实现底层），hashtable 使用hashtable编码时，字典的每个键都是一个包含集合元素的字符串对象，而字典的值全都置为null 当集合对象保存的所有对象均为整数时且集合中元素数量不超过512个时使用intset编码，否则使用hashtable编码 有序集合对象1234Typedef struct zset&#123; Skiplist *zsl;跳跃链表 Dict *dict;字典 &#125; 编码有两种：ziplist，skiplist（zset结构实现底层） 使用ziplist编码时，每个集合元素使用两个紧邻的压缩列表节点来保存，第一个保存元素成员，第二个保存元素的分值 Zset结构同时使用跳跃链表（有序排列集合元素，可实现范围型操作）和字典（O(1)复杂度查找集合元素值） 当集合每个元素的长度都小于64字节并且元素数量小于128个时，使用ziplist编码，否则使用skiplist编码 Bit arrays位数组 Bitmaps are not an actual data type, but a set of bit-oriented operations defined on the String type. 位数组并属于真正的数据类型，只是字符类型的一种位操作方式 二进制安全，最大长度为512M，可以设置2^32中不同的位 可单一操作，设置某一位为1或0，或者获取某一位的位值，也可一组位进行的操作，例如将某一范围的位值设置为1或0 极大的节约内存空间 用户访问网站记录，访问记为1，否记为0，可节约非常大的内存空间，同时可以快速计算出用户访问网站的总天数 To split a bitmap across different keys instead of setting all the bits into a key, a trivial strategy is just to store M bits per key and obtain the key name with bit-number/M and the Nth bit to address inside the key with bit-number MOD M. HyperLogLogs HyperLogLog是用于计算唯一事物的概率数据结构（从技术上讲，这被称为估计集合的基数）。 内存回收机制 不会立马回收内存 内存使用量取决于峰值内存使用量 内存分配器会机智的合理利用尚未回收的内存 若不设置最大内存，将会耗尽机器内存资源 引用计数技术 对象共享 对象的空转时长（当前时间-lru） 12345Typedef struct redisObject&#123; … Undigned lru:22;记录对象最后一次被命令程序访问的时间 … &#125; 当服务器的内存占用数超过maxmemory时，空转时长较高的会优先被服务器释放 单机数据库 Redis客户端默认目标数据库为0号数据库，可以使用SELECT命令来切换目标数据库 Set data “2013.12.03” 添加信息 Del data 删除信息 Set massage “hello” (将massage的值改为hello)或者 hset book page 80（将book中的page改为80）修改信息 Get message 查找信息 Expire/pexpire key 5 设置键的生存时间/过期时间 过期键的删除策略 定时删除：定时器 惰性删除：放任不管，只有当每次取键时检查是否过期，是删除，否返回 定期删除 RDB持久化（通过保存数据库中的键值对来记录数据库的不同状态） 数据存储格式：键值对形式 数据序列化格式：（压缩存储）二进制形式 手动或定期 .rdb 文件 压缩的二进制文件 配置参数 RDB方式配置参数 stop-write-on-bgsave-error no rdbcompression yes dbfilename dump.rdb AOP方式配置参数 appendonly on appendfsync everysec no-appendfsync-on-rewrite no auto-aop-rewrite-percnetage 100 auto-aop-rewrite-min-size 64mb dir ./共享持久化文件存放位置 Rdb文件的创建与载入1. Save命令会阻塞redis服务器进程，直到rdb文件创建完成，期间服务器不能处理任何请求；该命令生成快照持久化版本的时间较短 2. Bgsave命令会派生出一个子进程执行创建rdb文件，父进程继续执行请求处理；不阻塞但是生成快照的时间比save命令长 3. Bgsave命令阶段，save，bgsave，bgrewriteaof这三种命令不能执行，其他请求可以执行 4. 默认条件为（当满足条件就执行bgsave命令） 1. Save 900 1 服务器在900秒之内至少对数据库修改1次 2. Save 300 10服务器在300秒之内至少对数据库修改10次 3. Save 60 10000服务器在60秒之内至少对数据库修改10000次 5. Dirty计数器：记录上一次成功执行save/bgsave命令之后服务器对数据库的修改次数 6. Lastsave：时间戳，记录上一次成功执行/bgsave命令的时间 7. serverCron函数每隔100毫秒就执行一次，其中一项就是检查save/bgsave条件是否满足 限制 快照持久化RDB方式在redis宕机的时候，用户将会丢失最近一次快照之后所有的改动数据，因此该方式适用于即使丢失一部分数据也没有关系的应用程序。 设置过于频繁的快照生成会浪费资源，过于稀少又会造成数据的大量的丢失。 考虑好生产中如果宕机，最大可以承受丢失多长时间以内产生的数据，以此为标准设置redis快照持久化方式的配置参数 日志聚合计算 如何保证redis宕机后恢复后从处理中断处继续执行，那就需要在记录数据的同时记录数据处理进度，这样在宕机恢复后可以按照宕机前的中断处继续进行处理。 内存容量大小的影响 如果redis服务器内存存储数据的容量不是太多，只有几个G时，快照方式bgsave命令可以很快的创建子线程兵完成快照版本的持久化；但是当数据容量较大时，服务器内存资源所剩不多，快照所需创建子线程的时间也会增加，从而会造成redis停顿时间变长，停顿时间内不能处理任何请求命令。 AOF持久化（通过保存服务器执行的写命令来记录数据库的状态） 数据存储格式：写命令语句形式 数据序列化格式： 三步走：命令追加-&gt;文件写入-&gt;文件同步 每次执行完相应的命令会将命令以一定格式追加到aot_buf缓冲区的末尾 Redis服务器进程就是一个事件循环，每结束一个循环都会调用相应的函数考虑是否将aot_buf缓冲区的内容写入AOF文件，上次同步时间距离现在超过一秒就再次执行同步 Aof文件重写，随着时间的推移，aof文件的大小会迅速增加，其中会包括很多的冗余命令，所以需要重写来减小文件大小 原理：从数据库读取当前的键值，然后用命令来记录键值对，替换之前冗余的命令 子进程执行该过程，不会影响服务器的请求处理 Aof执行期间，服务器依旧会将执行过的写命令追加到aof缓冲区，同时还会将执行过的写命令追加到aof重写缓冲区 优势 aof方式的持久化设置为一秒时，redis性能和不适用任何持久化时的性能几乎一样，这样保证了redis的持久化不会影响到自身性能。 事件：redis服务器就是一个事件驱动程序 文件事件：redis通过套接字与客户端进行链接，文件事件就是服务器对套接字操作的抽象，服务器和客户端的通信会产生相应的文件事件，而服务器通过监听并处理这些事件来完成网络通信操作（读事件，写事件两类） 套接字（准备好链接应答，写入，读取，关闭等操作时）-&gt;I/O多路复用（将套接字以队列的形式往后传递）-&gt;文件事件派发器（根据套接字产生的事件类型调用相应的事件处理器执行）-&gt;事件处理器（命令请求处理器…） 时间事件：服务器对定时操作的抽象 定时事件，周期事件 所有时间事件存放在一个无序链表（不按照when属性排列）中，每当时间事件执行时都必须遍历整个链表来找到已到达时间事件（新事件的插入总是插入到表头） 两事件均同步，有序，原子执行，不会出现中断，抢占现象，需要时会主动让出执行权。 复制（主从数据同步） （slaveof命令）从服务器&gt; slaveof 主服务器 从redis连接主redis的时候，主会执行bgsave命令进行持久化 slaveof host part：开始复制同步主机host的数据 slaveof no one：停止复制同步 旧版复制=同步+命令传播 同步： 从向主发送sync命令 主收到sync命令后执行bgsave命令，后台生成一个rdb文件，并使用缓冲区记录从现在开始的所有写命令 主将rdb文件发给从服务器，从服务器接受并载入rdb文件，根据此文件将自己的数据库状态更新至主服务器状态 主将缓冲区内容发给从，从执行缓冲区命令更新自己 缓冲区命令也同步完成后，master每接受一个写命令就同时发给slave执行同步数据 数据同步影响因素：网络带宽，master内存容量（内存剩余量太小的话，没法提供足够的内存创建子线程和写缓冲区） 注意；slave第一次连接master的时候，自身数据会被全部清除，然后同步master的数据 不支持主主复制 将复制功能分担出去保证master的性能，不至于被大量复制拖垮，采用树形结构，master位于树的根部，一级一级将复制功能分散出去 命令传播：当同步执行完成之后，主服务器只需要一直保持将自己的写命令发给从服务器，从服务器接受并更新即可保持主从一直 复制分两种情况，初次复制，断线后重复制（低效，因为不能实现从断线处继续复制，而是重新复制），新版将同步分为完整同步和部分同步来优化断线后重新复制 redis集群 节点连接命令：cluster meet Cluster-enabled=yes开启服务器的集群模式 槽指派：redis集群通过分片方式来保存数据库中的键值对，整个数据库被分为16384个槽位，数据库中每一个键都属于槽的其中一个，每个节点可以处理0个或者16384个，当所有槽位均有节点在处理时，集群属于上线状态，否则属于下线状态 命令cluster addslots [slot…]将一个或者多个槽位指派给节点负责 16384/8个字节，包含16384个二进制位来保存节点负责的槽位信息，为1，表示该节点负责处理该槽位，否则不负责处理 Redis各个命令到底能跑多快 使用redis附带的性能测试工具redis-benchmark redis-benchmark -c 1 -q（参数c表示客户端个数（默认使用50个客户端测试），样例表示采用一个客户端来进行测试；参数q表示简化输出结果） 该命令不处理的返回结果，所以节省了大量的结果解析等耗费的时间，因此测试结果会比实际性能高； redis实际性能约为该命令测试结果的50%~60% 重新分片发布订阅Dict&lt;被订阅频道，List&lt;订阅者链表&gt;&gt;事物multi命令开始，中间执行命令，exec命令结束提交事务watch命令是一个乐观锁，在exec命令之前监视任意数量的数据库键是否至少有一个被修改过，是则拒绝事务Lua脚本排序sort命令排序。。。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Redis</tag>
        <tag>Catch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java描绘数据统计图]]></title>
    <url>%2F2018%2F04%2F01%2FJava%E6%8F%8F%E7%BB%98%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Java描绘数据统计图ECharts 最近需要实现一个数据曲线对比的小任务，于是想试试描绘数据统计图，了解到可以使用echarts和hcharts，这里使用的是echarts，首先官方实例很好，容易理解且上手快，但是都是静态的，我要实现的是动态获取后台数据来前台显示数据曲线对比，所以会涉及到ajax和json的相关内容（读者自行了解）！ 代码展示 首先是html最终呈现效果页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html lang="zh-CN"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 初始化移动浏览显示 --&gt; &lt;meta name="Author" content="Dreamer-1."&gt; &lt;title&gt;- 观测数据 -&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 初始化一块区域来显示Echarts图表 --&gt; &lt;div style="height:410px;min-height:100px;margin:0 auto;" id="main"&gt;&lt;/div&gt; &lt;!-- 引入相关js文件 --&gt; &lt;script type="text/javascript" src="js/jquery-3.3.1.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="js/echarts.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('main')); var companyName = []; //类别数组（每个企业名称） var mar = []; //隐患级别数组（企业每月隐患级别） var apr = []; var may = []; var jun = []; var jul = []; var aug = []; var sep = []; $.ajax(&#123; //使用JQuery内置的Ajax方法 type : "post", //post请求方式 async : true, //异步请求（同步请求将会锁住浏览器，用户其他操作必须等待请求完成才可以执行） url : "returnJsonData", //请求发送到returnJsonData的servlet处理 data : &#123;&#125;, dataType : "json", //返回数据形式为json success : function(result) &#123; //请求成功时执行该函数内容，result即为服务器返回的json对象 if (result != null &amp;&amp; result.length &gt; 0) &#123; for(var i=0;i&lt;result.length;i++)&#123; companyName.push(result[i].name); //挨个取出类别并填入类别数组 mar.push(result[i].mar); //挨个取出每个月份的隐患级别插入数组 apr.push(result[i].apr); may.push(result[i].may); jun.push(result[i].jun); jul.push(result[i].jul); aug.push(result[i].aug); sep.push(result[i].sep); &#125; //循环显示不同的曲线 var series = []; for(var i=0;i&lt;companyName.length;i++)&#123; series.push(&#123; "name":companyName[i], "type":"line", //折线图表示 "data":[mar[i],apr[i],may[i],jun[i],jul[i],aug[i],sep[i],] //数据值通过Ajax动态获取 &#125;); &#125; // 指定图表的配置项和数据 var option = &#123; title: &#123; //图表标题 text: '隐患数据表' &#125;, legend: &#123; //图表上方的类别显示 show:true, data : companyName &#125;, color:[ '#FF3333', //各曲线颜色 '#53FF53', '#B15BFF', ], toolbox: &#123; //工具栏显示 show: true, feature: &#123; saveAsImage: &#123;&#125; //显示“另存为图片”工具 &#125; &#125;, xAxis: &#123; //X轴 type: 'category', data: ["Mar","Apr","May","Jun","Jul","Aug","Sep"] &#125;, yAxis : [ &#123; type : 'value', name : '隐患级别', axisLabel : &#123; formatter: '&#123;value&#125; -level' //控制输出格式 &#125; &#125;, ], series : series &#125;; myChart.setOption(option); //载入图表 &#125; else &#123; //返回的数据为空时显示提示信息 alert("图表请求数据为空！"); myChart.hideLoading(); &#125; &#125;, error : function(errorMsg) &#123; //请求失败时执行该函数 alert("图表请求数据失败，可能是服务器开小差了"); myChart.hideLoading(); &#125; &#125;) &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 接下来是servlet后台获取数据并回传给前台显示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class returnJsonData extends HttpServlet &#123; private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public returnJsonData() &#123; super(); // TODO Auto-generated constructor stub &#125; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub doPost(request,response); &#125; /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub request.setCharacterEncoding("UTF-8"); //设定客户端提交给servlet的内容按UTF-8编码 response.setCharacterEncoding("UTF-8"); //设定servlet传回给客户端的内容按UTF-8编码 response.setContentType("text/html;charset=UTF-8"); //告知浏览器用UTF-8格式解析内容 //构造返回数据 List&lt;company&gt; list = new LinkedList&lt;company&gt;(); company com = new company(); company com1 = new company(); company com2 = new company(); list.add(fun(com,"企业一")); list.add(fun(com1,"企业二")); list.add(fun(com2,"企业三")); ObjectMapper mapper = new ObjectMapper(); //提供java-json相互转换功能的类 String json = mapper.writeValueAsString(list); //将list中的对象转换为Json格式的数组 //System.out.println(json);//打印验证json数据格式 //将json数据返回给客户端 response.setContentType("text/html; charset=utf-8"); response.getWriter().write(json); &#125; public company fun(company com, String str)&#123; com.setName(str); com.setMar(Math.random()); com.setApr(Math.random()); com.setMay(Math.random()); com.setJun(Math.random()); com.setJul(Math.random()); com.setAug(Math.random()); com.setSep(Math.random()); return com; &#125;&#125; 最后附上完整实例代码：https://github.com/LFstefan/LineChart_example]]></content>
      <categories>
        <category>ECharts</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ECharts</tag>
        <tag>Ajax</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle命令集]]></title>
    <url>%2F2018%2F03%2F25%2FOracle%E5%91%BD%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Oracle命令集 基本命令 INSERT ALL /FIRST,MERGE INTO maven使用oracle依赖指南 启动监听，供客户端链接：lsnrctl start 以管理员身份接入：sqlplus / as sysdba 以用户名/密码接入：sqlplus GAEA/GAEA 启动实例：startup 使用@或者start执行sql脚本文件：@TEST/START TEST 判定数据库版本位数：select * from v$version 创建临时表空间 CREATE TEMPORARY TABLESPACE TABLESPACE_NAME LOGGING TEMPFILE &#39;D:\LIUFEIN\..&#39; SIZE 50M AUTOEXTED ON NEXT 50M MAXSIZE 100M EXTEND MANAGEMENT LOCAL UNIFORM SIZE 1M; 创建数据表空间 CREATE TABLESPACE TABLESPACE_NAME LOGGING DATAFILE &#39;D:/&#39; SIZE 50M AUTOEXTED ON NEXT 50M MAXSIZE UNLIMITED EXTEND MANAGEMENT LOCAL AUTOALLOCATE; 删除表空间： DROP TABLESPACE TABLESPACE_NAME DROP TABLESPACE TABLESAPCE_NAME INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINT（包含数据文件级联关系） 创建用户并制定默认表空间 CREATE USER ADMIN IDENTIFIED BY 123 DEFAULT TABLESPACE TABLESPACE_NAME 修改用户默认表空间 ALTER USER USER_NAME DEFAULT TABLESPACE TABLESPACE_NAME 用户授权 GRANT CONNECT,RESOURCE,DBA TO ADMIN GRANT CONNECT,RESOURCE,DBA TO ADMIN WITH ADMIN OPTION 删除用户及级联关系 DROP USER AMMIN CASCADE 查看系统所有表空间 SELECT TABLESPACE_NAME FROM DBA_TABLESPACES; 查看当前用户下的所有表空间 SELECT TABLESPACE_NAME FROM USER_TABLESPACES; 查看所有用户 SELECT USERNAME FROM DBA_USERS; 查看当前用户下所有的数据表 SELECT TABLE_NAME FROM USER_TABLES; 查看系统中所有的数据表 SELECT TABLE_NAME FROM DBA_TABLES; 查看表结构 DESC GAEA.DEMO_LF; 查看系统权限和对象权限 select * from dba_sys_privs; select * from dba_tab_privs; 多表插入,之间的界限必须明确，否则会发生数据重复插入，多个表中可以条件插入，也可无条件插入 INSERT ALL INTO SMALL_ORDER VALUES () INTO MIDDLE_ORDER VALUES () INTO LARGE_ORDER VALUES () SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 使用all多表中可能存在重复数据行 INSERT ALL WHEN SUM_ORDER &lt; 100 THEN INTO SMALL_ORDER WHEN SUM_ORDER &gt;=100 AND SUM_ORDER &lt;=500 THEN INTO MIDDLE_ORDER ELSE INTO LARGE_ORDER SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 使用first多表中不可能存在重复数据行 INSERT FIRST WHEN SUM_ORDER &lt; 100 THEN INTO SMALL_ORDER WHEN SUM_ORDER &gt;=100 AND SUM_ORDER &lt;=500 THEN INTO MIDDLE_ORDER ELSE INTO LARGE_ORDER SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 解决insertOrUpdate这种需求而应用而生的新语法 Merge Into的原理是，从using 搜出来的结果逐条与on条件匹配， 然后决定是update还是Insert。 当USING后面的sql没有查询到数据的时候，Merge Into语句是不会执行update和Insert操作的。 所以要想让Merge Into正常运行，要保证USING 后面的SELECT有数据。12345678910MERGE INTO TABLE_TEMP TUSING( SELECT TABLE_ID TABLE_NAME FROM TABLE_DATA WHERE TABLE_NAME=&apos;&apos;) EON (T.ID=E.ID)WHEN MATCHED THEN UPDATE ... DELETE ...WHEN NOT MATCHED THEN INSERT INTO ... maven使用oracle依赖指南 maven安装oracle驱动命令： cd 驱动包目录下或者写明具体驱动包位置 maven环境变量配置好或者进入maven的bin目录下执行命令 mvn install:install-file -DgroupId=com.oracle -DartifactId=oracle7 -Dversion=7.0.0 -Dpackaging=jar -Dfile=D:\Administrator\Tools\maven\repository\com\oracle\oracle7\7.0.0\oracle7-7.0.0.jar 执行完命令后去对应的文件夹下验证是否安装成功]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql命令集]]></title>
    <url>%2F2018%2F03%2F18%2FMySql%E5%91%BD%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[MySql命令集 安装/更新/启动/登陆/授权 从建库到删库 复杂查询 windows free install 安装/更新/启动/登陆/授权 下载mysql包：wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm 安装mysql包：rpm -ivh mysql57-community-release-el7-8.noarch.rpm 安装mysql：yum install mysql MySQL授权：chmod 775 更新mysql：yum update mysql 启动mysql：service mysqld start 首次登陆查看临时密码：grep “password” /var/log/mysqld.log 使用临时密码登陆mysql：mysql -uroot -p 登陆远程mysql：mysql -host 192.168.184.132 -P 3306 -uroot -p 修改管理员登陆密码：alter user ‘root’@’localhost’ identified by ‘Root!123’ 创建用户：create user ‘repl’@’192.168.184.132’ identified by ‘password’; 用户授权： grant replication slave on . to ‘repl’@’192.168.184.132’; grant all on . to ‘repl’@’192.168.184.132’; grant all privileges on . to john@localhost identified by ‘123’; grant select,insert,update,delete,create,drop on test.hr to john@192.168.10.1 identified by ‘123’; priv代表权限：select,insert,update,delete,create,drop,index,alter,grant,references,reload,shutdown,process,file等14个权限 GRANT（当数据库存在用户的时候GRANT会对用户进行授权，但当数据库不存在该用户的时候，就会创建相应的用户并进行授权 查看权限： show grants for 用户; show createdatabase dbname; 这个可以看到创建数据库时用到的一些参数。 show createtable tickets; 可以看到创建表时用到的一些参数 撤销权限：revoke all on . from ‘dba’@’localhost’; 权限刷新：flush privileges; 从建库到删库 显示所有数据库：show databases 切换使用数据库：use database_name 设置编码：set names utf8 显示当前库中所有表：show tables 显示表结构：desc table_name 创建数据库：CREATE DATABASE database-name 删除数据库：DROP DATABASE dbname 修改数据库的名称：sp_renamedb ‘old_name’,’new_name’ 创建新表 1234567891011121314151617181920212223242526 DROP TABLE IF EXISTS `zf_jg_statistics`; CREATE TABLE `zf_jg_statistics` ( `id` varchar(50) NOT NULL, `corp_id` varchar(255) DEFAULT NULL COMMENT '企业id', `corp_name` varchar(50) DEFAULT NULL COMMENT '企业名称', `gname` varchar(50) DEFAULT NULL COMMENT '行业名称，无默认值', `gmjj` varchar(50) DEFAULT NULL COMMENT '行业分类', `aname` varchar(50) DEFAULT NULL COMMENT '地区名称', `area` varchar(50) DEFAULT NULL COMMENT '地区编号', `total` int(50) DEFAULT '0' COMMENT '风险防控点数，默认值为0', `type` int(2) DEFAULT NULL COMMENT '每日查还是月查', `scount` int(50) DEFAULT '0' COMMENT '应查询点数，默认值为0', `detail_count` int(50) DEFAULT '0' COMMENT '实查询点数，默认值为0', `warm` varchar(50) DEFAULT NULL COMMENT '警示标示', `frequency` varchar(50) DEFAULT NULL COMMENT '覆盖率', `time` date DEFAULT NULL COMMENT '查询时间，无默认值', `sync_timestamp` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '时间戳', `ybtotal` int(255) DEFAULT '0', `ybzg` int(255) DEFAULT '0', `yb` varchar(255) DEFAULT NULL, `zdtotal` int(255) DEFAULT '0', `zzgl` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `corp_id` (`corp_id`), KEY `time` (`time`) USING BTREE) ENGINE=MyISAM DEFAULT CHARSET=utf8; 根据已有的表创建新表： A：create table tab_new like tab_old B：create table tab_new as select col1,col2…from tab_old definition only 删除新表：drop table tabname 增加一个列：Alter table tabname add column col_name col_type（注：列增加后将不能删除） 添加主键：Alter table tabname add primary key(col) 删除主键：Alter table tabname drop primary key(col) 创建索引：create [unique] index idxname on tabname(col….) 删除索引：drop index idxname（注：索引是不可更改的，想更改必须删除重新建） 创建视图：create view viewname as select statement 删除视图：drop view viewname 选择：select *from table1 where 范围 插入：insert into table1(field1,field2) values(value1,value2) 删除：delete from table1 where 范围 清表：truncate table table_name 更新：update table1 set field1=value1 where 范围 查找：select *from table1 where field1 like ’%value1%’—like的语法很精妙，查资料! 排序：select *from table1 order by field1,field2 [desc] 总数：select count as totalcount from table1 求和：select sum(field1) as sumvalue from table1 平均：select avg(field1) as avgvalue from table1 最大：select max(field1) as maxvalue from table1 最小：select min(field1) as minvalue from table1 复杂查询 UNION 运算符通过组合其他两个结果表(例如TABLE1 和 TABLE2)并消去表中任何重复行而派生出一个结果表。当 ALL 随UNION 一起使用时(即UNION ALL)，不消除重复行。两种情况下，派生表的每一行不是来自TABLE1 就是来自 TABLE2。 EXCEPT 运算符EXCEPT 运算符通过包括所有在TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随EXCEPT 一起使用时(EXCEPT ALL)，不消除重复行。 INTERSECT 运算符INTERSECT 运算符通过只包括TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随INTERSECT 一起使用时(INTERSECT ALL)，不消除重复行。注：使用运算词的几个查询结果行必须是一致的。 内连接：A inner join B on A.a=B.b（结果为AB两表的交集） 左外连接(左连接)：left (outer)join（结果集既包括连接表的匹配行，也包括左连接表的所有行） SQL:select a.a,a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 右外连接(右连接)：right (outer)join（结果集既包括连接表的匹配连接行，也包括右连接表的所有行） 全外连接：full/cross (outer)join（不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录） between：between限制查询数据范围时包括了边界值,not between不包括 select *from table1 where time between time1 and time2 select a,b,c, from table1 where a not between 数值1 and 数值2 distinct：select distinct *into temp from tablename（去重） in：select *from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) top：select top 10 * form table1 where 范围 select top 5 from (select top 15 from table order by id asc) table_别名 order by id desc（选择从10到15的记录） 在线视图查询：select * from (SELECT b,c FROM a) T where t.a &gt; 1; windows free install mysql在windows下绿色免安装版 官网下载免安装绿色版本，官网zip包（非msi安装版） 解压，配置环境变量 管理员身份进入cmd，在mysql解压后的bin目录下 执行命令：mysqld –initialize-insecure –user=mysql ，生成data数据文件 执行mysqld -install命令安装 net start mysql启动服务 Mysql -uroot -p连接数据库服务 卸载：mysqld –remove mysql]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven_SettingsReference]]></title>
    <url>%2F2018%2F03%2F11%2FMaven_SettingsReference%2F</url>
    <content type="text"><![CDATA[Settings Referencemaven配置文件settings.xml可能存在于两个位置 The Maven install: ${maven.home}/conf/settings.xml—全局设置 A user’s install: ${user.home}/.m2/settings.xml—用户设置 当两者共存时，配置信息合并，用户设置优先 配置文件settings中有如下一些配置元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;localRepository/&gt;本地仓库位置 &lt;interactiveMode/&gt;是否允许交互模式,默认false &lt;offline/&gt;是否离线模式构建工程，默认false &lt;pluginGroups&gt;插件组 ...自动包含org.apache.maven.plugins and org.codehaus.mojo &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.mortbay.jetty&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; ... &lt;pluginGroups/&gt; &lt;servers/&gt; &lt;server&gt; &lt;id&gt;server001&lt;/id&gt;与maven尝试连接的仓库/镜像服务器id &lt;username&gt;my_login&lt;/username&gt; &lt;password&gt;my_password&lt;/password&gt;可加密 &lt;privateKey&gt;$&#123;user.home&#125;/.ssh/id_dsa&lt;/privateKey&gt;私钥 &lt;passphrase&gt;some_passphrase&lt;/passphrase&gt;私钥密码（可加密） &lt;filePermissions&gt;664&lt;/filePermissions&gt;创建文件权限 &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt;创建目录权限 &lt;configuration&gt;&lt;/configuration&gt; &lt;/server&gt; &lt;servers/&gt; &lt;mirrors/&gt; &lt;mirror&gt; &lt;id&gt;planetmirror.com&lt;/id&gt; &lt;name&gt;PlanetMirror Australia&lt;/name&gt; &lt;url&gt;http://downloads.planetmirror.com/pub/maven2&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;proxies/&gt; &lt;proxy&gt; &lt;id&gt;myproxy&lt;/id&gt; &lt;active&gt;true&lt;/active&gt;代理是否开启，同时只能有一个处于开启状态 &lt;protocol&gt;http&lt;/protocol&gt; &lt;host&gt;proxy.somewhere.com&lt;/host&gt; &lt;port&gt;8080&lt;/port&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;password&gt;somepassword&lt;/password&gt; &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt;无需代理主机集合 &lt;/proxy&gt; &lt;profiles/&gt; &lt;profile&gt;pom文件中的truncate版本，处于active状态将覆盖pom中配置 &lt;id&gt;test&lt;/id&gt; &lt;activation&gt;激活profile的条件如下，有一个满足即可激活 &lt;activeByDefault&gt;false&lt;/activeByDefault&gt;默认状态false &lt;jdk&gt;1.5&lt;/jdk&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;property&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;file&gt; &lt;exists&gt;$&#123;basedir&#125;/file2.properties&lt;/exists&gt; &lt;missing&gt;$&#123;basedir&#125;/file1.properties&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; ... &lt;properties&gt;参数设置，所有参数可在pom中直接引用$&#123;user.install&#125; &lt;user.install&gt;$&#123;user.home&#125;/our-project&lt;/user.install&gt; &lt;/properties&gt; ... &lt;repositories&gt;寻找匹配的正式版或快照版远程仓库 &lt;repository&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always/daily&lt;/updatePolicy&gt;总是/每天 &lt;checksumPolicy&gt;ignore/fail/warn&lt;/checksumPolicy&gt;忽略/失败/警告 &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; 与repository类似，插件仓库配置 &lt;pluginRepository/&gt; ... &lt;/pluginRepositories&gt; ... &lt;/profile&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;env-test&lt;/activeProfile&gt;profile id为env-test的将被激活 &lt;/activeProfiles&gt;&lt;/settings&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql DataType]]></title>
    <url>%2F2018%2F03%2F04%2FMySql%20Data%20Type%2F</url>
    <content type="text"><![CDATA[MySql DataType Numeric Type Date and Time Type String Type Json Type（Mysql 8.0新增特性） Numeric Type BIT(M)：M表示每个值的位数，范围1-64，默认为1，将value自动转换为M位的二进制存入，当value转成二进制后的位数大于已设定的位数时，bit值为设定位数的最大二进制值 TINYINT(M)：无符号范围0-255，有符号范围-128-127 BOOL：等价于 TINYINT(1)，0-false，1-true，默认为true SMALLINT(M)：无符号范围0-65535，有符号范围-32768-32767 MEDIUMINT(M)：无符号范围0-16777215，有符号范围-8388608-8388607 INT(M)：无符号范围0-4204967295，有符号范围-2147483648-2147483647 INTEGER(M)：等价于INT BIGINT(M)：无符号范围0-18446744073709551615，有符号范围-9223372036854775808-9223372036854775807. DECIMAL(M,D)：M总位数，D小数位数 DEC：等价于DECIMAL(M,D) FLOAT(M,D)：理论范围 -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLE(M,D)：理论范围-1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308. DOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL], REAL[(M,D)] [UNSIGNED] [ZEROFILL]：等价于DOUBLE，如果 REAL_AS_FLOAT SQL模式开启，REAL等价于FLOAT FLOAT(p) [UNSIGNED] [ZEROFILL]：用于判别结果数据类型使用FLOAT还是DOUBLE，p属于0-24，用FLOAT，p属于25-53，使用DOUBLE Type Storage (Bytes) Minimum Value Signed Minimum Value Unsigned Maximum Value Signed Maximum Value Unsigned TINYINT 1 -128 0 127 255 SMALLINT 2 -32768 0 32767 65535 MEDIUMINT 3 -8388608 0 8388607 16777215 INT 4 -2147483648 0 2147483647 4294967295 BIGINT 8 -2^63 0 2^63-1 2^64-1 Date and Time Type DATE：范围’1000-01-01’ 到 ‘9999-12-31’，支持STRING和NUMBER类型，NUMBER类型最多支持8位数字（四位表示年份，两位表示月份，两位表示天数），任何非法数字都会自动将值设置为默认值 DATETIME[(fsp)]：范围’1000-01-01 00:00:00.000000’ to ‘9999-12-31 23:59:59.999999’，支持STRING和NUMBER类型，fsp给定范围0-6来指定小数的精度 TIMESTAMP[(fsp)]：范围’1970-01-01 00:00:01.000000’ UTC to ‘2038-01-19 03:14:07.999999’ UTC， TIMESTAMP and DATETIME的自动初始化和更新1234CREATE TABLE t1 ( ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, dt DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP); TIME[(fsp)]：范围’-838:59:59.000000’ to ‘838:59:59.000000’ YEAR[(4)]：支持STRING和NUMBER类型 As a 4-digit number in the range 1901 to 2155. As a 4-digit string in the range ‘1901’ to ‘2155’. As a 1or 2-digit number in the range 1 to 99. MySQL converts values in the ranges 1 to 69 and 70 to 99 to YEAR values in the ranges 2001 to 2069 and 1970 to 1999. As a 1or 2-digit string in the range ‘0’ to ‘99’. MySQL converts values in the ranges ‘0’ to ‘69’ and ‘70’ to ‘99’ to YEAR values in the ranges 2000 to 2069 and 1970 to 1999. The result of inserting a numeric 0 has a display value of 0000 and an internal value of 0000. To insert zero and have it be interpreted as 2000, specify it as a string ‘0’ or ‘00’. Data Type “Zero” Value DATE ‘0000-00-00’ TIME ‘00 : 00 : 00’ DATETIME ‘0000-00-00 00 : 00 : 00’ TIMESTAMP ‘0000-00-00 00 : 00 : 00’ YEAR 0000 String Type CHAR[(M)]：M范围0-255，默认为1 VARCHAR(M)：M范围0-65535，默认为1 BINARY[(M)]：和char类似，只不过存储的是二进制位字符串，char存储的是非二进制字符串 VARBINARY(M)：类似于varchar TINYBLOB：最大长度255位，存储时用一个位的长度前缀来存储value的总位数 TINYTEXT：最大长度255个字符，存储时用一个位的长度前缀来存储value的总位数 BLOB[(M)]：最大长度65535位，存储时用两个位的长度前缀来存储value的总位数 TEXT[(M)]：最大长度65535个字符，存储时用两个位的长度前缀来存储value的总位数 MEDIUMBLOB：最大长度16777215位，存储时用三个位的长度前缀来存储value的总位数 MEDIUMTEXT：最大长度16777215个字符，存储时用三个位的长度前缀来存储value的总位数 LONGBLOB：最大长度4,294,967,295位，存储时用四个位的长度前缀来存储value的总位数 LONGTEXT：最大长度4,294,967,295个字符，存储时用四个位的长度前缀来存储value的总位数 ENUM(‘value1’,’value2’,…)：最多含有65535个不重复元素 SET(‘value1’,’value2’,…)：最多含有64个不重复成员 Value CHAR(4) Storage Required VARCHAR(4) Storage Required ‘’ ‘ ‘ 4 bytes ‘’ 1 byte ‘ab’ ‘ab ‘ 4 bytes ‘ab’ 3 bytes ‘abcd’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes ‘abcdefgh’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes 扩展 REAL类型：MySQL treats REAL as a synonym for DOUBLE, unless the REAL_AS_FLOAT SQL mode is enabled. Json Type• 存储格式为二进制,占用空间大小和longblob,longtext一致;• 每一列的json值磁盘存储大小限制受系统变量 max_allowed_packet限制,内存读取不受限• 使用JSON_STORAGE_SIZE()函数可以获取实际存储占用的空间大小• 不能有非空默认值• 8优化了更新方式,不再是以前的删除旧值写入新值,优化为可以部分更新 ○ JSON_SET(), JSON_REPLACE(), or JSON_REMOVE() ○ 部分更新只能将旧值更新为新值,不能添加新的元素 ○ 部分更新的值不能超过旧值的大小 使用函数 JSON_STORAGE_FREE()可以查看 待完善 使用样例 JSON_TYPE：查看json类型，数组，对象 JSON_ARRAY：构造json数组值，JSON_ARRAY（0，“”，now（）） JSON_OBJECT：构造json对象值，JSON_OBJECT（k1，v1，k2, v2….） 元素合并 JSON_MERGE_PRESERVE(‘[“a”, 1]’, ‘{“key”: “value”}’) 将多个对象/数组合并到一个对象/数组元素中， JSON_MERGE_PRESERVE（array，object，array…） JSON_MERGE_PATCH：同样是合并，但是会进行去重操作 插入操作 INSERT INTO facts VALUES &gt; (JSON_OBJECT(“mascot”, “Our mascot is a dolphin named \”Sakila\”.”)); 查询操作 SELECT col-&gt;”$.mascot” FROM qtest;查询json中某个属性key的value值（结果携带引号） SELECT sentence-&gt;&gt;”$.mascot” FROM facts;查询json中某个属性key的value值（结果补携带引号） JSON_EXTRACT(‘{“id”: 14, “name”: “Aztalan”}’, ‘$.name’);取出指定key的value值 SELECT JSON_EXTRACT(‘{“a”: 1, “b”: 2, “c”: [3, 4, 5]}’, ‘$.*’);把所有的value值取出并放到一个数组中 JSON_EXTRACT(‘{“a”: 1, “b”: 2, “c”: [3, 4, 5]}’, ‘$.c[*]’);把key为c的所有value值全部取出来 SELECT JSON_EXTRACT(‘{“a”: {“b”: 1}, “c”: {“b”: 2}}’, ‘$**.b’);跨key取相同属性的value值到数组中]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>DataType</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经纬度算法]]></title>
    <url>%2F2018%2F03%2F04%2F%E7%BB%8F%E7%BA%AC%E5%BA%A6%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[经纬度算法 引自：美团小组对经纬度算法的思考和改进 美团小组对经纬度算法的思考和改进地理空间距离计算及优化（根据两个点经纬度计算距离）https://blog.csdn.net/u011001084/article/details/52980834]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁-悲观锁]]></title>
    <url>%2F2018%2F02%2F25%2F%E4%B9%90%E8%A7%82%E9%94%81-%E6%82%B2%E8%A7%82%E9%94%81%2F</url>
    <content type="text"><![CDATA[乐观锁-悲观锁 乐观锁 悲观锁 乐观锁含义 乐观锁是一种思想，顾名思义，乐观锁看待所有的操作均持乐观的态度，即认为所有当前操作均不会造成数据信息的变更，操作不会加锁，只有当涉及到数据更新时才会将原始数据和库中实时数据进行比对，如果相同，说明当前操作期间没有其他并发操作对数据进行改动，执行更新操作，否则阻止该操作。 实现 基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 基于时间戳（ timestamp ）记录机制实现。为数据增加一个时间戳标识，为数据库表增加一个timestamp类型的字段来实现。同理如上。 CAS（Compare and Swap） CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 缺点：ABA问题（将引用和标志位同时作为检测项即可解决ABA问题），自旋CAS（不成功，就一直循环执行，直到成功）， 只能保证一个共享变量的原子操作（可以把多个变量放在一个对象里来进行CAS操作或者合并多个变量为一个） 优点 如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进行修改时（如更改用户帐户余额），如果采用悲观锁机制，也就意味着整个操作过 程中（从操作员读出数据、开始修改直至提交修改结果的全过程，甚至还包括操作 员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对几百上千个并发，这样的情况将导致怎样的后果。 乐观锁机制避免了长事务中的数据库加锁开销（操作员 A和操作员 B 操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系统整体性能表现。 缺点 乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。 应用 Hibernate 在其数据访问引擎中内置了乐观锁实现 12345678&lt;hibernate-mapping&gt;&lt;class name=&quot;org.hibernate.sample.TUser&quot; table=&quot;t_user&quot; dynamic-update=&quot;true&quot; dynamic-insert=&quot;true&quot; optimistic-lock=&quot;version&quot; &gt;&lt;id name=&quot;id&quot; column=&quot;id&quot; type=&quot;java.lang.Integer&quot;&gt;&lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt;&lt;/id&gt;&lt;version column=&quot;version&quot; name=&quot;version&quot; type=&quot;java.lang.Integer&quot;/&gt;……&lt;/class&gt; 悲观锁含义 悲观锁，正如其名，具有强烈的独占和排他特性。它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 应用 典型的倚赖数据库的悲观锁调用（使用for update）： select * from account where name=”Erica” for update 这条 sql 语句锁定了 account 表中所有符合检索条件（ name=”Erica” ）的记录。 本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。 Hibernate 的悲观锁，也是基于数据库的锁机制实现。 query.setLockMode(“user”,LockMode.UPGRADE); // 加锁]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Word Search II]]></title>
    <url>%2F2017%2F11%2F25%2FLintCode_WordSearch_II%2F</url>
    <content type="text"><![CDATA[Description Given a matrix of lower alphabets and a dictionary. Find all words in the dictionary that can be found in the matrix. A word can start from any position in the matrix and go left/right/up/down to the adjacent position. One character only be used once in one word. No same word in dictionary 思路 一般来说，类似的匹配问题最会归结为以谁为主，或者是说拿谁去匹配谁；本例中，我们可以用所给单词去字母矩阵中深度搜索匹配，或者我们使用字母矩阵中字母组成的单词去所给单词中使用前缀法匹配。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180/** DFS实现 * 使用dfs要注意几点 * 1.每到一个字母矩阵点，可选位移有上下左右四个，要注意数组的边界值约束 * 2.矩阵中字母只能使用一次，故此需要记录每个位置字母的使用情况，使用置为1，未使用置为0，要注意深度搜 * 索过程中出现的回退现象，回退后相应位置字母的使用情况要重置为0 * 3.当有多个分支dfs时，例如矩阵中上下左右四个方向的分支dfs，要注意分支之间的关系，本例中只要其中一个 * 满足条件后其他分支便可以剪掉，所以各个分支因该是互斥的关系 * 4.递归出口的选择 * 5.所有的操作一定要有非空判定，不仅可以避免异常，还能提高性能，少做无用功public class Solution &#123; public static List&lt;String&gt; wordSearchII(char[][] board, List&lt;String&gt; words) &#123; // write your code here List&lt;String&gt; list = new LinkedList&lt;&gt;(); words.forEach((word)-&gt;&#123; if(findTheFirstChar(word,board))&#123; list.add(word); &#125; &#125;); return list; &#125; public static boolean findTheFirstChar(String word,char[][] board)&#123; boolean boo = false; out:for(int i = 0;i&lt;board.length;i++)&#123; for (int j = 0;j&lt;board[0].length;j++)&#123; if(word.charAt(0)==board[i][j])&#123; if(dfs(word,board,new char[board.length][board[0].length],word.length(),0,i,j,new char[word.length()])) &#123; boo = true; break out; &#125; &#125; &#125; &#125; return boo; &#125; public static boolean dfs(String word,char[][] board,char[][] flag,int length,int i,int k,int k1,char[] result)&#123;// System.out.println(new String(result)); if (word.equals(new String(result))) return true; else &#123; if (i &lt; length) &#123; char c = word.charAt(i); if (c == board[k][k1] &amp;&amp; flag[k][k1] != 1) &#123; result[i] = board[k][k1]; flag[k][k1] = 1;//标志该位置字母已被使用，矩阵中每个字母只允许使用一次，否则容易出现死循环 if (k - 1 &gt;= 0 &amp;&amp; dfs(word, board, flag, length, i + 1, k - 1, k1, result) == true) &#123; return true; &#125; else if (k1 + 1 &lt; board[0].length &amp;&amp; dfs(word, board, flag, length, i + 1, k, k1 + 1, result) == true) &#123; return true; &#125; else if (k + 1 &lt; board.length &amp;&amp; dfs(word, board, flag, length, i + 1, k + 1, k1, result) == true) &#123; return true; &#125; else if (k1 - 1 &gt;= 0 &amp;&amp; dfs(word, board, flag, length, i + 1, k, k1 - 1, result) == true) &#123; return true; &#125; else &#123; flag[k][k1] = 0;//状态回退，还原使用标志 return word.equals(new String(result)) ? true : false; &#125; &#125; else &#123; return word.equals(new String(result)) ? true : false; &#125; &#125; else return word.equals(new String(result)) ? true : false; &#125; &#125; public static void main(String[] args)&#123; List&lt;String&gt; words = new LinkedList&lt;&gt;();// words.add(&quot;dog&quot;);// words.add(&quot;dad&quot;);// words.add(&quot;dgdg&quot;);// words.add(&quot;can&quot;);// words.add(&quot;again&quot;);// words.add(&quot;ab&quot;);// words.add(&quot;eeda&quot;); words.add(&quot;babcbababcacabbbccbaaabcccacaccbaabbbccacc&quot;);// char[][] board = new char[][]&#123;&#123;&apos;d&apos;,&apos;o&apos;,&apos;a&apos;,&apos;f&apos;&#125;,&#123;&apos;a&apos;,&apos;g&apos;,&apos;a&apos;,&apos;i&apos;&#125;,&#123;&apos;d&apos;,&apos;c&apos;,&apos;a&apos;,&apos;n&apos;&#125;&#125;;// char[][] board = new char[][]&#123;&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;e&apos;&#125;,&#123;&apos;s&apos;,&apos;f&apos;,&apos;c&apos;,&apos;s&apos;&#125;,&#123;&apos;a&apos;,&apos;d&apos;,&apos;e&apos;,&apos;e&apos;&#125;&#125;;// char[][] board = new char[][]&#123;&#123;&apos;a&apos;,&apos;c&apos;&#125;,&#123;&apos;c&apos;,&apos;b&apos;&#125;&#125;; char[][] board = new char[][]&#123;&quot;babcbababcacab&quot;.toCharArray(),&quot;cacccbaaabccbb&quot;.toCharArray(),&quot;accbaabbbccacc&quot;.toCharArray(),&quot;acbaabcabcbbab&quot;.toCharArray(),&quot;caacaaabbcaaca&quot;.toCharArray(),&quot;bbacbcccbcacbc&quot;.toCharArray(),&quot;acaccacabacaca&quot;.toCharArray(),&quot;bcacbbcabbaaaa&quot;.toCharArray(),&quot;cccaacbcbaacba&quot;.toCharArray(),&quot;acaccacaccbabb&quot;.toCharArray(),&quot;bacacbbccaabcb&quot;.toCharArray(),&quot;aaccacbacabcca&quot;.toCharArray(),&quot;abcbcbbbabcaba&quot;.toCharArray(),&quot;bbcacbcaaababa&quot;.toCharArray(),&quot;acaabccabbcaab&quot;.toCharArray()&#125;;// System.out.println(Arrays.deepToString(board)); Long startTime = System.currentTimeMillis(); wordSearchII(board,words); System.out.println(System.currentTimeMillis()-startTime); Long startT = System.currentTimeMillis(); wordSearchIIPre(board,words); System.out.println(System.currentTimeMillis()-startT); List&lt;String&gt; list = wordSearchII(board,words); list.forEach((e)-&gt;&#123; System.out.println(e); &#125;); List&lt;String&gt; listPre = wordSearchIIPre(board,words); listPre.forEach((e)-&gt;&#123; System.out.println(e); &#125;); &#125;&#125;//使用hashmap构建前缀表实现public class Solution &#123; public static int[] dx = &#123;0, 1, -1, 0&#125;; public static int[] dy = &#123;1, 0, 0, -1&#125;; /** * @param board: A list of lists of character * @param words: A list of string * @return: A list of string */ public List&lt;String&gt; wordSearchII(char[][] board, List&lt;String&gt; words) &#123; if (board == null || board.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; if (board[0] == null || board[0].length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; boolean[][] visited = new boolean[board.length][board[0].length]; Map&lt;String, Boolean&gt; prefixIsWord = getPrefixSet(words); Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; board.length; i++) &#123; for (int j = 0; j &lt; board[i].length; j++) &#123; visited[i][j] = true; dfs(board, visited, i, j, String.valueOf(board[i][j]), prefixIsWord, wordSet); visited[i][j] = false; &#125; &#125; return new ArrayList&lt;String&gt;(wordSet); &#125; private Map&lt;String, Boolean&gt; getPrefixSet(List&lt;String&gt; words) &#123; Map&lt;String, Boolean&gt; prefixIsWord = new HashMap&lt;&gt;(); for (String word : words) &#123; for (int i = 0; i &lt; word.length() - 1; i++) &#123; String prefix = word.substring(0, i + 1); if (!prefixIsWord.containsKey(prefix)) &#123; prefixIsWord.put(prefix, false); &#125; &#125; prefixIsWord.put(word, true); &#125; return prefixIsWord; &#125; private void dfs(char[][] board, boolean[][] visited, int x, int y, String word, Map&lt;String, Boolean&gt; prefixIsWord, Set&lt;String&gt; wordSet) &#123; if (!prefixIsWord.containsKey(word)) &#123; return; &#125; if (prefixIsWord.get(word)) &#123; wordSet.add(word); &#125; for (int i = 0; i &lt; 4; i++) &#123; int adjX = x + dx[i]; int adjY = y + dy[i]; if (!inside(board, adjX, adjY) || visited[adjX][adjY]) &#123; continue; &#125; visited[adjX][adjY] = true; dfs(board, visited, adjX, adjY, word + board[adjX][adjY], prefixIsWord, wordSet); visited[adjX][adjY] = false; &#125; &#125; private boolean inside(char[][] board, int x, int y) &#123; return x &gt;= 0 &amp;&amp; x &lt; board.length &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; board[0].length; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Longest Consecutive Sequence]]></title>
    <url>%2F2017%2F11%2F18%2FLintCode_LongestConsecutiveSequence%2F</url>
    <content type="text"><![CDATA[Description Given an unsorted array of integers, find the length of the longest consecutive elements sequence.Clarification：Your algorithm should run in O(n) complexity. Example Given [100, 4, 200, 1, 3, 2],The longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4. 思路 一开始想到的就是先排序，然后求最长连续序列，但是快排都需要nlogn的时间消耗，同时还需要去重操作，所以我想到的是用Map来存放数组元素，Map的key和value均为数组元素值，这样同时满足了排序和去重的需求，而且所耗时间为n（此处我忽略了map中key对负数的处理，导致我的代码只对数组中元素均为正数的情况有效），然后遍历map判定其下一个元素是否在map中存在，以此来找出最长连续序列，代码如下： 123456789101112131415161718192021public int longestConsecutive(int[] nums) &#123; if(nums.length==0) return 0; if(nums.length==1) return nums[0]; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i],nums[i]); &#125; int maxLength = 1; int tempLength = 1; for(Map.Entry&lt;Integer,Integer&gt; entry : map.entrySet())&#123; if(map.get(entry.getKey()+1)!=null)&#123; tempLength++; &#125;else&#123; maxLength = maxLength &gt; tempLength ? maxLength : tempLength; tempLength = 1; &#125; &#125; return maxLength; &#125; 改进：map改用set去重，然后遍历数组，然后利用set找出以该元素为中心的连续序列的上下限为多少（之前用map的好处是已经排好序，只需找出上限即可），实现代码如下： 123456789101112131415161718192021222324252627public class Solution &#123; /** * @param nums: A list of integers * @return an integer */ public int longestConsecutive(int[] nums) &#123; HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; set.add(nums[i]); &#125; int longest = 0; for (int i = 0; i &lt; nums.length; i++) &#123; int down = nums[i] - 1; while (set.contains(down)) &#123; set.remove(down); down--; &#125; int up = nums[i] + 1; while (set.contains(up)) &#123; set.remove(up); up++; &#125; longest = Math.max(longest, up - down - 1); &#125; return longest; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Merge K Sorted Lists]]></title>
    <url>%2F2017%2F11%2F11%2FLintCode_MergeKSortedLists%2F</url>
    <content type="text"><![CDATA[Description Merge k sorted linked lists and return it as one sorted list.Analyze and describe its complexity. 思路 合并K个有序链表，且不去重，首先联想到的是合并两个有序单链表的思路，然年顺势往下推，遍历K个有序单链表，依次与前面的结果相合并，最后返回结果，实现代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940public class Solution &#123; /** * @param lists: a list of ListNode * @return: The head of one sorted list. */ public ListNode mergeKLists(List&lt;ListNode&gt; lists) &#123; // write your code here ListNode listNode = null; if (lists == null) return listNode; if(lists.size() == 0 || lists.isEmpty()) return listNode; for (ListNode node : lists) &#123; if (node == null) continue; listNode = mergeList(listNode,node); &#125; return listNode; &#125; public ListNode mergeList(ListNode tempNode,ListNode tempNode1)&#123; ListNode listNode = new ListNode(0); ListNode tempListNode = listNode; while(tempNode!=null&amp;&amp;tempNode1!=null)&#123; if(tempNode.val&lt;tempNode1.val)&#123; tempListNode.next = tempNode; tempListNode = tempNode; tempNode = tempNode.next; &#125;else&#123; tempListNode.next = tempNode1; tempListNode = tempNode1; tempNode1 = tempNode1.next; &#125; &#125; if(tempNode!=null) tempListNode.next = tempNode; if(tempNode1!=null) tempListNode.next = tempNode1; return listNode.next; &#125;&#125; 改进，上述由于是直接遍历List，所以循环次数（即合并次数）为n，但是我们可以通过两两合并（参照二叉树结构从子节点向上合并，最终到达根节点）来降低黑冰次数为n/2，参考答案代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Solution &#123; /** * @param lists: a list of ListNode * @return: The head of one sorted list. */ public ListNode mergeKLists(List&lt;ListNode&gt; lists) &#123; if (lists.size() == 0) &#123; return null; &#125; return mergeHelper(lists, 0, lists.size() - 1); &#125; //借助递归来实现List的不断二等分 private ListNode mergeHelper(List&lt;ListNode&gt; lists, int start, int end) &#123; if (start == end) &#123; return lists.get(start); &#125; int mid = start + (end - start) / 2; ListNode left = mergeHelper(lists, start, mid); ListNode right = mergeHelper(lists, mid + 1, end); return mergeTwoLists(left, right); &#125; private ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; ListNode dummy = new ListNode(0); ListNode tail = dummy; while (list1 != null &amp;&amp; list2 != null) &#123; if (list1.val &lt; list2.val) &#123; tail.next = list1; tail = list1; list1 = list1.next; &#125; else &#123; tail.next = list2; tail = list2; list2 = list2.next; &#125; &#125; if (list1 != null) &#123; tail.next = list1; &#125; else &#123; tail.next = list2; &#125; return dummy.next; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Min Stack]]></title>
    <url>%2F2017%2F11%2F04%2FLintCode_MinStack%2F</url>
    <content type="text"><![CDATA[Description Implement a stack with min() function, which will return the smallest number in the stack.It should support push, pop and min operation all in O(1) cost. 思路 最直接的想法，遍历求最小值，每次入栈和出栈都会造成遍历的发生 改进：从一开始就比较每一个入栈的值，将最小值存入MIN中，但是，出栈依然会导致MIN值的缺失，从而触发遍历求最小值，我只想到这里。。。代码入下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class MinStack &#123; private Stack&lt;Integer&gt; stack = null; private int MIN = Integer.MIN_VALUE; public MinStack() &#123; // do intialization if necessary stack = new Stack&lt;Integer&gt;(); &#125; /* * @param number: An integer * @return: nothing */ public void push(int number) &#123; // write your code here if(MIN==Integer.MIN_VALUE)&#123; MIN = number; &#125;else&#123; MIN = number&gt;MIN?MIN:number; &#125; stack.push(number); &#125; /* * @return: An integer */ public int pop() &#123; // write your code here int topValue = stack.pop(); if(topValue==MIN)&#123; MIN = getMin(); &#125; return topValue; &#125; /* * @return: An integer */ public int min() &#123; // write your code here return MIN; &#125; public int getMin()&#123; if(stack.isEmpty())&#123; MIN = Integer.MIN_VALUE; &#125;else&#123; MIN = stack.peek(); for(Integer value:stack)&#123; MIN = value&gt;MIN?MIN:value; &#125; &#125; return MIN; &#125;&#125; 动态规划的思路，同样是从一开始就比较每一个入栈的值，然后将当前栈中的最小值存入另一个栈中，这样在入栈的时候就记录好了该元素发生入栈操作和出栈操作时候栈中的最小值，避免了遍历找寻最小值的时间，代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); minStack = new Stack&lt;Integer&gt;(); &#125; public void push(int number) &#123; stack.push(number); if (minStack.isEmpty()) &#123; minStack.push(number); &#125; else &#123; minStack.push(Math.min(number, minStack.peek())); &#125; &#125; public int pop() &#123; minStack.pop(); return stack.pop(); &#125; public int min() &#123; return minStack.peek(); &#125;&#125;// version 2, save more space. but space complexity doesn't change.//相同最小值将不会重复存入栈中，节省栈空间public class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); minStack = new Stack&lt;Integer&gt;(); &#125; public void push(int number) &#123; stack.push(number); if (minStack.empty() == true) minStack.push(number); else &#123; // 这里考虑的相等的情况也会继续push if (minStack.peek() &gt;= number) minStack.push(number); &#125; &#125; public int pop() &#123; if (stack.peek().equals(minStack.peek()) ) minStack.pop(); return stack.pop(); &#125; public int min() &#123; return minStack.peek(); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_ImplementQueueByTwoStacks]]></title>
    <url>%2F2017%2F10%2F28%2FLintCode_ImplementQueueByTwoStacks%2F</url>
    <content type="text"><![CDATA[Description As the title described, you should only use two stacks to implement a queue’s actions.The queue should support push(element), pop() and top() where pop is pop the first(a.k.a front) element in the queue.Both pop and top methods should return the value of first element. 思路 第一反应就是一个栈来存正序入队列的值，另一个存反序，入队列的时候往正序栈中添加，出队列的时候从反序栈中取栈顶，但是，两个栈的关系一直没有梳理清晰，直到看了提供标准答案才豁然卡朗，还是智商有点捉急啊。 两个栈的关系其实跟我一开始想的一样，栈A用来存入队列正序值，栈B用来存逆序，入队列的值负责往A中进入，出队列的时候先判定B是否为空，不为空，说明之前入队列进来的值还没有走光，B可以继续进行出队列操作，若B为空，则需要将A中值逆序放入B中，然后在进行出队列操作！ 注意：这里的正序和逆序指的是元素的先来后到的顺序，不是大小顺序 后来发现java提供的栈方法就可以很简洁的实现队列的操作（相当于底层方法帮助我们实现了这个功能）代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ImplementQueuebyTwoStacks &#123; private Stack&lt;Integer&gt; queue = null; public void MyQueue() &#123; // do intialization if necessary queue = new Stack&lt;Integer&gt;(); &#125; /* * @param element: An integer * @return: nothing */ public void push(int element) &#123; // write your code here queue.push(element); &#125; /* * @return: An integer */ public int pop() &#123; // write your code here int headValue = queue.firstElement();//获取栈底元素 queue.remove(0);//移除栈底元素 return headValue; &#125; /* * @return: An integer */ public int top() &#123; // write your code here return queue.firstElement(); &#125;&#125;//以下是官方标准代码public class MyQueue &#123; private Stack&lt;Integer&gt; stack1; private Stack&lt;Integer&gt; stack2; public MyQueue() &#123; // do initialization if necessary stack1 = new Stack&lt;Integer&gt;(); stack2 = new Stack&lt;Integer&gt;(); &#125; private void stack2ToStack1()&#123; while(! stack2.isEmpty())&#123; stack1.push(stack2.pop()); &#125; &#125; public void push(int element) &#123; // write your code here stack2.push(element); &#125; public int pop() &#123; // write your code here if(stack1.empty() == true)&#123; this.stack2ToStack1(); &#125; return stack1.pop(); &#125; public int top() &#123; // write your code here if(stack1.empty() == true)&#123; this.stack2ToStack1(); &#125; return stack1.peek(); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO详解]]></title>
    <url>%2F2017%2F10%2F21%2FIO%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[java8新特性 本文参考自官方文档What’s New in JDK 8，内容有所筛选！ 目录 BufferedInputStream BufferedInputStream(InputStream in)Creates a BufferedInputStream and saves its argument, the input stream in, for later use. BufferedInputStream(InputStream in, int size)Creates a BufferedInputStream with the specified buffer size, and saves its argument, the input stream in, for later use. BufferedOutputStream BufferedOutputStream(OutputStream out)Creates a new buffered output stream to write data to the specified underlying output stream. BufferedOutputStream(OutputStream out, int size)Creates a new buffered output stream to write data to the specified underlying output stream with the specified buffer size. BufferedReader BufferedReader(Reader in)Creates a buffering character-input stream that uses a default-sized input buffer. BufferedReader(Reader in, int sz)Creates a buffering character-input stream that uses an input buffer of the specified size. BufferedWriter BufferedWriter(Writer out)Creates a buffered character-output stream that uses a default-sized output buffer. BufferedWriter(Writer out, int sz)Creates a new buffered character-output stream that uses an output buffer of the given size. ByteArrayInputStream ByteArrayInputStream(byte[] buf)Creates a ByteArrayInputStream so that it uses buf as its buffer array. ByteArrayInputStream(byte[] buf, int offset, int length)Creates ByteArrayInputStream that uses buf as its buffer array. ByteArrayOutputStream ByteArrayOutputStream()Creates a new byte array output stream. ByteArrayOutputStream(int size)Creates a new byte array output stream, with a buffer capacity of the specified size, in bytes. CharArrayReader CharArrayReader(char[] buf)Creates a CharArrayReader from the specified array of chars. CharArrayReader(char[] buf, int offset, int length)Creates a CharArrayReader from the specified array of chars. CharArrayWriter CharArrayWriter()Creates a new CharArrayWriter. CharArrayWriter(int initialSize)Creates a new CharArrayWriter with the specified initial size. Console DataInputStream DataInputStream(InputStream in)Creates a DataInputStream that uses the specified underlying InputStream. DataOutputStream DataOutputStream(OutputStream out)Creates a new data output stream to write data to the specified underlying output stream. File File(File parent, String child)Creates a new File instance from a parent abstract pathname and a child pathname string. File(String pathname)Creates a new File instance by converting the given pathname string into an abstract pathname. File(String parent, String child)Creates a new File instance from a parent pathname string and a child pathname string. File(URI uri)Creates a new File instance by converting the given file: URI into an abstract pathname. FileDescriptor FileInputStream FileInputStream(File file)Creates a FileInputStream by opening a connection to an actual file, the file named by the File object file in the file system. FileInputStream(FileDescriptor fdObj)Creates a FileInputStream by using the file descriptor fdObj, which represents an existing connection to an actual file in the file system. FileInputStream(String name)Creates a FileInputStream by opening a connection to an actual file, the file named by the path name name in the file system. FileOutputStream FileOutputStream(File file)Creates a file output stream to write to the file represented by the specified File object. FileOutputStream(File file, boolean append)Creates a file output stream to write to the file represented by the specified File object. FileOutputStream(FileDescriptor fdObj)Creates a file output stream to write to the specified file descriptor, which represents an existing connection to an actual file in the file system. FileOutputStream(String name)Creates a file output stream to write to the file with the specified name. FileOutputStream(String name, boolean append)Creates a file output stream to write to the file with the specified name. FilePermission FileReader FileReader(File file)Creates a new FileReader, given the File to read from. FileReader(FileDescriptor fd)Creates a new FileReader, given the FileDescriptor to read from. FileReader(String fileName)Creates a new FileReader, given the name of the file to read from. FileWriter FileWriter(File file)Constructs a FileWriter object given a File object. FileWriter(File file, boolean append)Constructs a FileWriter object given a File object. FileWriter(FileDescriptor fd)Constructs a FileWriter object associated with a file descriptor. FileWriter(String fileName)Constructs a FileWriter object given a file name. FileWriter(String fileName, boolean append)Constructs a FileWriter object given a file name with a boolean indicating whether or not to append the data written. FilterInputStream FilterOutputStream FilterReader FilterWriter InputStream InputStream() InputStreamReader InputStreamReader(InputStream in)Creates an InputStreamReader that uses the default charset. InputStreamReader(InputStream in, Charset cs)Creates an InputStreamReader that uses the given charset. InputStreamReader(InputStream in, CharsetDecoder dec)Creates an InputStreamReader that uses the given charset decoder. InputStreamReader(InputStream in, String charsetName)Creates an InputStreamReader that uses the named charset. LineNumberInputStream LineNumberReader ObjectInputStream ObjectInputStream.GetField ObjectOutputStream ObjectOutputStream.PutField ObjectStreamClass ObjectStreamField OutputStream OutputStream() OutputStreamWriter OutputStreamWriter(OutputStream out)Creates an OutputStreamWriter that uses the default character encoding. OutputStreamWriter(OutputStream out, Charset cs)Creates an OutputStreamWriter that uses the given charset. OutputStreamWriter(OutputStream out, CharsetEncoder enc)Creates an OutputStreamWriter that uses the given charset encoder. OutputStreamWriter(OutputStream out, String charsetName)Creates an OutputStreamWriter that uses the named charset. PipedInputStream PipedInputStream()Creates a PipedInputStream so that it is not yet connected. PipedInputStream(int pipeSize)Creates a PipedInputStream so that it is not yet connected and uses the specified pipe size for the pipe’s buffer. PipedInputStream(PipedOutputStream src)Creates a PipedInputStream so that it is connected to the piped output stream src. PipedInputStream(PipedOutputStream src, int pipeSize)Creates a PipedInputStream so that it is connected to the piped output stream src and uses the specified pipe size for the pipe’s buffer. PipedOutputStream PipedOutputStream()Creates a piped output stream that is not yet connected to a piped input stream. PipedOutputStream(PipedInputStream snk)Creates a piped output stream connected to the specified piped input stream. PipedReader PipedReader()Creates a PipedReader so that it is not yet connected. PipedReader(int pipeSize)Creates a PipedReader so that it is not yet connected and uses the specified pipe size for the pipe’s buffer. PipedReader(PipedWriter src)Creates a PipedReader so that it is connected to the piped writer src. PipedReader(PipedWriter src, int pipeSize)Creates a PipedReader so that it is connected to the piped writer src and uses the specified pipe size for the pipe’s buffer. PipedWriter PipedWriter()Creates a piped writer that is not yet connected to a piped reader. PipedWriter(PipedReader snk)Creates a piped writer connected to the specified piped reader. PrintStream PrintWriter PushbackInputStream PushbackReader RandomAccessFile RandomAccessFile(File file, String mode)Creates a random access file stream to read from, and optionally to write to, the file specified by the File argument. RandomAccessFile(String name, String mode)Creates a random access file stream to read from, and optionally to write to, a file with the specified name. Reader Reader()Creates a new character-stream reader whose critical sections will synchronize on the reader itself. protected Reader(Object lock)Creates a new character-stream reader whose critical sections will synchronize on the given object. SequenceInputStream SerializablePermission StreamTokenizer StringBufferInputStream StringReader StringReader(String s)Creates a new string reader. StringWriter StringWriter()Create a new string writer using the default initial string-buffer size. StringWriter(int initialSize)Create a new string writer using the specified initial string-buffer size. Writer Writer()Creates a new character-stream writer whose critical sections will synchronize on the writer itself. protected Writer(Object lock)Creates a new character-stream writer whose critical sections will synchronize on the given object.]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>IO</tag>
        <tag>File</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8新特性]]></title>
    <url>%2F2017%2F10%2F21%2Fjava8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[java8新特性 本文参考自官方文档What’s New in JDK 8，内容有所筛选！ 目录 Java Programming Language Lambda Expressions（Lambda表达式） Method references （方法引用） Default methods （默认方法） Repeating Annotations （重复注释） Improved type inference（更好的类型推断） Method parameter reflection（方法参数反射） Collections（集合） Tool（工具） Javac tool Javadoc tool Internationalization（国际化） Date-Time Package （日期时间） IO and NIO java.lang and java.util Packages Parallel Array Sorting（并行数组排序） Standard Encoding and Decoding Base64（标准编码和解码Base64） Unsigned Arithmetic Support（无符号算术支持） JDBC The JDBC-ODBC Bridge has been removed. JDBC 4.2 introduces new features. Concurrency（并发） HotSpot 正文Java编程语言 Lambda表达式 Lambda表达式是一种新的语言功能，已在此版本中引入。它们使您能够将功能视为方法参数，或将代码视为数据。使用Lambda表达式可以更简洁地表达单方法接口（称为函数接口）的实例。 Lambda表达式可由逗号分隔的参数列表、-&gt;符号和语句块组成（其中参数列表中的参数e的类型可以由编译器推理得出的，也可以显式指定该参数的类型），例如： 1234567891011//基本语法://(params) -&gt; expression//(params) -&gt; statement//(params) -&gt; &#123; statements &#125;Arrays.asList( "a", "b", "d" ).forEach( e -&gt; System.out.println( e ) );//等价于Arrays.asList( "a", "b", "d" ).forEach( ( String e ) -&gt; System.out.println( e ) );Arrays.asList( "a", "b", "d" ).forEach( e -&gt; &#123; System.out.print( e ); System.out.print( e );&#125; ); Lambda表达式可以引用类成员和局部变量（会将这些变量隐式得转换成final），但是不能在lambda内部修改定义在域外的变量。同时Lambda表达式有返回值，返回值的类型也由编译器推理得出。如果Lambda表达式中的语句块只有一行，则可以不用使用return语句，例如 12345678(final) String separator = ",";Arrays.asList( "a", "b", "d" ).forEach( ( String e ) -&gt; System.out.print( e + separator ) );//Lambda表达式中语句块只有一行，可以不用使用return语句Arrays.asList( "a", "b", "d" ).sort( ( e1, e2 ) -&gt; e1.compareTo( e2 ) );Arrays.asList( "a", "b", "d" ).sort( ( e1, e2 ) -&gt; &#123; int result = e1.compareTo( e2 ); return result;&#125; ); 函数接口 函数接口指的是只有一个函数的接口，这样的接口可以隐式转换为Lambda表达式。java.lang.Runnable和java.util.concurrent.Callable是函数式接口的最佳例子。在实践中，函数式接口非常脆弱：只要某个开发者在该接口中添加一个函数，则该接口就不再是函数式接口进而导致编译失败。为了克服这种代码层面的脆弱性，并显式说明某个接口是函数式接口，Java 8 提供了一个特殊的注解@FunctionalInterface（Java 库中的所有相关接口都已经带有这个注解了），举个简单的函数式接口的定义： 1234@FunctionalInterfacepublic interface Functional &#123; void method();&#125; 不过有一点需要注意，默认方法和静态方法不会破坏函数式接口的定义，因此如下的代码是合法的。 1234567891011121314@FunctionalInterfacepublic interface FunctionalDefaultMethods &#123; void method(); default void defaultMethod() &#123; &#125; &#125;@FunctionalInterfacepublic interface FunctionalStaticMethods &#123; void method(); Static void defaultMethod() &#123; &#125; &#125; lambda表达式替换匿名类 1234567891011121314151617181920212223// Java 8之前：new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("Before Java8, too much code for too little to do"); &#125;&#125;).start();//Java 8方式：new Thread( () -&gt; System.out.println("In Java8, Lambda expression rocks !!") ).start();// Java 8之前：Collections.sort(list, new Comparator&lt;Object&gt;() &#123; public int compare(Object arg0, Object arg1) &#123; String s1 = (String)arg0; String s2 = (String)arg1; return s1.compareTo( s2 ); &#125; &#125;);//Java 8方式： Collections.sort(list,(arg0,arg1) -&gt; &#123; String s1 = (String)arg0; String s2 = (String)arg1; return s1.compareTo( s2 ); &#125;); ####Stream stream()Stream filter(Predicate&lt;? super T&gt; predicate) Stream map(Function&lt;? super T,? extends R&gt; mapper)void forEach(Consumer&lt;? super T&gt; action) 1 方法引用 方法引用为已有名称的方法提供易读的lambda表达式。lambda表达式内可以使用方法引用，仅当该方法不修改lambda表达式提供的参数。 （引用静态方法）ContainingClass :: staticMethodName 1Arrays.sort(rosterAsArray, MyComparisonProvider::staticCompare); （引用特定对象的实例方法）containsObject :: instanceMethodName 12//ComparisonProvider myComparisonProvider = new ComparisonProvider();Arrays.sort(rosterAsArray, myComparisonProvider::normalCompare); （引用特定类型任意对象的实例方法）ContainingType :: methodName 123String[] stringArray = &#123; "Barbara", "James", "Mary", "John", "Patricia", "Robert", "Michael", "Linda" &#125;;Arrays.sort(stringArray, String::compareToIgnoreCase); （引用一个构造函数）ClassName :: new 1Set&lt;Person&gt; rosterSet = transferElements(roster, HashSet::new); 默认方法 默认方法可以将新功能添加到库的接口，并确保与为这些接口的旧版本编写的代码的二进制兼容性。 12345678910public interface TimeClient &#123; //通过接口直接调用该静态方法 static void dispaly () &#123; System.out.println("static"); &#125; //该接口的实现类不强制要求重写default方法，使得接口可以添加新功能而不影响其实现类 default void dispaly() &#123; System.out.println("default"); &#125; &#125; 重复注释 重复注释提供了将同一注释类型多次应用于相同的声明或类型使用的功能。Java8之前的注解有一个很大的限制是：在同一个地方不能多次使用同一个注解。Java 8打破了这个限制，引入了重复注解的概念，允许在同一个地方多次使用同一个注解。在Java 8中使用@Repeatable注解定义重复注解，实际上，这并不是语言层面的改进，而是编译器做的一个trick，底层的技术仍然相同。 12345678910@Schedule(dayOfMonth="last")@Schedule(dayOfWeek="Fri", hour="23")public void doPeriodicCleanup() &#123; ... &#125;//The annotation type must be marked with the @Repeatable meta-annotation@Repeatable(Schedules.class)public @interface Schedule &#123; String dayOfMonth() default "first"; String dayOfWeek() default "Mon"; int hour() default 12;&#125; 更好的类型推断 12345678//Java 8方式： List&lt;String&gt; stringList = new ArrayList&lt;&gt;();stringList.add("A");stringList.addAll(Arrays.asList());//Java 8之前： List&lt;String&gt; stringList = new ArrayList&lt;&gt;();stringList.add("A");stringList.addAll(Arrays.&lt;String&gt;asList()); 方法参数反射 您可以使用方法java.lang.reflect.Executable.getParameters获取任何方法或构造函数的形式参数的名称。 （类Method和构造函数扩展了类Executable，因此继承了方法Executable.getParameters。）但是，.class文件默认不存储形式参数名称。 要将正式参数名称存储在特定的.class文件中，从而使Reflection API能够检索正式的参数名称，请使用javac编译器的-parameters选项编译源文件。 12345678public class ParameterNames &#123; public static void main(String[] args) throws Exception &#123; Method method = ParameterNames.class.getMethod( "main", String[].class ); for( final Parameter parameter: method.getParameters() ) &#123; System.out.println( "Parameter: " + parameter.getName() ); &#125; &#125;&#125; 集合 新的java.util.stream包中的类提供了一个Stream API来支持元素流上的函数式操作。 Stream API集成到Collections API中，可以对集合进行批量操作，例如顺序或并行的map-reduce转换。 java.util.stream.Stream部分方法如下 Stream filter(Predicate&lt;? super T&gt; predicate)（过滤） Stream map(Function&lt;? super T,? extends R&gt; mapper)（转换） IntStream mapToInt(ToIntFunction&lt;? super T&gt; mapper) Stream distinct()（返回由此流的不同元素，去重） Stream sorted()（默认排序） Stream sorted(Comparator&lt;? super T&gt; comparator)（排序） Stream peek(Consumer&lt;? super T&gt; action) 1234567//This method exists mainly to support debugging, where you want to see the elements as they flow past a certain point in a pipeline:Stream.of("one", "two", "three", "four") .filter(e -&gt; e.length() &gt; 3) .peek(e -&gt; System.out.println("Filtered value: " + e)) .map(String::toUpperCase) .peek(e -&gt; System.out.println("Mapped value: " + e)) .collect(Collectors.toList()); Stream limit(long maxSize)（限制） Stream skip(long n)（跳过前n个元素） void forEach(Consumer&lt;? super T&gt; action)（迭代） void forEachOrdered(Consumer&lt;? super T&gt; action) Object[] toArray()（转换成数组） 1Person[] men = people.stream().filter(p -&gt; p.getGender() == MALE).toArray(Person[]::new); T reduce(T identity,BinaryOperator accumulator)（合并） Optional reduce(BinaryOperator accumulator) U reduce(U identity,BiFunction accumulator,BinaryOperator combiner) R collect(Supplier supplier,BiConsumer accumulator,BiConsumer combiner) 1234//The following will accumulate strings into an ArrayList:List&lt;String&gt; asList = stringStream.collect(ArrayList::new, ArrayList::add,ArrayList::addAll);//The following will take a stream of strings and concatenates them into a single string:String concat = stringStream.collect(StringBuilder::new, StringBuilder::append,StringBuilder::append).toString(); R collect(Collector&lt;? super T,A,R&gt; collector) 123456//The following will accumulate strings into an ArrayList:List&lt;String&gt; asList = stringStream.collect(Collectors.toList());//The following will classify Person objects by city:按照城市分组Map&lt;String, List&lt;Person&gt;&gt;peopleByCity= personStream.collect(Collectors.groupingBy(Person::getCity));//The following will classify Person objects by state and city, cascading two Collectors together:按照国家和城市两项进行分组Map&lt;String, Map&lt;String, List&lt;Person&gt;&gt;&gt; peopleByStateAndCity= personStream.collect(Collectors.groupingBy(Person::getState,Collectors.groupingBy(Person::getCity))); Optional min(Comparator&lt;? super T&gt; comparator)（最小值） Optional max(Comparator&lt;? super T&gt; comparator)（最大值） long count()（计数） boolean anyMatch(Predicate&lt;? super T&gt; predicate)（匹配） boolean allMatch(Predicate&lt;? super T&gt; predicate) boolean noneMatch(Predicate&lt;? super T&gt; predicate) Optional findFirst() Optional findAny() static Stream empty() static Stream of(T t)（返回包含单个元素的顺序流。） static Stream of(T… values)（返回顺序排列的流，其元素是指定的值。） static Stream concat(Stream&lt;? extends T&gt; a,Stream&lt;? extends T&gt; b)（连接） forEach对列表进行迭代 12345678910// Java 8之前：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");for (String feature : features) &#123; System.out.println(feature);&#125;// Java 8之后：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");features.forEach(n -&gt; System.out.println(n));// 使用Java 8的方法引用更方便features.forEach(System.out::println); map将对象进行转换，reduce结果合并 123456789101112131415161718192021// Java 8之前：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; System.out.println(price);&#125;// Java 8之后：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).forEach(System.out::println);// Java 8之前：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double total = 0;for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; total = total + price;&#125;System.out.println("Total : " + total);// Java 8之后：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println("Total : " + bill); filter元素过滤 123// 创建一个字符串列表，每个字符串长度大于2List&lt;String&gt; filtered = strList.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList());System.out.printf("Original List : %s, filtered list : %s %n", strList, filtered); 具有关键冲突的HashMap性能改进 工具 Javac工具javac命令的-parameters选项可用于存储形式参数名称并使Reflection API检索正式参数名称。 Java语言规范（JLS）第15.21节中的相等运算符的类型规则现在可以通过javac命令正确执行。 Javadoc工具javadoc工具支持新的DocTree API，使您能够将Javadoc注释作为抽象语法树来遍历。 javadoc工具支持新的Javadoc Access API，使您可以直接从Java应用程序调用Javadoc工具，而无需执行新的过程。有关更多信息，请参阅javadoc什么是新页面。 现在，javadoc工具支持检查javadoc注释的内容，以解决可能导致运行javadoc时生成的文件中的各种问题（例如无效的HTML或可访问性问题）的问题。该功能默认启用，也可以通过新的-Xdoclint选项进行控制。有关更多详细信息，请参阅运行“javadoc -X”的输出。在javac工具中也可以使用此功能，但默认情况下它未启用。 国际化 Unicode增强功能，包括对Unicode 6.2.0的支持 采用Unicode CLDR数据和java.locale.providers系统属性 新的日历和区域设置API 能够将自定义资源包安装为扩展 日期时间包 - 一组提供全面日期 - 时间模型的新包。 IO和NIO 基于Solaris事件端口机制的Solaris新增SelectorProvider实现。要使用，使用设置为值sun.nio.ch.EventPortSelectorProvider的系统属性java.nio.channels.spi.Selector运行。 减小 /jre/lib/charsets.jar文件的大小 提高了java.lang.String（byte []，*）构造函数和java.lang.String.getBytes（）方法的性能。 java.lang和java.util包 并行数组排序 标准编码和解码Base64 无符号算术支持 JDBC- JDBC-ODBC Bridge已被删除。 - JDBC 4.2引入了新功能。 并发 类和接口已被添加到java.util.concurrent包中。 已经将方法添加到java.util.concurrent.ConcurrentHashMap类中，以支持基于新添加的流设施和lambda表达式的聚合操作。 已将类添加到java.util.concurrent.atomic包以支持可伸缩的可更新变量。 方法已被添加到java.util.concurrent.ForkJoinPool类中以支持公共池。 已添加java.util.concurrent.locks.StampedLock类以提供基于能力的锁，其中有三种控制读/写访问的模式。 HotSpot 硬件内在函数被添加到使用高级加密标准（AES）。 UseAES和UseAESIntrinsics标志可用于启用英特尔硬件的基于硬件的AES内在函数。硬件必须是2010年或更新的Westmere硬件。例如，要启用硬件AES，请使用以下标志：-XX：+ UseAES -XX：+ UseAESIntrinsics，要禁用硬件AES，请使用以下标志：-XX：-UseAES -XX：-UseAESIntrinsics 去除PermGen。 Java编程语言中的缺省方法由方法调用的字节码指令支持。 将值赋值给变量—-Java8之前将表达式，一段代码赋值给变量 这种只有一个接口函数需要被实现的接口类型，我们叫它”函数式接口“。为了避免后来的人在这个接口中增加接口函数导致其有多个接口函数需要被实现，变成”非函数接口”，我们可以在这个上面加上一个声明@FunctionalInterface, 这样别人就无法在里面添加新的接口函数了 stream流的应用 Lambda配合Optional可以使Java对于null的处理变的异常优雅Optionaloptional=Optional.ofNullable(LOGGING.valueOf(“debug”));optional.ifPresent(System.out::println); 你要是一定要在Lambda表达式里面修改外部变量的值也是可以的，可以将变量定义为实例变量或者将变量定义为数组。 Obejcts静态不可变类，对象object的工具类，可用于判定对象的空，非空，哈希值等操作 今天使用lambda表达式处理集合时，发现对return、break以及continue的使用有点迷惑，于是自己动手测试了一下，才发现在使用foreach()处理集合时不能使用break和continue这两个方法，也就是说不能按照普通的for循环遍历集合时那样根据条件来中止遍历，而如果要实现在普通for循环中的效果时，可以使用return来达到，也就是说如果你在一个方法的lambda表达式中使用return时，这个方法是不会返回的，而只是执行下一次遍历， 日期时间LocalDateLocalTimeLocalDateTimeTimestamp 静态方法+实例方法 LocalDate -&gt; LocalTimeLocalTime -&gt; LocalDate LocalDate -&gt; LocalDateTimeLocalDateTime -&gt; LocalDate LocalTime -&gt; LocalDateTimeLocalDateTime -&gt; LocalTime LocalDate -&gt; StringString -&gt; LocalDate LocalTime -&gt; StringString -&gt; LocalTime LocalDateTime -&gt; StringString -&gt; LocalDateTime publicvoiddateTest(){/* LocalDateLocalTime LocalDateTime*/LocalDatelocalDate=LocalDate.now();LocalTimelocalTime=LocalTime.now();LocalDateTimelocalDateTime=LocalDateTime.now(); //日期时间转字符串StringstringDate=localDate.format(DateTimeFormatter.ofPattern(“yyyy-MM-dd”));StringstringTime=localTime.format(DateTimeFormatter.ofPattern(“hh:mm:ss”));StringstringDateTime=localDateTime.format(DateTimeFormatter.ofPattern(“yyyy-MM-ddhh:mm:ss”)); //字符串转日期时间LocalDatedate=LocalDate.parse(“stringDate”);LocalTimetime=LocalTime.parse(“stringTime”);LocalDateTimedateTime=LocalDateTime.parse(“stringDateTime”); //日期时间互转LocalDatedate1=localDateTime.toLocalDate();LocalTimetime1=localDateTime.toLocalTime(); }]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式文档]]></content>
      <categories>
        <category>Regular_Expression</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Regular_Expression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库优化]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[数据库优化选取最适用的字段属性 数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。 例如，邮政编码字段，CHAR(6)好过CHAR(255)和VARCHAR，同样MEDIUMINT好过BIGIN来定义整型字段（五种整型tinyint，smallint，mediumint，int，bigint）。 把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。 使用连接（JOIN）来代替子查询(Sub-Queries) MySQL从4.1开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接（JOIN）..替代。连接（JOIN）..之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 使用联合(UNION)来代替手动创建的临时表 MySQL从4.0的版本开始支持union查询，它可以把需要使用临时表的两条或更多的select查询合并的一个查询中。在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐、高效。使用union来创建查询的时候，我们只需要用UNION作为关键字把多个select语句连接起来就可以了，要注意的是所有select语句中的字段数目要想同。例如。SELECT Name,Phone FROM client UNION SELECT Name,BirthDate FROM author 事务 尽管我们可以使用子查询（Sub-Queries）、连接（JOIN）和联合（UNION）来创建各种各样的查询，但不是所有的数据库操作都可以只用一条或少数几条SQL语句就可以完成的。更多的时候是需要用到一系列的语句来完成某种工作。但是在这种情况下，当这个语句块中的某一条语句运行出错的时候，整个语句块的操作就会变得不确定起来。设想一下，要把某个数据同时插入两个相关联的表中，可能会出现这样的情况：第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样，就会造成数据的不完整，甚至会破坏数据库中的数据。要避免这种情况，就应该使用事务，它的作用是：要么语句块中每条语句都操作成功，要么都失败。换句话说，就是可以保持数据库中数据的一致性和完整性。事物以BEGIN关键字开始，COMMIT关键字结束。在这之间的一条SQL操作失败，那么，ROLLBACK命令就可以把数据库恢复到BEGIN开始之前的状态。 BEGIN;INSERT INTO salesinfo …;UPDATE inventory SET Quantity = 11 WHERE item = ‘book’;COMMIT; 事务的另一个重要作用是当多个用户同时使用相同的数据源时，它可以利用锁定数据库的方法来为用户提供一种安全的访问方式，这样可以保证用户的操作不被其它的用户所干扰。 锁定表 尽管事务是维护数据库完整性的一个非常好的方法，但却因为它的独占性，有时会影响数据库的性能，尤其是在很大的应用系统中。由于在事务执行的过程中，数据库将会被锁定，因此其它的用户请求只能暂时等待直到该事务结束。如果一个数据库系统只有少数几个用户来使用，事务造成的影响不会成为一个太大的问题；但假设有成千上万的用户同时访问一个数据库系统，例如访问一个电子商务网站，就会产生比较严重的响应延迟。 其实，有些情况下我们可以通过锁定表的方法来获得更好的性能。下面的例子就用锁定表的方法来完成前面一个例子中事务的功能。 LOCKTABLE inventory WRITESELECT Quantity FROM inventory WHERE Item = ‘book’;…UPDATE inventory SET Quantity = 11 WHERE Item = ‘book’;UNLOCKTABLES 这里，我们用一个select语句取出初始数据，通过一些计算，用update语句将新值更新到表中。包含有WRITE关键字的LOCKTABLE语句可以保证在UNLOCKTABLES命令被执行之前，不会有其它的访问来对inventory进行插入、更新或者删除的操作。 使用索引 索引是提高数据库性能的常用方法，它可以令数据库服务器以比没有索引快得多的速度检索特定的行，尤其是在查询语句当中包含有MAX(),MIN()和ORDERBY这些命令的时候，性能提高更为明显。 那该对哪些字段建立索引呢？一般说来，索引应建立在那些将用于JOIN,WHERE判断和ORDERBY排序的字段上。尽量不要对数据库中某个含有大量重复的值的字段建立索引。对于一个ENUM类型的字段来说，出现大量重复值是很有可能的情况 优化的查询语句 首先，最好是在相同类型的字段间进行比较的操作。在MySQL3.23版之前，这甚至是一个必须的条件。例如不能将一个建有索引的INT字段和BIGINT字段进行比较；但是作为特殊的情况，在CHAR类型的字段和VARCHAR类型字段的字段大小相同的时候，可以将它们进行比较。 其次，在建有索引的字段上尽量不要使用函数进行操作。例如，在一个DATE类型的字段上使用YEAE()函数时，将会使索引不能发挥应有的作用。所以，下面的两个查询虽然返回的结果一样，但后者要比前者快得多。 第三，在搜索字符型字段时，我们有时会使用LIKE关键字和通配符，这种做法虽然简单，但却也是以牺牲系统性能为代价的(like ‘xxx%’可以用到索引，但是like ‘%xxx%’不行，通过覆盖索引进行优化)。 例如下面的查询将会比较表中的每一条记录。SELECT FROM books WHERE name like “MySQL%”但是如果换用下面的查询，返回的结果一样，但速度就要快上很多：SELECT FROM books WHERE name＞=”MySQL” and name＜”MySQM” 数据分页处理 客户端(应用程序或浏览器)分页：将数据从应用服务器全部下载到本地应用程序或浏览器，在应用程序或浏览器内部通过本地代码进行分页处理 优点：编码简单，减少客户端与应用服务器网络交互次数 缺点：首次交互时间长，占用客户端内存 适应场景：客户端与应用服务器网络延时较大，但要求后续操作流畅，如手机GPRS，超远程访问（跨国）等等。 应用服务器分页：将数据从数据库服务器全部下载到应用服务器，在应用服务器内部再进行数据筛选。以下是一个应用服务器端Java程序分页的示例： 123List list=executeQuery(“select * from employee order by id”);Int count= list.size();List subList= list.subList(10, 20); 优点：编码简单，只需要一次SQL交互，总数据与分页数据差不多时性能较好。 缺点：总数据量较多时性能较差。 适应场景：数据库系统不支持分页处理，数据量较小并且可控。 数据库SQL分页：采用数据库SQL分页需要两次SQL完成，一个SQL计算总数量，一个SQL返回分页后的数据 优点：性能好 缺点：编码复杂，各种数据库语法不同，需要两次SQL交互。 oracle数据库一般采用rownum来进行分页，常用分页语法有如下两种： 直接通过rownum分页：数据访问开销=索引IO+索引全部记录结果对应的表数据IO 12345select * from ( select a.*,rownum rn from (select * from product a where company_id=? order by status) a where rownum&lt;=20)where rn&gt;10; 采用rowid分页语法：优化原理是通过纯索引找出分页记录的ROWID，再通过ROWID回表返回数据，要求内层查询和排序字段全在索引里。(数据访问开销=索引IO+索引分页结果对应的表数据IO) 12345678create index myindex on product(company_id,status);select b.* from ( select * from ( select a.*,rownum rn from (select rowid rid,status from product a where company_id=? order by status) a where rownum&lt;=20) where rn&gt;10) a, product bwhere a.rid=b.rowid; 减少交互次数 batch DML：数据库访问框架一般都提供了批量提交的接口，jdbc支持batch的提交处理方法，当你一次性要往一个表中插入1000万条数据时，如果采用普通的executeUpdate处理，那么和服务器交互次数为1000万次，按每秒钟可以向数据库服务器提交10000次估算，要完成所有工作需要1000秒。如果采用批量提交模式，1000条提交一次，那么和服务器交互次数为1万次，交互次数大大减少。采用batch操作一般不会减少很多数据库服务器的物理IO，但是会大大减少客户端与服务端的交互次数，从而减少了多次发起的网络延时开销，同时也会降低数据库的CPU开销。 In List 12//我们也可以做一个小的优化， 如下所示，用ID IN LIST的这种方式写SQL：select * from mytable where id in(:id1,id2,...,idn); 通过这样处理可以大大减少SQL请求的数量，从而提高性能。那如果有10000个ID，那是不是全部放在一条SQL里处理呢？答案肯定是否定的。首先大部份数据库都会有SQL长度和IN里个数的限制，如ORACLE的IN里就不允许超过1000个值。 另外当前数据库一般都是采用基于成本的优化规则，当IN数量达到一定值时有可能改变SQL执行计划，从索引访问变成全表访问，这将使性能急剧变化。随着SQL中IN的里面的值个数增加，SQL的执行计划会更复杂，占用的内存将会变大，这将会增加服务器CPU及内存成本。 评估在IN里面一次放多少个值还需要考虑应用服务器本地内存的开销，有并发访问时要计算本地数据使用周期内的并发上限，否则可能会导致内存溢出。 综合考虑，一般IN里面的值个数超过20个以后性能基本没什么太大变化，也特别说明不要超过100，超过后可能会引起执行计划的不稳定性及增加数据库CPU及内存成本，这个需要专业DBA评估。 如果确实想使用IN而且里面数量较多时，这个情况有两种解决方式： 将in列表里面的数据放入一张中间小表，采用两个表Hash Join关联的方式处理； 采用str2varList方法将字段串列表转换一个临时表处理； 设置Fetch Size 当我们采用select从数据库查询数据时，数据默认并不是一条一条返回给客户端的，也不是一次全部返回客户端的，而是根据客户端fetch_size参数处理，每次只返回fetch_size条记录，当客户端游标遍历到尾部时再从服务端取数据，直到最后全部传送完成。所以如果我们要从服务端一次取大量数据时，可以加大fetch_size，这样可以减少结果数据传输的交互次数及服务器数据准备时间，提高性能。 123456789101112//以下是jdbc测试的代码，采用本地数据库，表缓存在数据库CACHE中，因此没有网络连接及磁盘IO开销，客户端只遍历游标，不做任何处理，这样更能体现fetch参数的影响：String vsql ="select * from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql,ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);pstmt.setFetchSize(1000);ResultSet rs = pstmt.executeQuery(vsql);int cnt = rs.getMetaData().getColumnCount();Object o;while (rs.next()) &#123; for (int i = 1; i &lt;= cnt; i++) &#123; o = rs.getObject(i); &#125;&#125; 测试可以看出fetchsize对性能影响还是比较大的，但是当fetchsize大于100时就基本上没有影响了。fetchsize并不会存在一个最优的固定值，因为整体性能与记录集大小及硬件平台有关。根据测试结果建议当一次性要取大量数据时这个值设置为100左右，不要小于40。注意，fetchsize不能设置太大，如果一次取出的数据大于JVM的内存会导致内存溢出，所以建议不要超过1000，太大了也没什么性能提高，反而可能会增加内存溢出的危险。 1234//iBatis的SqlMapping配置文件可以对每个SQL语句指定fetchsize大小，如下所示：&lt;select id="getAllProduct" resultMap="HashMap" fetchSize="1000"&gt; select * from employee&lt;/select&gt; 使用存储过程 大型数据库一般都支持存储过程，合理的利用存储过程也可以提高系统性能。如你有一个业务需要将A表的数据做一些加工然后更新到B表中，但是又不可能一条SQL完成，这时你需要如下3步操作： a：将A表数据全部取出到客户端； b：计算出要更新的数据； c：将计算结果更新到B表。 如果采用存储过程你可以将整个业务逻辑封装在存储过程里，然后在客户端直接调用存储过程处理，这样可以减少网络交互的成本。 当然，存储过程也并不是十全十美，存储过程有以下缺点： a、不可移植性，每种数据库的内部编程语法都不太相同，当你的系统需要兼容多种数据库时最好不要用存储过程。 b、学习成本高，DBA一般都擅长写存储过程，但并不是每个程序员都能写好存储过程，除非你的团队有较多的开发人员熟悉写存储过程，否则后期系统维护会产生问题。 c、业务逻辑多处存在，采用存储过程后也就意味着你的系统有一些业务逻辑不是在应用程序里处理，这种架构会增加一些系统维护和调试成本。 d、存储过程和常用应用程序语言不一样，它支持的函数及语法有可能不能满足需求，有些逻辑就只能通过应用程序处理。 e、如果存储过程中有复杂运算的话，会增加一些数据库服务端的处理成本，对于集中式数据库可能会导致系统可扩展性问题。 f、为了提高性能，数据库会把存储过程代码编译成中间运行代码(类似于java的class文件)，所以更像静态语言。当存储过程引用的对像(表、视图等等)结构改变后，存储过程需要重新编译才能生效，在24*7高并发应用场景，一般都是在线变更结构的，所以在变更的瞬间要同时编译存储过程，这可能会导致数据库瞬间压力上升引起故障(Oracle数据库就存在这样的问题)。 建议：普通业务逻辑尽量不要使用存储过程，定时性的ETL任务或报表统计函数可以根据团队资源情况采用存储过程处理。 使用ResultSet游标处理记录 现在大部分Java框架都是通过jdbc从数据库取出数据，然后装载到一个list里再处理，list里可能是业务Object，也可能是hashmap。由于JVM内存一般都小于4G，所以不可能一次通过sql把大量数据装载到list里。为了完成功能，很多程序员喜欢采用分页的方法处理，如一次从数据库取1000条记录，通过多次循环搞定，保证不会引起JVM Out of memory问题。以下是实现此功能的代码示例，t_employee表有10万条记录，设置分页大小为1000： 12345678910111213141516171819202122232425262728293031d1 = Calendar.getInstance().getTime();//第一次先取出数据总数String vsql = "select count(*) cnt from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql);ResultSet rs = pstmt.executeQuery();Integer cnt = 0;while (rs.next()) &#123; cnt = rs.getInt("cnt");&#125;//第二次分页取数据Integer lastid = 0;Integer pagesize = 1000;System.out.println("cnt:" + cnt);for (int i = 0; i &lt;= cnt / pagesize; i++) &#123; vsql = "select * from (select * from t_employee where id&gt;? order by id) where rownum&lt;=?"; pstmt = conn.prepareStatement(vsql); pstmt.setFetchSize(1000); pstmt.setInt(1, lastid); pstmt.setInt(2, pagesize); rs = pstmt.executeQuery(); int col_cnt = rs.getMetaData().getColumnCount(); Object o; while (rs.next()) &#123; for (int j = 1; j &lt;= col_cnt; j++) &#123; o = rs.getObject(j); &#125; lastid = rs.getInt("id"); &#125; rs.close(); pstmt.close();&#125; 以上代码实际执行时间为6.516秒 很多持久层框架为了尽量让程序员使用方便，封装了jdbc通过statement执行数据返回到resultset的细节，导致程序员会想采用分页的方式处理问题。实际上如果我们采用jdbc原始的resultset游标处理记录，在resultset循环读取的过程中处理记录，这样就可以一次从数据库取出所有记录。显著提高性能。 这里需要注意的是，采用resultset游标处理记录时，应该将游标的打开方式设置为FORWARD_READONLY模式(ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY)，否则会把结果缓存在JVM里，造成JVM Out of memory问题。 123456789101112//代码示例：String vsql ="select * from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql,ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);pstmt.setFetchSize(100);ResultSet rs = pstmt.executeQuery(vsql);int col_cnt = rs.getMetaData().getColumnCount();Object o;while (rs.next()) &#123; for (int j = 1; j &lt;= col_cnt; j++) &#123; o = rs.getObject(j); &#125;&#125; 调整后的代码实际执行时间为3.156秒 iBatis等持久层框架考虑到会有这种需求，所以也有相应的解决方案，在iBatis里我们不能采用queryForList的方法，而应用该采用queryWithRowHandler加回调事件的方式处理，如下所示：12345678MyRowHandler myrh=new MyRowHandler();sqlmap.queryWithRowHandler("getAllEmployee", myrh);class MyRowHandler implements RowHandler &#123; public void handleRow(Object o) &#123; //todo something &#125;&#125;//iBatis的queryWithRowHandler很好的封装了resultset遍历的事件处理，效果及性能与resultset遍历一样，也不会产生JVM内存溢出。 使用绑定变量 绑定变量是指SQL中对变化的值采用变量参数的形式提交，而不是在SQL中直接拼写对应的值。 非绑定变量写法：Select * from employee where id=1234567 绑定变量写法： Select * from employee where id=? Preparestatement.setInt(1,1234567) Java中Preparestatement就是为处理绑定变量提供的对像，绑定变量有以下优点： 防止SQL注入 提高SQL可读性 提高SQL解析性能，不使用绑定变更我们一般称为硬解析，使用绑定变量我们称为软解析。 数据库SQL执行原理 当一条SQL发送给数据库服务器后，系统首先会将SQL字符串进行hash运算，得到hash值后再从服务器内存里的SQL缓存区中进行检索，如果有相同的SQL字符，并且确认是同一逻辑的SQL语句，则从共享池缓存中取出SQL对应的执行计划，根据执行计划读取数据并返回结果给客户端。如果在共享池中未发现相同的SQL则根据SQL逻辑生成一条新的执行计划并保存在SQL缓存区中，然后根据执行计划读取数据并返回结果给客户端。 为了更快的检索SQL是否在缓存区中，首先进行的是SQL字符串hash值对比，如果未找到则认为没有缓存，如果存在再进行下一步的准确对比，所以要命中SQL缓存区应保证SQL字符是完全一致，中间有大小写或空格都会认为是不同的SQL。 如果我们不采用绑定变量，采用字符串拼接的模式生成SQL,那么每条SQL都会产生执行计划，这样会导致共享池耗尽，缓存命中率也很低。 ORACLE采用自下而上的顺序解析WHERE子句,根据这个原理,表之间的连接必须写在其他WHERE条件之前, 那些可以过滤掉最大数量记录的条件必须写在WHERE子句的末尾.]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Oracle</tag>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BitSet]]></title>
    <url>%2F2017%2F10%2F07%2FBitSet%2F</url>
    <content type="text"><![CDATA[BitSet BitSet：用来操作位的数据结构，可实现指定的位的值反转，设置，获取，清空等；经常用于海量数据中的去重，判重，判存，排序等操作当使用一位表示一个数字时，一个1G的空间，有 8102410241024=8.5810^9bit，也就是可以表示85亿个不同的数。 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161//内部使用long数组来保存位数据，一个long可以保存64位的信息，顺序方向为从低位到高位private long[] words;/** 根据指定位数初始化，构建合适大小的long数组* 通常我们求所需long数组大小的方法为：（nbits/64 + 1）* 但是除法效率远没有位运算高效，这里使用的方法为：（（nbits-1）&gt;&gt; 6）+ 1* 其实平时如果我们的除数正好是2的n次方的时候，均可以使用这种方法来提高效率*/public BitSet(int nbits) &#123; // nbits can&apos;t be negative; size 0 is OK if (nbits &lt; 0) throw new NegativeArraySizeException(&quot;nbits &lt; 0: &quot; + nbits); initWords(nbits); sizeIsSticky = true;&#125;private void initWords(int nbits) &#123; words = new long[wordIndex(nbits-1) + 1];&#125;private final static int ADDRESS_BITS_PER_WORD = 6;private static int wordIndex(int bitIndex) &#123; return bitIndex &gt;&gt; ADDRESS_BITS_PER_WORD;&#125;//bitset的逻辑大小，wordsInUse负责记录当前long数组的大小private transient int wordsInUse = 0;//设置指定位的值为truepublic void set(int bitIndex) &#123; if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); //先计算出指定位在long数组的第几个long中保存的 int wordIndex = wordIndex(bitIndex); //验证long数组是否需要扩容 expandTo(wordIndex); words[wordIndex] |= (1L &lt;&lt; bitIndex); // Restores invariants checkInvariants();&#125;//与当前long数组大小进行比较，判定是否需要扩容private void expandTo(int wordIndex) &#123; int wordsRequired = wordIndex+1; if (wordsInUse &lt; wordsRequired) &#123; ensureCapacity(wordsRequired); wordsInUse = wordsRequired; &#125;&#125;private void ensureCapacity(int wordsRequired) &#123; if (words.length &lt; wordsRequired) &#123; // 扩容后数组大小为：原数组大小翻倍后和所需数组大小的最大值 int request = Math.max(2 * words.length, wordsRequired); //拷贝源数据到新数组中 words = Arrays.copyOf(words, request); sizeIsSticky = false; &#125;&#125;//设置指定位为指定值public void set(int bitIndex, boolean value) &#123; if (value) set(bitIndex); else clear(bitIndex);&#125;private static final long WORD_MASK = 0xffffffffffffffffL;//设置指定区间位的值为truepublic void set(int fromIndex, int toIndex) &#123; checkRange(fromIndex, toIndex); if (fromIndex == toIndex) return; // 判定指定区间是否需要扩容 int startWordIndex = wordIndex(fromIndex); int endWordIndex = wordIndex(toIndex - 1); expandTo(endWordIndex); //WORD_MASK是个64位均为1的常量，用于向左向右位移一定区间位之后与long元素进行或操作实现将一定区间的位置为true long firstWordMask = WORD_MASK &lt;&lt; fromIndex; long lastWordMask = WORD_MASK &gt;&gt;&gt; -toIndex; if (startWordIndex == endWordIndex) &#123; // 其实区间位于同一个long元素上 words[startWordIndex] |= (firstWordMask &amp; lastWordMask); &#125; else &#123; // 其实区间位于不同的long元素上 // 处理第一个long元素上的值 words[startWordIndex] |= firstWordMask; // 处理位于中间的long元素上的值，直接置为1 for (int i = startWordIndex+1; i &lt; endWordIndex; i++) words[i] = WORD_MASK; // 处理最后一个long元素上的值 words[endWordIndex] |= lastWordMask; &#125; checkInvariants();&#125;//set方法默认将位置为true，clear方法默认将位置为false，原理过程基本一样，均是通过位操作完成，这里不再解释其代码//get方法获取指定位的值，其结果为布尔类型public boolean get(int bitIndex) &#123; if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); checkInvariants(); int wordIndex = wordIndex(bitIndex); //若是指定位没超出已有界限并且指定位为1，返回true，否返回false return (wordIndex &lt; wordsInUse)&amp;&amp; ((words[wordIndex] &amp; (1L &lt;&lt; bitIndex)) != 0);&#125;//获取指定区间的位，返回bitsetpublic BitSet get(int fromIndex, int toIndex) &#123;&#125;//返回指定位之后第一个值为true的位索引位置，若没有则返回-1private final static int ADDRESS_BITS_PER_WORD = 6;private final static int BITS_PER_WORD = 1 &lt;&lt; ADDRESS_BITS_PER_WORD;public int nextSetBit(int fromIndex) &#123; if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;fromIndex &lt; 0: &quot; + fromIndex); checkInvariants(); //指定位越界直接返回-1 int u = wordIndex(fromIndex); if (u &gt;= wordsInUse) return -1; //找到指定位所在的long，然后开始循环查找第一个不为0的位 long word = words[u] &amp; (WORD_MASK &lt;&lt; fromIndex); while (true) &#123; //先判定所在long的值是否为0，为0直接查找下一个long，若当前long越界，返回-1 if (word != 0) /** 若当前long不为空，计算该第一个不为0的位的位置索引：一个long64位，u乘以64再加上当前long从低位开始到第一个不为0的位之前的0的个数 * Long.numberOfTrailingZeros(word)：该方法用于计算一个long从低位开始到第一个不为0的位之前0的个数 */ return (u * BITS_PER_WORD) + Long.numberOfTrailingZeros(word); if (++u == wordsInUse) return -1; word = words[u]; &#125;&#125;//返回指定位之后第一个值为false的位索引位置，若没有则返回-1，实现过程与nextSetBit一样，相当于取反后执行nextSetBitpublic int nextClearBit(int fromIndex) &#123;&#125;//返回指定位之前距离最近的第一个值为true的位索引位置，若没有则返回-1，实现原理均与上面雷同public int previousSetBit(int fromIndex) &#123;&#125;//返回指定位之前距离最近的第一个值为false的位索引位置，若没有则返回-1，实现原理均与上面雷同public int previousClearBit(int fromIndex) &#123;&#125;//返回最高位的位置索引public int length() &#123; if (wordsInUse == 0) return 0; return BITS_PER_WORD * (wordsInUse - 1) + (BITS_PER_WORD - Long.numberOfLeadingZeros(words[wordsInUse - 1]));&#125;//不同于length方法，size方法返回当前long数组的容量public int size() &#123; return words.length * BITS_PER_WORD;&#125;//是否为空判定：不是取决于long数组大小，而是看逻辑大小，当前已使用的long个数wordsInUse变量值public boolean isEmpty() &#123; return wordsInUse == 0;&#125;//判定两个bitset是否有交集public boolean intersects(BitSet set) &#123; for (int i = Math.min(wordsInUse, set.wordsInUse) - 1; i &gt;= 0; i--) if ((words[i] &amp; set.words[i]) != 0) return true; return false;&#125;//返回位值为true的总个数，Long.bitCount()方法用于统计long中位为1的个数public int cardinality() &#123; int sum = 0; for (int i = 0; i &lt; wordsInUse; i++) sum += Long.bitCount(words[i]); return sum;&#125;//两个bitset进行与操作，同理还有或操作，异或操作等public void and(BitSet set) &#123;&#125;]]></content>
      <categories>
        <category>BitSet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>BitSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrency]]></title>
    <url>%2F2017%2F10%2F07%2FConcurrency%2F</url>
    <content type="text"><![CDATA[并发，多线程竞态：一个计算结果的正确性与时间有关的现象叫做竞态竞态产生的条件 read-modify-write（例如i++） check-then-act（if条件语句） 数据资源竞争：各个线程的访问顺序不同可能会造成不同的结果 cpu和主内存之间的高度缓存：缓存一致协议 原子性 基础类型（除long/double之外）和引用类型变量的写操作都是原子的，long/double变量由于占64位，所以当32位的java虚拟机对这种变量的写操作会被分成两步，先写高位在写低位（或先写低位在写高位），这样就会出现一个线程写高位，而另一个线程写低位的情况，不具备原子性。 使用Lock实现原子性 利用处理器提供的CAS指令（硬件锁） 有序性 重排序：处理器可能不完全按照目标代码所制定的顺序执行指令（对内存访问读写操作的一种的优化，在不影响单线程程序正确性的情况下提高程序的性能），重排序不是必然出现的。 指令重排序（程序顺序与源代码顺序不一致，执行顺序与程序顺序不一致） java平台编译器有两种，静态（javac）和动态（JIT），前者将java源码编译为字节码class文件，后者将字节码动态编译为虚拟机宿主机的本地代码-机器码 例如 Person p = new Person(); 1. objRef = allocate(Person.class); 分配Pserson实例所需的内存空间，并获得一个指向该空间的引用 2. invokeConstrutor(objRef); 调用Person类的构造器初始化objRef引用指向的Person实例 3. p = objRef;3. 将Person实例引用赋值给实例变量p JIT编译器会将操作3排到操作2之前，即JIT编译器在初始化Person实例之前可能已经将该实例的引用写入p实例变量。 处理器的乱序执行，顺序提交：现代处理器为了提高执行效率，往往不是按照程序顺序逐一执行指令，而是动态调整指令的顺序，做到哪条指令准备就绪就先执行哪条，这就是处理器的乱序执行，这些指令执行的结果会先被写入重排序缓冲器（ROB），而不是直接写入寄存器或者内存，重排序缓冲器会将各个指令的执行结果按照相应的指令被读取的顺序提交，即写入到内存或者寄存器中，这就是处理器的顺序提交。也是因此处理器的指令重排序不会影响到单线程程序的正确性。 处理器的猜测执行：向执行if的语句体并将其结果保存在ROB中，然后在判定if的条件体是否成立，若成立，则将ROB中的结果写入到内存中，否则ROB丢弃其结果来实现语句体没有被执行过的效果。 存储子系统重排序（内存重排序）：是一种现象而不是一种动作，并没有真正的改变指令的执行顺序，其排序对象是内存操作的结果。 LoadLoad重排序：处理器的执行顺序为L1-&gt;L2，其他处理器的感知顺序为L2-&gt;L1 StoreStore重排序 LoadStore重排序 StoreLoad重排序 貌似串行语义：重排序并非是任意的，而是遵循一定的规则，从而给单线程造成一种假象（指令按照程序源码顺序执行），这种假象叫做貌似串行语义，其从单线程的角度保证了重排序后的运行结果不会影响到程序的正确性。为了保证串行语义，存在数据依赖，控制依赖的语句不会被重排序。 线程的活性故障 死锁：线程的生命周期状态永远处于非运行状态，相互等待对方 锁死：解锁条件永远得不到满足 活锁：处于运行状态却不执行任务，处于做无用功状态 饥饿：优先级低的线程一直得不到处理器资源 何为死锁 死锁：两个线程互相等待对方持有的资源，A持有c，等待d；B持有d，等待c 123456789101112131415161718192021222324252627282930313233343536//写一段死锁代码public class DeadLockTest&#123; private static final Object lock1 = new Object(); private static final Object lock2 = new Object(); public void instanceMethods1()&#123; synchronized(lock1)&#123; synchronized(lock2)&#123; System.out.println(&quot;锁住lock1之后开始等待lock2&quot;); &#125; &#125; &#125; public void instanceMethods2()&#123; synchronized(lock2)&#123; synchronized(lock1)&#123; System.out.println(&quot;锁住lock2之后开始等待lock1&quot;); &#125; &#125; &#125; public static void main(String[] args)&#123; DeadLockTest dl = new DeadLockTest(); Thread thread1 = new Thread(()-&gt;&#123; while()&#123; dl.instanceMethods1(); &#125; try&#123;Thread.sleep(50);&#125;catch(Exception e)&#123;&#125; &#125;); Thread thread2 = new Thread(()-&gt;&#123; while()&#123; dl.instanceMethods1(); &#125; try&#123;Thread.sleep(50);&#125;catch(Exception e)&#123;&#125; &#125;); thread1.start(); thread2.start(); &#125;&#125; 如何避免死锁的发生（因为Java和jvm都没有提供避免死锁的方式，所以只有程序来避免） 避免同步块调用其他的同步快 活锁：线程持续重试一个总是失败的操作 饿死：总有线程可以抢占他的资源，导致该线程一致无法执行 线程的两种创建方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public interface Runnable &#123; public abstract void run();&#125;public class Thread implements Runnable &#123; private static int threadInitNumber; private static synchronized int nextThreadNum() &#123; return threadInitNumber++; &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc) &#123; if (name == null) &#123; throw new NullPointerException("name cannot be null"); &#125; this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; /* Determine if it's an applet or not */ /* If there is a security manager, ask the security managerwhat to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security doesn't have a strong opinion of the matteruse the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; /* checkAccess regardless of whether or not threadgroup isexplicitly passed in. */ g.checkAccess(); //Do we have the required permissions? if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); &#125; //8个构造方法， public Thread(Runnable target) &#123; init(null, target, "Thread-" + nextThreadNum(), 0); &#125; Thread(Runnable target, AccessControlContext acc) &#123; init(null, target, "Thread-" + nextThreadNum(), 0, acc); &#125; public Thread(ThreadGroup group, Runnable target) &#123; init(group, target, "Thread-" + nextThreadNum(), 0); &#125; public Thread(String name) &#123; init(null, null, name, 0); &#125; public Thread(Runnable target, String name) &#123; init(null, target, name, 0); &#125; public Thread(ThreadGroup group, String name) &#123; init(group, null, name, 0); &#125; public Thread(ThreadGroup group, Runnable target, String name) &#123; init(group, target, name, 0); &#125; public Thread(ThreadGroup group, Runnable target, String name,long stackSize) &#123; init(group, target, name, stackSize); &#125; /*run()方法由java虚拟机直接调用，但是，java语言并不阻止我们直接调用，如果我们没有启动线程，而是在应用代码中直接调用线程run()方法，那么这个run()方法其实是运行在当前线程（run()方法的调用代码的执行线程）之中，而不是自身线程中，违背了线程创建的初衷，所以应该避免这样做*/ public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 继承Thread类 12345678public void MyThread extends Thread&#123; public void run()&#123;...&#125;&#125;public static void main(String [] args)&#123; MyThread t = new MyThread(); t.start();&#125; 实现Runnable接口 12345678public void MyThread implements Runnable&#123; public void run()&#123;...&#125;&#125;public static void main(String [] args)&#123; Thread t = new Thread(new MyThread()); t.start();&#125; 线程属于一次性用品，即我们不能通过出重新调用一个已经运行结束的线程的start()方法来使其重新运行，start()方法只能被调用一次，多次调用会导致抛出异常 i++三步走 取i的原值到寄存器r1（load(i,r1)） 执行i+1，即寄存器r1的值加1（increment(r1)） 将结果赋值给i，即将寄存器的值写回i对应的内存空间（store(i,r1)） system.out.println(i++)非线程安全 线程方法 currentThread() 返回代码段正在被那个线程调用 isLive() 判断当前才线程是否处于活跃状态（线程启动尚未终止，正在运行或者准备开始运行） sleep() 在指定的毫秒数内让当前正在执行的线程休眠（如果在sleep状态下停止某一线程，会进入catch语句，并且清除停止状态值，使之变成false）不会释放对象锁 geiId() stop()停止,suspend()暂停,resume()恢复 已作废方法 interrupt() 在当前线程中打一个停止符号，并未真正停止线程 this.interrupted() 测试当前线程（运行this.interrupted()方法的线程）是否中断，如果是中断（true），则会将其状态标识更改为false，再一次执行该方法时则返回非中断false this.Isinterrupted() 测试线程是否中断（不会清除状态标识） yield() 放弃当前CPU 资源，让给其它任务，放弃时间不确定，有其他任务则放弃，无则继续自身线程 setPriority() 设置优先级（1~10级，优先级具有继承性，优先级高的线程大部分先执行完，(并不代表一定全部先执行完)，CPU只是尽量将执行资源让给优先级高的线程，同时，代码的执行顺序与线程的优先级无关） setDaemon(true为守护进程)，必须发生在start()调用之前 不建议使用的方法及缘由 stop suspend resume 这三个方法不建议使用，因为这三种方法的使用后不一定会释放资源（例如锁等），所以极其容易引发死锁等其他问题 守护进程/用户进程线程的生命周期状态1234567891011//最好通过抛异常来停止线程public void run()&#123; try()&#123; for()&#123; if(this.interrupted())&#123; //return；不建议 threw new InterruptedException(); &#125; &#125; &#125;catch(InterruptedException e)&#123;&#125;&#125; 内部锁（非公平锁）——synchronized（同步）/asynchronized（异步） 关键字synchronized取得是对象锁，而不是一段代码或者方法的锁 A线程持有O对象的Lock锁，B线程可以以异步的方式调用O对象中的非synchronized方法，对于synchronized方法则需要同步等待 脏读：在读取实例变量时，该值已被其他线程修改 synchronized锁 重入，即自己可以再次获取自己的内部锁，synchronized方法内部可以调用本类的其他synchronized方法 出现异常，锁自动释放 同步不具有继承性，子类中重写的方法还得加关键字synchronized实现同步 synchronized（this）{}同步代码块，与synchronized方法类似，锁定整个对象 任意对象的对象监视器synchronized（Object，非this对象），只有在保证同一对象的前提下才能保证同步 synchronized关键字加到static静态方法上是给class类上锁（对类的所有实例对象起作用，与synchronized（xxx.class）效果一样），加到非static方法上是给对象上锁 String常量池缓存带来的麻烦 采用同步代码块synchronized（Object1）和synchronized（Object2）来避免同步带来的死循环无线等待 可见性 程序中的变量可能会被分配到寄存器中，而不是主内存中。每个处理器都有其寄存器，而一个处理器无法读取另一个处理器上的寄存器中的内容。处理器对主内存的访问也不是直接访问，而是通过高速缓存子系统进行的。一个处理器上运行的线程对变量的更新可能只是更新到该处理器的写缓冲器中，还没有到达该处理器的高速缓存中，更不用说到主内存中了。而一个写缓冲器中的内容无法被另一个处理器读取。 处理器不是直接与主内存(RAM)打交道而执行内存的读写操作，而是通过寄存器，高速缓存，写缓冲器，和无效队列等部件执行内存的读写操作。 缓存同步：一个处理器不能直接从另一个处理器的高度缓存中读取数据，但是可以通过缓存一致协议来读取处理器高速缓存中的数据，这种方式叫做缓存同步。冲刷处理器缓存：是一个处理器对共享变量的更新最终被写入处理器的高速缓存或主内存中，而不是停留在写缓冲器中。 刷新处理器缓存：一个处理器在读取共享变量时，如果其他处理器在此之前更新了该变量，该处理器必须从其他处理器高速缓存或主内存中对相应的变量进行缓存同步。 写入一个volatile关键字修饰的变量，会使得相应的处理器执行冲刷处理器缓存的动作。 可见性的保证是通过写线程冲刷处理器缓存和读线程刷新处理器缓存这两个动作实现的，java平台中，锁的获得隐含着刷新处理器缓存这个动作，这使得读线程在执行临界区代码前可以将写线程对共享变量的更新同步到该线程执行处理器的高速缓存中，而锁的释放隐含着冲刷处理器缓存的动作，这使得写线程对共享变量的更新能够被推送到该执线程执行处理器的高速缓存中，从而对读线程可以同步。 volatile关键字——使变量在多个线程间可见 解决同步/异步死循环，强制从公共堆栈中获取变量的值，而不是从线程私有数据栈中取得变量值 只能修饰变量 不支持原子性（例如i++） 多线程访问不会发生阻塞 synchronized关键字解决的是多个线程间的访问资源的同步性（同步公共堆栈中变量的值与线程私有数据栈中变量值），而volatile关键字解决的是多个线程间的可见性问题 线程间通信 等待/通知机制 使用sleep()结合whlie(true)死循环实现多个线程间通信 ？？？ 123456789//通过抛异常来停止线程public void run()&#123; try()&#123; while(true)&#123; if(条件成立) threw new InterruptedException(); &#125; &#125;catch(InterruptedException e)&#123;&#125;&#125; wait/notify机制，wait()方法和notify()方法都是Object类的方法，无论是wait还是notify，在执行调用之前都必须获得该对象的对象锁（即只能在同步方法或代码块中调用），wait调用发生后，当前线程自动释放锁进入等待队列，notify调用后（当前线程不会马上释放对象锁，要等程序执行完，即退出synchronized代码块后才会释放对象锁），线程规划器随机挑选一个等待同一资源的呈wait状态的线程（即等待队列），对其发出notify通知，并使其获得该资源的对象锁 wait(long) 等待一段时间是否有线程对锁进行唤醒，超过此时间没有，则自动唤醒 生产者/消费者模式 管道通信，字节流（PipeInputStream，PipeOutStream），字符流（PipeReader，PipeWriter） join()方法——等待线程对象销毁（例如线程A需要用到线程B的结果，则要用到join，A阻塞等到B结束之后才能继续执行，类似于使线程排队） join(long)等待一定时间后自动继续执行（内部使用wait(long)来实现，所以具有释放锁的特点） ThreadLocal——解决的是变量在不同线程间的隔离性，也就是不同线程拥有自己的值，不同的线程中的值可以放入T和readLocal类中进行保存 InheritableThreadLocal类可以使得子线程获取父线程继承下来的值 显示锁（公平/非公平锁）——Lock ReentrantLock类 12345678public void display()&#123; private Lock lock = new ReentrantLock(); //lock()方法获取锁 lock.lock(); ... //unlock()方法释放锁 lock.unlock();&#125; Condition实现等待/通知，一个Lock对象中可以创建多个Conditoin实例（对象监视器），从而实现选择性通知 123456789101112public void display()&#123; private Lock lock = new ReentrantLock(); Conditoin condition1 = lock.newCondition(); //Conditoin condition2 = lock.newCondition(); lock.lock(); condition.await();//等价于Object的wait()方法 //condition.await(long);//等价于Object的wait(long)方法 ... condition.signal();//等价于Object的notify()方法 //condition.signalAll();//等价于Object的notifyAll()方法 lock.unlock();&#125; 公平锁（按照加锁顺序，先来先得），非公平锁（抢占机制，随机分配） getHoldCount() 查询当前线程保持此锁定的个数，也就是调用lock()方法的次数 getQueueLength() 返回正等待获取此锁定的线程估计数 getWaitQueueLength(Condition condition)返回正等待与此锁定相关给定条件Condition的线程估计数 hasQueuedThread(Thread thread) 查询指定线程是否正在等待获取此锁定 hasQueuedThreads() 查询是否有线程正在等待获取此锁定 hasWaiters(Condition condition) 查询是否有线程正在等待获取此锁定有关的condition条件 isFair() 判定是否为公平锁 IsHeldByCurrentThread() 查询当前线程是是否保持此锁定 isLocked() 查询此锁定是否由任意线程保持 tryLock()：尝试申请相应Lock实例锁表示的锁，如果该锁未被其他任何线程所持有，则获得该锁，并返回true，否则什么操作都不做，只是返回false； 123Lock lock = ...if(lock.tryLock())&#123;...&#125;else&#123;...&#125; 使用Condition实现顺序执行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; ... int next = 1; private Lock lock = new ReentrantLock(); Conditoin condition1 = lock.newCondition(); Conditoin condition2 = lock.newCondition(); Conditoin condition3 = lock.newCondition(); Thread thread1 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=1)&#123;condition1.await();&#125; System.out.println(1); next = 2; condition2.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; Thread thread2 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=2)&#123;condition2.await();&#125; System.out.println(2); next = 3; condition3.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; Thread thread3 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=3)&#123;condition3.await();&#125; System.out.println(3); next = 1; condition1.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; ...&#125; ReentrantReadWriteLock类-读写锁 读读共享 写写互斥 读写互斥 写读互斥123456private Lock lock = new ReentrantLock();lock.readLock().lock();lock.writeLock().lock();...lock.writeLock().unlock();lock.readLock().unlock();]]></content>
      <categories>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥Map源码]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%88%9D%E7%AA%A5Map%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[MapHashMap Java7实现原理（数组+链表） Java8实现原理（数组+链表+红黑树） 存，取，扩容（数组翻倍，链转树） 负载因子为何为0.75 modCount在hashmap线程安全中的作用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; //默认容量 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认负载因子为0.75，使性能在空间和时间上达到了平衡，只有当表到达3/4满时才会进行再散列，增大负载因子可以降低所需空间，但会增加查找时间 static final float DEFAULT_LOAD_FACTOR = 0.75f; //当链表长度超过8时转换为红黑树 static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; //内部节点类，实现了map接口内的entry接口，所以hashmap中的每一个键值对都是一个Entry&lt;K,V&gt; static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;&#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; ... &#125; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; //构造方法，自定义容量和负载因子，当初始化容量是一个确切的数值值，负载因子直接指定为1，避免无谓的扩容 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; // 自定义容量数值调整，均调整为2的次幂方结果 static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; //构造方法，自定义容量和默认负载因子 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //构造方法，默认负容量和默认负载因子 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125; public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; //通过key值获取value值 final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; /*判断table数组是否为空，数组长度是否为零，判断所给hash值对应的数组下标中的元素是否为空。它通过 h &amp; (table.length -1) 来得到该对象的保存位，即table数组的下标，而HashMap底层数组的长度总是 2 的 n 次方，这是HashMap在速度上的优化（保证初始化时HashMap的容量总是2的n次方，即底层数组的长度总是为2的n次方）。当length总是 2 的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。*/ if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;(first = tab[(n - 1) &amp; hash]) != null) &#123; //验证数组tab[(n - 1) &amp; hash]中存的第一个节点是否为所需节点，是则返回 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //验证数组table中所存的节点类型是否为红黑树，是则按照红黑树的方式继续查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); /*调用红黑树的查找方法find final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; */ //如果节点类型为链表，则按照链表的方式进行查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; public boolean containsKey(Object key) &#123;return getNode(hash(key), key) != null;&#125; public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //table数组为空或长度为零，重新调整数组大小，当第一个元素放入的时候会调用resize()函数，resize()函数源码注释明确说明该函数为初始化table大小（同时会调整扩容上限值 = 当前table大小（初始化大小） * 扩容因子）或者扩容使用 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //hash值对应的数组下标的位置为空，则直接构造节点插入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果hash值对应的数组下标的位置中的元素与插入元素相同 if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果hash值对应的数组下标的位置中的元素类型为红黑树，则按照红黑树方式插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果hash值对应的数组下标的位置中的元素类型为链表，则按照链表方式插入 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表插入元素后要检验链表大小是否大于8，实则需将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; /*我们知道java.util.HashMap不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。*/ ++modCount; /*threshold就是在此loadFactor和capacity对应下允许的最大元素数目，超过这个数目就重新resize，以降低实际的负载因子，即扩容 */ if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; //直接将table数组大小至为0并将数组元素均至为空，然后交由GC回收 public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; //entrySet遍历 public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; LinkedHashMap(extends HashMap)继承自HashMap，但是比HashMap多了一组双向链表来维持插入顺序，或者是最近最少使用的次序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class LinkedHashMap&lt;K,V&gt;extends HashMap&lt;K,V&gt;implements Map&lt;K,V&gt;&#123; //节点移除后，双向链表删除该节点 void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b; &#125; //节点插入后， void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125; &#125; //节点访问后，移动节点到链表最后 void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p =(LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125; &#125; public void clear() &#123; super.clear(); //双向链表首尾指针至空 head = tail = null; &#125; TreeMap基于红黑树，由Comparable或Comparator排序而成]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Map</tag>
        <tag>Source_Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥Set源码]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%88%9D%E7%AA%A5Set%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[SetHashSet（HashMap的HashMap版本）LinkedHashSet（LinkedHashMap的LinkedHashMap版本）TreeSet（TreeMap的TreeMap版本） 123456789101112131415public class HashSet&lt;E&gt;extends AbstractSet&lt;E&gt;implements Set&lt;E&gt;, Cloneable, java.io.Serializable&#123; static final long serialVersionUID = -5024744406713321676L; private transient HashMap&lt;E,Object&gt; map; private static final Object PRESENT = new Object(); //构造方法，直接调用HashMap的构造方法生成entry&lt;E,Object&gt; //类似的所有其他构造方法均直接调用HashMap的构造方法生成 public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125;]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Source_Code</tag>
        <tag>Set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥List源码]]></title>
    <url>%2F2017%2F09%2F23%2F%E5%88%9D%E7%AA%A5List%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[ListArrayList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; //Default initial capacity（初始容量为10） private static final int DEFAULT_CAPACITY = 10; //Shared empty array instance used for empty instances. private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //Shared empty array instance used for default sized empty instances. private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; transient Object[] elementData; // non-private to simplify nested class access private int size; //Constructs an empty list with the specified initial capacity. //带有容量参数的构造方法 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; //Constructs an empty list with an initial capacity of ten. //不含参的构造方法，默认初始化大小为10 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; //Constructs a list containing the elements of the specifiedcollection //含参构造方法 public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; //Increases the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance, ifnecessary, to ensure that it can hold at least the number of elementsspecified by the minimum capacity argument. public void ensureCapacity(int minCapacity) &#123; &#125; private void ensureCapacityInternal(int minCapacity) &#123;&#125; private void ensureExplicitCapacity(int minCapacity) &#123; &#125; //The maximum size of array to allocate.数组分配最大值 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //Increases the capacity to ensure that it can hold at least thenumber of elements specified by the minimum capacity argument. private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //最大容量 private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; //数组大小 public int size() &#123;return size;&#125; //判空 public boolean isEmpty() &#123; return size == 0;&#125; //判包含 public boolean contains(Object o) &#123;return indexOf(o) &gt;= 0; &#125; //获取元素下标 public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; //获取最后一次出现的下标 public int lastIndexOf(Object o) &#123; if (o == null) &#123; //倒序循环 for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; //转换成对象数组 public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; //转换成具体类型数组 @SuppressWarnings("unchecked") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; //根据下标获取元素值 public E get(int index) &#123; //边界检查 rangeCheck(index); return elementData(index); &#125; //设置元素值（返回旧值） public E set(int index, E element) &#123; rangeCheck(index); //保留旧值 E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; //添加元素 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; //添加元素到指定位置 public void add(int index, E element) &#123; //检查范围 rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // //数组移动，index之后的元素整体后移一位 System.arraycopy(elementData, index, elementData, index + 1,size - index); elementData[index] = element; size++; &#125; //根据下标移除指定元素，并返回该元素的值 public E remove(int index) &#123; //检查范围 rangeCheck(index); modCount++; E oldValue = elementData(index); //计算需要移动的元素个数 int numMoved = size - index - 1; if (numMoved &gt; 0)&#123; //数组移动 System.arraycopy(elementData, index+1, elementData, index,numMoved); &#125; elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; //移除指定元素 public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; //服务于public boolean remove(Object o) 方法 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index,numMoved); elementData[--size] = null; // clear to let GC do its work &#125;//清空ArrayList，将数组元素全都至为空，数组大小设置为0，然后让GC来回收内存空间 public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; //将一个容器中的元素全部添加到list后 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; //将一个容器中的元素全部插入到list中 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index +numNew,numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; //删除置顶区间的元素 protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex,numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); //数组前移后剩下的位置的值至为空，让GC回收该空间 for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; //数组上边界检查 private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; //添加元素前的数组上下边界检查 private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; public boolean removeAll(Collection&lt;?&gt; c) &#123; //判空 Objects.requireNonNull(c); return batchRemove(c, false); &#125; /*判空requireNonNull()方法源码如下 public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj; &#125; */ public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; &#125; finally &#123; if (r != size) &#123; System.arraycopy(elementData, r,elementData, w,size - r); w += size - r; &#125; if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified; &#125; //元素迭代遍历 public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException("Index: "+index); return new ListItr(index); &#125; public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; //内部类 private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123;&#125; public E next() &#123;&#125; public void remove() &#123;&#125; public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; //内部类 private class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; super(); cursor = index; &#125; public boolean hasPrevious() &#123;&#125; public int nextIndex() &#123;&#125; public int previousIndex() &#123;&#125; public E previous() &#123;&#125; public void set(E e) &#123;&#125; public void add(E e) &#123;&#125; &#125; //返回子数组 public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; //边界检查 subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); &#125; //内部类返回子数组 private class SubList extends AbstractList&lt;E&gt; implements RandomAccess &#123; private final AbstractList&lt;E&gt; parent; private final int parentOffset; private final int offset; int size; SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) &#123; this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount; &#125; public E set(int index, E e) &#123;&#125; public E get(int index) &#123;&#125; public int size() &#123;&#125; public void add(int index, E e) &#123;&#125; public E remove(int index) &#123;&#125; protected void removeRange(int fromIndex, int toIndex) &#123;&#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; public Iterator&lt;E&gt; iterator() &#123; return listIterator(); &#125; public ListIterator&lt;E&gt; listIterator(final int index) &#123; checkForComodification(); rangeCheckForAdd(index); final int offset = this.offset; //匿名内部类 return new ListIterator&lt;E&gt;() &#123; int cursor = index; int lastRet = -1; int expectedModCount = ArrayList.this.modCount; public boolean hasNext() &#123;&#125; public E next() &#123;&#125; public boolean hasPrevious() &#123;&#125; public E previous() &#123;&#125; public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123;&#125; public int nextIndex() &#123;&#125; public int previousIndex() &#123;&#125; public void remove() &#123;&#125; public void set(E e) &#123;&#125; public void add(E e) &#123;&#125; final void checkForComodification() &#123;&#125; &#125;; &#125; &#125; //遍历 public void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings("unchecked") final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123; action.accept(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; LinkedList123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412public class LinkedList&lt;E&gt;extends AbstractSequentialList&lt;E&gt;implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializabl&#123; transient int size = 0; transient Node&lt;E&gt; first;//链首 transient Node&lt;E&gt; last;//链尾 public LinkedList() &#123;&#125; public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; //链首插入元素 private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; &#125; //链尾插入元素 void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; public void addFirst(E e) &#123;linkFirst(e);&#125; public void addLast(E e) &#123;linkLast(e);&#125; public boolean add(E e) &#123;linkLast(e);return true;&#125; //节点前插入 void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; &#125; //去链首 private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; //去链尾 private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125; //移除链首元素 public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; //移除链尾元素 public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125; //去节点 E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; //获取链首元素 public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125; //获取链尾元素 public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125; //判包含 public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; public int size() &#123;return size; &#125; //移除元素o public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123;return addAll(size, c);&#125; public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;//转成数组循环添加&#125; public void clear() &#123;//循环至空，包括值，前指针，后指针 &#125; public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; public E set(int index, E element) &#123;&#125; public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); &#125; public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index)); &#125; private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size; &#125; private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size; &#125; private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; //收尾两个指针目的就是加快查找目标元素 Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; public int lastIndexOf(Object o) &#123;&#125; //队列操作，返回队首元素 public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; public E element() &#123; return getFirst(); &#125; //队列操作，去除队首元素 public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; public E remove() &#123; return removeFirst(); &#125; //队列操作，队尾入队列 public boolean offer(E e) &#123; return add(e); &#125; // 队列操作，队头入队列（双向链表） public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; public boolean offerLast(E e) &#123; addLast(e); return true; &#125; public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; public void push(E e) &#123; addFirst(e); &#125; public E pop() &#123; return removeFirst(); &#125; public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; public boolean removeLastOccurrence(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index); &#125; //迭代遍历内部类 private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; //节点内部类，双向链表 private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; public Iterator&lt;E&gt; descendingIterator() &#123; return new DescendingIterator(); &#125; //反向迭代遍历内部类 private class DescendingIterator implements Iterator&lt;E&gt; &#123; private final ListItr itr = new ListItr(size()); public boolean hasNext() &#123; return itr.hasPrevious(); &#125; public E next() &#123; return itr.previous(); &#125; public void remove() &#123; itr.remove(); &#125; &#125; public Object[] toArray() &#123;&#125; public &lt;T&gt; T[] toArray(T[] a) &#123;&#125;&#125;]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Source_Code</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反射机制]]></title>
    <url>%2F2017%2F09%2F16%2FReflection%2F</url>
    <content type="text"><![CDATA[参考自百度百科-反射机制 反射机制 JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 Java反射机制主要提供了以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法； 在运行时调用任意一个对象的方法； 生成动态代理。 ClassObject 类作为所有Java 类的继承根源，其内声明了12个方法： public Object() public final Class&lt;?&gt; getClass() public final void notify() public final void notifyAll() public final void wait(long timeout)throws InterruptedException public final void wait(long timeout,int nanos)throws InterruptedException public final void wait() throws InterruptedException public int hashCode() public boolean equals(Object obj) protected Object clone()throws CloneNotSupportedException public String toString() protected void finalize()throws Throwable 其中getClass()返回一个Class 对象。Class 类十分特殊。它和一般类一样继承自Object，其实体用以表达Java程序运行时的classes和interfaces，也用来表达enum、array、primitive Java types（boolean, byte, char, short, int, long, float, double）以及关键词void。当一个class被加载，或当加载器（class loader）的defineClass()被JVM调用，JVM 便自动产生一个Class 对象。如果您想借由“修改Java标准库源码”来观察Class 对象的实际生成时机（例如在Class的constructor内添加一个println()），这样是行不通的！因为Class并没有public constructor。Class是Reflection故事起源。针对任何您想探勘的类，唯有先为它产生一个Class 对象，接下来才能经由后者唤起为数十多个的Reflection APIs。这些APIs将在稍后的探险活动中一一亮相。12345678910public final class Class&lt;T&gt; implements Serializable, java.lang.reflect.GenericDeclaration, java.lang.reflect.Type, java.lang.reflect.AnnotatedElement &#123; //私有构造方法 private Class() &#123;&#125; public String toString() &#123; return ( isInterface() ? &quot;interface &quot; : (isPrimitive() ? &quot;&quot; : &quot;class &quot;)) + getName();&#125; Class object 诞生管道 运用getClass() Class c1 = str.getClass(); 运用Class.getSuperclass() Class c2 = c1.getSuperclass(); 运用static method——Class.forName()（最常被使用） Class c1 = Class.forName (“java.lang.String”); 运用primitive wrapper classes的TYPE 语法1234567Class c1 = Boolean.TYPEClass c3 = Character.TYPE;Class c5 = Integer.TYPE;Class c6 = Long.TYPE;Class c7 = Float.TYPE;Class c8 = Double.TYPE;Class c9 = Void.TYPE; Reflection 的三个动态性质： 运行时生成instances public Constructor getDeclaredConstructor(Class&lt;?&gt;… parameterTypes)（同下） public Constructor&lt;?&gt;[] getDeclaredConstructors() public Constructor getConstructor(Class&lt;?&gt;… parameterTypes) public Constructor&lt;?&gt;[] getConstructors()12345678910111213//无参构造函数Class&lt;?&gt; c = Class.forName(&quot;DynTest&quot;);Object obj = null;obj = c.newInstance(); //有参构造函数， 需要获取响应的构造方法Class&lt;?&gt; c = Class.forName(&quot;DynTest&quot;);Class&lt;?&gt;[] pTypes = new Class&lt;?&gt;[] &#123; double.class, int.class &#125;;Constructor&lt;?&gt; ctor = c.getConstructor(pTypes);//Constructor&lt;?&gt; ctor = c.getConstructor(double.class, int.class);Object obj = null;Object[] arg = new Object[] &#123;3.14159, 125&#125;; obj = ctor.newInstance(arg);//obj = ctor.newInstance(3.14159, 125); 执行期唤起methods 索取Method object时不需指定回返类型，因为method overloading机制要求signature（署名式）必须唯一，而回返类型并非signature的一个成份。换句话说，只要指定了method名称和参数列，就一定指出了一个独一无二的method。 public Method getDeclaredMethod(String name,Class&lt;?&gt;… parameterTypes)throws NoSuchMethodException,SecurityException（返回一个Method对象，该对象反映了由此Class对象表示的类或接口的指定已声明方法） public Method getMethod(String name,Class&lt;?&gt;… parameterTypes)throws NoSuchMethodException,SecurityException（返回一个Method对象，该对象反映此Class对象所表示的类或接口的指定公共成员方法） public Method[] getDeclaredMethods()throws SecurityException（返回一个包含Method对象的数组，该对象反映了由此Class对象表示的类或接口的所有已声明方法，包括public，protected，default（package）访问和private方法，但不包括继承方法。） public Method[] getMethods()throws SecurityException（返回一个包含Method对象的数组，该对象反映了由此Class对象表示的类或接口的所有公共方法，包括由类或接口声明的那些以及从超类和超接口继承的那些方法。）123456789101112131415161718public String func(String s, Hashtable ht)&#123; System.out.println(&quot;func invoked&quot;); return s;&#125;public static void main(String args[])&#123; Class c = Class.forName(&quot;Test&quot;); Class ptypes[] = new Class[2]; ptypes[0] = Class.forName(&quot;java.lang.String&quot;); ptypes[1] = Class.forName(&quot;java.util.Hashtable&quot;); //获取指定方法 Method m = c.getMethod(&quot;func&quot;,ptypes); Test obj = new Test(); //Test obj = (Test)c.newInstance(); Object arg[] = new Object[2]; arg[0] = new String(&quot;Hello,world&quot;); arg[1] = null; String r = (String)m.invoke(obj, arg);&#125; 运行时改动fields。 public Field getField(String name)（同上） public Field[] getFields() public Field getDeclaredField(String name) public Field[] getDeclaredFields() 1234567891011public class Test &#123; public double d; public static void main(String args[])&#123; Class c = Class.forName(&quot;Test&quot;); Field f = c.getField(&quot;d&quot;); //指定field 名称 Test obj = new Test(); System.out.println(&quot;d= &quot; + (Double)f.get(obj)); f.set(obj, 12.34); System.out.println(&quot;d= &quot; + obj.d); &#125;&#125; 12345678910111213141516171819202122232425//实际应用样例Class cname=null;Object theInst = null;try &#123; cname = Class.forName (className); 由字符串找到相应的类 theInst=(Object)cname.newInstance(); 实例化初始类&#125;catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; Method[] methodes = cname.getDeclaredMethods(); 获取类中所有的方法for (int i = 0; i &lt; methodes.length; i++)&#123; Method method = methodes[i]; if (method.getName().equals(methodName)) 查找并判定与既定方法相同的方法 &#123; Object result=null; try&#123; System.out.println(method.getName()); result = method.invoke(theInst, arg);执行相应的方法(agr为方法所需要的参数，不止一个可能) &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Reflection</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字节序]]></title>
    <url>%2F2017%2F09%2F09%2F%E5%AD%97%E8%8A%82%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[字节序 顾名思义，字节顺序，又称端序或尾序。在计算机科学领域中，是跨越多字节的程序对象的存储规则。 在几乎所有的机器上，多字节对象都被存储为连续的字节序列。例如在C语言中，一个类型为int的变量x地址为0x100，那么其对应地址表达式&amp;x的值为0x100。且x的四个字节将被存储在存储器的0x100, 0x101, 0x102, 0x103位置。而存储地址内的排列则有两个通用规则。一个多位的整数将按照其存储地址的最低或最高字节排列。如果最低有效位在最高有效位的前面，则称小端序；反之则称大端序。在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以均按照网络标准转化。例如假设上述变量x类型为int，位于地址0x100处，它的十六进制为0x01234567，地址范围为0x100~0x103字节，其内部排列顺序依赖于机器的类型。大端法从首位开始将是：0x100: 01, 0x101: 23,..。而小端法将是：0x100: 67, 0x101: 45,..。大端模式和小端模式的起源 关于大端小端名词的由来，有一个有趣的故事，来自于Jonathan Swift的《格利佛游记》：Lilliput和Blefuscu这两个强国在过去的36个月中一直在苦战。战争的原因：大家都知道，吃鸡蛋的时候，原始的方法是打破鸡蛋较大的一端，可以那时的皇帝的祖父由于小时侯吃鸡蛋，按这种方法把手指弄破了，因此他的父亲，就下令，命令所有的子民吃鸡蛋的时候，必须先打破鸡蛋较小的一端，违令者重罚。然后老百姓对此法令极为反感，期间发生了多次叛乱，其中一个皇帝因此送命，另一个丢了王位，产生叛乱的原因就是另一个国家Blefuscu的国王大臣煽动起来的，叛乱平息后，就逃到这个帝国避难。据估计，先后几次有11000余人情愿死也不肯去打破鸡蛋较小的端吃鸡蛋。这个其实讽刺当时英国和法国之间持续的冲突。Danny Cohen一位网络协议的开创者，第一次使用这两个术语指代字节顺序，后来就被大家广泛接受。 ##什么是大端和小端 小端就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 大端就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。 比如数字0x12 34 56 78在内存中的表示形式为： 大端模式：(低地址 -&gt; 高地址)0x12 | 0x34 | 0x56 | 0x78 小端模式：(低地址 -&gt; 高地址)0x78 | 0x56 | 0x34 | 0x12 可见，大端模式和字符串的存储模式类似。 大端小端没有谁优谁劣，各自优势便是对方劣势： 小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。 大端模式 ：符号位的判定固定为第一个字节，容易判断正负。 为什么会有大小端模式之分呢？ 这是因为在计算机系统中，我们是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8bit。但是在C语言中除了8bit的char之外，还有16bit的short型，32bit的long型（要看具体的编译器），另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着一个如果将多个字节安排的问题。因此就导致了大端存储模式和小端存储模式。例如一个16bit的short型x，在内存中的地址为0x0010，x的值为0x1122，那么0x11为高字节，0x22为低字节。对于大端模式，就将0x11放在低地址中，即0x0010中，0x22放在高地址中，即0x0011中。小端模式，刚好相反。我们常用的X86结构是小端模式，而KEIL C51则为大端模式。很多的ARM，DSP都为小端模式。有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。 如何判断机器的字节序12345678910111213141516171819202122232425BOOL IsBigEndian() &#123; int a = 0x1234; char b = *(char *)&amp;a; //通过将int强制类型转换成char单字节，通过判断起始存储位置。即等于 取b等于a的低地址部分 if( b == 0x12) &#123; return TRUE; &#125; return FALSE; &#125;//联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写：BOOL IsBigEndian() &#123; union NUM &#123; int a; char b; &#125;num; num.a = 0x1234; if( num.b == 0x12 ) &#123; return TRUE; &#125; return FALSE; &#125;]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java创建对象]]></title>
    <url>%2F2017%2F09%2F02%2FJava%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[创建对象的四种方式 new语句 Object.clone()方法 序列化、反序列化 反射手段,调用java.lang.Class 或者 java.lang.reflect.Constructor 类的newInstance()实例方法 new语句调用类的构造方法创建对象person p = new person(8); Object.clone()方法### API中定义为protected Object clone() throws CloneNotSupportedException{}，即意味着该方法只对其子类可见！ 与此同时API还强调Throws:CloneNotSupportedException - if the object’s class does not support the Cloneable interface. Subclasses that override the clone method can also throw this exception to indicate that an instance cannot be cloned.即意味着想要实现复制克隆的类必须实现cloneable接口,而该接口中并无任何方法，其作用可以看做是一个标识！ 浅复制，如需实现深拷贝，则需重新实现clone（）；实例1234567891011121314151617public class Person implements Cloneable&#123; public int number; person(int number)&#123; this.number = number; &#125; public person getInstance() throws CloneNotSupportedException&#123; return (Person) this.clone(); &#125;&#125;public class Test &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Person p = new Person(8); Person temp = p.getInstance(); System.out.println(temp.number); &#125;&#125; 序列化、反序列化ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;Person.java&quot;)); Person p = (Person) in.readObject(); 反射手段,调用java.lang.Class 或者 java.lang.reflect.Constructor 类的newInstance()实例方法 调用java.lang.Class类的newInstance()实例方法 //第一种方式 Person p = (Person) Class.forName(“other.Person”).newInstance(); //第二种方式 Person p1 = Person.class.newInstance(); 调用java.lang.reflect.Constructor 类的newInstance()实例方法 Constructor c = Person.class.getConstructor(); Person p = c.newInstance();]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Template Method Pattern]]></title>
    <url>%2F2017%2F08%2F26%2FTemplateMethodPattern%2F</url>
    <content type="text"><![CDATA[Template Method Pattern（模板方法模式）Define the skeleton of an algorithm in an operation,deferring some steps to subclasses.Template Method lets subclass redefine certain steps of an algorithm without changing the algorithm’s structure. （定义一个操作中的算法框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可以重定义该算法的某些特定步骤。） 抽象模板（AbstractTemplate）：一个抽象类,定义若干方法表示一个算法的步骤，有抽象方法也有非抽象方法，抽象方法表示原子操作，非抽象方法表示原子步骤 具体模板（ConcreteTemplate）：抽象模板的子类，实现抽象模板的原子操作 应用场景：非抽象方法负责定义步骤流程，钩子方法，子类可以按照抽象模板的规定步骤进行（用final修饰来强制继承不能改动），也可重写非抽象方法来自己定义步骤流程，或者还可以在确定什么样的条件下去执行算法的哪些步骤（boolean返回类型的钩子方法的用途） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930//AbstractTemplatepublic abstract class Template&#123; public abstract void first(); public abstract void second(); public abstract void third(); public final void templateMethod()&#123; first(); second(); third(); &#125;&#125;//ConcreteTemplatepublic class ConcreteTemplate extends Template&#123; public void first()&#123; System.out.println("首先"); &#125; public void second()&#123; System.out.println("然后"); &#125; public void third()&#123; System.out.println("其次"); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Template t = new ConcreteTemplate(); t.templateMethod(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Visitor Pattern]]></title>
    <url>%2F2017%2F08%2F26%2FVisitorPattern%2F</url>
    <content type="text"><![CDATA[Visitor Pattern（访问者模式）Represent an operation to be performed on the elements of an object structure.Visitor lets you define a new operation without changing the classes of the elements on which it operates.（封装一些作用于某种数据结构中的各种元素，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。） 抽象元素（Element）：一个抽象类，定义了接受访问者的accept方法 具体元素（ConcreteElement）：Element的子类 抽象访问者(Visitor)：一个接口，定义了操作具体元素的方法 具体访问者(ConcreteVisitor)：抽象访问者接口的实现类 应用场景：双重分派（数据的存储和操作解耦）,不同的访问者访问同一元素，进行的操作不同，结果也不同，但访问这一动作共同的，只是传入的对象不同，导致操作/结果不同 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445//Elementpublic abstract class Element&#123; public abstract void accept(Visitor v); public abstract double showElectricAmount(); public abstract void setElectricAmount(double n); &#125;//ConcreteElementpublic class ConcreteElement extends Element&#123; double count; public void accept(Visitor v)&#123; System.out.println(v.visitor(this)); &#125; public double showElectricAmount()&#123; return count; &#125; public void setElectricAmount(double n)&#123; count = n; &#125;&#125;//Visitorpublic interface Visitor&#123; public double visitor(Element element);&#125;//ConcreteVisitorpublic class ConcreteVisitorOne implements Visitor&#123; public double visitor(Element element)&#123; return element.showElectricAmount(); &#125;&#125;public class ConcreteVisitorTwo implements Visitor&#123; public double visitor(Element element)&#123; return element.showElectricAmount()+1; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Element e = new ConcreteElement(); Visitor v = new ConcreteVisitorOne(); e.setElectricAmount(20); e.accept(v); v = new ConcreteVisitorTwo(); e.accept(v); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Proxy Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FProxypattern%2F</url>
    <content type="text"><![CDATA[Proxy pattern（代理模式）Provide a surrogate (代理) or placeholder for another object to control access to it.（为其他对象提供一种代理以控制对这个对象的访问。） 抽象主题（Subject）：一个接口 实际主题（RealSubject）：实现了抽象主题接口的类 代理(Proxy)：实现了抽象主题接口的类，含有抽象主题声明的变量，来存放实际主题的实例的引用 应用场景：代理的实例用来控制对他所包含的实际主题的实例的访问，即控制他所代理对象的访问权限（java远程代理RMI同理） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627//Subjectpublic interface Employee&#123; public String hearPhone();&#125;//RealSubjectpublic class Boss implements Employee&#123; public String hearPhone()&#123; return "面谈吧"; &#125;&#125;//Proxypublic class Secretary implements Employee&#123; Boss boss; Secretary()&#123; boss = new Boss(); &#125; public String hearPhone()&#123; return "我们老板说："+boss.hearPhone(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Secretary s = new Secretary(); System.out.println(s.hearPhone()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Singleton Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FSingletonPattern%2F</url>
    <content type="text"><![CDATA[Singleton PatternEnsure a class has only one instance, and provide a global point of access to it.（确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。） 某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。 省去了new操作符，降低了系统内存的使用频率，减轻GC压力。 有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。 123456789101112131415161718192021public class Singleton &#123; /* 立即加载/恶汉模式 在使用类的时候就已经将对象创建完毕，在调用方法前，实例已经被创建 private static Singleton instance = new Singleton(); 延迟加载/懒汉模式 在调用get()方法时实例才被创建 public static Singleton getInstance() &#123; instance = new Singleton(); &#125; */ //持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 private static Singleton instance = null; //私有构造方法，防止被实例化 private Singleton() &#123;&#125; //静态工程方法，创建实例 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 上面的类在单线程情况下不会出错，但是如果我们把它放入多线程的环境下，就会出现问题了，如何解决？我们可以对getInstance方法加synchronized关键字，如下：123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; 但是，synchronized关键字会锁住整个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都会对对象上锁，事实上，我们只需要在第一次创建对象的时候需要加锁，之后就不需要了，所以，我们进一步改进为：12345678910public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (instance) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; 如果不了解jvm中指令重排的同学可能认为上面的改进已经算是完善了，但是，在Java指令中创建对象和赋值操作是分开进行的，也就是说instance = new Singleton()语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例： a&gt;A、B线程同时进入了第一个if判断 b&gt;A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); c&gt;由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，在写多线程环境下的程序是有一定难度的。我们对该程序做进一步优化：1234567//静态内置类实现单例private static class SingletonFactory&#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonFactory.instance; &#125; 实际上，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们可以暂时总结一个完整的单例模式如下：1234567891011121314151617181920212223242526272829303132333435363738394041public class Singleton &#123; //私有构造方法，防止被实例化 private Singleton() &#123;&#125; //此处使用一个内部类来维护单例 private static class SingletonFactory &#123; private static Singleton instance = new Singleton(); &#125; //获取实例 public static Singleton getInstance() &#123; return SingletonFactory.instance; &#125; &#125; //变形，使用static代码块实现public class Singleton &#123; private static Singleton instance = null； //私有构造方法内放置static代码块，里面实例化对象 private Singleton() &#123; static&#123; instance = new Singleton(); &#125; &#125; //获取实例 public static Singleton getInstance() &#123; return instance; &#125; &#125; //扩展，使用枚举enum实现public class Singleton &#123; public enum EnumSingleton&#123; connectionFactory； private Connection connection; private EnumSingleton&#123; ... connection = DriverManager.getConnection(url,username,password); &#125; public Connection getConnection()&#123; return connection; &#125; &#125; public static Connection getConnection() &#123; return EnumSingleton.connectionFactory.getConnection(); &#125; &#125; 静态内置类可以达到线程安全问题，但是当遇到序列化对象时，使用默认的方式运行得到的结果还是多例的12345678910111213141516171819202122232425262728293031323334353637public class MyObject implements Serializable &#123; private static final long serialVersionUID = 888L; private static class MyObjectHandler &#123; private static final MyObject myObject = new MyObject(); &#125; private MyObject() &#123;&#125; public static MyObject getInstance() &#123; return MyObjectHandler.myObject; &#125; //readResolve()方法解决序列化单例模式 protected Object readResolve() throws ObjectStreamException &#123; System.out.println("调用了readResolve方法！"); return MyObjectHandler.myObject; &#125; &#125; //输出hashCode来验证序列化前后对象是否为同一个public class SaveAndRead &#123; public static void main(String[] args) &#123; try &#123; MyObject myObject = MyObject.getInstance(); FileOutputStream fosRef = new FileOutputStream(new File("myObjectFile.txt")); ObjectOutputStream oosRef = new ObjectOutputStream(fosRef); oosRef.writeObject(myObject); oosRef.close(); fosRef.close(); System.out.println(myObject.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; try &#123; FileInputStream fisRef = new FileInputStream(new File("myObjectFile.txt")); ObjectInputStream iosRef = new ObjectInputStream(fisRef); MyObject myObject = (MyObject) iosRef.readObject(); iosRef.close(); fisRef.close(); System.out.println(myObject.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[State Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FStatePattern%2F</url>
    <content type="text"><![CDATA[State Pattern（状态模式）Allow an object to alter its behavior when its internal state changes.The object will appear to change its class.（当一个对象在状态改变时允许其改变行为，这个对象看起来像改变了其类。） 抽象状态（State）：一个接口或者抽象类 环境（Context）：依赖于策略接口的类（组合关系） 具体状态（ConcreteState）：状态接口（抽象类）的实现类（扩展类） 应用场景：一个对象的状态依赖于它的行为，状态随着行为的改变为改变 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//Statepublic abstract class State&#123; public abstract void shoot(); public abstract void loadBullets();&#125;//Contextpublic class Gun&#123; public State stateThree,stateTwo,stateOne,stateNull; public State state; public Gun()&#123; stateThree = new BulletStateThree(this); stateTwo = new BulletStateTwo(this); stateOne = new BulletStateOne(this); stateNull = new BulletStateNull(this); state = stateThree; &#125; public void setState(State state)&#123; this.state = state; &#125; public void fire()&#123; state.shoot(); &#125; public void load()&#123; state.loadBullets(); &#125;&#125;//ConcreteStatepublic class BulletStateNull extends State&#123; Gun gun; BulletStateNull(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("没有子弹了！"); &#125; public void loadBullets()&#123; System.out.println("装弹-------"); gun.setState(gun.stateThree); &#125;&#125;public class BulletStateOne extends State&#123; Gun gun; BulletStateOne(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateNull); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;public class BulletStateTwo extends State&#123; Gun gun; BulletStateTwo(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateOne); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;public class BulletStateThree extends State&#123; Gun gun; BulletStateThree(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateTwo); //gun,setState(new BulletStateTwo(gun)); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; Gun gun = new Gun(); gun.fire(); gun.fire(); gun.fire(); gun.fire(); gun.load(); gun.fire(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Strategy Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FStrategyPattern%2F</url>
    <content type="text"><![CDATA[Strategy Pattern（策略模式）Define a family of algorithms, encapsulate each one, and make them interchangeable.（定义一组算法，将每个算法都封装起来，并且使他们之间可以互换。） 策略（Strategy）：一个接口 上下文（Context）：依赖于策略接口的类（组合关系） 具体策略（ConcreteStrategy）：策略接口的实现类 应用场景：一个类定义了多种行为构成了多个条件分支（封装算法的细节） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//Strategypublic interface Strategy&#123; public double computerAverage(double [] a); &#125;//Contextpublic class AverageScore&#123; //组合 Strategy stratrgy; public void setStrategy(Strategy stratrgy)&#123; this.stratrgy = stratrgy; &#125; public double getAverage(double [] a)&#123; return stratrgy.computerAverage(a); &#125;&#125;//ConcreteStrategypublic class StrategyA implements Strategy &#123; public double computerAverage(double [] a)&#123; double average = 0; for (double i : a) &#123; average += i; &#125; average /=a.length; return average; &#125;&#125;import java.util.Arrays;public class StrategyB implements Strategy &#123; public double computerAverage(double [] a)&#123; double average = 0; Arrays.sort(a); for (int i = 1;i &lt; a.length-1 ;i++ ) &#123; average += a[i]; &#125; average /=(a.length-2); return average; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; double [] tuple = new double[]&#123;90,90,98,87,76,45&#125;; AverageScore ave = new AverageScore(); //策略A ave.setStrategy(new StrategyA()); double score = ave.getAverage(tuple); //策略B ave.setStrategy(new StrategyB()); double score1 = ave.getAverage(tuple); System.out.printf("%10f %10f",score,score1); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mediator Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FMediatorPattern%2F</url>
    <content type="text"><![CDATA[Mediator Pattern（中介者模式）Define an object that encapsulates how a set of objects interact.Mediator promotes loose couping by keeping objects from referring to each other explicitly, and it lets you vary their interaction independently.（用一个中介对象封装一系列的对象交互，中介者使各对象不需要显示的相互作用，从而使其耦合松散，而且可以独立的改变它们之间的交互。） 中介者（Mediator）：一个接口，定义同事Colleague对象中间用于通信的方法 具体中介者（Invoker）：Mefiator接口的实现类，包含具体同事ConcreteColleague对象的引用 同事（Colleague）：一个接口，定义具体同事要是实现的方法 具体同事（ConcreteColleague）：同事接口的实现类，同事包含中介者的引用，同事之间也可以相互交流 应用场景：避免同事对象之间显示的引用，将同事之间的通信交由中介来负责 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Mediatorpublic interface Mediator&#123; public void registerColleague(Colleague colleague); public void deliverMess(String mess,Colleague... c);&#125;//Invokerimport java.util.ArrayList;public class ConcreteMediator implements Mediator&#123; ArrayList&lt;Colleague&gt; list; ConcreteMediator()&#123; list = new ArrayList&lt;Colleague&gt;(); &#125; public void registerColleague(Colleague colleague)&#123; list.add(colleague); &#125; public void deliverMess(String mess,Colleague... c)&#123; for (Colleague colleague : c) &#123; if(list.contains(colleague)) colleague.receiveMess(mess,colleague); else continue; &#125; &#125;&#125;//Colleaguepublic interface Colleague&#123; public void setName(String name); public String getName(); public void sendMess(String mess,Colleague... c); public void receiveMess(String mess,Colleague c); public void setMediator(Mediator mediator);&#125;//ConcreteColleaguepublic class ConcreteColleague implements Colleague&#123; Mediator mediator; String name; public void setName(String name)&#123; this.name = name; &#125; public String getName()&#123; return name; &#125; public void sendMess(String mess,Colleague... c)&#123; mediator.deliverMess(mess,c); &#125; public void receiveMess(String mess,Colleague c)&#123; System.out.println(this.getName()+":来自"+c.getName()+"的消息"); System.out.println("-----------"+mess); &#125; public void setMediator(Mediator mediator)&#123; this.mediator = mediator; mediator.registerColleague(this); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Mediator m = new ConcreteMediator(); Colleague c = new ConcreteColleague(); Colleague c1 = new ConcreteColleague(); Colleague c2 = new ConcreteColleague(); c.setMediator(m); c1.setMediator(m); c2.setMediator(m); c.setName("C"); c1.setName("C1"); c2.setName("C2"); c.sendMess("Hello!",c1,c2); c1.sendMess("Hi",c); c2.sendMess("Hi!",c); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memento Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FMementoPattern%2F</url>
    <content type="text"><![CDATA[Memento Pattern（备忘录模式）Without violating encapsulation， capture and externalize an object’s internal state so that the object can be restored to this state later.（在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样以后就可将该对象恢复到原来保存的状态。）Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//public class Original &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public Original(String value) &#123; this.value = value; &#125; public Memento createMemento()&#123; return new Memento(value); &#125; public void restoreMemento(Memento memento)&#123; this.value = memento.getValue(); &#125; &#125; //public class Memento &#123; private String value; public Memento(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; &#125; //public class Storage &#123; private Memento memento; public Storage(Memento memento) &#123; this.memento = memento; &#125; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125; &#125; //Testpublic class Test &#123; public static void main(String[] args) &#123; // 创建原始类 Original origi = new Original("egg"); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println("初始化状态为：" + origi.getValue()); origi.setValue("niu"); System.out.println("修改后的状态为：" + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println("恢复后的状态为：" + origi.getValue()); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Observer Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FObserverPattern%2F</url>
    <content type="text"><![CDATA[Observer Pattern（观察者模式）Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.（定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。） 主题（Subject）：一个接口,规定具体主题需要实现的方法 观察者（Observer）：一个接口，规定了具体观察者用来获取数据的方法 具体主题(ConcreteSubject)：主题接口的实现类，该实例包含观察者所关心的数据（经常变动），含有观察者的引用，以便在数据发生变化时通知观察者更新数据 具体观察者(ConcreteObserver)：观察者接口的实现类，含有具体主题的引用，以便于具体主题将自己添加/删除到其集合中去，成为该主题的观察者 应用场景：观察者对于主题中的数据可采用两种方法——“拉”数据或者——-“推”数据,即主题主动将数据更新推送给观察者，或者只是通知观察者数据已更新，观察者自己调用主题方法实现数据更新，适用于一个对象数据更新时需要通知其他对象（或者让其自行更新） javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//Subjectpublic interface Subject&#123; public void addObserver(Observer o); public void deleteObserver(Observer o); public void notifyObservers(); public void setDate(String name,String author,String publisher,float price); public String getName(); public float getPrice(); public String getAuthor(); public String getPublisher();&#125;//Observerpublic interface Observer&#123; public void update();&#125;//ConcreteSubjectimport java.util.LinkedList;public class BookStore implements Subject&#123; private String name,author,publisher; private float price; private LinkedList&lt;Observer&gt; list; BookStore()&#123; list = new LinkedList&lt;Observer&gt;(); &#125; public void addObserver(Observer o)&#123; if(!list.contains(o)) list.add(o); &#125; public void deleteObserver(Observer o)&#123; if(list.contains(o)) list.remove(o); &#125; public void notifyObservers()&#123; for (Observer observer : list) &#123; observer.update(); &#125; &#125; public void setDate(String name,String author,String publisher,float price)&#123; this.name = name; this.author = author; this.publisher = publisher; this.price = price; notifyObservers(); //一旦发生数据更新，随即通知各个观察者 &#125; public String getName()&#123; return name; &#125; public float getPrice()&#123; return price; &#125; public String getAuthor()&#123; return author; &#125; public String getPublisher()&#123; return publisher; &#125;&#125;//ConcreteObserverpublic class CustomerOne implements Observer &#123; private Subject subject; private String bookName; private float price; CustomerOne(Subject subject)&#123; this.subject = subject; subject.addObserver(this); &#125; public void update()&#123; bookName = subject.getName(); price = subject.getPrice(); System.out.println(bookName+"和"+price+"更新了"); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Subject s = new BookStore(); Observer o = new CustomerOne(s); s.setDate("设计模式","刘飞","清华出版社",25); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prototype Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FPrototypePattern%2F</url>
    <content type="text"><![CDATA[Prototype Pattern（原型模式）Specify the kinds of objects to create using a prototypical instance,and create new objects by copying this prototype.（用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。） 抽象原型（Prototype）：一个接口，定义对象复制自身的方法 具体原型（ConcretePrototype）：抽象原型的实现类 应用场景：通过复制原型创建新的对象(序列化/反序列化，Class.clone()克隆，深度克隆) javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//Prototypepublic interface Prototype&#123; public Object cloneMe() throws CloneNotSupportedException;&#125;//ConcretePrototypepublic class CloneA implements Prototype,Cloneable &#123; int a; CloneA(int a)&#123; this.a = a; &#125; public Object cloneMe() throws CloneNotSupportedException&#123; CloneA object = (CloneA)clone(); return object; &#125;&#125;import java.io.*;public class CloneB implements Prototype,Serializable &#123; StringBuffer color; public void setColor(StringBuffer c)&#123; color = c; &#125; public StringBuffer getColor()&#123; return color; &#125; public Object cloneMe() throws CloneNotSupportedException&#123; Object object = null; try&#123; ByteArrayOutputStream outOne = new ByteArrayOutputStream(); ObjectOutputStream outTwo = new ObjectOutputStream(outOne); outTwo.writeObject(this); ByteArrayInputStream inOne = new ByteArrayInputStream(outOne.toByteArray()); ObjectInputStream inTwo = new ObjectInputStream(inOne); object = inTwo.readObject(); &#125;catch(Exception e)&#123;&#125; return object; &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; try&#123; CloneA c = new CloneA(2); CloneA c1 = (CloneA)c.cloneMe(); System.out.print(c.a+"---"+c1.a); CloneB cc = new CloneB(); cc.setColor(new StringBuffer("A")); CloneB cc1 = (CloneB)cc.cloneMe(); cc1.setColor(new StringBuffer("copyA")); System.out.print(cc.getColor()+"---"+cc1.getColor()); &#125;catch(Exception e)&#123;&#125; &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Decorator Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FDecoratorPattern%2F</url>
    <content type="text"><![CDATA[Decorator Pattern（装饰模式）Attach additional responsibilities to an object dynamically keeping the same interface.Decorators provide a flexible alternative to subclassing for extending functionality.（动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。） 抽象组件（Component）:抽象类，定义需要进行装饰的方法，被装饰角色 具体组件（ConcreteComponent）:抽象组件的一个子类 装饰（Decorator）：也是抽象组件的一个子类，装饰者角色 具体装饰（ConcreteDecorator）：装饰的一个非抽象子类 应用场景：动态的给对象添加一些额外的方法，改进类的某个对象的功能，调用同样的方法，不一样的结果 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142//Componentpublic abstract class Bird&#123; public abstract int fly();&#125;//ConcreteComponentpublic class Sparrow extends Bird&#123; private final static int DISTANCE = 100; public int fly()&#123; return DISTANCE; &#125;&#125;//Decoratorpublic abstract class Decorator extends Bird&#123; Bird bird; Decorator()&#123;&#125; Decorator(Bird bird)&#123; this.bird = bird; &#125;&#125;//ConcreteDecoratorpublic class ConcreteDecorator extends Decorator&#123; private final static int DISTANCE = 50; ConcreteDecorator(Bird bird)&#123; super(bird); &#125; public int fly()&#123; return bird.fly()+DISTANCE; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Bird bird = new Sparrow(); System.out.println(bird.fly()); bird = new ConcreteDecorator(bird); System.out.println(bird.fly()); bird = new ConcreteDecorator(bird); System.out.println(bird.fly()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Facade Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FFacadePattern%2F</url>
    <content type="text"><![CDATA[Facade Pattern（门面模式）Provide a unified interface to a set of interface in a subsystem.Facede defines a higher-level interface that makes the subsystem easier to use.(要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供了一个高层次的接口，使得子系统更容易使用。) 子系统（Subsystem）:若干类的集合，均不包含外观类的实例引用 外观（Facade）：一个含有子系统中全部或者部分类的实例引用的类 应用场景：跟踪系统使用情况（经过同一个接口），更换系统（只需更改外观接口的代码） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//Subsystempublic class CPU &#123; public void startup()&#123; System.out.println("cpu startup!"); &#125; public void shutdown()&#123; System.out.println("cpu shutdown!"); &#125; &#125; public class Memory &#123; public void startup()&#123; System.out.println("memory startup!"); &#125; public void shutdown()&#123; System.out.println("memory shutdown!"); &#125; &#125; public class Disk &#123; public void startup()&#123; System.out.println("disk startup!"); &#125; public void shutdown()&#123; System.out.println("disk shutdown!"); &#125; &#125; //Facadepublic class Computer &#123; private CPU cpu; private Memory memory; private Disk disk; public Computer()&#123; cpu = new CPU(); memory = new Memory(); disk = new Disk(); &#125; public void startup()&#123; System.out.println("start the computer!"); cpu.startup(); memory.startup(); disk.startup(); System.out.println("start computer finished!"); &#125; public void shutdown()&#123; System.out.println("begin to close the computer!"); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println("computer closed!"); &#125; &#125; //Testpublic class Application &#123; public static void main(String[] args) &#123; Computer computer = new Computer(); computer.startup(); computer.shutdown(); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flyweight Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FFlyweightPattern%2F</url>
    <content type="text"><![CDATA[Flyweight Pattern（享元模式）Use sharing to support large numbers of fine-grained objects efficiently.（使用共享对象可有效地支持大量的细粒度对象。） 享元接口（Flyweight）：一个接口，定义了享元对外公开内部数据的方法以及接受外部数据的方法 具体享元（ConcreteFlyweight）：享元接口的实现类的实例 享元工厂(FlyweightFactory)：一个类，负责创建和管理享元实例，其他对象对享元的请求必须通过工厂才能获得一个享元对象的实例引用 应用场景：利用一个叫做享元的对象来为其他对象提供共享的状态，且保证其他对象不能更改享元中的数据 javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//Flyweightpublic interface Flyweight&#123; public double getWeight(); public double getWidth(); public double getLength();&#125;//ConcreteFlyweightpublic class Car&#123; Flyweight flyweight; String color; double power; Car(Flyweight flyweight,String color,double power)&#123; this.flyweight = flyweight; this.color = color; this.power = power; &#125; public void print()&#123; System.out.println(color); System.out.println(power); System.out.println(flyweight.getWeight()); System.out.println(flyweight.getWidth()); System.out.println(flyweight.getLength()); &#125;&#125;//FlyweightFactorypublic class FlyweightFactory&#123; static FlyweightFactory factory = new FlyweightFactory(); static Flyweight intrinsic; private FlyweightFactory()&#123;&#125; public static FlyweightFactory getFactory()&#123; return factory; &#125; public Flyweight getFlyweight()&#123; intrinsic = new DateCar(1.43,1.45,5.21); return intrinsic; &#125; //内部类 class DateCar implements Flyweight&#123; private double weight; private double width; private double length; //私有构造方法，不允许其他程序直接使用享元类来直接创建享元对象 private DateCar(double weight,double width,double length)&#123; this.weight = weight; this.width = width; this.length = length; &#125; public double getWeight()&#123; return weight; &#125; public double getWidth()&#123; return width; &#125; public double getLength()&#123; return length; &#125; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; FlyweightFactory factory = FlyweightFactory.getFactory(); Flyweight carIntrinsic = factory.getFlyweight(); Car one = new Car(carIntrinsic,"red",5000); Car two = new Car(carIntrinsic,"blue",3000); one.print(); two.print(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interpreter Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FInterpreterPattern%2F</url>
    <content type="text"><![CDATA[Interpreter Pattern（解释器模式）Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences int the language.（给定一门语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。） 123456789101112131415161718192021222324252627282930313233343536373839404142434445//public interface Expression &#123; public int interpret(Context context); &#125; public class Plus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()+context.getNum2(); &#125; &#125; public class Minus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()-context.getNum2(); &#125; &#125; public class Context &#123; private int num1; private int num2; public Context(int num1, int num2) &#123; this.num1 = num1; this.num2 = num2; &#125; public int getNum1() &#123; return num1; &#125; public void setNum1(int num1) &#123; this.num1 = num1; &#125; public int getNum2() &#123; return num2; &#125; public void setNum2(int num2) &#123; this.num2 = num2; &#125; &#125; //Testpublic class Test &#123; public static void main(String[] args) &#123; // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus() .interpret(new Context(9, 2)), 8))); System.out.println(result); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chain Of Responsibility Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FChainOfResponsibilityPattern%2F</url>
    <content type="text"><![CDATA[Chain Of Responsibility Pattern（责任链模式）Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request.Chain the receiving objects and pass the request along the chain until an object handles it.（使多个对象有机会处理请求，从而避免了请求的发送者和接收者之间的耦合关系 。将这些对象连成一个链，并沿着这条链传递请求，知道有对象处理它为止。） 处理者（Handler）：一个接口,负责规定具体处理者处理用户的请求的方法和具体处理者设置后继对象的方法 具体处理者（ConcreteHandler）：Handler接口的实现类，调用处理者接口规定的方法处理用户的请求，若能处理则进行处理，不能则传给下一节点 应用场景：形成一个处理链，挨个节点判断是否能够进行处理，阶乘的计算（从结果的数据量按需判断那个节点可以容纳结果） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//Handlerpublic interface Handler&#123; public abstract void computerMultiply(String number); public abstract void setNextHandler(Handler handler);&#125;//ConcreteHandlerimport java.util.*;public class UseInt implements Handler&#123; private int result = 1; private Handler handler; public void computerMultiply(String number)&#123; try&#123; int n = Integer.parseInt(number); while(n &gt; 0)&#123; result *=n--; if (result &lt;= 0) &#123; System.out.println("超出int计算范围"); handler.computerMultiply(number); return; &#125; &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;public class UseLong implements Handler&#123; private long result = 1; private Handler handler; public void computerMultiply(String number)&#123; try&#123; long n = Long.parseLong(number); while(n &gt; 0)&#123; result *=n--; if (result &lt;= 0) &#123; System.out.println("超出long计算范围"); handler.computerMultiply(number); return; &#125; &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;import java.util.*;import java.math.BigInteger;public class UseBigInteger implements Handler&#123; private BigInteger result = new BigInteger("1"); private Handler handler; public void computerMultiply(String number)&#123; try&#123; BigInteger n = new BigInteger(number); BigInteger ONE = new BigInteger("1"); while(n.compareTo(ONE) &gt; 0)&#123; result = result.multiply(n); n = n.subtract(ONE); &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;//Testimport java.util.*;public class Application&#123; public static void main(String[] args) &#123; Handler uint,ulong,ubint; uint = new UseInt(); ulong = new UseLong(); ubint = new UseBigInteger(); uint.setNextHandler(ulong); ulong.setNextHandler(ubint); uint.computerMultiply("5"); uint.computerMultiply("19"); uint.computerMultiply("30"); uint.computerMultiply("100"); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Builder Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FBuilderPattern%2F</url>
    <content type="text"><![CDATA[Builder Pattern（建造者模式）Separate the construction of a complex object form its representation so that the same construction process can create different representations.（将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。） 产品（Product）：具体生成器要构造的复杂对象 抽象生成器（Builder）：一个接口，有为创建一个产品对象的各个组件定义的若干方法，还有返回产品对象的方法 具体生成器（ConcreteBuilder）：Builder的实现类 指挥者（Director）：一个类，拥有Builder接口声明的变量，负责向用户提供具体生成器 应用场景：将一个复杂对象的构建与表示分离，使得同样的构建可以创建不同的表示 javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//Productpublic class Product&#123; //产品假设是一台电脑 public String "主机"； public String "显示器"; public String "键盘";&#125;//Builderpublic interface Builder&#123; public abstract String buildZJ(); public abstract String buildXSQ(); public abstract String buildJP(); public abstract void creat();&#125;//ConcreteBuilderpublic class BuilderOne implements Builder &#123; public String buildZJ()&#123; return "YYY牌主机"; &#125; public String buildXSQ()&#123; return "YYY牌显示器"; &#125; public String buildJP()&#123; return "YYY牌键盘"; &#125; public void creat()&#123; System.out.println(buildZJ()); System.out.println(buildJP()); System.out.println(buildXSQ()); &#125; &#125;public class BuilderTwo implements Builder &#123; public String buildZJ()&#123; return "XXX牌主机"; &#125; public String buildXSQ()&#123; return "XXX牌显示器"; &#125; public String buildJP()&#123; return "XXX牌键盘"; &#125; public void creat()&#123; System.out.println(buildZJ()); System.out.println(buildXSQ()); System.out.println(buildJP()); &#125;&#125;//Directorpublic class Director&#123; private Builder builder; Director(Builder builder)&#123; this.builder = builder; &#125; public void createComputer()&#123; builder.creat(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Builder b = new BuilderOne(); Director d = new Director(b); d.createComputer(); b = new BuilderTwo(); d = new Director(b); d.createComputer(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Command Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FCommandPattern%2F</url>
    <content type="text"><![CDATA[Command Pattern（命令模式）Encapsulate a request as an object,thereby letting you parameterize clients with different requests,queue or log requests, and support undoable operations.（将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和恢复功能。） 命令（Command）：一个接口，封装请求的若干方法 请求者（Invoker）：包含Command接口变量的类的实例（组合关系） 接收者（Receiver）：一个类的实例，执行与请求有关的操作 具体命令（ConcreteCommand）：Command接口的实现类 应用场景：请求者与接收者不直接交互，消除彼此的耦合（将命令拆分），命令的撤销（栈的应用）：”\b” 退格键 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//Commandpublic interface BattleCommand&#123; abstract void execute();&#125;//Invokerpublic class ArmySuperior&#123; public BattleCommand command; public void setBattleCommand(BattleCommand command)&#123; this.command = command; &#125; public void startExecuteCommand()&#123; command.execute(); &#125;&#125;//Receiverpublic interface Army&#123; public void attack();&#125;public class ArmyA implements Army&#123; public void attack()&#123; System.out.println("炮火攻打县城A外围"); System.out.println("坦克进攻"); System.out.println("步兵进攻"); &#125;&#125;public class ArmyB implements Army&#123; public void attack()&#123; System.out.println("在敌人增援路上埋地雷"); System.out.println("在战壕里射击增援的敌人"); &#125;&#125;public class ArmyC implements Army&#123; public void attack()&#123; System.out.println("佯攻县城B"); &#125;&#125;//ConcreteCommandpublic class CommandA implements BattleCommand&#123; Army army; public CommandA(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;public class CommandB implements BattleCommand&#123; Army army; public CommandB(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;public class CommandC implements BattleCommand&#123; Army army; public CommandC(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; ArmySuperior superior = new ArmySuperior(); Army army = new ArmyA(); BattleCommand command = new CommandA(army); superior.setBattleCommand(command); superior.startExecuteCommand(); army = new ArmyB(); command = new CommandB(army); superior.setBattleCommand(command); superior.startExecuteCommand(); army = new ArmyC(); command = new CommandC(army); superior.setBattleCommand(command); superior.startExecuteCommand(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Command Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FCompositePattern%2F</url>
    <content type="text"><![CDATA[Composite Pattern（组合模式）Compose objects into tree structure to represent part-whole hierarchies.Composite lets clients treat individual objects and compositions of objects uniformly.（将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。） 抽象组件（Component）:一个接口或者抽象类，定义了个体对象和组合对象需要实现的关于原子操作的方法 Composite节点（Composite Node）:实现了Component接口的类，其中可包含其他Composite节点（组合对象） Leaf节点（Leaf Node）：实现了Component接口的类，不可包含其他Composite节点或者Leaf节点（个体对象） 应用场景：个体对象和组合对象实现于同一接口，形成树形结构（部分-整体层次结构） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//Componentimport java.util.*;public interface MilitaryPerson&#123; public void add(MilitaryPerson person); public void remove(MilitaryPerson person); public MilitaryPerson getChild(int index); public Iterator&lt;MilitaryPerson&gt; getAllChild(); public boolean isLeaf(); public double getSalary(); public void setSalary(double salary); &#125;//Composite Nodeimport java.util.*;public class MilitaryOfficer implements MilitaryPerson&#123; private String name; private double salary; private LinkedList&lt;MilitaryPerson&gt; list; MilitaryOfficer(String name,double salary)&#123; this.name = name; this.salary = salary; list = new LinkedList&lt;MilitaryPerson&gt;(); &#125; public void add(MilitaryPerson person)&#123; list.add(person); &#125; public void remove(MilitaryPerson person)&#123; list.remove(person); &#125; public MilitaryPerson getChild(int index)&#123; return list.get(index); &#125; public Iterator&lt;MilitaryPerson&gt; getAllChild()&#123; return list.iterator(); &#125; public boolean isLeaf()&#123; return false; &#125; public double getSalary()&#123; return salary; &#125; public void setSalary(double salary)&#123; this.salary = salary; &#125;&#125;//Leaf Nodeimport java.util.*;public class MilitarySoldier implements MilitaryPerson&#123; private String name; private double salary; MilitarySoldier(String name,double salary)&#123; this.name = name; this.salary = salary; &#125; public void add(MilitaryPerson person)&#123;&#125; public void remove(MilitaryPerson person)&#123;&#125; public MilitaryPerson getChild(int index)&#123;return null;&#125; public Iterator&lt;MilitaryPerson&gt; getAllChild()&#123;return null;&#125; public boolean isLeaf()&#123; return true; &#125; public double getSalary()&#123; return salary; &#125; public void setSalary(double salary)&#123; this.salary = salary; &#125;&#125;//Testimport java.util.*;public class Application&#123; public static void main(String[] args) &#123; MilitaryPerson 连长 = new MilitaryOfficer("连长",5000); MilitaryPerson 营长 = new MilitaryOfficer("营长",4000); MilitaryPerson 班长 = new MilitaryOfficer("班长",3000); MilitaryPerson 士兵 = new MilitarySoldier("士兵",2000); 连长.add(营长); 营长.add(班长); 班长.add(士兵); System.out.println(computerSalary(连长)); &#125; public static double computerSalary(MilitaryPerson person)&#123; double sum = 0; if(person.isLeaf()==true) sum += person.getSalary(); else&#123; sum += person.getSalary(); Iterator&lt;MilitaryPerson&gt; it = person.getAllChild(); while(it.hasNext())&#123; MilitaryPerson p = it.next(); sum += computerSalary(p); &#125; &#125; return sum; &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Abstract Factory Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FAbstractFactoryPattern%2F</url>
    <content type="text"><![CDATA[Abstract Factory Pattern（抽象工厂模式）Provide an interface for creating families of related or dependent objects without specifying their concrete classes.（为创建一组相关或相互依赖的对象提供一个接口，而且无需指定它们的具体类。） 抽象产品（Product）：一个接口或者抽象类，定义、产品必须实现的方法 具体产品（ConcreteProduct）：抽象产品的子类或者实现类 抽象工厂（AbstractFactory）：一个接口或者抽象类，定义若干个抽象方法 具体工厂（ConcreteFactory）：抽象工厂的实现类或者子类，重写抽象方法，使其返回具体产品的实例 应用场景：提供一个创建一系列或相互依赖对象的接口，而无需知道他们具体的类，反射机制+抽象工厂（反射可以灵活地进行实例化） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//Productpublic abstract class Weapon&#123; protected String type; public abstract void loadBullet(Bullet bullet);&#125;public abstract class Bullet&#123; public abstract void load(String type);&#125;//ConcreteProductpublic class JiQiang extends Weapon&#123; JiQiang()&#123; type = "机枪"; &#125; public void loadBullet(Bullet bullet)&#123; bullet.load(type); &#125;&#125;public class ShouQiang extends Weapon&#123; ShouQiang()&#123; type = "手枪"; &#125; public void loadBullet(Bullet bullet)&#123; bullet.load(type); &#125;&#125;public class JiQiangBullet extends Bullet&#123; public void load(String type)&#123; System.out.println(type+"---装载机枪型子弹"); &#125;&#125;public class ShouQiangBullet extends Bullet&#123; public void load(String type)&#123; System.out.println(type+"---装载手枪型子弹"); &#125;&#125;//Creatorpublic abstract class Factory&#123; public abstract Weapon createWeapon(); public abstract Bullet createBullet();&#125;//ConcreteCreatorpublic class ShouQiangFactory extends Factory &#123; public Weapon createWeapon()&#123; return new ShouQiang(); &#125; public Bullet createBullet()&#123; return new ShouQiangBullet(); &#125;&#125;public class JiQiangFactory extends Factory&#123; public Weapon createWeapon()&#123; return new JiQiang(); &#125; public Bullet createBullet()&#123; return new JiQiangBullet(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Factory factory = new ShouQiangFactory(); Weapon gun = factory.createWeapon(); Bullet bullet = factory.createBullet(); gun.loadBullet(bullet); factory = new JiQiangFactory(); gun = factory.createWeapon(); bullet = factory.createBullet(); gun.loadBullet(bullet); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Adapter Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FAdapterPattern%2F</url>
    <content type="text"><![CDATA[Adapter Pattern（适配器模式） Convert the inface of a class into another interface clients expect.Adapter lets classes work together that couldn’t otherwise because of incompatible interface.（将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。）“系统的数据和行为都正确，单接口不符时，我们应该考虑使用适配器，目的是是控制范围之外的一个原有对象与某个接口匹配。适配器模式主要用于希望复用一些现存的类，但是接口又与复用环境不一致的情况。”（《大话设计模式》） 目标（Target）：一个接口，客户想要使用的接口 被适配器（Adaptee）：一个已经存在的接口或者抽象类 适配器(Adapter)：一个实现了目标接口并且含有被适配器引用的类 应用场景：目标和被适配器完全解耦，通过适配器来建立联系（单接口适配器） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233//Targetpublic interface ZhiLiuDian&#123; public String privideZhiLiuDian();&#125;//Adapteepublic interface JiaoLiuDian&#123; public String privideJiaoLiuDian();&#125;public class JiaoLiuDianHost implements JiaoLiuDian&#123; public String privideJiaoLiuDian()&#123; return "交流电"; &#125;&#125;//Adapterpublic class Adapter implements ZhiLiuDian&#123; JiaoLiuDian jiao; Adapter(JiaoLiuDian jiao)&#123; this.jiao = jiao; &#125; public String privideZhiLiuDian()&#123; String s = jiao.privideJiaoLiuDian(); return "转换"+s+"成直流电"; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; JiaoLiuDian jiao = new JiaoLiuDianHost(); System.out.println(jiao.privideJiaoLiuDian()); ZhiLiuDian zhi = new Adapter(jiao); System.out.println(zhi.privideZhiLiuDian()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bridge Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FBridgePattern%2F</url>
    <content type="text"><![CDATA[Bridge Pattern（桥梁模式）Decouple an abstraction from its implementation so that the two can vary independently.（将抽象和实现解耦，使得两者可以独立的变化。） 抽象（Abstraction）：一个抽象类，含有实现者声明的变量， 实现者（Implementor）：一个接口，定义基本操作 细化抽象（RefinedAbstraction）：抽象的子类 具体实现者（ConcreteImplementor）：实现者的实现类 应用场景：分离实现和抽象，将抽象中方法的重要实现部分交给另外一个抽象类的子类或者接口的类 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//Abstractionpublic abstract class BookEdit&#123; BookWriter [] author; String [] seriesBookName; public abstract void planBook(String [] s,String [] a); public abstract void releaseBook();&#125;//Implementorpublic interface BookWriter&#123; public void startWriterBook(String bookName); public String getName();&#125;//RefinedAbstractionpublic class TUBookEdit extends BookEdit&#123; public void planBook(String [] s,String [] a)&#123; seriesBookName = s; author = new BookAuthor[seriesBookName.length]; for (int i = 0;i &lt; seriesBookName.length ;i++ ) &#123; author[i] = new BookAuthor(a[i]); author[i].startWriterBook(seriesBookName[i]); &#125; &#125; public void releaseBook()&#123; System.out.println("图书有关信息"); for (int i = 0;i &lt; seriesBookName.length ;i++ ) &#123; System.out.print("书名："+seriesBookName[i]+"-------"); System.out.println("作者："+author[i].getName()); &#125; &#125;&#125;//ConcreteImplementorpublic class BookAuthor implements BookWriter&#123; String name; BookAuthor(String s)&#123; name = s; &#125; public void startWriterBook(String s)&#123; System.out.println(name+"编著了"+s); &#125; public String getName()&#123; return name; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; TUBookEdit zhang = new TUBookEdit(); String seriesBookName [] = &#123;"C程序设计","Java程序设计","XML程序设计"&#125;; String authorName [] = &#123;"张三","李四","王五"&#125;; zhang.planBook(seriesBookName,authorName); zhang.releaseBook(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Factory Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FFactoryPattern%2F</url>
    <content type="text"><![CDATA[Factory Pattern（工厂模式） Define an interface for creating an object,but let subclass decide which class to instantiate.Factory Method lets a class defer instantiation to subclass.（定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法是一个类的实例化延迟到其子类。） 抽象产品（Product）：一个接口或者抽象类，定义、产品必须实现的方法 具体产品（ConcreteProduct）：抽象产品的子类或者实现类 构造者（Creator）：一个接口或者抽象类，定义一个叫做工厂方法的抽象方法，该方法返回具体产品类的实例 具体构造者（ConcreteCreator）：构造者实现类或者子类 应用场景：使一个类的实例化延迟到其子类，或者是想得到某一类的子类的实例，但是却无法直接使用new（不允许与该子类形成耦合），或者不清楚该类有哪些子类可用 javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//Productpublic abstract class PenCore&#123; String color; public abstract void writeword(String s);&#125;//ConcreteProductpublic class RedPen extends PenCore&#123; RedPen()&#123; color = "红色"; &#125; public void writeword(String s)&#123; System.out.println("写出"+color+"的字："+s); &#125;&#125;public class BluePen extends PenCore&#123; BluePen()&#123; color = "蓝色"; &#125; public void writeword(String s)&#123; System.out.println("写出"+color+"的字："+s); &#125;&#125;public class BallPen&#123; PenCore core; public void usePenCore(PenCore core)&#123; this.core = core; &#125; public void write(String s)&#123; core.writeword(s); &#125;&#125;//AbstractFactorypublic abstract class Creator&#123; public abstract PenCore getPenCore();&#125;//ConcreteFactorypublic class RedCreator extends Creator&#123; public PenCore getPenCore()&#123; return new RedPen(); &#125;&#125;public class BlueCreator extends Creator&#123; public PenCore getPenCore()&#123; return new BluePen(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; PenCore core; //笔芯 Creator c = new RedCreator(); //笔芯构造者 BallPen b = new BallPen(); //圆珠笔 core = c.getPenCore(); b.usePenCore(core); b.write("哈"); c = new BlueCreator(); core = c.getPenCore(); b.usePenCore(core); b.write("ha"); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java架构学习心得(一)]]></title>
    <url>%2F2017%2F07%2F15%2FJava%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[序言 软件开发从最初的pc单机的人机交互模式到后来局域网的出现开启了软件开发的c/s模式（客户端/服务器模式），在到现在的b/s模式（浏览器/服务器），其实都面临的着相同的问题——代码的冗余，相似代码的大量重复导致整体代码量的庞大，所以为了减少代码的冗余，避免上述情况的产生，框架应用而生！而框架的原理其实主要就只有两部分，流程的抽象和数据类型的抽象，下面我们一一道来！（此文章适合于学过jsp及j2EE的童鞋） 正文首先我们来说流程控制，b/s模式均由浏览器向服务器发出请求，然后服务器响应相关请求并回传结果给浏览器，这是个一成不变的通用过程，所以我要做的就是抽象这个过程，类似于Struts2，把请求和响应的控制流程抽象到框架中去，让框架去拦截掉你的所有请求，然后经过处理后在传递给服务器，服务器的相响应结果同样被框架截获，然后处理后再扔给浏览器去显示，以上是大概流程，下面我们用程序代码详细道来！1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;FlowControl&gt; &lt;Action name="login"&gt; &lt;OperatePoint name="login_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;OperatePoint name="login_check"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;OperatePoint name="login_init"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;Action name="register"&gt; &lt;OperatePoint name="register_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;Action name="xxx"&gt; &lt;OperatePoint name="xxx_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;/FlowControl&gt; 上面的xml配置文件类似于Struts2的struts.xml，用于表明整个项目中所有的请求与对应请求的响应，Action为我自己定义的用于处理相关的请求动作类，OperatePoint为动作类中不同的方法，用于减少过多动作类，将一组相关的动作处理放入到同一个类中，用不同的方法去处理，减少代码的冗余。123456789101112131415161718192021222324252627282930313233343536&lt;filter&gt; &lt;filter-name&gt;FrameFilter&lt;/filter-name&gt; &lt;filter-class&gt;edu.frame.web.core.FrameFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;ExcludedPages&lt;/param-name&gt; &lt;param-value&gt;/authImage,/register&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;DataBaseName&lt;/param-name&gt; &lt;param-value&gt;MySql&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;DBConfigFile&lt;/param-name&gt; &lt;param-value&gt;DBConfig.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;FlowControlConfigFile&lt;/param-name&gt; &lt;param-value&gt;flowcontrol.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;AppBasePath&lt;/param-name&gt; &lt;param-value&gt;edu.demo.web.flowcontrol&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;ConfigPath&lt;/param-name&gt; &lt;param-value&gt;config&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;JspPath&lt;/param-name&gt; &lt;param-value&gt;jsp&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;FrameFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 上述代码段来自web.xml，我们用一个名叫FrameFilter的filter来拦截浏览器发送的所有的请求然后判定请求的类别，如果是jsp页面，我们不做处理直接扔给服务器，如果是action类请求，我们获取路径分解出类名和方法名，利用Java反射机制实例化相应的的动作类执行相应的方法，然后返回结果字符串result，在根据结果result找到流程控制配置文件中对应的jsp页面扔给服务器。init-param部分为初始化参数，包括ExcludedPages（请求过滤页面），DataBaseName（选用数据库名称，我们将数据库的统一操作也封装在框架内，应用层通过配置文件来进行数据库的选择和连接），DBConfigFile（数据库配置文件）FlowControlConfigFile（流程控制文件），AppBasePath（action动作类目录），ConfigPath（配置文件地址），JspPath（页面地址）。因此FrameFilter.java为本框架中最核心的部分，下面我们来看一下此文件的具体内容123456789101112131415161718public class FrameFilter implements Filter &#123; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)&#123;&#125; //前处理，字符的乱码，数据库和流程控制配置文件的解析与实例化封装 public void perpare(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //初始化过滤器，加载web.xml文件中参数 public void init(FilterConfig config) throws ServletException &#123;&#125; //获取物理路径 private String getRealPath(FilterConfig config, String name)&#123;&#125; //请求匹配，判定是action还是jsp页面 public String actionMapping(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //action执行前的准备，action动作类名及方法的提取分离 public void prepareExecute(HttpServletRequest request, HttpServletResponse response,String functionName)&#123;&#125; //根据传来的动作类名和方法名去相应的action中执行相应的方法，返回result public String executeAction(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //根据action类返回的result跳转到相应的jsp页面 public void dispatcher(HttpServletRequest request, HttpServletResponse response,String result)&#123;&#125;&#125; 上述即为流程控制的核心部分，涉及到的细节有xml配置文件的解析（需引入dom4j或者其他的xml解析jar包，例如数据库配置文件和流程控制文件的解析均需要用到），还有就是java的反射机制，已知类名和方法名的字符串实现类的实例化，及方法的执行。]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Struts</tag>
        <tag>JavaWeb</tag>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅尝MyBatis]]></title>
    <url>%2F2017%2F07%2F08%2F%E6%B5%85%E5%B0%9DMyBatis%2F</url>
    <content type="text"><![CDATA[引言什么是JDBC？ JDBC（Java DataBase Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。JDBC提供了一种基准，据此可以构建更高级的工具和接口，使数据库开发人员能够编写数据库应用程序。 有了JDBC，向各种关系数据发送SQL语句就是一件很容易的事。换言之，有了JDBC API，就不必为访问Sybase数据库专门写一个程序，为访问Oracle数据库又专门写一个程序，或为访问Informix数据库又编写另一个程序等等，程序员只需用JDBC API写一个程序就够了，它可向相应数据库发送SQL调用。同时，将Java语言和JDBC结合起来使程序员不必为不同的平台编写不同的应用程序，只须写一遍程序就可以让它在任何平台上运行，这也是Java语言“编写一次，处处运行”的优势。 JDBC的用途简单地说，JDBC 可做三件事：与数据库建立连接、发送 操作数据库的语句并处理结果。下列代码段给出了以上三步的基本示例：123456789Class.forName("sun.jdbc.odbc.JdbcOdbcDriver");Connection con = DriverManager.getConnection("jdbc:odbc:wombat","login","password");Statement stmt = con.createStatement();ResultSet rs = stmt.executeQuery("SELECT a, b, c FROM Table1");while (rs.next()) &#123; int x = rs.getInt("a"); String s = rs.getString("b"); float f = rs.getFloat("c");&#125; 正文MyBatis基本构成 SqlSessionFactoryBuilder：根据配置文件生成SqlSessionFactory 1234567891011public static SqlSessionFactory initSqlSessionFactory() &#123; try &#123; InputStream intputStream = Resources.getResourceAsStream("mybatis_config.xml"); &#125; catch (IOException e) &#123;&#125; synchronized(CLASS_LOCK)&#123; if(sqlSessionFactory == null)&#123; sqlSessionFactory = new SqlSessionFactoryBuilder().build(intputStream); &#125; &#125; return sqlSessionFactory;&#125; SqlSessionFactory：依靠工厂生成SqlSession会话 123456public static SqlSession openSqlSession()&#123; if(sqlSessionFactory == null)&#123; initSqlSessionFactory(); &#125; return sqlSessionFactory.openSession();&#125; SqlSession(类似于jdbc的Connection对象)：1)发送sql执行并返回结果，2)获取Mapper的接口 12345678910SqlSession session = sqlSessionFactory.openSession();//1)发送sql执行并返回结果，不建议使用try &#123; Role role = session.selectOne("org.mybatis.example.RoleMapper.getRole", 101); &#125; finally &#123; session.close(); &#125;//2)获取Mapper的接口，建议使用try &#123; RoleMapper mapper = session.getMapper(RoleMapper.class); Role role = mapper.getRole(101); &#125; finally &#123; session.close(); &#125; SQL Mapper：由java接口和xml文件或注解构成，需要给出对应的sql和映射规则，发送sql执行并返回结果。 XML配置文件方式实现Mapper 第一步给出java接口 123public interface RoleMapper &#123; public Role getRole(Long id);&#125; 第二步给出XML配置文件 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybtis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt; &lt;mapper namespace="com.mybatis.demo.mapper.RoleMapper"&gt; &lt;select id="getRole" parameterType="long" resultType="role"&gt; select id,role_name as roleName,role_name from t_role where id=#&#123;id&#125; &lt;/select&gt; &lt;/mapper&gt; 第三步给出javaBean类 123456789101112131415161718192021222324252627282930public class Role &#123; private Long id; private String roleName; private String note; public Role() &#123;&#125; public Role(Long id, String roleName, String note) &#123; super(); this.id = id; this.roleName = roleName; this.note = note; &#125; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getRoleName() &#123; return roleName; &#125; public void setRoleName(String roleName) &#123; this.roleName = roleName; &#125; public String getNote() &#123; return note; &#125; public void setNote(String note) &#123; this.note = note; &#125;&#125; 最后获取Mapper执行方法 123RoleMapper mapper = session.getMapper(RoleMapper.class); Role role = mapper.getRole(101); System.out.println(role.getRoleName()); java注解方式实现Mapper（不建议使用）1234public interface BlogMapper &#123; @Select("SELECT * FROM blog WHERE id = #&#123;id&#125;") Blog selectBlog(int id); &#125; MyBatis的配置上面我们用到了一个名为mybatis_config.xml的配置文件，下面我们来看一下文件具体内容123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt; &lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias = "role" type = "com.mybatis.demo.po.Role"/&gt; &lt;/typeAliases&gt; &lt;typeHandlers&gt; &lt;typeHandler handler="org.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;/typeHandlers&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="root"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="com/mybatis/demo/mapper/roleMapper.xml"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 首先我们来看数据源dataSource，引入数据源的方式有几种，我们分别介绍一下 第一种就是文件中的形式直接显示在property子元素中 1234&lt;property name="driver" value=""/&gt; &lt;property name="url" value=""/&gt; &lt;property name="username" value=""/&gt; &lt;property name="password" value=""/&gt; 第二种是使用properties配置文件 12345//jdbc.properties文件内容driver=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/mybatis username=root password=root 12//直接引入配置文件即可&lt;properties resource="jdbc.properties"/&gt; 如果properties配置文件中数据库用户名和密码是密文的形式，系统提供了解密方法DECODE(str)1234567891011121314151617181920212223public static SqlSessionFactory initSqlSessionFactory() &#123; InputStream cfgStream = null; Reader cfgReader = null; InputStream proStream = null; Reader proReader = null; Properties properties = null; try &#123; cfgStream = Resources.getResourceAsStream("mybatis_config.xml"); cfgReader = new InputStreamReader(cfgStream); proStream = Resources.getResourceAsStream("jdbc.properties"); proReader = new InputStreamReader(proStream); properties = new Properties(); properties.load(proReader); properties.setProperty("username", DECODE(properties.getProperty("username"))); properties.setProperty("password", DECODE(properties.getProperty("password"))); &#125; catch (IOException e) &#123;&#125; synchronized(CLASS_LOCK)&#123; if(sqlSessionFactory == null)&#123; sqlSessionFactory = new SqlSessionFactoryBuilder().build(cfgReader,properties); &#125; &#125; return sqlSessionFactory;&#125; 接下来我们看看typeAliases（别名） 逐个定义别名 123456&lt;typeAliases&gt; &lt;!-- 使用role来代替全路径com.mybatis.demo.po.Role --&gt; &lt;typeAlias alias = "role" type = "com.mybatis.demo.po.Role"/&gt; &lt;typeAlias alias = "a" type = "com.mybatis.demo.po.A"/&gt; ...&lt;/typeAliases&gt; 自动扫描（当定义数量较大时） 123&lt;typeAliases&gt; &lt;package name="com.mybatis.demo.po"&gt;&lt;/typeAliases&gt; 12345//当采用自动扫描方式的时候，配合注解@Alias()使用//若不使用注解则自动扫描按照当前类的首字母自动小写后为别名进行装载import org.apache.ibatis.type.Alias;@Alias("role")public class Role &#123;&#125; typeHandler类型处理器 MyBatis会在预处理语句（PrepareStatement）中设置一个参数时，或者从结果集（ResultSet）中取出一个值时，都会使用注册了的typeHandler进行处理，即实现javaType和jdbcType之间的相互转化。MyBatis中为我们提供了多种基本的typeHandler，同时我们也可以自定义typeHandler！ 自定义typeHandler 首先编写我们自己的typeHandler 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class MyStringTypeHandlerByInterface implements TypeHandler&lt;String&gt;&#123; private Logger log = Logger.getLogger(MyStringTypeHandler.class); @Override public String getResult(ResultSet rs, String columnName) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，resultSet列名获取字符串"); return rs.getString(columnName); &#125; @Override public String getResult(ResultSet rs, int columnIndex) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，resultSet下标获取字符串"); return rs.getString(columnIndex); &#125; @Override public String getResult(CallableStatement cs, int columnIndex) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，CallableStatement下标获取字符串"); return cs.getString(columnIndex); &#125; @Override public void setParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler"); ps.setString(i, parameter); &#125;&#125;//GenericTypeHandler.java /*You can create a generic TypeHandler that is able to handle more than one class. For that purpose add a constructor that receives the class as a parameter and MyBatis will pass the actual class when constructing the TypeHandler.*/public class GenericTypeHandler&lt;E extends MyObject&gt; extends BaseTypeHandler&lt;E&gt; &#123; private Class&lt;E&gt; type; public GenericTypeHandler(Class&lt;E&gt; type) &#123; if (type == null) throw new IllegalArgumentException("Type argument cannot be null"); this.type = type; &#125; ...``` - 然后我们有三种方法来使用自定义的typeHandler - 第一种是先在配置文件mybatis_config.xml中声明，然后在映射文件中使用 ```xml //mybatis_config.xml文件 &lt;typeHandlers&gt; &lt;typeHandler handler="com.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;!-- 自动扫描 &lt;package name="com.mybatis.demo.myTypeHandler"/&gt; --&gt; &lt;/typeHandlers&gt; //roleMapper.xml文件 &lt;resultMap type="role" id="roleMap"&gt; &lt;id column="id" property="id" javaType="long" jdbcType="BIGINT"/&gt; &lt;result column="role_name" property="roleName" javaType="String" jdbcType="VARCHAR"/&gt; &lt;/resultMap&gt; 第二种是直接在映射文件中定义具体typeHandler 12345//roleMapper.xml文件&lt;resultMap type="role" id="roleMap"&gt; &lt;id column="id" property="id" javaType="long" jdbcType="BIGINT"/&gt; &lt;result column="note" property="note" typeHandler="com.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;/resultMap&gt; 第三种是直接在参数中制定typeHandler 12345//roleMapper.xml文件 &lt;select id="findRole" parameterType="String" resultMap="roleMap"&gt; select id,role_name,role_name from t_role where role_name like concat('%',#&#123;roleName javaType=String, jdbcType=VARCHAR, typeHandler=com.mybatis.demo.myTypeHandler.MyStringTypeHandler&#125;, '%') &lt;/select&gt; 枚举typeHandler 系统枚举类 12345678910111213141516171819202122232425262728293031323334353637//创建性别枚举类Sexpublic enum Sex &#123; MALE(1,"男") , FEMALE(2,"女"); private int id; private String name; private Sex(int id, String name) &#123; this.id = id; this.name = name; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; //以下为自定义方法，供自定义typeHandler使用 public static Sex getSex(int id)&#123; if(id==1) return MALE; else if(id==2) return FEMALE; return null; &#125; public static Sex getSex(String name)&#123; if(name.equals("男")) return MALE; else if(name.equals("女")) return FEMALE; return null; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344mybatis_config.xml文件配置&lt;!-- 采用枚举字符串名称作为参数传递 --&gt;&lt;typeHandler handler="org.apache.ibatis.type.EnumTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt; &lt;!-- 采用整数下标作为参数传递 --&gt;&lt;typeHandler handler="org.apache.ibatis.type.EnumOrdinalTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt;roleMapper.xml文件配置&lt;result column="sex" property="sex" typeHandler="org.apache.ibatis.type.EnumTypeHandler"/&gt;&lt;result column="sex" property="sex" typeHandler="org.apache.ibatis.type.EnumOrdinalTypeHandler"/&gt;``` - 自定义枚举类，类似于前面所述的自定义typeHandler```java//创建自定义性别枚举类public class SexEnumTypeHandler implements TypeHandler&lt;Sex&gt;&#123; @Override public Sex getResult(ResultSet rs, String name) throws SQLException &#123; // TODO Auto-generated method stub /*自定义Id作为参数传递 int id = rs.getInt(name); return Sex.getSex(id);*/ //自定义Name作为参数传递 return Sex.getSex(rs.getString(name)); &#125; @Override public Sex getResult(ResultSet rs, int index) throws SQLException &#123; // TODO Auto-generated method stub /*int id = rs.getInt(index); return Sex.getSex(id);*/ return Sex.getSex(rs.getString(index)); &#125; @Override public Sex getResult(CallableStatement cs, int index) throws SQLException &#123; // TODO Auto-generated method stub /*int id = cs.getInt(index); return Sex.getSex(id);*/ return Sex.getSex(cs.getString(index)); &#125; @Override public void setParameter(PreparedStatement ps, int index, Sex sex, JdbcType jdbcType) throws SQLException &#123; // TODO Auto-generated method stub /*ps.setInt(index,sex.getId());*/ ps.setString(index, sex.getName()); &#125;&#125; 123456789101112131415161718192021222324252627 mybatis_config.xml文件配置 &lt;typeHandler handler="com.mybatis.demo.myTypeHandler.SexEnumTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt; roleMapper.xml文件配置 &lt;result column="sex" property="sex" typeHandler="com.mybatis.demo.myTypeHandler.SexEnumTypeHandler"/&gt; ``` #### SQL元素的运用```xml&lt;sql id="userColumns"&gt; $&#123;alias&#125;.id,$&#123;alias&#125;.username,$&#123;alias&#125;.password &lt;/sql&gt;&lt;select id="selectUsers" resultType="map"&gt; select &lt;include refid="userColumns"&gt;&lt;property name="alias" value="t1"/&gt;&lt;/include&gt;, &lt;include refid="userColumns"&gt;&lt;property name="alias" value="t2"/&gt;&lt;/include&gt; from some_table t1 cross join some_table t2 &lt;/select&gt;&lt;sql id="sometable"&gt; $&#123;prefix&#125;Table &lt;/sql&gt;&lt;sql id="someinclude"&gt; from &lt;include refid="$&#123;include_target&#125;"/&gt; &lt;/sql&gt;&lt;select id="select" resultType="map"&gt; select field1, field2, field3 &lt;include refid="someinclude"&gt; &lt;property name="prefix" value="Some"/&gt; &lt;property name="include_target" value="sometable"/&gt; &lt;/include&gt; &lt;/select&gt; 级联 一对一关联 1234567891011121314151617181920&lt;!-- 方式一 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;association property="author" column="author_id" javaType="Author" select="selectAuthor"/&gt; &lt;/resultMap&gt;&lt;select id="selectBlog" resultMap="blogResult"&gt; SELECT * FROM BLOG WHERE ID = #&#123;id&#125; &lt;/select&gt;&lt;!-- 方式二 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;id property="id" column="blog_id" /&gt; &lt;result property="title" column="blog_title"/&gt; &lt;association property="author" resultMap="authorResult" /&gt; &lt;/resultMap&gt;&lt;resultMap id="authorResult" type="Author"&gt; &lt;id property="id" column="author_id"/&gt; &lt;result property="username" column="author_username"/&gt; &lt;result property="password" column="author_password"/&gt; &lt;result property="email" column="author_email"/&gt; &lt;result property="bio" column="author_bio"/&gt; &lt;/resultMap&gt; 一对多关联 12345678910111213141516171819&lt;!-- 方式一 --&gt;&lt;!-- javaType可有可无，MyBatis会自动识别返回数据类型 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;collection property="posts" javaType="ArrayList" column="id" ofType="Post" select="selectPostsForBlog"/&gt; &lt;/resultMap&gt;&lt;select id="selectBlog" resultMap="blogResult"&gt; SELECT * FROM BLOG WHERE ID = #&#123;id&#125; &lt;/select&gt;&lt;!-- 方式二 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;id property="id" column="blog_id" /&gt; &lt;result property="title" column="blog_title"/&gt; &lt;collection property="posts" ofType="Post" resultMap="blogPostResult" columnPrefix="post_"/&gt; &lt;/resultMap&gt;&lt;resultMap id="blogPostResult" type="Post"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="subject" column="subject"/&gt; &lt;result property="body" column="body"/&gt; &lt;/resultMap&gt; 鉴别器(eg：根据性别属性进行判定去关联不同的对象) 1234567891011121314&lt;discriminator javaType="int" column="sex"&gt; &lt;case value="1" resultType="maleStudentMap"&gt; &lt;result property="" column="" /&gt; &lt;/case&gt; &lt;case value="2" resultType="femaleStudentMap"&gt; &lt;result property="" column="" /&gt; &lt;/case&gt;&lt;/discriminator&gt;&lt;resultMap id="maleStudentMap" type="com.mybatis.demo.po.MaleStudentMap" extends="studentMap"&gt; &lt;result property="" column="" /&gt; &lt;/resultMap&gt;&lt;resultMap id="femaleStudentMap" type="com.mybatis.demo.po.FemaleStudentMap" extends="studentMap"&gt; &lt;result property="" column="" /&gt; &lt;/resultMap&gt; 延迟加载 全局变量lazyLoadingEnabled和aggressiveLazyLoading 开启lazyLoadingEnabled延迟加载，使得关联属性按需加载，而不是自动加载 当aggressiveLazyLoading为true时，MyBatis的内容按照层级加载，我们关闭它，从而实现按照我们调用需求加载 局部变量fetchType123&gt; &lt;association fetchType="lazy"/&gt; &gt; &lt;collection fetchType="lazy"/&gt; &gt; 动态SQL if 123456&lt;select id="findActiveBlogWithTitleLike" resultType="Blog"&gt; SELECT * FROM BLOG WHERE 1 = 1 &lt;if test="title != null"&gt; AND title like #&#123;title&#125; &lt;/if&gt; &lt;/select&gt; choose (when, otherwise) 1234567891011121314&lt;select id="findActiveBlogLike" resultType="Blog"&gt; SELECT * FROM BLOG WHERE 1 = 1 &lt;choose&gt; &lt;when test="title != null"&gt; AND title like #&#123;title&#125; &lt;/when&gt; &lt;when test="author != null and author.name != null"&gt; AND author_name like #&#123;author.name&#125; &lt;/when&gt; &lt;otherwise&gt; AND featured = 1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/select&gt; trim (where, set) 1234567891011121314151617181920212223242526272829303132333435&lt;select id="findActiveBlogLike" resultType="Blog"&gt; SELECT * FROM BLOG &lt;where&gt; &lt;if test="state != null"&gt; state = #&#123;state&#125; &lt;/if&gt; &lt;if test="title != null"&gt; AND title like #&#123;title&#125; &lt;/if&gt; &lt;if test="author != null and author.name != null"&gt; AND author_name like #&#123;author.name&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt;&lt;!-- prefix表示前缀为WHERE，prefixOverrides表示要去掉的元素 --&gt;&lt;trim prefix="WHERE" prefixOverrides="AND |OR "&gt; ... &lt;/trim&gt;&lt;!-- set实现动态更新，按需更新 --&gt;&lt;update id="updateAuthorIfNecessary"&gt; update Author &lt;set&gt; &lt;if test="username != null and username！=''"&gt; username=#&#123;username&#125;, &lt;/if&gt; &lt;if test="password != null"&gt; password=#&#123;password&#125;, &lt;/if&gt; &lt;if test="email != null"&gt; email=#&#123;email&#125;, &lt;/if&gt; &lt;if test="bio != null"&gt; bio=#&#123;bio&#125; &lt;/if&gt; &lt;/set&gt; where id=#&#123;id&#125; &lt;/update&gt; foreach 1234567&lt;select id="selectPostIn" resultType="domain.blog.Post"&gt; SELECT * FROM POST P WHERE ID in &lt;!-- item当前元素,index当前元素下标--&gt; &lt;foreach item="item" index="index" collection="list" open="(" separator=","close=")"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/select&gt; bind 12345&lt;!-- 不使用concat('%',#&#123;parameter&#125;, '%')实现模糊查询 --&gt;&lt;select id="selectBlogsLike" resultType="Blog"&gt; &lt;bind name="pattern" value="'%' + _parameter.getTitle() + '%'" /&gt; SELECT * FROM BLOG WHERE title LIKE #&#123;pattern&#125; &lt;/select&gt; GitHub实例——MyBatis_Example]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Database</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温JavaEE_SSH框架]]></title>
    <url>%2F2017%2F07%2F08%2F%E9%87%8D%E6%B8%A9JavaEE-SSH%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[知识只有当需要书写下来或者讲解出来的时候才显得如此匮乏——菜鸟飞 struts2 hibernate spring ssh整合及项目实例 Struts2 Struts2是一个基于MVC设计模式的Web应用框架，它本质上相当于一个servlet，在MVC设计模式中，Struts2作为控制器(Controller)来建立模型与视图的数据交互。——百度百科 在我看来，struts本质就类似于一个filter，所以在使用前需要在项目lib目录中导入相应的jar包并在项目的web.xml文件中配置如下内容12345678&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 配置完成后，所有的页面请求便会被截获到struts.xml的配置文件中，如下图所示，Struts2框架中核心组件就是Action、拦截器等，Struts2框架使用包来管理Action和拦截器等。每个包就是多个Action、多个拦截器、多个拦截器引用的集合。在struts.xml文件中package元素用于定义包配置，每个package元素定义了一个包配置。它的常用属性有： name：必填属性，用来指定包的名字。 extends：可选属性，用来指定该包继承其他包。继承其它包，可以继承其它包中的Action定义、拦截器定义等。 namespace：可选属性，用来指定该包的命名空间。(考虑到同一个Web应用中需要同名的Action，Struts2以命名空间的方式来管理Action，同一个命名空间不能有同名的Action。Struts2通过为包指定namespace属性来为包下面的所有Action指定共同的命名空间。) 其中action标签中的name属性表示与你所截获的请求名称进行匹配(也就是说将来你项目的所有页面请求在这里都会有所记录，可以清晰地体现你项目的页面跳转逻辑，同时也极大的方便了以后的更改操作)struts.xml12345678&lt;struts&gt; &lt;package name="default" extends="struts-default"&gt; &lt;action name="index" class="com.action.IndexAction"&gt; &lt;result name="success"&gt;index.jsp&lt;/result&gt; &lt;result name="error"&gt;error.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt; &lt;/struts&gt; 对应的action标签中的class属性表示该请求所对应的Action处理类，因为Struts2中的Action采用了低侵入式的设计，所以Struts2不要求Action类继承任何的Struts2的基类或实现Struts2接口。但是，我们为了方便实现Action，大多数情况下都会继承com.opensymphony.xwork2.ActionSupport类，并重写此类里的public String execute() throws Exception方法(Action处理类默认执行方法)。（因为此类中实现了很多的实用接口，提供了很多默认方法，这些默认方法包括获取国际化信息的方法、数据校验的方法、默认的处理用户请求的方法等，这样可以大大的简化Action的开发。)，Action处理类的所有方法最后都会返回一个字符串，如SUCCESS给struts.xml，而action标签内的result标签中的name属性负责匹配传回的字符串，从而跳转至不同的页面123456789101112public class IndexAction extends ActionSupport&#123; public String execute()throws Exception&#123; try &#123; &#125; return SUCCESS; &#125; catch (Exception e) &#123; e.printStackTrace(); return ERROR; &#125; &#125; public String ownMethod()throws Exception&#123;&#125;&#125; 当然你也可以去书写并执行自己的方法，这时你只需要在处理类中加入自己的ownMethod()方法，并在struts.xml文件中的对应的action标签中做如下修改即可1&lt;action name="index" class="com.action.IndexAction!ownMethod"&gt; 以下内容为struts.xml配置详解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;struts&gt; &lt;!-- include节点是struts2中组件化的方式 可以将每个功能模块独立到一个xml配置文件中 然后用include节点引用 --&gt; &lt;include file="struts-default.xml"&gt;&lt;/include&gt; &lt;!-- 所有匹配*.action的请求都由struts2处理 --&gt; &lt;constant name="struts.action.extension" value="action" /&gt; &lt;!-- 是否启用开发模式 --&gt; &lt;constant name="struts.devMode" value="true" /&gt; &lt;!-- struts配置文件改动后，是否重新加载 --&gt; &lt;constant name="struts.configuration.xml.reload" value="true" /&gt; &lt;!-- 设置浏览器是否缓存静态内容 --&gt; &lt;constant name="struts.serve.static.browserCache" value="false" /&gt; &lt;!-- 请求参数的编码方式 --&gt; &lt;constant name="struts.i18n.encoding" value="utf-8" /&gt; &lt;!-- 每次HTTP请求系统都重新加载资源文件，有助于开发 --&gt; &lt;constant name="struts.i18n.reload" value="true" /&gt; &lt;!-- 文件上传最大值 --&gt; &lt;constant name="struts.multipart.maxSize" value="104857600" /&gt; &lt;!-- 让struts2支持动态方法调用 --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="true" /&gt; &lt;!-- Action名称中是否还是用斜线 --&gt; &lt;constant name="struts.enable.SlashesInActionNames" value="false" /&gt; &lt;!-- 允许标签中使用表达式语法 --&gt; &lt;constant name="struts.tag.altSyntax" value="true" /&gt; &lt;!-- 对于WebLogic,Orion,OC4J此属性应该设置成true --&gt; &lt;constant name="struts.dispatcher.parametersWorkaround" value="false" /&gt; &lt;package name="basePackage" extends="struts-default"&gt; &lt;interceptors&gt; &lt;!-- 定义拦截器 name:拦截器名称 class:拦截器类路径 --&gt; &lt;interceptor name="timer" class="com.kay.timer"&gt;&lt;/interceptor&gt; &lt;interceptor name="logger" class="com.kay.logger"&gt;&lt;/interceptor&gt; &lt;!-- 定义拦截器栈 --&gt; &lt;interceptor-stack name="mystack"&gt; &lt;interceptor-ref name="timer"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="logger"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;!-- 定义默认的拦截器 每个Action都会自动引用 如果Action中引用了其它的拦截器 默认的拦截器将无效 --&gt; &lt;default-interceptor-ref name="mystack"&gt;&lt;/default-interceptor-ref&gt; &lt;!-- 全局results配置 --&gt; &lt;global-results&gt; &lt;result name="input"&gt;/error.jsp&lt;/result&gt; &lt;/global-results&gt; &lt;action name="" class=""&gt; &lt;!-- 引用拦截器 name:拦截器名称或拦截器栈名称 --&gt; &lt;interceptor-ref name="timer"&gt;&lt;/interceptor-ref&gt; &lt;!-- 节点配置 name : result名称 和Action中返回的值相同 type : result类型 不写则选用superpackage的type struts-default.xml中的默认为dispatcher --&gt; &lt;result name="success" type="dispatcher"&gt;/talk.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 允许一个Action内包含多个请求处理方法：动态方法调用是指：表单元素的action不直接等于某个Action的名字，而是以感叹号后加方法名来指定对应的动作名：要使用动态方法调用，必须设置Struts2允许动态方法调用，通过设置struts.enable.DynamicMethodInvocation常量来完成，该常量属性的默认值是true。1234567&lt;struts&gt; &lt;!-- //禁用动态方法调用，默认为true启用，false禁用 constant:name="struts.enable.DynamicMethodInvocation" --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="true" /&gt;&lt;/struts&gt; 默认Action： 在浏览器输入一个不存在的Action，页面将呈现404错误，为了网站更友好，我们可以设置一个默认的Action。1234&lt;default-action-ref name="defaultAction"&gt;&lt;/default-action-ref&gt; &lt;action name="defaultAction"&gt; &lt;result&gt;/error.jsp&lt;/result&gt; &lt;/action&gt; 处理结果类型： Struts2提供了对不同种类返回结果的支持，常见的有JSP，FreeMarker，Velocity等。 Struts2支持的不同类型的返回结果为：(加粗为常用) 名字 说明 chain 用来处理Action链 dispatcher 用来转向页面，通常处理JSP，这是默认的结果类型 freeMarker 处理FreeMarker模板 httpHeader 用来控制特殊的Http行为 redirect 重定向到一个URL redirect-action 重定向到一个Action stream 向浏览器发送InputSream对象，通常用来处理文件下载 velocity 处理Velocity模板 xslt 处理XML/XLST模板 plaintext 显示原始文件内容，例如文件源代码 tiles 结合Tile使用strutsUI页面标签库的引用需在jsp页面加入以下内容（详细介绍链接）1&lt;%@ taglib prefix="s" uri="/struts-tags"%&gt; Hibernate Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。——百度百科 Hibernate的API一共有6个，分别为:Session、SessionFactory、Transaction、Query、Criteria和Configuration。通过这些接口，可以对持久化对象进行存取、事务控制。 SessionSession接口负责执行被持久化对象的CRUD操作(CRUD的任务是完成与数据库的交流，包含了很多常见的SQL语句)。但需要注意的是Session对象是非线程安全的。同时，Hibernate的session不同于JSP应用中的HttpSession。这里当使用session这个术语时，其实指的是Hibernate中的session，而以后会将HttpSession对象称为用户session。 SessionFactorySessionFactory接口负责初始化Hibernate。它充当数据存储源的代理，并负责创建Session对象。这里用到了工厂模式。需要注意的是SessionFactory并不是轻量级的，因为一般情况下，一个项目通常只需要一个SessionFactory就够，当需要操作多个数据库时，可以为每个数据库指定一个SessionFactory。 TransactionTransaction 接口是一个可选的API，可以选择不使用这个接口，取而代之的是Hibernate 的设计者自己写的底层事务处理代码。 Transaction 接口是对实际事务实现的一个抽象，这些实现包括JDBC的事务、JTA 中的UserTransaction、甚至可以是CORBA 事务。之所以这样设计是能让开发者能够使用一个统一事务的操作界面，使得自己的项目可以在不同的环境和容器之间方便地移植。 QueryQuery接口让你方便地对数据库及持久对象进行查询，它可以有两种表达方式：HQL语言或本地数据库的SQL语句。Query经常被用来绑定查询参数、限制查询记录数量，并最终执行查询操作。 CriteriaCriteria接口与Query接口非常类似，允许创建并执行面向对象的标准化查询。值得注意的是Criteria接口也是轻量级的，它不能在Session之外使用。 ConfigurationConfiguration 类的作用是对Hibernate 进行配置，以及对它进行启动。在Hibernate 的启动过程中，Configuration 类的实例首先定位映射文档的位置，读取这些配置，然后创建一个SessionFactory对象。虽然Configuration 类在整个Hibernate 项目中只扮演着一个很小的角色，但它是启动hibernate 时所遇到的第一个对象。 Hibernate.xml配置 Hibernate.show_sql：是否在运行时候sql语句输出到控制台，编码阶段便于测试的。（默认设置为true） Hibernate.format_sql：输出在控制台sql语句是否进行排版，便于阅读。（默认设置为true） Hbm2ddl.auto：可帮助由Java代码生成数据库脚本，进而生成具体表结构。如：create/update/create-drop/validate。 hbm2ddl.auto: 生成表结构的策略配置update(最常用的取值): 如果当前数据库中不存在表结构,那么自动创建表结构.如果存在表结构,并且表结构与实体一致,那么不做修改如果存在表结构,并且表结构与实体不一致,那么会修改表结构.会保留原有列.create(很少):无论是否存在表结构.每次启动Hibernate都会重新创建表结构.(数据会丢失)create-drop(极少): 无论是否存在表结构.每次启动Hibernate都会重新创建表结构.每次Hibernate运行结束时,删除表结构.validate(很少):不会自动创建表结构.也不会自动维护表结构.Hibernate只校验表结构. 如果表结构不一致将会抛出异常.12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC"-//Hibernate/Hibernate Configuration DTD 3.0//EN""http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- property 元素用于配置Hibernate中的属性键:值 --&gt; &lt;!-- hibernate.connection.driver_class : 连接数据库的驱动 --&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!-- hibernate.connection.username : 连接数据库的用户名 --&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;!-- hibernate.connection.password : 连接数据库的密码 --&gt; &lt;property name="hibernate.connection.password"&gt;123&lt;/property&gt; &lt;!-- hibernate.connection.url : 连接数据库的地址,路径 --&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hibernatedemｏ&lt;/property&gt; &lt;!-- show_sql: 操作数据库时,会 向控制台打印sql语句 --&gt; &lt;property name="show_sql"&gt;true&lt;/property&gt; &lt;!-- format_sql: 打印sql语句前,会将sql语句先格式化 --&gt; &lt;property name="format_sql"&gt;true&lt;/property&gt; &lt;property name="hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 数据库方言配置org.hibernate.dialect.MySQLDialect (选择最短的)--&gt; &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- hibernate.connection.autocommit: 事务自动提交 --&gt; &lt;property name="hibernate.connection.autocommit"&gt;true&lt;/property&gt; &lt;!-- 将Session与线程绑定=&gt; 只有配置了该配置,才能使用getCurrentSession --&gt; &lt;property name="hibernate.current_session_context_class"&gt;thread&lt;/property&gt; &lt;!-- 引入ORM 映射文件 填写src之后的路径--&gt; &lt;mapping resource="com/itheima/a_hello/User.hbm.xml"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; XXXX.hbm.xml(ecplise可自动生成)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0"?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt; &lt;!-- &lt;hibernate-mapping&gt;一般不去配置，采用默认即可。 default-cascade="none"：默认的级联风格，表与表联动。 default-lazy="true"：默认延迟加载 --&gt; &lt;hibernate-mapping&gt; &lt;!-- &lt;class&gt;：使用class元素定义一个持久化类。 name="cn.javass.user.vo.UserModel"：持久化类的java全限定名； table="tbl_user"：对应数据库表名； mutable="true"：默认为true，设置为false时则不可以被应用程序更新或删除； dynamic-insert="false"：默认为false，动态修改那些有改变过的字段，而不用修改所有字段； dynamic-update="false"：默认为false，动态插入非空值字段； select-before-update="false"：默认为false，在修改之前先做一次查询，与用户的值进行对比，有变化都会真正更新； optimistic-lock="version"：默认为version(检查version/timestamp字段)，取值：all(检查全部字段)、dirty(只检查修改过的字段)、 none(不使用乐观锁定)，此参数主要用来处理并发，每条值都有固定且唯一的版本，版本为最新时才能执行操作； --&gt; &lt;class name="cn.javass.user.vo.UserModel" table="tbl_user" dynamic-insert="true" dynamic-update="true" optimistic-lock="version"&gt; &lt;!-- &lt;id&gt;：定义了该属性到数据库表主键字段的映射。 name="userId"：标识属性的名字； column="userId"：表主键字段的名字，如果不填写与name一样； --&gt; &lt;id name="userId"&gt; &lt;!-- &lt;generator&gt;：指定主键由什么生成，推荐使用uuid（随机生成唯一通用的表示符，实体类的ID必须是String）， native（让数据库自动选择用什么生成（根据底层数据库的能力选择identity，sequence或hilo中的一种））， assigned（指用户手工填入，默认）。 --&gt; &lt;generator class="uuid"/&gt; &lt;/id&gt; &lt;!-- &lt;version/&gt;：使用版本控制来处理并发，要开启optimistic-lock="version"和dynamic-update="true"。 name="version"：持久化类的属性名，column="version"：指定持有版本号的字段名； --&gt; &lt;version name="version" column="version"/&gt; &lt;!-- &lt;property&gt;：为类定义一个持久化的javaBean风格的属性。 name="name"：标识属性的名字，以小写字母开头； column="name"：表主键字段的名字，如果不填写与name一样； update="true"/insert="true"：默认为true，表示可以被更新或插入； --&gt; &lt;property name="name" column="name" /&gt; &lt;property name="sex" column="sex"/&gt; &lt;property name="age" column="age"/&gt; &lt;!-- 组件映射：把多个属性打包在一起当一个属性使用，用来把类的粒度变小。 &lt;component name="属性，这里指对象"&gt; &lt;property name="name1"&gt;&lt;/property&gt; &lt;property name="name2"&gt;&lt;/property&gt; &lt;/component&gt; --&gt; &lt;!-- &lt;join&gt;:一个对象映射多个表，该元素必须放在所有&lt;property&gt;之后。 &lt;join table="tbl_test：子表名"&gt; &lt;key column="uuid：子表主键"&gt;&lt;/key&gt; &lt;property name="name1：对象属性" column="name：子表字段"&gt;&lt;/property&gt; &lt;/join&gt; --&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; 实例 post.hbm.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping&gt; &lt;class name="com.form.Post" table="post"&gt; &lt;id name="id" type="java.lang.Integer"&gt; &lt;column name="id"/&gt; &lt;generator class="identity"/&gt; &lt;/id&gt; &lt;many-to-one name="admin" class="com.form.Admin" fetch="select" lazy="false"&gt; &lt;column name="aid"/&gt; &lt;/many-to-one&gt; &lt;many-to-one name="user" class="com.form.User" fetch="select" lazy="false"&gt; &lt;column name="uid"/&gt; &lt;/many-to-one&gt; &lt;many-to-one name="board" class="com.form.Board" fetch="select" lazy="false"&gt; &lt;column name="bid"/&gt; &lt;/many-to-one&gt; &lt;property name="name" type="string"&gt; &lt;column name="name"/&gt; &lt;/property&gt; &lt;property name="content" type="string"&gt; &lt;column name="content"/&gt; &lt;/property&gt; &lt;property name="publishTime" type="timestamp"&gt; &lt;column name="publishTime"/&gt; &lt;/property&gt; &lt;property name="count" type="java.lang.Integer"&gt; &lt;column name="count"/&gt; &lt;/property&gt; &lt;property name="photoPath" type="string"&gt; &lt;column name="photoPath"/&gt; &lt;/property&gt; &lt;set name="replies" inverse="true" cascade="all-delete-orphan" lazy="false" order-by="publishTime desc"&gt; &lt;key&gt; &lt;column name="pid" not-null="true"/&gt; &lt;/key&gt; &lt;one-to-many class="com.form.Reply"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;``` ### 说说为什么使用lazy```xml&lt;set name="replies" inverse="true" cascade="all-delete-orphan" lazy="true"&gt; 当使用Hibernate中的one-to-many、many-to one、many-to-many关系映射的时候，一个对象中会包含一个或多个Set来关联其他的对象。例如：user-groups，当程序取user 对象时，如果一个用户有多个自定义组，那么程序将把组的信息也读取出来，在log中可以看到两个sql的输出。但是在页面的显示上，也许并不需要显示这个用户相关组的信息，这样系统的消耗就白白浪费了，于是hibernate提供了lazy（延迟加载）的方法来避免这一情况的发生，我们只需要在 user.hbm.xml中设置lazy=true，就能实现延迟加载。 Spring 是一个非常强大的反转控制(IOC)框架，以帮助分离项目组件之间的依赖关系 控制反转——Spring通过一种称作控制反转（IoC）的技术促进了低耦合。当应用了IoC，一个对象依赖的其它对象会通过被动的方式传递进来，而不是这个对象自己创建或者查找依赖对象。你可以认为IoC与JNDI相反——不是对象从容器中查找依赖，而是容器在对象初始化时不等对象请求就主动将依赖传递给它。 面向切面——Spring提供了面向切面编程的丰富支持，允许通过分离应用的业务逻辑与系统级服务（例如审计（auditing）和事务（transaction）管理）进行内聚性的开发。应用对象只实现它们应该做的——完成业务逻辑——仅此而已。它们并不负责（甚至是意识）其它的系统级关注点，例如日志或事务支持。 容器——Spring包含并管理应用对象的配置和生命周期，在这个意义上它是一种容器，你可以配置你的每个bean如何被创建——基于一个可配置原型（prototype），你的bean可以创建一个单独的实例或者每次需要时都生成一个新的实例——以及它们是如何相互关联的。 web.xml配置123456789101112131415161718192021&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;filter&gt;&lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.orm.hibernate4.support.OpenSessionInViewFilter&lt;/filter-class&gt;&lt;init-param&gt; &lt;param-name&gt;org.springframework.orm.hibernate4.LocalSessionFactoryBean&lt;/param-name&gt; &lt;param-value&gt;sessionFactory&lt;/param-value&gt;&lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt;&lt;/filter-mapping&gt; 说说为什么使用OpenSessionInView1&lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt; 当hibernate+spring配合使用的时候，如果设置了lazy=true,那么在读取数据的时候，当读取了父数据后，hibernate会自动关闭session，这样，当要使用子数据的时候，系统会抛出lazyinit的错误，这时就需要使用spring提供的 OpenSessionInViewFilter,OpenSessionInViewFilter主要是保持Session状态知道request将全部页面发送到客户端，这样就可以解决延迟加载带来的问题 applicationContext.xml配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?xml version="1.0" encoding="UTF-8"? &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd" &lt;!-- 自动扫描与装配bean，扫描web包，将带有注解的类纳入spring容器管理 --&gt; &lt;!-- &lt;context:component-scan base-package="cn.itcast.oa"&gt;作用 Spring容器初始化时，会扫描cn.itcast.oa目录下标有@Component；@Service；@Controller；@Repository 注解的类纳入Spring容器管理 在类上，使用以下注解，实现bean的声明： @Component：泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @Service 用于标注业务层组件 @Controller 用于标注控制层组件（如springMvc的controller，struts中的action） @Repository用于标注数据访问组件，即DAO组件 在类的成员变量上，使用以下注解，实现属性的自动装配 @Autowired ：按类的类型进行装配 @Resource： 1.如果同时指定了name和type，那么从Spring上下文中找到唯一匹配的bean进行装配 2. 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常 3.如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常 4.如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配； --&gt; &lt;context:component-scan base-package="cn.itcast.oa"&gt;&lt;/context:component-scan&gt; &lt;!-- 加载外部的properties配置文件（引入jdbc的配置文件） -- &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!-- 配置数据库连接池（c3p0）这个可以在hibernate.cfg.xml中配置 -- &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;!-- 基本信息 ：jdbc的url、驱动名、数据库名字、密码-- &lt;property name="jdbcUrl" value="$&#123;jdbcUrl&#125;"&gt;&lt;/property&gt; &lt;property name="driverClass" value="$&#123;driverClass&#125;"&gt;&lt;/property&gt; &lt;property name="user" value="$&#123;username&#125;"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;password&#125;"&gt;&lt;/property&gt; &lt;!-- 其他配置 -- &lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 -- &lt;property name="initialPoolSize" value="3"&gt;&lt;/property&gt; &lt;!--连接池中保留的最小连接数。Default: 3 -- &lt;property name="minPoolSize" value="3"&gt;&lt;/property&gt; &lt;!--连接池中保留的最大连接数。Default: 15 -- &lt;property name="maxPoolSize" value="5"&gt;&lt;/property&gt; &lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 -- &lt;property name="acquireIncrement" value="3"&gt;&lt;/property&gt;&lt;!-- 控制数据源内加载的PreparedStatements数量。如果maxStatements与maxStatementsPerConnection均为0，则缓存被关闭。Default: 0 -- &lt;property name="maxStatements" value="8"&gt;&lt;/property&gt;&lt;!-- maxStatementsPerConnection定义了连接池内单个连接所拥有的最大缓存statements数。Default: 0 -- &lt;property name="maxStatementsPerConnection" value="5"&gt;&lt;/property&gt; &lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 -- &lt;property name="maxIdleTime" value="1800"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置SessionFactory （把数据源注入给session工厂）、配置映射文件将Spring与hibernate初步整合起来 -- &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.LocalSessionFactoryBean" &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property &lt;property name="configLocation" value="classpath:hibernate.cfg.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置声明式的事务管理（采用基于注解的方式） session工厂注入到事务管理器transactionManager使Spring与Hinbernate整合实现业务逻辑 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.hibernate3.HibernateTransactionManager" &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; &lt;/beans&gt; 常见问题 自动装配与扫描有问题，context的命名空间的问题1&lt;context:component-scan base-package="cn.itcast.oa"&gt;&lt;/context:component-scan&gt; &lt;beans xmlns=”http://www.springframework.org/schema/beans“ xmlns:context=”http://www.springframework.org/schema/context“ ssh整合及项目实例项目实例链接:https://github.com/LFstefan/JavaEE]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Struts</tag>
        <tag>JavaWeb</tag>
        <tag>Architecture</tag>
        <tag>Spring</tag>
        <tag>Hibernate</tag>
        <tag>Frame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树]]></title>
    <url>%2F2017%2F07%2F01%2F%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树红黑树，一种自平衡二叉查找树，又称之为”对称二叉B树”，虽然复杂，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的：它可以在logn时间内做查找，插入和删除。 红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。 红黑树是2-3-4树的一种等同。换句话说，对于每个2-3-4树，都存在至少一个数据元素是同样次序的红黑树。在2-3-4树上的插入和删除操作也等同于在红黑树中颜色翻转和旋转。这使得2-3-4树成为理解红黑树背后的逻辑的重要工具，这也是很多介绍算法的教科书在红黑树之前介绍2-3-4树的原因，尽管2-3-4树在实践中不经常使用。 性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 下面是一个具体的红黑树的图例： 这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 要知道为什么这些性质确保了这个结果，注意到性质4导致了路径不能有两个毗连的红色节点就足够了。最短的可能路径都是黑色节点，最长的可能路径有交替的红色和黑色节点。因为根据性质5所有最长的路径都有相同数目的黑色节点，这就表明了没有路径能多于任何其他路径的两倍长。 在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用”nil叶子”或”空（null）叶子”，如上图所示，它不包含数据而只充当树在此结束的指示。这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再匹配红黑树的性质。恢复红黑树的性质需要少量的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为logn次。 插入 我们首先以二叉查找树的方法增加节点并标记它为红色。（如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换和树旋转来调整。）下面要进行什么操作取决于其他临近节点的颜色。同人类的家族树中一样，我们将使用术语叔父节点来指一个节点的父节点的兄弟节点。注意： 性质1和性质3总是保持着。 性质4只在增加红色节点、重绘黑色节点为红色，或做旋转时受到威胁。 性质5只在增加黑色节点、重绘红色节点为黑色，或做旋转时受到威胁。 在下面的的代码中，将要插入的节点标为N，N的父节点标为P，N的祖父节点标为G，N的叔父节点标为U。 通过下列函数，可以找到一个节点的叔父和祖父节点：123456789public node grandparent(node n)&#123; return n.parent.parent;&#125;public node uncle(node n)&#123; if(n.parent == grandparent(n).left) return grandparent (n).right; else return grandparent (n).left;&#125; 情形1:新节点N位于树的根上，没有父节点。在这种情形下，我们把它重绘为黑色以满足性质2。因为它在每个路径上对黑节点数目增加一，性质5匹配。123456public void insert_case1(node n)&#123; if(n.parent == NULL) n.color = BLACK; else insert_case2 (n);&#125; 情形2:新节点的父节点P是黑色，所以性质4没有失效（新节点是红色的）。在这种情形下，树仍是有效的。性质5也未受到威胁，尽管新节点N有两个黑色叶子子节点；但由于新节点N是红色，通过它的每个子节点的路径就都有同通过它所取代的黑色的叶子的路径同样数目的黑色节点，所以依然满足这个性质。123456public void insert_case2(node n)&#123; if(n.parent.color == BLACK) return; /* 树仍旧有效*/ else insert_case3 (n);&#125; 注意：在下列情形下我们假定新节点的父节点为红色，所以它有祖父节点；因为如果父节点是根节点，那父节点就应当是黑色。所以新节点总有一个叔父节点，尽管在情形4和5下它可能是叶子节点。 情形3:如果父节点P和叔父节点U二者都是红色，（此时新插入节点N做为P的左子节点或右子节点都属于情形3，这里右图仅显示N做为P左子的情形）则我们可以将它们两个重绘为黑色并重绘祖父节点G为红色（用来保持性质5）。现在我们的新节点N有了一个黑色的父节点P。因为通过父节点P或叔父节点U的任何路径都必定通过祖父节点G，在这些路径上的黑节点数目没有改变。但是，红色的祖父节点G可能是根节点，这就违反了性质2，也有可能祖父节点G的父节点是红色的，这就违反了性质4。为了解决这个问题，我们在祖父节点G上递归地进行情形1的整个过程。（把G当成是新加入的节点进行各种情形的检查）12345678910public void insert_case3(node n)&#123; if(uncle(n) != NULL &amp;&amp; uncle (n).color == RED) &#123; n.parent.color = BLACK; uncle (n).color = BLACK; grandparent (n).color = RED; insert_case1(grandparent(n)); &#125; else insert_case4 (n);&#125; 注意：在余下的情形下，我们假定父节点P是其父亲G的左子节点。如果它是右子节点，情形4和情形5中的左和右应当对调。 情形4:父节点P是红色而叔父节点U是黑色或缺少，并且新节点N是其父节点P的右子节点而父节点P又是其父节点的左子节点。在这种情形下，我们进行一次左旋转调换新节点和其父节点的角色;接着，我们按情形5处理以前的父节点P以解决仍然失效的性质4。注意这个改变会导致某些路径通过它们以前不通过的新节点N（比如图中1号叶子节点）或不通过节点P（比如图中3号叶子节点），但由于这两个节点都是红色的，所以性质5仍有效。12345678910public void insert_case4(node n)&#123; if(n == n.parent.right &amp;&amp; n.parent == grandparent(n).left) &#123; rotate_left(n-&gt;parent); n = n-&gt;left; &#125; else if(n == n.parent.left &amp;&amp; n.parent == grandparent(n).right) &#123; rotate_right(n.parent); n = n.right; &#125; insert_case5 (n);&#125; 情形5：父节点P是红色而叔父节点U是黑色或缺少，新节点N是其父节点的左子节点，而父节点P又是其父节点G的左子节点。在这种情形下，我们进行针对祖父节点G的一次右旋转；在旋转产生的树中，以前的父节点P现在是新节点N和以前的祖父节点G的父节点。我们知道以前的祖父节点G是黑色，否则父节点P就不可能是红色（如果P和G都是红色就违反了性质4，所以G必须是黑色）。我们切换以前的父节点P和祖父节点G的颜色，结果的树满足性质4。性质5也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过祖父节点G，现在它们都通过以前的父节点P。在各自的情形下，这都是三个节点中唯一的黑色节点。12345678910public void insert_case5(node n)&#123; n.parent.color = BLACK; grandparent (n).color = RED; if(n == n.parent.left &amp;&amp; n.parent == grandparent(n).left) &#123; rotate_right(grandparent(n)); &#125; else &#123; /* Here, n == n.parent.right &amp;&amp; n.parent == grandparent (n).right */ rotate_left(grandparent(n)); &#125;&#125; 注意插入实际上是原地算法，因为上述所有调用都使用了尾部递归。 删除 如果需要删除的节点有两个儿子，那么问题可以被转化成删除另一个只有一个儿子的节点的问题（为了表述方便，这里所指的儿子，为非叶子节点的儿子）。对于二叉查找树，在删除带有两个非叶子儿子的节点的时候，我们找到要么在它的左子树中的最大元素、要么在它的右子树中的最小元素，并把它的值转移到要删除的节点中。我们接着删除我们从中复制出值的那个节点，它必定有少于两个非叶子的儿子。因为只是复制了一个值，不违反任何性质，这就把问题简化为如何删除最多有一个儿子的节点的问题。它不关心这个节点是最初要删除的节点还是我们从中复制出值的那个节点。 在本文余下的部分中，我们只需要讨论删除只有一个儿子的节点（如果它两个儿子都为空，即均为叶子，我们任意将其中一个看作它的儿子）。如果我们删除一个红色节点（此时该节点的儿子将都为叶子节点），它的父亲和儿子一定是黑色的。所以我们可以简单的用它的黑色儿子替换它，并不会破坏性质3和性质4。通过被删除节点的所有路径只是少了一个红色节点，这样可以继续保证性质5。另一种简单情况是在被删除节点是黑色而它的儿子是红色的时候。如果只是去除这个黑色节点，用它的红色儿子顶替上来的话，会破坏性质5，但是如果我们重绘它的儿子为黑色，则曾经通过它的所有路径将通过它的黑色儿子，这样可以继续保持性质5。 需要进一步讨论的是在要删除的节点和它的儿子二者都是黑色的时候，这是一种复杂的情况。我们首先把要删除的节点替换为它的儿子。出于方便，称呼这个儿子为N（在新的位置上），称呼它的兄弟（它父亲的另一个儿子）为S。在下面的示意图中，我们还是使用P称呼N的父亲，SL称呼S的左儿子，SR称呼S的右儿子。我们将使用下述函数找到兄弟节点： 123456public node sibling(node n)&#123; if(n == n-&gt;parent-&gt;left) return n-&gt;parent-&gt;right; else return n-&gt;parent-&gt;left;&#125; 我们可以使用下列代码进行上述的概要步骤，这里的函数replace_node替换child到n在树中的位置。出于方便，在本章节中的代码将假定空叶子被用不是NULL的实际节点对象来表示（在插入章节中的代码可以同任何一种表示一起工作）。 123456789101112public void delete_one_child(struct node *n)&#123; //Precondition: n has at most one non-null child. struct node *child = is_leaf(n-&gt;right)? n-&gt;left : n-&gt;right; replace_node(n, child); if(n-&gt;color == BLACK)&#123; if(child-&gt;color == RED) child-&gt;color = BLACK; else delete_case1 (child); &#125; free (n);&#125; 如果N和它初始的父亲是黑色，则删除它的父亲导致通过N的路径都比不通过它的路径少了一个黑色节点。因为这违反了性质5，树需要被重新平衡。有几种情形需要考虑： 情形1: N是新的根。在这种情形下，我们就做完了。我们从所有路径去除了一个黑色节点，而新根是黑色的，所以性质都保持着。1234public void delete_case1(struct node *n)&#123; if(n-&gt;parent != NULL) delete_case2 (n);&#125; 注意：在情形2、5和6下，我们假定N是它父亲的左儿子。如果它是右儿子，则在这些情形下的左和右应当对调。 情形2： S是红色。在这种情形下我们在N的父亲上做左旋转，把红色兄弟转换成N的祖父，我们接着对调N的父亲和祖父的颜色。完成这两个操作后，尽管所有路径上黑色节点的数目没有改变，但现在N有了一个黑色的兄弟和一个红色的父亲（它的新兄弟是黑色因为它是红色S的一个儿子），所以我们可以接下去按情形4、情形5或情形6来处理。 注意：N是删除了黑色节点后替换上来的子节点，所以这个过程中由P-&gt;X-&gt;N变成了P-&gt;N，实际上是少了一个黑色节点，也可以理解为Parent(Black)和Silbing(Red)那么他们的孩子黑色节点的数目肯定不等，让他们做新兄弟肯定是不平衡的，还需后面继续处理。 123456789101112public void delete_case2(struct node *n)&#123; struct node *s = sibling (n); if(s-&gt;color == RED)&#123; n-&gt;parent-&gt;color = RED; s-&gt;color = BLACK; if(n == n-&gt;parent-&gt;left) rotate_left(n-&gt;parent); else rotate_right(n-&gt;parent); &#125; delete_case3 (n);&#125; 情形3： N的父亲、S和S的儿子都是黑色的。在这种情形下，我们简单的重绘S为红色。结果是通过S的所有路径，它们就是以前不通过N的那些路径，都少了一个黑色节点。因为删除N的初始的父亲使通过N的所有路径少了一个黑色节点，这使事情都平衡了起来。但是，通过P的所有路径现在比不通过P的路径少了一个黑色节点，所以仍然违反性质5。要修正这个问题，我们要从情形1开始，在P上做重新平衡处理。123456789public void delete_case3(struct node *n)&#123; struct node *s = sibling (n); if((n-&gt;parent-&gt;color == BLACK)&amp;&amp;(s-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == BLACK)) &#123; s-&gt;color = RED; delete_case1(n-&gt;parent); &#125; else delete_case4 (n);&#125; 情形4： S和S的儿子都是黑色，但是N的父亲是红色。在这种情形下，我们简单的交换N的兄弟和父亲的颜色。这不影响不通过N的路径的黑色节点的数目，但是它在通过N的路径上对黑色节点数目增加了一，添补了在这些路径上删除的黑色节点。123456789public void delete_case4(struct node *n)&#123; struct node *s = sibling (n); if（(n-&gt;parent-&gt;color == RED)&amp;&amp;(s-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == BLACK)) &#123; s-&gt;color = RED; n-&gt;parent-&gt;color = BLACK; &#125; else delete_case5 (n);&#125; 情形5： S是黑色，S的左儿子是红色，S的右儿子是黑色，而N是它父亲的左儿子。在这种情形下我们在S上做右旋转，这样S的左儿子成为S的父亲和N的新兄弟。我们接着交换S和它的新父亲的颜色。所有路径仍有同样数目的黑色节点，但是现在N有了一个黑色兄弟，他的右儿子是红色的，所以我们进入了情形6。N和它的父亲都不受这个变换的影响。123456789101112131415public void delete_case5(struct node *n)&#123; struct node *s = sibling (n); if（s-&gt;color == BLACK)&#123; if((n == n-&gt;parent-&gt;left)&amp;&amp;(s-&gt;right-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == RED)) &#123; // this last test is trivial too due to cases 2-4. s-&gt;color = RED; s-&gt;left-&gt;color = BLACK; rotate_right (s); &#125; else if((n == n-&gt;parent-&gt;right)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == RED)) &#123;// this last test is trivial too due to cases 2-4. s-&gt;color = RED; s-&gt;right-&gt;color = BLACK; rotate_left (s); &#125; &#125; delete_case6 (n);&#125; 情形6： S是黑色，S的右儿子是红色，而N是它父亲的左儿子。在这种情形下我们在N的父亲上做左旋转，这样S成为N的父亲（P）和S的右儿子的父亲。我们接着交换N的父亲和S的颜色，并使S的右儿子为黑色。子树在它的根上的仍是同样的颜色，所以性质3没有被违反。但是，N现在增加了一个黑色祖先：要么N的父亲变成黑色，要么它是黑色而S被增加为一个黑色祖父。所以，通过N的路径都增加了一个黑色节点。此时，如果一个路径不通过N，则有两种可能性： 它通过N的新兄弟。那么它以前和现在都必定通过S和N的父亲，而它们只是交换了颜色。所以路径保持了同样数目的黑色节点。 它通过N的新叔父，S的右儿子。那么它以前通过S、S的父亲和S的右儿子，但是现在只通过S，它被假定为它以前的父亲的颜色，和S的右儿子，它被从红色改变为黑色。合成效果是这个路径通过了同样数目的黑色节点。 在任何情况下，在这些路径上的黑色节点数目都没有改变。所以我们恢复了性质4。在示意图中的白色节点可以是红色或黑色，但是在变换前后都必须指定相同的颜色。 123456789101112public void delete_case6(node n)&#123; node s = sibling (n); s.color = n.parent.color; n.parent.color = BLACK; if(n == n.parent.left)&#123; s.right.color = BLACK; rotate_left(n.parent); &#125; else &#123; s.left.color = BLACK; rotate_right(n.parent); &#125;&#125; 同样的，函数调用都使用了尾部递归，所以算法是原地算法。此外，在旋转之后不再做递归调用，所以进行了恒定数目（最多3次）的旋转。]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2-3树]]></title>
    <url>%2F2017%2F06%2F24%2F2-3%E6%A0%91%2F</url>
    <content type="text"><![CDATA[2-3查找树 2–3树是一种树型数据结构，内部节点（存在子节点的节点）要么有2个孩子和1个数据元素，要么有3个孩子和2个数据元素，叶子节点没有孩子，并且有1个或2个数据元素。2–3树是平衡树，意味着右边，左边，中间的子树的元素数量都是相同或接近的。 如果一个内部节点拥有一个数据元素、两个子节点，则此节点为2节点。 如果一个内部节点拥有两个数据元素、三个子节点，则此节点为3节点。 当且仅当以下叙述中有一条成立时，T为2–3树： T为空。即T不包含任何节点。 T为拥有数据元素a的2节点。若T的左孩子为L、右孩子为R，则L和R是等高的非空2–3树； a大于L中的所有数据元素；同时a小于等于R中的所有数据元素。 T为拥有数据元素a和b的3节点，其中a &lt; b。若T的左孩子为L、中孩子为M、右孩子为R，则L、M、和R是等高的非空2–3树； a大于L中的所有数据元素，并且小于等于M中的所有数据元素；同时b大于M中的所有数据元素，并且小于等于R中的所有数据元素。 上面介绍了什么是2-3树，接下来我们看看2-3树有什么用，或者说是为什们会出现这种结构，下面我们先来考虑一个问题： 我们知道二叉搜索树的查找和搜索在平均情况下时间复杂度都能达到O(logn)，而且能保证数据有序。二叉搜索树的中序遍历就是数据的顺序。但是这个效率只是在平均情况下。如果数据是逆序，或者顺序，那么这棵树就会发生一边倒的情况使复杂度直接达到O(n)，就如同快排中选择到糟糕的主元(最大或者最小)。 通过上面的问题我们可以看出2-3树用来弥补二叉查找树在极端条件下的不足，因为2-3树是平衡树，所以不管数据怎么样，查找删除操作时间复杂度都至少能达到O(logn)，比起二叉查找树来有过之而无不及！2-3查找树的性质： 如果中序遍历2-3查找树，就可以得到排好序的序列； 在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。 复杂度分析： 在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为log2(N) 在最好的情况下，所有的节点都是3-node节点，查找效率为log3(N) 距离来说，对于1百万个节点的2-3树，树的高度为12-20之间，对于10亿个节点的2-3树，树的高度为18-30之间。 对于插入来说，只需要常数次操作即可完成，因为他只需要修改与该节点关联的节点即可，不需要检查其他节点，所以效率和查找类似。 但是2-3树实现比较复杂，需要掌控的情况很多，剥离节点，传递节点等操作，都需要很复杂的代码，且也会耗费不少的时间。所以我们一般不怎么用原始的2-3树，而是用2-3树的变形红黑树.]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B树和B+树]]></title>
    <url>%2F2017%2F06%2F17%2FB%E6%A0%91%E5%92%8CB%2B%E6%A0%91%2F</url>
    <content type="text"><![CDATA[平衡查找树中的2-3树以及其实现红黑树。2-3树种，一个节点最多有2个key，而红黑树则使用染色的方式来标识这两个key。 维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。 B树定义： B树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。 根节点至少有两个子节点 每个节点有M-1个key，并且以升序排列 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间 其它节点至少有M/2个子节点 可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入 B+树定义： B+树是对B树的一种变形树，它与B树的差异在于： 有k个子结点的结点必然有k个关键码；非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。 B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。 B+ 树的优点在于： 由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。 但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。 B/B+树常用于文件系统和数据库系统中，它通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。它广泛用于文件系统及数据库中，如： Windows：HPFS文件系统；Mac：HFS，HFS+文件系统；Linux：ResiserFS，XFS，Ext3FS，JFS文件系统；数据库：ORACLE，MYSQL，SQLSERVER等中。 有关B/B+树在数据库索引中的应用，请看张洋的MySQL索引背后的数据结构及算法原理这篇文章，这篇文章对MySQL中的如何使用B+树进行索引有比较详细的介绍，推荐阅读。 树表查找总结： 二叉查找树平均查找性能不错，为O(logn)，但是最坏情况会退化为O(n)。在二叉查找树的基础上进行优化，我们可以使用平衡查找树。平衡查找树中的2-3查找树，这种数据结构在插入之后能够进行自平衡操作，从而保证了树的高度在一定的范围内进而能够保证最坏情况下的时间复杂度。但是2-3查找树实现起来比较困难，红黑树是2-3树的一种简单高效的实现，他巧妙地使用颜色标记来替代2-3树中比较难处理的3-node节点问题。红黑树是一种比较高效的平衡查找树，应用非常广泛，很多编程语言的内部实现都或多或少的采用了红黑树。 除此之外，2-3查找树的另一个扩展——B/B+平衡树，在文件系统和数据库系统中有着广泛的应用。]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[约瑟夫环]]></title>
    <url>%2F2017%2F06%2F10%2F%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[约瑟夫环问题问题描述 ：这个问题是以弗拉维奥·约瑟夫命名的，它是1世纪的一名犹太历史学家。他在自己的日记中写道，他和他的n个战友被罗马军队包围在洞中。他们讨论是自杀还是被俘，最终决定自杀，他们围成一个圈，从第1个人开始报数，报到m的人自杀，下一个人重新开始报数，如此循环，直到所有人全都自杀为止。约瑟夫斯和另外一个人是最后两个留下的人。约瑟夫斯说服了那个人，他们将向罗马军队投降，不再自杀。约瑟夫斯把他的存活归因于运气或天意，他不知道是哪一个。 我们首先模拟整个过程将自杀顺序打印粗来，n个人用1~N来标号表示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public int showJoseph(int total, int cycle) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = 0; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; //过滤掉已经自杀的人 while (!arr[index]) &#123; index = (index + 1) % total; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = (index+1); index = (index+1) % total; &#125; &#125; return result; &#125; //限定起点位置public int showJoseph(int total, int cycle, int start) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = start - 1; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; while (!arr[index]) &#123; index = (index + 1) % total; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = index+1; index = (index+1) % total; &#125; &#125; return result; &#125; //限定起点位置递归版public int showJoseph(int total, int cycle, int start) &#123; int result = (showJoseph(total, cycle) + (start-1) -1) % total + 1; return result; &#125; //限定起点+限定循环方向private static int showJoseph(int total, int cycle, int start, boolean forward) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = start - 1; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; while (!arr[index]) &#123; if (forward) &#123; //正向走 index = (++index + total) % total; &#125; else &#123; //反向走 index = (--index + total) % total; &#125; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = index+1; if (forward) &#123; index = (++index + total) % total; &#125; else &#123; index = (--index + total) % total; &#125; &#125; &#125; return result; &#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最大公约数和最小公倍数]]></title>
    <url>%2F2017%2F06%2F03%2F%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%92%8C%E6%9C%80%E5%B0%8F%E5%85%AC%E5%80%8D%E6%95%B0%2F</url>
    <content type="text"><![CDATA[最大公约数和最小公倍数最大公约数123456789//欧几里德算法public long gcd(long m, long n) &#123; while(n!=0)&#123; long rem = m%n; m = n; n = rem; &#125; return m;&#125; 由于除法代价太大，所以接下来我们用减法来代替除法实现该算法，首先我们需要知道gcd(a,b)=gcd(b,a-b)，即数字A和数字B的最大公因数和数字B和数字(A-B)的最大公因数是相同的，所以我们可以得出以下的算法1234567public long gcd(long m, long n) &#123; if(m==n) return m; else&#123; return m-n&gt;0 ? gcd(n,m-n) : gcd(m,n-m); &#125;&#125; 然而存在一个问题就是减法会导致迭代次数较多，所以我们接下来想办法降低迭代次数，我们知道一个奇数和一个偶数的最大公约数其实等于这个奇数和这个(偶数/2)的最大公约数，所以程序进一步改进为：12345678910111213141516public long gcd(long m, long n) &#123; if(m==n) return m; //m,n均为奇数 else if(m&amp;1==1&amp;&amp;n&amp;1==1) return m-n&gt;0 ? gcd(n,m-n) : gcd(m,n-m); //m为偶数，n为奇数 else if(m&amp;1==0&amp;&amp;n&amp;1==1) return gcd(m&gt;&gt;1,n); //n为偶数，m为奇数 else if(m&amp;1==1&amp;&amp;n&amp;1==0) return gcd(m,n&gt;&gt;1); //m,n均为为偶数 else return 2*gcd(m&gt;&gt;1,n&gt;&gt;1);&#125; 最小公倍数123public long zxgbs(long m, long n) &#123; return m*n/gcd(m,n);&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql_DATE_FORMAT_分组查询]]></title>
    <url>%2F2017%2F05%2F27%2FMySql_DATE_FORMAT_%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[MySql_DATEFORMAT分组查询12345678&lt;!-- 按日查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%m-%d') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按月查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%m') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按年查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按周查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%u') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time DATE_FORMAT(date,format) :根据format字符串格式化date值。下列修饰符可以被用在format字符串中： %M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) …]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySql</tag>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[堆排序 堆是具有下列性质的完全二叉树:每个节点的值都大于或等于其左右孩子节点的值,称为大顶堆；或者每个节点的值都小于或等于其左右孩子节点的值,称为小顶堆。 堆排序就是利用堆进行排序的方法.基本思想是:将待排序的序列构造成一个大顶堆.此时,整个序列的最大值就是堆顶的根结点.将它移走(其实就是将其与堆数组的末尾元素交换, 此时末尾元素就是最大值),然后将剩余的n-1个序列重新构造成一个堆,这样就会得到n个元素的次大值.如此反复执行,便能得到一个有序序列了。 时间复杂度为 O(nlogn)！ 如何由一个无序序列键成一个堆？ 可以直接使用线性数组来表示一个堆，由初始的无序序列建成一个堆就需要自底向上从第一个非叶元素开始挨个调整成一个堆。 如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？ 怎么调整成堆？首先是将堆顶元素和最后一个元素交换。然后比较当前堆顶元素的左右孩子节点，因为除了当前的堆顶元素，左右孩子堆均满足条件，这时需要选择当前堆顶元素与左右孩子节点的较大者（大顶堆）交换，直至叶子节点。我们称这个自堆顶自叶子的调整成为筛选。 每次堆调整找出一个最大值/最小值，N次调整完成全部排序 使用数组构建大/小顶堆时，按照堆的层级排序从上到下，从左到右依次存入数组中，因此当各个节点的下标为i时，其左右孩子的节点下标分别为2i+1,2i+2 123456789101112131415161718192021222324252627282930313233public void heapAdjust(int[] arr, int start, int end) &#123; int temp = arr[start]; for(int i=2*start+1; i&lt;=end; i*=2) &#123; //左右孩子的节点分别为2*i+1,2*i+2 //选择出左右孩子较小的下标 if(i &lt; end &amp;&amp; arr[i] &lt; arr[i+1]) &#123; i ++; &#125; if(temp &gt;= arr[i]) &#123; break; //已经为大顶堆，=保持稳定性。 &#125; arr[start] = arr[i]; //将子节点上移 start = i; //下一轮筛选 &#125; arr[start] = temp; //插入正确的位置&#125;public void heapSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; //建立大顶堆，从第一个非叶子结点从下至上，从右至左调整结构 for(int i=arr.length/2; i&gt;=0; i--) &#123; heapAdjust(arr, i, arr.length-1); &#125; for(int i=arr.length-1; i&gt;=0; i--) &#123; swap(arr, 0, i); heapAdjust(arr, 0, i-1); &#125;&#125;public void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[归并排序归并排序使用了递归分治的思想，其基本思想是，先递归划分子问题，然后合并结果。把待排序列看成由两个有序的子序列，然后合并两个子序列，然后把子序列看成由两个有序序列。。。。。倒着来看，其实就是先两两合并，然后四四合并。。。最终形成有序序列。空间复杂度为O(n)，时间复杂度为O(nlogn)。 1234567891011121314151617181920212223242526272829303132public static void mergeSort(int[] arr, int left, int right) &#123; if(left &gt;= right) return ; int mid = (left&gt;&gt;1) + (right&gt;&gt;1); mergeSort(arr, left, mid); //递归排序左边 mergeSort(arr, mid+1, right); //递归排序右边 merge(arr, left, mid, right); //合并&#125;//合并两个有序数组public static void merge(int[] arr, int left, int mid, int right) &#123; //左数组[left, mid] 右数组[mid+1, right] int[] temp = new int[right - left + 1]; //中间数组 int i = left; int j = mid + 1; int k = 0; while(i &lt;= mid &amp;&amp; j &lt;= right) &#123; if(arr[i] &lt;= arr[j]) temp[k++] = arr[i++]; else temp[k++] = arr[j++]; &#125; while(i &lt;= mid) &#123; temp[k++] = arr[i++]; &#125; while(j &lt;= right) &#123; temp[k++] = arr[j++]; &#125; for(int p=0; p&lt;temp.length; p++) &#123; arr[left + p] = temp[p]; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组打印]]></title>
    <url>%2F2017%2F05%2F27%2F%E6%95%B0%E7%BB%84%E6%89%93%E5%8D%B0%2F</url>
    <content type="text"><![CDATA[数组打印 一维数组12345int [] num = &#123;1,2,3,4,5&#125;;System.out.println(num.toString());//输出：[I@15db9742...System.out.println(Arrays.toString(num));//输出：[1, 2, 3, 4, 5] 二维数组123456789101112int [][] nums = &#123;&#123;1,2&#125;,&#123;3,4,5&#125;,&#123;6,7&#125;&#125;;System.out.println(Arrays.toString(nums));//输出：[[I@6d06d69c, [I@7852e922, [I@4e25154f]...System.out.println(Arrays.deepToString(nums));//输出：[[1, 2], [3, 4, 5], [6, 7]]//补充int [][] a = new int[][]&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;,&#123;7,8,9&#125;&#125;;int [][] b = new int[][]&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;,&#123;7,8,9&#125;&#125;;System.out.println(Arrays.equals(a, b));//输出：FALSESystem.out.println(Arrays.deepEquals(a, b));//输出：TRUE 附上：工具类Arrays部分源码解读123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146public class Arrays &#123; private static final int MIN_ARRAY_SORT_GRAN = 1 &lt;&lt; 13; //排序底层采用快排实现 public static void sort(int[] a) &#123; DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0); &#125; //二分查找 public static int binarySearch(long[] a, long key) &#123; return binarySearch0(a, 0, a.length, key); &#125; //一维数组简单判定相等 public static boolean equals(long[] a, long[] a2) &#123; if (a==a2) return true; if (a==null || a2==null) return false; int length = a.length; if (a2.length != length) return false; for (int i=0; i&lt;length; i++) if (a[i] != a2[i]) return false; return true; &#125; //多维数组或复杂对象深度判定相等 public static boolean deepEquals(Object[] a1, Object[] a2) &#123; if (a1 == a2) return true; if (a1 == null || a2==null) return false; int length = a1.length; if (a2.length != length) return false; for (int i = 0; i &lt; length; i++) &#123; Object e1 = a1[i]; Object e2 = a2[i]; if (e1 == e2) continue; if (e1 == null) return false; // Figure out whether the two elements are equal boolean eq = deepEquals0(e1, e2); if (!eq) return false; &#125; return true; &#125; //数组填充，只能以同一个值填充数组 public static void fill(long[] a, long val) &#123; for (int i = 0, len = a.length; i &lt; len; i++) a[i] = val; &#125; //Arrays.asList()返回的是ArrayList类型，其底层构成仍然是数组 public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a); &#125; private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;implements RandomAccess, java.io.Serializable&#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; ... &#125; //一维数组打印 public static String toString(int[] a) &#123; if (a == null) return "null"; int iMax = a.length - 1; if (iMax == -1) return "[]"; StringBuilder b = new StringBuilder(); b.append('['); for (int i = 0; ; i++) &#123; b.append(a[i]); if (i == iMax) return b.append(']').toString(); b.append(", "); &#125; &#125; //多维数组或对象数组打印 public static String deepToString(Object[] a) &#123; if (a == null) return "null"; int bufLen = 20 * a.length; if (a.length != 0 &amp;&amp; bufLen &lt;= 0) bufLen = Integer.MAX_VALUE; StringBuilder buf = new StringBuilder(bufLen); deepToString(a, buf, new HashSet&lt;Object[]&gt;()); return buf.toString(); &#125; private static void deepToString(Object[] a, StringBuilder buf,Set&lt;Object[]&gt; dejaVu) &#123; if (a == null) &#123; buf.append("null"); return; &#125; int iMax = a.length - 1; if (iMax == -1) &#123; buf.append("[]"); return; &#125; dejaVu.add(a); buf.append('['); for (int i = 0; ; i++) &#123; Object element = a[i]; if (element == null) &#123; buf.append("null"); &#125; else &#123; //获取子元素类型 Class&lt;?&gt; eClass = element.getClass(); //如果子元素类型是数组类型，进而判定是哪一种数组类型 if (eClass.isArray()) &#123; if (eClass == byte[].class) buf.append(toString((byte[]) element)); else if (eClass == short[].class) buf.append(toString((short[]) element)); else if (eClass == int[].class) buf.append(toString((int[]) element)); else if (eClass == long[].class) buf.append(toString((long[]) element)); else if (eClass == char[].class) buf.append(toString((char[]) element)); else if (eClass == float[].class) buf.append(toString((float[]) element)); else if (eClass == double[].class) buf.append(toString((double[]) element)); else if (eClass == boolean[].class) buf.append(toString((boolean[]) element)); else &#123; // element is an array of object references if (dejaVu.contains(element)) buf.append("[...]"); else deepToString((Object[])element, buf, dejaVu); &#125; &#125; else &#123; // element is non-null and not an array buf.append(element.toString()); &#125; &#125; if (i == iMax) break; buf.append(", "); &#125; buf.append(']'); dejaVu.remove(a); &#125;&#125;]]></content>
      <categories>
        <category>Arrays</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Arrays</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桶排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E6%A1%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[桶排序桶排序 (Bucket sort)或所谓的箱排序的原理是将数组分到有限数量的桶子里（即基于某种映射函数 ，将待排序列的关键字k映射到第i个桶中），然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。 桶排序是稳定的 桶排序是常见排序里最快的一种,比快排还要快…大多数情况下 桶排序非常快,但是同时也非常耗空间,基本上是最耗空间的一种排序算法 假设待排序的一组数统一的分布在一个范围中，并将这一范围划分成几个子范围，也就是桶 将待排序的一组数，分档规入这些子桶，并将桶中的数据进行排序 将各个桶中的数据有序的合并起来 桶排序分析：桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值的计算，其作用就相当于快排中划分，希尔排序中的子序列，归并排序中的子问题，已经把大量数据分割成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。 对N个关键字进行桶排序的时间复杂度分为两个部分： (1) 循环计算每个关键字的桶映射函数，这个时间复杂度是O(N)。 (2) 利用先进的比较排序算法对每个桶内的所有数据进行排序，其时间复杂度为 ∑ O(Ni*logNi) 。其中Ni 为第i个桶的数据量。 很显然，第(2)部分是桶排序性能好坏的决定因素。尽量减少桶内数据的数量是提高效率的唯一办法(因为基于比较排序的最好平均时间复杂度只能达到O(N*logN)了)。因此，我们需要尽量做到下面两点： (1) 映射函数f(k)能够将N个数据平均的分配到M个桶中，这样每个桶就有[N/M]个数据量。 (2) 尽量的增大桶的数量。极限情况下每个桶只能得到一个数据，这样就完全避开了桶内数据的“比较”排序操作。当然，做到这一点很不容易，数据量巨大的情况下，f(k)函数会使得桶集合的数量巨大，空间浪费严重。这就是一个时间代价和空间代价的权衡问题了。 对于N个待排数据，M个桶，平均每个桶[N/M]个数据的桶排序平均时间复杂度为：O(N)+O(M(N/M)log(N/M))=O(N+N(logN-logM))=O(N+NlogN-N*logM)，当N=M时，即极限情况下每个桶只有一个数据时。桶排序的最好效率能够达到O(N)。总结： 桶排序的平均时间复杂度为线性的O(N+C)，其中C=N*(logN-logM)。如果相对于同样的N，桶数量M越大，其效率越高，最好的时间复杂度达到O(N)。 当然桶排序的空间复杂度 为O(N+M)，如果输入数据非常庞大，而桶的数量也非常多，则空间代价无疑是昂贵的。123456789101112131415161718192021222324252627282930public static void bucketSort(int[] arr) &#123; if(arr == null &amp;&amp; arr.length == 0) return ; int bucketNums = 10; //这里默认为10，规定待排数[0,100) List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;List&lt;Integer&gt;&gt;(); //桶的索引 for(int i=0; i&lt;10; i++) &#123; buckets.add(new LinkedList&lt;Integer&gt;()); //用链表比较合适 &#125; //划分桶 for(int i=0; i&lt;arr.length; i++) &#123; buckets.get(fun(arr[i])).add(arr[i]); &#125; //对每个桶进行排序 for(int i=0; i&lt;buckets.size(); i++) &#123; if(!buckets.get(i).isEmpty()) &#123; Collections.sort(buckets.get(i)); //对每个桶进行快排 &#125; &#125; //还原排好序的数组 int k = 0; for(List&lt;Integer&gt; bucket : buckets) &#123; for(int ele : bucket) &#123; arr[k++] = ele; &#125; &#125;&#125;//映射函数public int fun(int x) &#123; return x / 10;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[计数排序一个O(n)时间复杂度的排序算法，我们知道基于比较的排序的下限是O(nlogn)。而计数排序只需线性时间复杂度的排序，只不过有前提条件，就是待排序的数要满足一定的范围的整数，而且计数排序需要比较多的辅助空间。其基本思想是，用待排序的数作为计数数组的下标，统计每个数字的个数。然后依次输出即可得到有序序列。如果被排序序列是无重的，即意味着无需统计个数，那么我们可以使用位数组来实现该算法！ 123456789101112131415161718192021222324public void countSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int max = max(arr);//获取被排序序列中的最大值来开辟新数组 int[] count = new int[max+1]; Arrays.fill(count, 0); for(int i=0; i&lt;arr.length; i++) &#123; count[arr[i]] ++; &#125; int k = 0; for(int i=0; i&lt;=max; i++) &#123; for(int j=0; j&lt;count[i]; j++) &#123; arr[k++] = i; &#125; &#125;&#125;public int max(int[] arr) &#123; int max = Integer.MIN_VALUE; for(int ele : arr) &#123; if(ele &gt; max) max = ele; &#125; return max;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_最大数]]></title>
    <url>%2F2017%2F05%2F22%2FLintCode-%E6%9C%80%E5%A4%A7%E6%95%B0%2F</url>
    <content type="text"><![CDATA[问题描述 给出一组非负整数，重新排列他们的顺序把他们组成一个最大的整数。(注意事项：最后的结果可能很大，所以我们返回一个字符串来代替这个整数。)样例：给出 [1, 20, 23, 4, 8]，返回组合最大的整数应为8423201。 思路拿到题目的第一反应就是比较大小嘛，但是继续往下想发现比较条件有点繁琐，同位数的直接比较大小即可，不同位数就比较麻烦了，需要一位一位进行比较…，然后突然间就想到了全排列，其实数据量比较小的时候是可以的，但是数据量大的情况就不行了，于是我卡在了数据样例[0,0,0,0,0,0,…,0,0,0]上，而且全然做了无用功，所以思路又回到了比较排序上，但是没想到什么好的比较方案，最终还是上网找了找资料，发现一个新思路，去比较两个数字组合后的大小，然后选择结果较大的组合，比如1和20，我们直接去比较120和201的大小，很明显201&gt; 120，所以1应该在20后面。这样一来比较就变得灰常容易，整个算法也瞬间简单明了起来！题解1234567891011121314151617181920212223242526public String largestNumber(int[] num) &#123; String[] A = new String[num.length]; int check = 0; for (int i=0;i&lt;num.length;i++) &#123; A[i] = String.valueOf(num[i]); check = Math.max(check,num[i]); &#125; if (check == 0) &#123; return "0"; &#125; Arrays.sort(A,new Comparator&lt;String&gt;() &#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;); StringBuilder s = new StringBuilder(); for (int i=0;i&lt;num.length;i++) &#123; s.append(String.valueOf(A[i])); &#125; return s.toString(); &#125; 收获一：以前只知道Arrays.sort(a[])这一种最简单的用法，今天又收获了两种更高级的用法，其中一种在本题中已用到，总结起来Arrays.sort()排序函数有以下几种用法 Arrays.sort(a[]) 排序a数组，且规则是从小到大，a可以是int,long,double,char,flaat,Object… Arrays.sort(a[], int fromIndex, int toIndex) 排序a数组的部分，从下标fromIndex到toIndex(不包括toIndex) Arrays.sort(T[] a, Comparator&lt;? super T&gt; c) 排序a数组，按照比较器中的规则 12345class MyComparator implements Comparator&lt;Integer&gt;&#123; public int compare(Integer s1, Integer s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125; 二：匿名内部类，think in java中研究了好久，只是一直没怎么使用过，如今又看到了，却也感觉熟悉而陌生，所以再拿出来简单说道说道，看代码1234567Arrays.sort(A,new Comparator&lt;String&gt;() &#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;); 完整类为123456789101112public class Main &#123; public static void main(String[] args) &#123; String[] a = &#123;9, 8, 7, 2, 3, 4, 1, 0, 6, 5&#125;; Comparator cmp = new MyComparator(); Arrays.sort(a, cmp); &#125; &#125; class MyComparator implements Comparator&lt;String&gt;&#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基数排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基数排序基数排序是一种借助多关键字排序思想对单逻辑关键字进行排序的方法。所谓的多关键字排序就是有多个优先级不同的关键字。比如说成绩的排序，如果两个人总分相同，则语文高的排在前面，语文成绩也相同则数学高的排在前面。。。如果对数字进行排序，那么个位、十位、百位就是不同优先级的关键字，如果要进行升序排序，那么个位、十位、百位优先级一次增加。基数排序是通过多次的收分配和收集来实现的，关键字优先级低的先进行分配和收集。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void radixSort(int[] arr) &#123; if(arr == null &amp;&amp; arr.length == 0) return ; int maxBit = getMaxBit(arr); for(int i=1; i&lt;=maxBit; i++) &#123; List&lt;List&lt;Integer&gt;&gt; buf = distribute(arr, i); //分配 collecte(arr, buf); //收集 &#125;&#125;//待分配数组public List&lt;List&lt;Integer&gt;&gt; distribute(int[] arr, int iBit) &#123; List&lt;List&lt;Integer&gt;&gt; buf = new ArrayList&lt;List&lt;Integer&gt;&gt;(); for(int j=0; j&lt;10; j++) &#123; buf.add(new LinkedList&lt;Integer&gt;()); &#125; for(int i=0; i&lt;arr.length; i++) &#123; buf.get(getNBit(arr[i], iBit)).add(arr[i]); &#125; return buf;&#125;//把分配的数据收集到arr中public void collecte(int[] arr, List&lt;List&lt;Integer&gt;&gt; buf) &#123; int k = 0; for(List&lt;Integer&gt; bucket : buf) &#123; for(int ele : bucket) &#123; arr[k++] = ele; &#125; &#125;&#125;//获取最大位数public int getMaxBit(int[] arr) &#123; int max = Integer.MIN_VALUE; for(int ele : arr) &#123; int len = (ele+"").length(); if(len &gt; max) max = len; &#125; return max;&#125;//获取x的第n位，如果没有则为0public int getNBit(int x, int n) &#123; String sx = x + ""; if(sx.length() &lt; n) return 0; else return sx.charAt(sx.length()-n) - '0';&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希尔排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[希尔排序希尔排序是插入排序的一种高效率的实现，也叫缩小增量排序。简单的插入排序中，如果待排序列是正序时，时间复杂度是O(n)，如果序列是基本有序的，使用直接插入排序效率就非常高。希尔排序就利用了这个特点。基本思想是：先将整个待排元素序列分割成若干子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序（增量为1）。其时间复杂度为O(n^3/2),要好于直接插入排序的O(n^2) 1234567891011121314151617181920212223public void shellInsert(int[] arr, int d) &#123; for(int i=d; i&lt;arr.length; i++) &#123; int j = i - d; int temp = arr[i]; //记录要插入的数据 while (j&gt;=0&amp;&amp;arr[j]&gt;temp) &#123; //从后向前，找到比其小的数的位置 arr[j+d] = arr[j]; //向后挪动 j -= d; &#125; if (j != i - d) //存在比其小的数 arr[j+d] = temp; &#125;&#125;public void shellSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int d = arr.length / 2; while(d &gt;= 1) &#123; shellInsert(arr, d); d&gt;&gt;1; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序快速排序在实际应用当中确实是表现最好的排序算法。但其思想是来自冒泡排序，冒泡排序是通过相邻元素的比较和交换把最小的冒泡到最顶端，而快速排序是比较和交换小数和大数，这样一来不仅把小数冒泡到上面，同时也把大数沉到下面。举个栗子：对5,3,8,6,4这个无序序列进行快速排序，思路是右指针从尾部找比基准数小的，左指针从头部找比基准数大的，然后交换之。通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。时间复杂度为O(nlogn) 12345678910111213141516171819202122232425public int partition(int[] arr, int left, int right) &#123; int pivotKey = arr[left]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; arr[right] &gt;= pivotKey) right --; arr[left] = arr[right]; //把小的移动到左边 while(left &lt; right &amp;&amp; arr[left] &lt;= pivotKey) left ++; arr[right] = arr[left]; //把大的移动到右边 &#125; arr[left] = pivotKey; //最后把pivot赋值到中间 return left;&#125;public void quickSort(int[] arr, int left, int right) &#123; if(left &gt;= right) return ; int pivotPos = partition(arr, left, right); quickSort(arr, left, pivotPos-1); quickSort(arr, pivotPos+1, right);&#125;public void sort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; quickSort(arr, 0, arr.length-1);&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[冒泡排序 基本思想:两两比较相邻记录的关键字,如果反序则交换 冒泡排序时间复杂度最好的情况为O(n),最坏的情况是O(n^2) 设置标志位，明显如果有一趟没有发生交换（flag = false)，说明排序已经完成 记录一轮下来标记的最后位置，下次从头部遍历到这个位置就Ok 12345678910111213141516171819public void bubbleSort(int[] array)&#123; boolean flag = true; int n = array.length; while(flag)&#123; flag = false; for(int i = 0;i &lt; n-1;i++)&#123; if(array[i] &gt; array[i+1])&#123; //数据交换，将较大的数据换至数组后方 array[i] = array[i]^array[i+1]; array[i+1] = array[i]^array[i+1]; array[i] = array[i]^array[i+1]; //设置标记，当本次循环未发生交换动作时，排序完成 flag = true; &#125; &#125; //每次循环均有一位当前最大值换至正确的位置，故每下一次循环减少一次比较 n--; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接插入排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E7%9B%B4%E6%8E%A5%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[直接插入排序 将一个记录插入到已经排好序的有序表中, 从而得到一个新的,记录数增1的有序表 时间复杂度也为O(n^2), 比冒泡法和选择排序的性能要更好一些 123456789101112131415public void insertSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; for(int i=1; i&lt;arr.length; i++) &#123; //假设第一个数位置时正确的；要往后移，必须要假设第一个。 int j = i; int target = arr[i]; //待插入的 //后移 while(j&gt;0&amp;&amp;target&lt;arr[j-1]) &#123; arr[j] = arr[j-1]; j --; &#125; //插入 arr[j] = target; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[选择排序 通过n-i次关键字之间的比较,从n-i+1 个记录中选择关键字最小的记录,并和第i(1&lt;=i&lt;=n)个记录交换之 尽管与冒泡排序同为O(n^2),但简单选择排序的性能要略优于冒泡排序 12345678910111213141516171819202122public static void selectSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int minIndex = 0; for(int i=0; i&lt;arr.length-1; i++) &#123; //只需要比较n-1次 minIndex = i; for(int j=i+1;j&lt;arr.length; j++) &#123; //从i+1开始比较，因为minIndex默认为i了，i就没必要比了。 if(arr[j]&lt;arr[minIndex]) &#123; minIndex = j; &#125; &#125; if(minIndex != i) &#123; //如果minIndex不为i，说明找到了更小的值，交换之。 swap(arr, i, minIndex); &#125; &#125;&#125;public static void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海量数据处理]]></title>
    <url>%2F2017%2F05%2F10%2F%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[海量数据处理问题 topK问题 重复问题 排序问题 相关算法 topK问题（10亿词中查找出现频率最高的10个） 单机+单核+足够大内存 10亿词（每个词占8B）中查找出现频率最高的10个 首先考虑全部放入内存，需要至少10^9*8=8GB 用HashMap（Map：key是单词，value是次数）统计频率在求出结果 词频统计构造单词树，前缀单词树（相比较map极大的节省空间） 单机+多核（意味着可以多线程）+足够大内存 在内存中用hash将数据分为n个partition，交给n个线程处理，最后有一个线程负责将结果合并 上述有一个瓶颈问题，即（数据倾斜）线程处理速度不一致，所以快的线程必须等慢的线程，速度取决最慢的线程 解决办法，将数据分成c*n个partition（c&gt;1）,依然是n个线程，快的线程处理完后主动取下一个partition进行处理，直到数据全部处理完成，最后合并结果 单机+单核+受限内存 Hash（x）%M将源文件数据切割成M个小文件，然后用（单机+单核+足够大内存）方法处理，最后合并 多机+受限内存 数据分发到各个机器，每台机器用（单机+单核+受限内存）方法进行处理 查找乱序数组中第K个最大值，或者前K个最大值（这种问题是不统计频率，只是查找第K个最大值） 方法一：全部排序 方法二：维护一个K长度的数组a[]，先读取源数据中的前K个放入数组，对该数组进行升序排序，再依次读取源数据第K个以后的数据，和数组中最小的元素（a[0]）比较，如果小于a[0]直接pass，大于的话，就丢弃最小的元素a[0]，利用二分法找到其位置，然后该位置前的数组元素整体向前移位，直到源数据读取结束。这比全部排序后统计频率效率会有很大的提高，但是当K的值较大的时候，长度为K的数据整体移位，也是非常耗时的。 方法三：找出数组中最大的元素，与第一个元素交换，再找出第二大元素，与第二个元素交换，直到找到第 $k$ 大元素便停止。 方法四：堆排序（最优） 重复问题（电话号码去重求个数，即不同的电话号码有多少个，假设电话号码为8位） HashMap去重法 位图法 8位能表示的十进制数最大为99999999，假设每个数字对应位图中的一位，大概需要内存99MB/8=7.375MB排序问题（9亿个不重复的9位整数数排序） 9亿个不重复的9位整数数排序，32位机器中整数占4B，所有数据全放入内存需0.9G*4B=3.6GB 1.利用数据库索引排序 2.分治法，将数据分断放入内存，最后合并（但是每次换入换出浪费时间） 3.位数组，声明一个可包含9位整数的bit数组，需内存大概9亿/8=120MB左右即可，数组内0、1表示是否含有此数，遍历出结果相关算法 1.hash算法 构造函数 冲突处理 2.位图法bit-map 快查，判重，判存 3.bloomfilter（位图+哈希） 判断元素是否属于集合 不属于（绝对正确） 属于（可能错误） m位的位数组+k个不同的hash（判定属于—k个哈希映射后，k位均为1，则可能存在于集合中，有位不为1，则元素肯定不在集合中） K=ln2*（m/n）n个元素，错误率最小 延伸：CBF（counter），SBF 4.倒排索引 单词指向包含他的文档（此单词在那些文档中出现过），例如论文的关键字搜索 5.trie树 利用公共前缀来减少时空消耗 6.堆 前n大/小 中位数（双堆）]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵相关运算]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[矩阵相关运算矩阵加减法（等行等列） 12345678910111213141516171819202122232425262728public int[][] add(int[][] a,int[][] b)&#123; //获取二维数组的行数 int row = a.length; //获取二维数组的列数 int column = a[row-1].length; int[][] c = new int[row][column]; for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; c[i][j]=a[i][j]+b[i][j]; &#125; &#125; return c;&#125;public int[][] sub(int[][] a,int[][] b)&#123; int row = a.length; int column = a[row-1].length; int[][] c = new int[row][column]; for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; c[i][j]=a[i][j]-b[i][j]; &#125; &#125; return c;&#125; 矩阵相乘（A[m][n]*B[n][k]=C[m][k]）1234567891011121314151617181920public int[][] add(int[][] a,int[][] b)&#123; //获取二维数组a的行数作为c的行数 int row = a.length; //获取二维数组a的列数 int n = a[row-1].length; 获取二维数组b的列数作为c的列数 int column = b[n-1].length; int[][] c = new int[row][column]; Arrays.fill(c,0); for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; for(int k=0;k&lt;n;k++)&#123; c[i][j]+=a[i][k]*b[k][j] &#125; &#125; &#125; return c;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法]]></title>
    <url>%2F2017%2F05%2F06%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[常用查找算法顺序查找 无序或有序队列,按顺序比较每个元素，直到找到关键字为止。 时间复杂度：O(n) 123456789101112131415161718192021222324252627282930313233343536373839//用链表来实现，动态的插入和删除便于维护序列的有序性public class SequentialSearchST&lt;Key,Value&gt; &#123; private Node head; private int size=0; //插入时间复杂度为O(n) public void put(Key key,Value v)&#123; Node p=head; while(p!=null)&#123; if(p.key.equals(key))&#123; p.v=v; return; &#125; p=p.next; &#125; head=new Node(key,v,head); size++; &#125; //查找时间复杂度为O(n) public Value get(Key key)&#123; Node p=head; while (p!=null)&#123; if(p.key.equals(key))&#123; return p.v; &#125; p=p.next; &#125; return null; &#125; //删除时间复杂度为O(n) public void delete(Key key)&#123; Node p=head; while (p!=null)&#123; if(p.key.equals(key))&#123; p.v = p.next.v; p.next = p.next.next; &#125; &#125; &#125;&#125; 二分查找（折半查找） 条件：有序数组 原理： 查找过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束； 如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中重复步骤1。 如果在某一步骤数组为空，则代表找不到。 时间复杂度：O(logn)1234567891011121314public int binarySearach(int[] array,int key)&#123; int low = 0; int high = array.length-1; while(low &lt;= high)&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) high = middle-1; else if(key &gt; array[middle]) low = middle+1; else return array[middle]; &#125; return -1;//没找到目标值返回-1&#125; 插值查找 插值查找，基于折半查找的优化变种。由于折半查找这种查找方式，不是自适应的（也就是说是傻瓜式的）打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。所以插值查找克服了折半查找的傻瓜式，采用自适应查找点，从而让每次所选择的查找点更加接近被查找值，以加快查找速度。 二分查找中查找点计算如下：mid=(low+high)/2, 即mid=low+1/2*(high-low); 插值查找中查找点计算如下：mid=low+(key-a[low])/(a[high]-a[low])*(high-low) 123456789101112131415161718public int insertKeySearch(int [] a, int key)&#123; int low, high, mid; low = 0; high = a.length-1; while(low &lt;= high)&#123; /* 插值查找的计算公式 */ mid = low + (high - low)*(key - a[low])/(a[high] - a[low]); if (key &lt; a[mid])&#123; high = mid - 1; &#125; else if (key &gt; a[mid])&#123; low = mid + 1; &#125; else return mid; &#125; return 0;&#125; 复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。注：对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。斐波那契查找 在介绍斐波那契查找算法之前，先介绍一下很它紧密相连的一个概念——黄金分割。黄金比例又称黄金分割，是指事物各部分间一定的数学比例关系，即将整体一分为二，较大部分与较小部分之比等于整体与较大部分之比，其比值约为1:0.618或1.618:1。0.618被公认为最具有审美意义的比例数字，这个数值的作用不仅仅体现在诸如绘画、雕塑、音乐、建筑等艺术领域，而且在管理、工程设计等方面也有着不可忽视的作用。因此被称为黄金分割。斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。然后我们会发现，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618，利用这个特性，我们就可以将黄金比例运用到查找技术中。 斐波那契查找也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。斐波那契查找就是在二分查找的基础上根据斐波那契数列进行分割的。在斐波那契数列找一个等于略大于查找表中元素个数的数F[n]，将原查找表扩展为长度为Fn，完成后进行斐波那契分割，即F[n]个元素分割为前半部分F[n-1]个元素，后半部分F[n-2]个元素，找出要查找的元素在那一部分并递归，直到找到。相对于折半查找，一般将待比较的key值与第mid=（low+high）/2位置的元素比较，比较结果分三种情况： key值与第mid=（low+high）/2相等，mid位置的元素即为所求； key值大于第mid=（low+high）/2，则令 low=mid+1； key值小于第mid=（low+high）/2，则令high=mid-1。斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1；开始将k值与第F(k-1)位置的记录进行比较(及mid=low+F(k-1)-1)，比较结果也分为三种： key值与第mid=low+F(k-1)-1相等，则mid位置的元素即为所求； key值大于第mid=low+F(k-1)-1，则low=mid+1，k-=2；说明：low=mid+1说明待查找的元素在[mid+1,high]范围内，k-=2 说明范围[mid+1,high]内的元素个数为n-(F(k-1))=Fk-1-F(k-1)=Fk-F(k-1)-1=F(k-2)-1个，所以可以递归的应用斐波那契查找。 key值小于第mid=low+F(k-1)-1，则high=mid-1，k-=1。说明：low=mid+1说明待查找的元素在[low,mid-1]范围内，k-=1 说明范围[low,mid-1]内的元素个数为F(k-1)-1个，所以可以递归的应用斐波那契查找。 上代码我们来实际操作一番123456789101112131415161718192021222324252627public int FibonacciSearch(int [] a, int key)&#123; int [] F = &#123;0,1,1,2,3,5,8,13,21,34&#125;;//构造一个斐波那契数列 int low, high, mid, k; low = 1; high = a.length-1; k = 0; while (n &gt; F[k]-1) /* 计算n位于斐波那契数列的位置 */ k++; while (low &lt;= high) &#123; mid = low + F[k-1] -1; if (key &lt; a[mid])&#123; high = mid - 1; k -= 1; &#125; else if (key &gt; a[mid])&#123; low = mid + 1; k -= 2; &#125; else &#123; if (mid &lt;= n) return mid; else return n; &#125; &#125; return 0;&#125; 在最坏情况下，斐波那契查找的时间复杂度还是O(log2n)，且其期望复杂度也为O(log2n)，但是与折半查找相比，斐波那契查找的优点是它只涉及加法和减法运算，而不用除法，而除法比加减法要占用更多的时间，因此，斐波那契查找的运行时间理论上比折半查找小，但是还是得视具体情况而定。二叉排序树查找特性： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。在二叉查找树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则搜索左子树；否则： 查找右子树。时间复杂度：O(log_2(n)) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//查找public TreeNode BSTSearach(TreeNode root, Value value) &#123; if(root==null) return null; if(root.value==value) return root; else return root.value&lt;value ? BSTSearach(roo.right,value) : BSTSearach(root.left,value);&#125;//插入节点public void insertNode(TreeNode root,TreeNode node) &#123; if (root == NULL) root = node; else if (root.val &gt; node.val) insertNode(root.left,node); else if(root.val &lt; node.val) insertNode(root.right,node); else return;&#125; //删除二叉查找树的节点public TreeNode removeNode(TreeNode root, int value) &#123; if (root == null)&#123; return null; &#125; if (root.val == value)&#123;//当前节点值等于value值 if (root.left == null &amp;&amp; root.right == null)&#123;//当前节点没有左右孩子节点 root = null; &#125; else if (root.left == null)&#123;//当前节点只有右孩子节点 root = root.right; &#125; else if (root.right == null)&#123;//当前节点只有左孩子节点 root = root.left; &#125; else &#123;//当前节点有左右孩子节点 TreeNode tmp = root; tmp = tmp.left; while(tmp.right != null)&#123; tmp = tmp.right; &#125; root.val = tmp.val; root.left = removeNode(root.left,root.val); &#125; &#125; else if (value &lt; root.val)&#123;//当前节点值大于value if (root.left == null)&#123; return root; &#125; root.left = removeNode(root.left, value); &#125; else &#123;//当前节点值小于value if (root.right == null)&#123; return root; &#125; root.right = removeNode(root.right,value); &#125; return root;&#125; 哈希表法（散列表） 先创建哈希表（散列表） 根据键值方式(Key value)进行查找，通过散列函数，定位数据元素。 时间复杂度：几乎是O(1)，取决于产生冲突的多少。123456789101112131415161718192021222324public int searchHash(int[] hash, int hashLength, int key) &#123; // 哈希函数 int hashAddress = key % hashLength; // 指定hashAdrress对应值存在但不是关键值，则用开放寻址法解决 while (hash[hashAddress] != 0 &amp;&amp; hash[hashAddress] != key) &#123; hashAddress = (++hashAddress) % hashLength; &#125; // 查找到了开放单元，表示查找失败 if (hash[hashAddress] == 0) return -1; return hashAddress; &#125; //数据插入Hash表 public void insertHash(int[] hash, int hashLength, int data) &#123; // 哈希函数 int hashAddress = data % hashLength; // 如果key存在，则说明已经被别人占用，此时必须解决冲突 while (hash[hashAddress] != 0) &#123; // 用开放寻址法找到 hashAddress = (++hashAddress) % hashLength; &#125; // 将data存入字典中 hash[hashAddress] = data; &#125; 分块查找 将n个数据元素”按块有序”划分为m块（m ≤ n）。 每一块中的结点不必有序，但块与块之间必须”按块有序”；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，…… 然后使用二分查找确定数据所处在哪一块后用顺序查找key。123456789101112131415161718public int blockSearch(int[] index, int[] st, int key, int m) &#123; // 在序列st数组中，用分块查找方法查找关键字为key的记录 // 1.在index[ ] 中折半查找，确定要查找的key属于哪个块中 int i = binarySearch(index, key); if (i &gt;= 0) &#123; int j = i &gt; 0 ? i * m : i; int len = (i + 1) * m; // 在确定的块中用顺序查找方法查找key for (int k = j; k &lt; len; k++) &#123; if (key == st[k]) &#123; System.out.println("查询成功"); return k; &#125; &#125; &#125; System.out.println("查找失败"); return -1; &#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找]]></title>
    <url>%2F2017%2F05%2F06%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[二分查找非递归版1234567891011121314public int binarySearch(int[] array,int key)&#123; int low = 0; int high = array.length-1; while(low &lt;= high)&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) high = middle-1; else if(key &gt; array[middle]) low = middle+1; else return array[middle]; &#125; return -1;//没找到目标值返回-1&#125; 递归版12345678910111213public int binarySearch(int[] array,int key,int low,int high)&#123; if(low &gt;= high) return -1; else&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) binarySearach(array,key,low,middle-1); else if(key &gt; array[middle]) binarySearach(array,key,middle-1,high); else return array[middle]; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>BinarySearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map的遍历]]></title>
    <url>%2F2017%2F05%2F06%2FMap%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[Map的遍历 EntrySet遍历 KeySet/Values遍历 Iterator遍历 foreach遍历 使用EntrySet 1234Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue()); &#125; 使用keyset或者values 123456789Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); //遍历map中的键 for (Integer key : map.keySet()) &#123; System.out.println("Key = " + key); &#125; //遍历map中的值 for (Integer value : map.values()) &#123; System.out.println("Value = " + value); &#125; 使用Iterator(在遍历时调用iterator.remove()可以来删除entries) 123456Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator(); while (entries.hasNext()) &#123; Map.Entry&lt;Integer, Integer&gt; entry = entries.next(); System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue()); &#125; 使用foreach遍历 1234567891011121314Map&lt;String, Integer&gt; items = new HashMap&lt;&gt;();items.put("A", 10);items.put("B", 20);items.put("C", 30);items.put("D", 40);items.put("E", 50);items.put("F", 60);items.forEach((k,v)-&gt;System.out.println("Item : " + k + " Count : " + v));items.forEach((k,v)-&gt;&#123; System.out.println("Item : " + k + " Count : " + v); if("E".equals(k))&#123; System.out.println("Hello E"); &#125;&#125;);]]></content>
      <categories>
        <category>Iteration</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Iteration</tag>
        <tag>Map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初心]]></title>
    <url>%2F2017%2F04%2F30%2F%E5%88%9D%E5%BF%83%2F</url>
    <content type="text"><![CDATA[引言 2017-04-29是我阳历的生日，同时也是我第一个博客的诞辰！初心是为了能有一个可以记录自己在代码中的成长过程的空间，同时也希望能够发挥自己的一些微不足道的能力去帮助一些人，在此过程中不断提高自己。——————一只奋进的小菜鸟 随笔 起因其实可以追溯到一篇微博，内容讲述了为什么程序员要写博客，作者文笔着实不错，让我看着动了心，回想起从前码代码的日子，经历过好多的坑，走过好多的弯路，一直想可以把自己心得或者当时的想法，做法记录下来，以后可以回头看看自己当初犯过那些错，走过那些弯路，警醒一下自己，同时也可以提醒同在路上的人不要重蹈我的覆辙，为他人尽自己的一丝绵薄之力。 本人小小一程序员菜鸟，无意间对编程产生了浓厚的兴趣，遂开始了码代码的日子，由于起步较晚，基础也薄弱，希望以后的日子有幸能看我文章的小伙伴不要吝啬你们的口水，为我提出宝贵的意见，更希望各位大牛心情愉悦之际能指点一二，同路的菜鸟我们相互交流，共同学习，一起奋进！]]></content>
      <categories>
        <category>初心</category>
      </categories>
      <tags>
        <tag>初心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F04%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hello World</category>
      </categories>
      <tags>
        <tag>Hello World</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet]]></title>
    <url>%2F2017%2F02%2F25%2FServlet%2F</url>
    <content type="text"><![CDATA[Servlet 本文来自百度百科：https://baike.baidu.com/item/servlet/477555?fr=aladdin Servlet由来Servlet 是在服务器上运行的小程序。这个词是在 Java applet的环境中创造的。 Java applet 是一种当作单独文件跟网页一起发送的小程序，它通常用于在客户端运行，结果得到为用户进行运算或者根据用户互作用定位图形等服务。 服务器上需要一些程序，常常是根据用户输入访问数据库的程序。这些通常是使用公共网关接口（Common Gateway Interface，CGI）应用程序完成的。 但是，在服务器上运行 Java，这种程序可使用 Java 编程语言实现。在通信量大的服务器上，JavaServlet 的优点在于它们的执行速度更快于 CGI 程序。各个用户请求被激活成单个程序中的一个线程，而无需创建单独的进程，这意味着服务器端处理请求的系统开销将明显降低。 实现过程 最早支持 Servlet 技术的是 JavaSoft 的 Java Web Server。此后，一些其它的基于 Java 的 Web Server 开始支持标准的 Servlet API。 Servlet 的主要功能在于交互式地浏览和修改数据，生成动态 Web 内容。这个过程为： 客户端发送请求至服务器端； 服务器将请求信息发送至 Servlet； Servlet 生成响应内容并将其传给服务器。响应内容动态生成，通常取决于客户端的请求； 服务器将响应返回给客户端。 Servlet 看起来像是通常的 Java 程序。Servlet 导入特定的属于 Java Servlet API 的包。因为是对象字节码，可动态地从网络加载，可以说 Servlet 对 Server 就如同 Applet对 Client 一样，但是，由于 Servlet 运行于 Server 中，它们并不需要一个图形用户界面。从这个角度讲，Servlet 也被称为 FacelessObject。 一个 Servlet 就是 Java 编程语言中的一个类，它被用来扩展服务器的性能，服务器上驻留着可以通过“请求-响应”编程模型来访问的应用程序。虽然 Servlet 可以对任何类型的请求产生响应，但通常只用来扩展 Web 服务器的应用程序。 生命周期 客户端请求该 Servlet； 加载 Servlet 类到内存； 实例化并调用init()方法初始化该 Servlet； service()（根据请求方法不同调用doGet() 或者 doPost()，此外还有doHead()、doPut()、doTrace()、doDelete()、doOptions()、destroy())。 加载和实例化 Servlet。这项操作一般是动态执行的。然而，Server 通常会提供一个管理的选项，用于在 Server 启动时强制装载和初始化特定的 Servlet（loadOnStartUp）。 对于更多的客户端请求，Server 创建新的请求和响应对象，仍然激活此 Servlet 的 service() 方法，将这两个对象作为参数传递给它。如此重复以上的循环，但无需再次调用 init() 方法。一般 Servlet 只初始化一次(只有一个对象)，当 Server 不再需要 Servlet 时（一般当 Server 关闭时），Server 调用 Servlet 的 destroy() 方法。 比较与 Applet 的比较 相似之处： 它们不是独立的应用程序，没有 main() 方法。 它们不是由用户或程序员调用，而是由另外一个应用程序(容器)调用。 它们都有一个生存周期，包含 init() 和 destroy() 方法。 不同之处： Applet具有很好的图形界面(AWT)，与浏览器一起，在客户端运行。 Servlet 则没有图形界面，运行在服务器端。 与 CGI 比较 与传统的 CGI 和许多其他类似 CGI 的技术相比，Java Servlet 具有更高的效率，更容易使用，功能更强大，具有更好的可移植性，更节省投资。在未来的技术发展过程中，Servlet 有可能彻底取代 CGI。在传统的 CGI中，每个请求都要启动一个新的进程，如果 CGI 程序本身的执行时间较短，启动进程所需要的开销很可能反而超过实际执行时间。而在 Servlet 中，每个请求由一个轻量级的 Java 线程处理（而不是重量级的操作系统进程）。在传统 CGI 中，如果有 N 个并发的对同一 CGI程序的请求，则该CGI程序的代码在内存中重复装载了 N 次；而对于 Servlet，处理请求的是 N 个线程，只需要一份 Servlet 类代码。在性能优化方面，Servlet 也比 CGI 有着更多的选择。 方便Servlet 提供了大量的实用工具例程，例如自动地解析和解码 HTML 表单数据、读取和设置 HTTP头、处理Cookie、跟踪会话状态等。 功能强大在Servlet中，许多使用传统 CGI 程序很难完成的任务都可以轻松地完成。例如，Servlet 能够直接和 Web服务器交互，而普通的 CGI 程序不能。Servlet 还能够在各个程序之间共享数据，使得数据库连接池之类的功能很容易实现。 可移植性好Servlet 用 Java 编写，Servlet API具有完善的标准。因此，为 IPlanet Enterprise Server 写的 Servlet 无需任何实质上的改动即可移植到 Apache、MicrosoftIIS 或者 WebStar。几乎所有的主流服务器都直接或通过插件支持 Servlet。 与 JSP 比较 JSP 和 Servlet 的区别到底在应用上有哪些体现，很多人搞不清楚。简单的说，SUN 首先发展出 Servlet，其功能比较强劲，体系设计也很先进，只是，它输出 HTML 语句还是采用了老的 CGI 方式，是一句一句输出，所以，编写和修改 HTML 非常不方便。 Java Server Pages(JSP)是一种实现普通静态HTML 和动态 HTML 混合编码的技术，JSP 并没有增加任何本质上不能用 Servlet 实现的功能。但是，在 JSP 中编写静态HTML 更加方便，不必再用 println语 句来输出每一行 HTML 代码。更重要的是，借助内容和外观的分离，页面制作中不同性质的任务可以方便地分开：比如，由页面设计者进行 HTML设计，同时留出供 Servlet 程序员插入动态内容的空间。后来 SUN 推出了类似于 ASP 的镶嵌型的 JSP，把 JSP TAG 镶嵌到 HTML 语句中，这样，就大大简化和方便了网页的设计和修改。新型的网络语言如 ASP，PHP，JSP 都是镶嵌型的语言。 这是 JSP 和 Servlet 区别的运作原理层面。 从网络三层结构的角度看 JSP 和 Servlet 的区别，一个网络项目最少分三层：data layer(数据层)，business layer(业务层)，presentation layer(表现层)。当然也可以更复杂。Servlet 用来写 business layer 是很强大的，但是对于写 presentation layer 就很不方便。JSP 则主要是为了方便写 presentation layer 而设计的。当然也可以写 business layer。写惯了 ASP，PHP，CGI的朋友，经常会不自觉的把 presentation layer 和 business layer 混在一起。 根据 SUN 自己的推荐，JSP中应该仅仅存放与 presentation layer 有关的东西，也就是说，只放输出 HTML 网页的部分。而所有的数据计算，数据分析，数据库联结处理，统统是属于 business layer，应该放在 Java BEANS 中。通过 JSP 调用 Java BEANS，实现两层的整合。]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Servlet</tag>
        <tag>Web</tag>
      </tags>
  </entry>
</search>