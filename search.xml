<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Rate Limit]]></title>
    <url>%2F2019%2F01%2F20%2FRate%20Limit%2F</url>
    <content type="text"><![CDATA[限流算法 基于计数器的限流算法 基于滑动窗口的限流算法 漏桶算法 令牌桶算范 基于计数器的限流算法 定义每秒或者每分钟可以通过的请求数量，用一个变量来记录；超过该请求数量的直接丢弃，然后每秒/分钟重置该变量 这种算法是最简单的，就是定义了单位时间内允许的流量。 危险的边界值 这种算法实现起来很简单，但是对于边界值的处理很危险 假设定义一分钟内允许通过的流量为1000，一个用户在59.98秒的时候发了1000个请求（该一分钟内除了此用户没有其他用户流量），这1000个请求按照计数器算法合理通过给到服务器，然后此用户又在60.01秒（也就是上一分钟刚刚结束，下一分钟刚刚开始的时候）再次发送了1000个请求，根据计数器算法依然合理通过给到服务器，这个时候相当于服务器在1秒内接受到了2000个请求，如果2000这个值大于服务器的承受能力，则会造成服务器的故障甚至宕机。 基于滑动窗口的限流算法 由于计数器算法会存在危险的边界值问题，所以出现了加强版算法基于滑动窗口的限流算法 基于滑动窗口的限流算法将定义的一个时间单位会分成若干个小的窗口，单位时间内的流量限制不变，只不过变成各个小窗口的和；这样时间移动过程中，每次滑动一个小窗口； 安全的边界值 假设定义一分钟内允许通过的流量为1000，窗口个数为10个（编号1到10），一个用户在59.98秒的时候，也就是第10个窗口发了1000个请求（该一分钟内除了此用户没有其他用户流量且其他窗口也没有流量），这1000个请求按照算法合理通过给到服务器，然后此用户又在60.01秒（也就是上一分钟刚刚结束，下一分钟刚刚开始的时候；这个时候1号窗口移动到了10号窗口的后面，其他窗口不变；）再次发送了1000个请求，根据算法这个时间限制内请求已经达到上限（10个窗口之和），所以请求会被拒绝丢弃掉。这个时候相当于服务器在1秒内接受到了1000个请求，避免了请求瞬间翻倍的情况。 漏桶算法 采用一个固定容量的桶来存放请求（实际中使用消息队列），存放速率不做任何限制，但是当桶满了之后就不能再存放请求，这个时候请求被丢弃；一边没有限制的存放请求，一边我们定义一个固定的速率去拿取请求； 该算法对于服务器来说比较友好，因为始终以一种固定的速率给服务器发送请求，服务器不会面对突发流量（因为都被挡在桶中） 不存在边界值问题，因为发往服务器的请求均以一定的速率返送，而该速率的制定一定是服务器承受范围之内的。 令牌桶算法 令牌桶算法与漏桶算法思路相反，限制往桶中存放请求的速率，而不限制从桶中拿取请求的速率； 同样采用一个固定容量的桶来存放请求，以一定的速率往桶中存放请求；实际该速率值可能较大，正常流量较少时，往桶中存放的请求也就相对较少，这时发往服务器的请求也就相对较少（拿取时可以直接将桶中请求全部拿走发给服务器，因为没有限制）；当有突发流量时，桶中请求也会瞬间猛增，这时发往服务器的请求也会骤增，相当于面对突发流量） 安全的边界值 虽然从桶中拿取的速率不做限制，但是桶中得有请求才行，所以从桶中拿取的速率其实是受限于桶中请求的存放速率，如果桶中一秒中可以积累100个请求，则从桶中拿取的速率就是100个请求/s，但是实际桶中请求的数量需要一定时间的积累，所以当上一秒拿取速率特别大时（存放积累好久的请求），下一秒往往不会很大（积累的请求都被上一秒拿走了），也就不会存在边界值翻倍的情况。]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2F2019%2F01%2F13%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁 悲观锁 重量级锁 自旋锁 自适应自旋锁 独占锁 乐观锁 轻量级锁 偏向锁 共享锁 可重入锁 公平/非公平锁 共享锁和独占锁 分段锁 java中的锁 如何优化锁 悲观锁 悲观锁以一种悲观的心态看待所有的程序调用，认为只要发生调用就会发生数据改动，所以一旦调用就会加锁，防止其他线程来改动数据；适用于写多读少的情况。 重量级锁 线程判定资源是否可用，可用加锁使用，使用完释放锁；若不可用则直接进入阻塞状态，等待锁释放唤醒重新抢夺锁资源；这种一旦判定资源可用就将资源加锁锁定不允许其他线程访问的我们称之为重量级锁。 线程进入阻塞状态和加锁操作都是一个很耗时的过程，会涉及到上下文保存，线程用户态，核心态的切换等，所以称之为重量级锁。 自旋锁 由于重量级锁线程每次都要经历进出阻塞状态这个耗时的过程，但是有时候可能线程等待锁资源释放的时间要比进出阻塞状态所耗费的时间少，所以出现自旋锁。 自旋锁当线程判定资源不可用时，并不是直接进入阻塞状态，而是挂起等待一定时间，即自旋（类似空循环一样）；若是自旋结束后锁也释放则直接抢夺锁资源，否则线程进入阻塞状态。 自适应自旋锁 自旋锁的关键就是自旋时间的长短，太长太短都不合适，并且不同情况自旋时间也大不相同，所以采用相同的自旋时间明显不合适，因此出现了自适应自旋锁。 自适应自旋锁的自旋时间由系统本身去判定，根据线程获取到锁的概率去定制不同的自旋时间。 乐观锁 乐观锁以一种乐观的心态看待所有的程序调用，认为所有的调用均不会发生数据改动，所以发生调用的时候并不会加锁（而是做一个标记，标记次调用有人在执行，采用CAS操作执行），而是等到真正发生数据改动的时候才进行加锁；适用于读多写少的情况。 乐观锁的实现 以对某一张表执行更新操作为例，表中添加一个version字段作为乐观锁标记字段，类型为timestamp not null default current_timestamp on update current_time update之前我们进行select将version字段取出作为乐观锁的标记 然后执行update的时候将之前取出的version值作为where条件加到update语句中，以此来作为乐观锁标记 如果在执行select语句到update语句之间数据没有没其他线程改动过，则version字段值不会发生变动，update语句也可以执行成功，否则标记字段发生变动，update语句执行失败，重新从select开始执行 轻量级锁 对于资源竞争激烈，即同一时间还有多个线程来访问资源，我们使用重量级锁（悲观锁）是应该的，但是并不是所有的时候都会有那么多的线程竞争，所以如果当线程很少或者说是根本没有竞争存在，那么加锁就变得冗余了，因此出现了轻量级锁来应对线程竞争不是很激烈的情况或者是线程总是交错执行的情况。 轻量级锁每次线程判定资源可用时，不会加锁，而是添加一个标识，标识该资源有人在使用了（该标识的改变使用CAS操作完成），使用完成后再将其标识更改为无人使用； 如果就是没有竞争的发生，我们可能认为标识位可有可无，因为没有用到，那么标识位什么时候用到呢；当出现竞争的时候标识位就有用了，他会告知当前线程有人来抢资源了，这时资源就必须要加锁了，也就是轻量级锁必须升级为重量级锁了，不然就会出现数据被其他线程改动的情况。 偏向锁 偏向锁直接认为资源不会发生竞争，所以和轻量级锁一样在进入资源的时候会添加一个标识，同时比轻量级锁多添加一个当前线程id。而当离开资源的时候也不会去更改资源标识，这样当下次再次访问该资源的时候，如果判定标识为已有人使用，同时线程id是自己的话，直接进入避免执行CAS操作。这样，偏向锁可以使的线程更快的进入资源执行操作； 偏向锁适用于线程竞争几乎不存在的情况，相当于单线程； 当资源竞争发生时，线程判定资源标识为又人使用，但是却不是自己的id时，偏向锁就升级为轻量级锁了。 可重入锁 可重入锁，也叫 做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受 影响。 公平/非公平锁 公平锁 加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得 非公平锁 加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待 非公平锁性能比公平锁高5~10倍，因为公平锁需要在多核的情况下维护一个队列 Java中的synchronized是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。 共享锁和独占锁 独占锁 独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。 独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线 程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 共享锁 共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种 乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 分段锁 分段锁也并非一种实际的锁，而是一种思想。ConcurrentHashMap是学习分段锁的最好实践 java中的锁Synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁，同时属于可重入锁，非公平锁。 由操作系统Mutex Lock实现。 ReentrantLock 由jdk实现；提供公平/非公平锁，条件锁，响应中断锁；属于重入锁，独占锁，乐观锁 Semaphore 基于计数器实现；提供公平/非公平锁，基本可以完成ReentrantLock的所有工作 AtomicInteger 原子类，为i++专门提供的原子类，性能比手动加锁高很多 ReadWriteLock 读写锁：java专门为提供读写性能提供的锁 读锁 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁 写锁 如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上 读锁，写的时候上写锁！ 如何优化锁 减少锁持有时间 减少锁的粒度（分段锁） 锁分离（读写锁分离） 锁粗化 当一个线程对资源操作时间较长时，出于减少锁持有时间的考虑，会造成该线程对锁资源不停的进行持有和释放操作，其本身也会浪费大量的性能]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Limits on MySql]]></title>
    <url>%2F2019%2F01%2F06%2FLimits%20on%20MySql%2F</url>
    <content type="text"><![CDATA[Limits on MySql 以下所有内容基于存储引擎为InnoDB mysql没有数据库数量的限制和表数量的限制，InnoDB允许多达40亿个表。 数据文件大小（数据文件，索引文件）取决于操作系统磁盘空间 mysql硬性限制一张表最多4096个字段，实际情况肯定小于此值 mysql限制表中每行记录大小最大为65535个字节（text类型的字段除外，也就是说含有text类型字段的表中每行记录大小可以突破65535字节的限制） mysql存储可变参数时，不仅要空间保存其value值，还要保存其length长度，例如：varchar(N)在编码格式为utf8mb3下，长度需要占2个字节，所以该字段长度为N+2，计算行大小时要注意把长度也算在内。 MyISAM存储引擎下，字段非空的时候需要额外的空间去保存该值是否为空，所以计算每行大小时也要计算在内。 ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBs InnoDB限制一张表最多含有1017个字段（mysql5.6.9之前为1000） InnoDB限制一张表最多含有64个耳机索引 InnoDB：默认索引前缀长度限制为767个字节，当编码格式为utf8mb3时，varchar(n)类型或者text(n)类型字段一个字符占3字节，所以其上限为255个字符；当配置选项 innodb_large_prefix开启后，使用dynamic或者compressed行格式的表索引前缀上限可以提升至3072个字节； InnoDB一个page的默认大小是 16 k。由于是Btree组织，要求叶子节点上一个page至少包含两条记录（否则就退化链表了）。所以一个记录最多不能超过 8 k。又由于InnoDB的聚簇索引结构，一个二级索引要包含主键索引，因此每个单个索引不能超过 4 k（极端情况，pk和某个二级索引都达到这个限制）。由于需要预留和辅助空间，扣掉后不能超过 3500 ，取个“整数”就是(1024*3)。主要字符集的计算方式： latin1 = 1 byte = 1 character uft8 = 3 byte = 1 character gbk = 2 byte = 1 character varchar最大有效长度是 65532 字节，在 varchar 存字符串的时候，第一个字节是空的，不存任何的数据，然后还需要两个字节来存放字符串的长度。所以有效长度就是 65535 - 1 - 2= 65532 由字符集来确定，字符集分单字节和多字节 Latin1 一个字符占一个字节，最多能存放 65532 个字符 GBK 一个字符占两个字节， 最多能存 32766 个字符 UTF8 一个字符占三个字节， 最多能存 21844 个字符 InnoDB限制一个索引最多包含16个字段 InnoDB限制，除了可变长度列（VARBINARY，VARCHAR，BLOB和TEXT）之外，最大行长度略小于页面的一半；配置参数 innodb_page_size=16K时，每行记录最大长度为8000个字节，8K时为4000个字节，4K时为2000个字节 尽管InnoDB在内部支持大于65,535字节的行大小，但MySQL本身对所有列的组合大小施加了行大小限制65,535： 当表空间太大时，建议将其分为多个小文件 log日志文件大小最大512GB 最小表空间大小10M，最大表空间大小取决于page size的设置 InnoDB Page Size Maximum Tablespace Size 4KB 16TB 8KB 32TB 16KB 64TB]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Reference]]></title>
    <url>%2F2018%2F12%2F30%2FJava%20Reference%2F</url>
    <content type="text"><![CDATA[Java Reference FinalReference WeakReference SoftReference PhantomReference FinalReference强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 ps：强引用其实也就是我们平时A a = new A()这个意思。 WeakReference如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存（下文给出示例）。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 SoftReference弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 PhantomReference“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。 应用场景缓存]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Replication]]></title>
    <url>%2F2018%2F12%2F23%2FMySQL%20Replication%2F</url>
    <content type="text"><![CDATA[Replication Principle Implement And Configuration Problems In The Process PrincipleBinary Logging File 二进制日志文件：数据库实例操作master将更新和变动以event的形式写入二进制日志文件中，slave配置读取master的二进制日志问文件在本地执行以实现数据同步（slave可以自行决定执行文件的哪些部分，还是全部执行），slave同时保存二进制日志文件的文件名和读取位置以便于下次增量读取同步数据 mysql配置文件中’binlog = /日志文件位置’开启master同步，配置文件修改后记得重启mysql master的binary logging一定要处于开启状态，但是slave并不需要，因此建议关闭，除非遇到A-&gt;B-&gt;C这种主从关系 server-id master和slave均必须配置唯一ID（范围[1,2^32-1]，master配置id为0不允许任何slave连接，slave配置id为0不会连接任何master Replication Exclusive User master可以创建replication的专属用户设置 mysql&gt; CREATE USER &apos;repl&apos;@&apos;%.example.com&apos; IDENTIFIED BY &apos;password&apos;; mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;%.example.com&apos;; Implement And Configuration master配置 log-bin开启 配置唯一server-id 最好使用innodb引擎，并配置如下参数 innodb_flush_log_at_trx_commit=1 sync_binlog=1 确保 skip-networking未开启，否则没有网络，主从无法通信 slave配置 配置唯一server-id slave中log-bin没必要开启，除非slave下还有slave挂载，该情况下还需要开启–log-slave-updates（默认开启）以实现将master传送过来的写更新操作通过sql线程更新到自己的log-bin中，以实现数据向下同步 –skip-log-bin 和–skip-log-slave-updates 参数可关闭slave的log-bin和log-slave-updates 创建同步专属用户 Replication Exclusive User 获取master同步二进制文件坐标position 使用 FLUSH TABLES WITH READ LOCK, 操作（刷新所有表数据，获取读锁，阻断写操作）会阻断所有在 InnoDB 引擎的下表操作的提交 如果要shutdown主机拷贝数据，则不需要再获取master同步二进制文件坐标position，因为主机重启后会创建新的二进制文件 在master的一个客户端session连接中执行FLUSH TABLES WITH READ LOCK;命令，该命令在该客户端session连接保持内有效，若该客户端session连接关闭，该命令失效 在另一个客户端session连接中执行show master status，查看主机状态信息，记录同步日志文件名和位置 master含有原始数据，保持读锁，执行数据拷贝（转向步骤5） master没有原始数据，slave也是新机器（转向步骤6） 选择数据快照方式 mysqldump方式（推荐方式） 命令mysqldump –all-databases –master-data &gt; dbdump.sql将所有的数据库数据和结构dump到的比dbdump.sql中，并包含–master-data选项，该选项自动附加从站上所需的CHANGE MASTER TO语句以启动复制过程： 如果不使用–master-data，则需要手动锁定单独会话中的所有表 参数–ignore-table排除不想同步的表 参数–databases指定同步数据库 若数据存储在便携式二进制文件中，可以拷贝行数据文件实现数据拷贝（不做过多介绍） 设置复制从属 master解锁 UNLOCK TABLES; 如果有原始数据需要引入slave中 启动slave，并使用参数–skip-slave-start 避免复制同步开始 向slave中导入master原始数据 slave配置master信息 start slave开启复制同步 没有原始数据需要引入slave， 启动slave slave配置master信息 start salve开启复制同步 在slave中配置master主机信息123456mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST='master_host_name', -&gt; MASTER_USER='replication_user_name', -&gt; MASTER_PASSWORD='replication_password', -&gt; MASTER_LOG_FILE='recorded_log_file_name', -&gt; MASTER_LOG_POS=recorded_log_position; 在已有的主从环境中添加slave 停止已有的slave并记录状态信息 mysql&gt; STOP SLAVE; mysql&gt; SHOW SLAVE STATUS\G shutdown已有slave 由已有slave向新slave拷贝数据，包括log文件和relay log文件 拷贝完成，重启已有slave 配置新slave（注：唯一id） 启动新slave使用参数 –skip-slave-start ，查看状态信息是否正确 SHOW SLAVE STATUS 启动复制过程mysql&gt; START SLAVE; Problems In The Process 服务器之间ping通但是telnet不通解决方案： 清防火墙sudo iptables -F 开通防火墙响应端口（centos6常用的防火墙文件路径是/etc/sysconfig/iptables）1234开通防火墙端口22-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT开通防火墙端口3306-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT mysql配置文件位置：/etc/my.cnf（有些配置内容写在mysqld下生效，mysql_safe下无效） Error reading packet from server: Slave can not handle replication events with the checksum that master is configured to log; the first event ‘localhost-bin.000002’ at 123, the last event read from ‘./localhost-bin.000002’ at 123, the last byte read from ‘./localhost-bin.000002’ at 123. ( server_errno=1236) 这是由于 master 用的 mysql5.6 , binlog_checksum 默认设置的是 crc32。 如果slave用的 5.5 或者更早的版本，请将master的 binlog_checksum设置为 none。（binlog_checksum=none） mysqldump命令 1234mysqldump -u用户名 -p 数据库名 &gt; 导出的文件名.sqlmysqldump -u用户名 -p 数据库名 表名&gt; 导出的文件名.sqlmysqldump -u用户名 -p -d（只导出表结构参数） 数据库名 表名&gt; 导出的文件名.sql导入文件命令：mysql&gt;source d:wcnc_db.sql mysql数据库容量和表容量大小磁盘占用查看 查看该实例下各个库大小 123select table_schema, sum(data_length+index_length)/1024/1024 as total_mb, sum(data_length)/1024/1024 as data_mb, sum(index_length)/1024/1024 as index_mb, count(*) as tables, curdate() as today from information_schema.tables group by table_schema order by 2 desc; 查看单库下所有表的状态 123select table_name, (data_length/1024/1024) as data_mb , (index_length/1024/1024) as index_mb, ((data_length+index_length)/1024/1024) as all_mb, table_rows from information_schema.tables where table_schema = &apos;ifp&apos;; 或者在mysql数据文件物理路径下(/var/lib/mysql/)执行命令du -h查看各个数据文件所占空间大小 Could not initialize master info structure; more error messages can be found in the MySQL error log+Failed to open the relay log ‘./localhost-relay-bin.000001’ (relay_log_pos 4) 由于之前配置过，生成了一些relay文件，使得再次配置无法生成，删除掉之前生成的文件就可以。 mysql数据导入导出 导出使用mysqldump 较快，10分钟/亿级别 导入使用source命令时，在innodb引擎下较慢，可以将主键，索引先删除，引擎更改为myisam，之后完成数据导入后再添加主键，索引，更换引擎 采用直接拷贝数据文件来实现数据迁移，但是innodb的表，直接复制文件是无法使用的，会提示表不存在，在复制的时候，应将数据目录下的ibdata1文件一并复制过去，并且删除ib_logfile0，ib_logfile1等文件 mysql的root用户密码忘记了怎么办？ 进入配置文件：/etc/mysql/目录下 配置文件my.conf中可以直接配置，亦可以引入配置，例如如下12!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 添加skip-grant-tables 重新启动mysql即可进入 查看mysql库中user表root的相关信息，密码字段为authentication_string，内容为加密后的，可以直接将其设置为空，保存退出mysql， 修改配置文件将刚才添加的一行去掉，重启mysql登录]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>Replication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2018%2F12%2F16%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 什么是ThreadLocal 使用指南 实现原理 应用场景 Magic Number 0x61c88647 ##什么是ThreadLocal 早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。 ThreadLocal很容易让人望文生义，想当然地认为是一个“本地线程”。其实，ThreadLocal并不是一个Thread，而是Thread的局部变量，也许把它命名为ThreadLocalVariable更容易让人理解一些。 值得一提的是，在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal，之前为ThreadLocal。 使用样例 ThreadLocal一般声明为public static. 12345678910111213141516171819202122232425262728public class ThreadLocalTest &#123; public static ThreadLocal&lt;SimpleDateFormat&gt; dateFormat = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); &#125; &#125;; public static void main(String[] args)&#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-mm-dd&quot;); for (int i = 0;i &lt; 100;i++) &#123; printDate(); new Thread() &#123; @Override public void run() &#123; super.run(); alterAndpPrintDate(); &#125; &#125;.start(); &#125; &#125; public static void printDate()&#123; System.out.println(&quot;thread 1 :&quot; + threadLocal.get().format(new Date())); &#125; public static void alterAndpPrintDate()&#123; threadLocal.set(new SimpleDateFormat(&quot;yyyy-mm&quot;)); System.out.println(&quot;thread 2 :&quot; + threadLocal.get().format(new Date())); &#125;&#125; 实现原理 从下面的源码中可以看出：具体的ThreadLocalMap实例并不是ThreadLocal保持，而是每个Thread持有，且不同的Thread持有不同的ThreadLocalMap实例, 因此它们是不存在线程竞争的； ThreadLocalMap为ThreadLocal的一个内部类，用于保存线程共享变量的副本值 哈希冲突解决方案：碰撞时,会从当前位置开始向后环型遍历,找到一个空位置,这方法我们可以称之为线性探测法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261//获取共享变量副本过程如下public T get() &#123; Thread t = Thread.currentThread();//获取当前线程对象 /** 获取线程持有的ThreadLocalMap实例，该实例用来保存每个线程的共享变量副本 */ ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125;//从ThreadLocalMap实例中获取当前线程保存的变量副本，无则返回初始化值 return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;public class Thread&#123; /** ThreadLocal values pertaining to this thread. This map is maintained by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null;&#125;//设置共享变量副本过程如下public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;//ThreadLocal内部类ThreadLocalMapstatic class ThreadLocalMap &#123;//存储共享变量数据的Entry节点，继承自弱引用，随时可能被GC回收 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;//初始容量16，底层实现数组，扩容点默认0，设置规则为数组长度的2/3 private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int threshold; // Default to 0 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; //以一个初始值构造ThreadLocalMap ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; //以一个现成的ThreadLocalMap构造ThreadLocalMap private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125; //根据key值取value private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1);//根据哈希值计算key在数组中的位置 Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else //若是第一次没有取到值，可能是哈希冲突，也可能是弱引用key已经被GC回收，走下面这个方法处理 return getEntryAfterMiss(key, i, e); &#125; private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; //由于第一次哈希值对应数组位置中没能找到对应的key，则可能由于哈希冲突导致key遵循线性探测法解决冲突，因此从当前位置向后循环判定是否key向后移动了，同时清除key为null的value值，避免内存泄漏 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key)//若找到对应的key，直接返回 return e; if (k == null)//若key为null，怎清理过期值 expungeStaleEntry(i); else i = nextIndex(i, len);//向后移动数组继续判定 e = tab[i]; &#125; return null; &#125; private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //往里存数据时，避免哈希冲突，循环判定所处位置是否已经有值存在，是则数组索引后移，直到有一个空位置可以存放新值，如果期间找到了已经存在的旧值，即意味着要更新旧key的值，旧key不为null，直接覆盖其value值，否，将为null的key替换掉。 for (Entry e = tab[i];e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125; &#125; //替换过期数据 private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len);(e = tab[i]) != null;i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; for (int i = nextIndex(staleSlot, len);(e = tab[i]) != null;i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; //清除过期数据 private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i; &#125; private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed; &#125; //扩容必然导致重新哈希计算数组中的位置索引 private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize(); &#125; //扩容 private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab; &#125; private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125; &#125; &#125; 应用场景 ThreadLocal和其它同步机制相比有什么优势呢？ThreadLocal和其它所有的同步机制都是为了解决多线程中的对同一变量的访问冲突，在普通的同步机制中，是通过对象加锁来实现多个线 程对同一变量的安全访问的。这时该变量是多个线程共享的，使用这种同步机制需要很细致地分析在什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放该对象的锁等等很多。所有这些都是因为多个线程共享了资源造成的。ThreadLocal就从另一个角度来解决多线程的并发访问，ThreadLocal会为每一个线程维护一个和该线程绑定的变量的副本，从而隔离了多个线程的数据，每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的整个变量封装进ThreadLocal，或者把该对象的特定于线程的状态封装进ThreadLocal。 当然ThreadLocal并不能替代同步机制，两者面向的问题领域不同。同步机制是为了同步多个线程对相同资源的并发访问，是为了多个线程之间进行通信的有效方式；而ThreadLocal是隔离多个线程的数据共享，从根本上就不在多个线程之间共享资源（变量），这样当然不需要对多个线程进行同步了。所以，如果你需要进行多个线程之间进行通信，则使用同步机制；如果需要隔离多个线程之间的共享冲突，可以使用ThreadLocal，这将极大地简化我们的程序，使程序更加易读、简洁。ThreadLocal类为各线程提供了存放局部变量的场所。 应用 一：将request请求中的数据放入ThreadLocal中可以使得入参在整个请求流程中作为全局上下文使用（因为每一请求都会是一个独立的线程处理）应用二：用ThreadLocal保存session的值 每个线程访问数据库都应当是一个独立的Session会话，如果多个线程共享同一个Session会话，有可能其他线程关闭连接了，当前线程再执行提交时就会出现会话已关闭的异常，导致系统异常。此方式能避免线程争抢Session，提高并发下的安全性。 应用三：线程不安全的类在多线程中使用，如 SimpleDateFormat；在一个线程中修改不影响其他线程的使用。 java里面的变量的作用范围，有的是局部变量，有的是成员变量。局部变量永远不存在线程安全问题，成员变量是所有的线程所共享的，ThreadLocal的出现就弥补了这两种范围的一个不足，它比局部变量的范围要大，不仅仅是局限于一个方法块，但是又比成员变量的范围要小，因为它不会被多个线程共享，是线程独占的。 Magic Number 0x61c88647(32进制) ThreadLocal用到了map，就一定会存在冲突。而魔法数字0x61c88647的作用就是减少冲突并且增强数据的均匀分布性。 123456789101112/** 源码中线程局部变量哈希值通过原子类AtomicInteger每次加魔法数字0x61c88647而生成，为的就是让哈希码能均匀的分布在2的N次方的数组里 */private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;/** 底层数组扩容每次右移一位，保证数组大小始终为2的N次方；而哈希值和数组长度减一后的值进行与操作相当于取模操作，将变量存入指定数组位置中 */int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);int h = key.threadLocalHashCode &amp; (len - 1);int i = key.threadLocalHashCode &amp; (table.length - 1);&#125; 扩展 弱引用：弱引用还可以用来实现缓存。例如用弱哈希表，即通过弱引用来缓存各种引用对象的哈希表]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Sentinel]]></title>
    <url>%2F2018%2F12%2F09%2FRedis%20Sentinel%2F</url>
    <content type="text"><![CDATA[Redis Sentinel 哨兵能干什么？ 什么是哨兵模式？ 如何启动redis以哨兵模式？ 如何配置哨兵？ 部署哨兵模式需要注意什么？ 哨兵API 如何添加或者移除哨兵？ 订阅/发布消息 哨兵能干什么？ 监控：监控主从实例是否正常运行 通知：通知系统管理员、编程人员，运行实例出错了 自动失败策略：当master实例不在正常运行时，自动将其中一个slave上升为master，其他slave重新配置新的master，应用使用redis服务器通知的新master地址进行连接 配置提供者：哨兵作为客户端连接的权限关卡，所有的客户端连接哨兵索要master的连接地址，当master宕机时，哨兵会报告新master地址 什么是哨兵模式？ 哨兵模式是一种分布式系统 哨兵本身设计被运行在多个哨兵进程协同工作的环境中 保证master停止工作判定的正确性，多个哨兵同意方能确认该master真正停止工作 拥有故障转移系统本身就是一个单一的故障点并不是一件好事。 如何启动redis以哨兵模式？ redis-sentinel /path/to/sentinel.conf redis-server /path/to/sentinel.conf –sentinel 均需要配置文件sentinel.conf 哨兵模式启动默认端口TCP：26379，确保该端口开启保证哨兵之间的通话和决策，否则故障转移功能将无法奏效 注意： 至少三个哨兵实例保证 三个哨兵实例之间不能存在失败依赖关系，即将其放置到不同的物理服务器上或者不同的可用空间 由于Redis使用异步复制，因此不保证在失败期间保留已确认的写入，但是可以将写入丢失控制在一定时间内 并不是所有的客户端都会被哨兵模式支持，比较的流行的会 开发环境的多次测试才能换来生产环境的高可用安全 哨兵和docker混合使用时，要注意地址转换和端口匹配 如何配置哨兵？ 配置文件 sentinel monitor &lt;master-group-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; quorum参数：决策master不可达的哨兵数量 该参数仅仅用来检测master不可达，真正实际执行失败策略需要得到哨兵集群中大部分哨兵的决策同意，也就是说，当检测master不可达的哨兵数量达到quorum参数设置值的时候，检测不可达的其中一台哨兵可以尝试执行失败策略，但是如果该数量并没有到达哨兵集群数量的大多数，则失败策略实际并不会执行；只有当集群数量中大多数均认为该master不可达才会被授权真正实行失败策略。 sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt; down-after-milliseconds：认为该master不可达的时间限制，单位毫秒 parallel-syncs：失败策略执行后，同一时间可以重新配置新master地址的salve个数，该值设置越小，失败策略完成的越慢； 所有配置均可在运行时通过sentinel set命令设置 12345678910//只要mastername命名不同，哨兵即可配置多个master（可含有任意数量的slave）sentinel monitor mastername 127.0.0.1 6379 2sentinel down-after-milliseconds mastername 60000sentinel failover-timeout mastername 180000sentinel parallel-syncs mastername 1sentinel monitor mastername1 127.0.0.1 6379 2sentinel down-after-milliseconds mastername1 60000sentinel failover-timeout mastername1 180000sentinel parallel-syncs mastername1 1 部署哨兵模式需要注意什么？ 请至少部署三个哨兵实例在不同的物理机上（满足分布式的高可用） 当master不可达后，失败策略完成之前，连接该master的客户端上的所有写操作将会永久性丢失 解决方案：设置master被检测到不可同步写记录到指定数量的slave，然后指定时间后不再接受写操作 min-slaves-to-write 1（数量） min-slaves-max-lag 10（时间/s） 当服务器资源无法承载哨兵模式的最小数量3，可以将哨兵和客户端放置在一起 docker的端口映射：不同应用的同一端口会被docker映射成不同的端口暴露出去 端口和ip的映射可能对哨兵模式造成的影响 哨兵之间的自动发现是基于发送接收hello message给他们所监听的端口和ip，重要的是他们不知道啥叫ip、端口映射。 当展示master下的slave时，所有的slave会被列出在master的输出上，其中信息时通过tcp连接获得，而端口是在tcp三次握手时得到，映射操作可能会造成端口有误 实战指南 三个哨兵实例配置 文件如下： 123456789101112131415port 5000sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1port 5001sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1port 5002sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel parallel-syncs mymaster 1 redis-cli -p 5000：客户端登录哨兵实例1 sentinel master mymaster：查看被监控master信息 flags：表示master状态，master表示正常， s_down or o_down 表示异常 SENTINEL slaves mymaster：查看slave信息 SENTINEL sentinels mymaster：查看哨兵信息 SENTINEL get-master-addr-by-name mymaster：获取当前master的ip信息 redis-cli -p 6379 DEBUG sleep 30：手动测试失败策略，之后可查看master的ip信息已变更 哨兵API PING：连通性检测 sentinel masters：显示多有被监视的master列表和其状态 sentinel master ：显示指定master状态 sentinel slaves ：显示指定master下所有的slave的状态信息 sentinel sentinels ：显示指定master的哨兵列表信息状态 sentinel get-master-addr-by-name ：返回指定master的ip和端口 sentinel reset pattern&gt;：重置所有匹配到的master状态，清空所有目前的数据 sentinel failover ：如果master不可达，强制启动失败策略，不经过哨兵的同意 sentinel flushconfig：强制哨兵重写磁盘配置文件，包括当前哨兵状态 重新配置哨兵在运行时 哨兵订阅命令可以使得哨兵实例的配置跟新变得自动化，避免人为手动每个实例去更改 sentinel monitor ：根据所给信息重新配置哨兵的监控master sentinel remove ：移除指定master sentinel set ：更改指定master的配置参数 如何添加或者移除哨兵？ 基于哨兵的自动发现机制，只需要启动一台配置好当前活跃的master的哨兵实例即可，10秒中便内便会自动被其他哨兵发现并添加到哨兵列表中 若需要一次性添加多台哨兵实例，建议一台一台添加，等待其他所有的哨兵已经知晓被添加的第一台实例后再添加第二台 由于哨兵永远不会忘记已经见过的其他哨兵，所以哨兵的移除有些复杂 停止想要移除的哨兵实例进程 发送sentinel reset * 命令给所有其他哨兵实例，每个哨兵实例发送命令的时间间隔至少30秒 检查所有哨兵是否同意当前活跃哨兵实例个数（sentinel master mastername） 移除旧master或者不可达的slave 哨兵不会忘记所给master的所有的slave，即使他们不可达很长一段时间 发送命令sentinel reset mastername 给所有的哨兵，未来10秒哨兵会刷新slave列表，仅仅添加当前正在从master同步信息的slave 订阅/发布消息 客户端可以使用Sentinel，因为它是Redis兼容的发布/订阅服务器（但您不能使用PUBLISH），以便SUBSCRIBE或PSUBSCRIBE到频道并获得有关特定事件的通知。 频道名称和事件名称一致 PSUBSCRIBE *可以订阅所有频道得到所有信息 +reset-master ：订阅master重置reset信息 == @ 更多订阅信息命令请看：Redis–Pub/Sub Messages salve由优先级 redis有一个配置参数叫做slave-priority 哨兵根据这个信息来选出失败策略后新的master slave优先级设置为0,表示永远不可能晋升为master 优先级数字越小，越有可能晋升为master 权限问题 如果master配置需要客户端登录密码，则slave连接master同样需要该密码 requirepass：在master中，设置密码校验跳过对于那些无需验证的客户端 masterauth：在slave中，设置被master已认证，便于进行主从同步 哨兵连接配置了requirepass的master时需要使用一下命令 sentinel auth-pass 哨兵实例权限配置（redis5.0.1之后支持） requirepass “your_password_here”配置后所有的客户端连接均需要密码，哨兵之间的通讯也需要该密码 意味着所有的哨兵实例中配置同样的密码 哨兵模式的细节实现 自动发现机制 哨兵实例之间通过订阅/发布机制来互通信交换信息检测对方状态 该特性的实现通过往名为sentinel:hello的频道发送hello消息 每一个哨兵发布一条消息到它所监控的每一个master和slave发布/订阅频道sentinel:hello上，每两秒，公布他们目前的ip，port和运行id 每个哨兵订阅了每一个master和slave和频道sentinel:hello，去寻找未知的哨兵，一旦发现，加入本master的哨兵列表 hello信息包括当前master的完整配置信息，以供哨兵更新旧的配置信息 新哨兵加入之前总要检测目前列表中是否已存在同样runid的哨兵实例，确保移除添加互不冲突 Sentinel是一个系统，其中每个进程将始终尝试将最后一个逻辑配置强制应用于受监视实例集。 slave选举和优先级 衡量标准严格按照以下顺序进行 和master失连时间（超过10次master配置的超时时间，取消选举资格） salve优先级设置（优先级数字设置低的优先） 同步进度（同步进度快的优先） 运行id（小的运行id优先） epochs配置 标记配置版本信息，每一次失败策略触发更换master均会导致配置版本信息的迭代 更多实现细节待补充。。。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql插入去重]]></title>
    <url>%2F2018%2F12%2F02%2FMySql%E6%8F%92%E5%85%A5%E5%8E%BB%E9%87%8D%2F</url>
    <content type="text"><![CDATA[MySql插入去重 insert ignore… Replace into… insert into … ON DUPLICATE KEY UPDATE … 最近碰到一个数据迁移的需求： 基础环境为分库分表（四个分片库，1024张表），mysql数据库 需求为将某个表中的几个字段值抽取出来迁移到新的表中（新旧表之后会共存） 数据量约为2000万 应用服务器12台（8C，12G） 解决方案 业务代码改动，单写改双写，同时向新旧表写数据 业务代码改动上线后，旧表为全量数据，新表只有增量数据，需要将存量数据批量导入新表中 这个地方思维陷入了死胡同，好长一段时间僵持在找不到存量和增量数据的临界点在哪 单库单表向分库分表进行数据迁移的方案通常我们可以定一个MAX(自增主键)来区分存量和增量数据，或者其他可以代表全局唯一性的字段来作为临界点的参考对象，例如流水号，客户号，时间戳等 分库分表环境下，MAX(自增主键)明显不好使了，而且旧表中唯一能作为全局唯一性参考的字段只有客户号，但是由于业务原因，客户号无法作为临界点对象 在没有办法找到明显存量和增量数据的分界点时，我们怎么实现数据的迁移？ 存量和增量数据区分的本质是什么？—去重 之前考虑为题的方向是：拿取数据的时候就完成去重操作，之后直接插入新表即可。这种思路下必须找到新旧数据的分界点。 抛弃固有思维，我们可以将去重这个动作放到拿到数据之后再来完成，一种情况可以放到代码中来实现去重（受项目环境限制，实现较为复杂，考虑因素较多），另一种情况可以在插入新表的时候去完成去重操作（由数据库完成，操作简单） MySql INSERT语法官方文档地址 1234567891011121314151617181920212223242526272829INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ... [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] SET assignment_list [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] SELECT ... [ON DUPLICATE KEY UPDATE assignment_list]value: &#123;expr | DEFAULT&#125;value_list: value [, value] ...assignment: col_name = valueassignment_list: assignment [, assignment] ... IGNORE ：忽略由UNIQUE index or PRIMARY KEY造成的错误，可以理解为插入操作执行时，若发现表中已有该数据，则不执行该操作 insert ignore into table_name () vlaues() ON DUPLICATE KEY UPDATE：插入时若造成UNIQUE index or PRIMARY KEY冲突，更新指定字段的值 insert into table_name () values() on duplicate key update cloumn_name=cloumn_values,… MySql REPLACE语法12345678910111213141516171819202122232425262728REPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ...REPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] SET assignment_listREPLACE [LOW_PRIORITY | DELAYED] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] SELECT ...value: &#123;expr | DEFAULT&#125;value_list: value [, value] ...assignment: col_name = valueassignment_list: assignment [, assignment] ... 当检测到PRIMARY KEY or a UNIQUE index冲突时，删除旧数据，插入新数据（必须同时拥有插入，删除权限） replace into table_name () values();]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Idempotency]]></title>
    <url>%2F2018%2F11%2F25%2FIdempotency%2F</url>
    <content type="text"><![CDATA[Idempotency 何为幂等性 幂等实现方式 何为幂等性 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 应用场景 分布式环境下，我们经常会用到远程调用。但是远程调用不像本地调用，本地调用后的结果只有成功，失败两种情况。分布式环境中的远程调用多了一种超时的情况，超时本身又是不确定的一种状态，可能包含多种情况（调用成功但是返回中断，调用中断等等）。由此引出了幂等性验证。 何为幂等操作 幂等操作：update tab1 set col1 = 1 where id = 2（这样的更新语句，无论执行多少次结果都是不受影响的，所以是幂等的） 非幂等操作：update tab1 set col1 = col1 + 1 where id = 2http中幂等/非幂等方法 幂等方法 OPTIONS GET HEAD PUT DELETE 非幂等方法 POST PATCH 幂等实现方式 排重表dup_forbidden校验 好多业务表本身就具有排重表的功能（基于业务存在唯一的业务编号来设计实现的） 利用交易流水在数据库表里面设置的唯一约束来实现（可以在很长的时间范围内实现幂等控制） 123456begin transaction;count = insert ignore dup_forbidden (...biz_id...) value(...biz_id...)if (count &gt; 0) &#123; f(biz_id)&#125; commit;]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Idempotency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识分库分表]]></title>
    <url>%2F2018%2F11%2F18%2F%E5%88%9D%E8%AF%86%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[分库分表 分库分表 解决方案 部署上线 数据库拆分方案案例 引发问题 分库分表 分库 集群通过读写分离缓解了数据库的读取压力，但是由于master只能有一个且所有的写压力全部在master上，所以当单台资源无法承受海量的写压力时，便需要进行分库操作，将数据分摊在不同的分片资源机器上，写压力随即均分缓解。 分表 水平分表：将表中数据分配到多个表中存储，缓解单表量级 垂直分表：将表中字段分配到多个表中，缓解单表字段太多造成的读写压力 任何数据的切分均不是任意而为之，均需根据实际业务需要来操作，例如：数据有冷热之分，新旧之分，常用之分，渠道之分，来源之分，等等（字段同理），均可以作为切分维度，实际项目中需要根据业务需求做出相应的抉择。 不同维度的数据存储模式也不尽相同。例如： 热数据：存储于mysql中，操作实时性高 冷数据1：不经常使用，可以使用es存储，定期将部分数据降级为冷数据2 冷数据2：基本不会使用，可用使用hive存储，一旦使用到及升级为冷数据1 ##解决方案 分库分表必然需要中间件来做这一层工作，而且希望对于客户端是透明的，但是目前还没有一个一统江湖的中间件，列举一些大公司的解决方案供大家参考： 阿里 TDDL DRDS (基于阿里云的RDS 做分库分表的中间件) 开源 sharding-jdbc Atlas(Qihoo 360) alibaba.cobar(是阿里巴巴（B2B）部门开发) MyCAT（基于阿里开源的Cobar产品而研发） Oceanus(58同城数据库中间件) OneProxy(支付宝首席架构师楼方鑫开发) vitess（谷歌开发的数据库中间件） 部署上线分库分表后如何进行项目的部署上线 停机部署（常规做法） 取决于公司产品性质，如非电商公司产品，不具有海量的流量，尤其是夜间，几乎没有，所以可以选择夜间时间点停机部署 提前发布停机维护公告（夜间00:00-06:00） 数据迁移程序上线，开始数据迁移 将旧库数据通过中间件迁入新库 数据迁入完成，验证迁移前后数据的一致性 迁移程序下线 切换业务到新库，全面验证业务正确性 双写部署法（无需停机，会侵入业务代码） 统计计算历史数据（记录某一时刻的max（主键），然后将小于该max（主键）的称为历史数据，大于max（主键）的称为增量数据，历史数据直接由旧库迁往新库，增量数据动态写入消息队列中，随后再写入新库。（如何区分历史数据和增量数据除了用max（主键），还可以用时间字段排序等） 业务代码中新增往消息队列中发送操作sql的代码，只发送写sql操作，作为增量数据 迁移程序上线，迁移历史数据（通过中间件） 订阅程序上线，将消息队列中增量数据通过中间件写入新库 验证数据一致性，下线双写代码 切换业务至新库 历史数据发生变动怎么办：delete操作，update操作主要是，迁移之前执行的操作没有影响，迁移之后发生的操作会被记录在消息队列中作为增量数据更新掉发生变动的原始数据 数据一致性验证 全量验证，逐条数据验证 抽样验证，验证关键字段（例如：一次取出若干条数据拼接成字符串，然后md5 加密，最后比较字符串的一致性） 数据库拆分方案案例背景介绍 两个应用独立部署，资源独立，但是数据库共享，现需要将其中一个应用数据拆分到新的数据库资源机器上。 环境资源 测试环境：一主一从一备，四分片，12 台机器 生产环境：一主两从三备，四分片，24台机器 拆分方案步骤 从资源集群中摘下备库，拷贝其数据，注意：方案为直接拷贝mysql数据目录，而不是导出insert.sql语句，拷贝完成后将备库再挂上去（备库摘下与挂上的两个阶段前后均需一段平稳的交易模拟压测，查看两个步骤对旧系统交易的影响有多大） 将拷贝好的数据目录拷贝到新资源集群的所有机器中（新集群中主从备关系已经搭建好，但是未开启同步），然后再次开启压测 紧接着将新集群中master挂载到旧集群中的master下作为该从库进行增量数据的同步，压测持续监测数据同步对旧系统交易的影响 新集群master挂载好了之后便逐个开启新集群中主从备的同步，加大了同步压力（相当于将一整个主从备的集群挂载到了旧集群master下），压测持续监测旧系统的交易TPS变化，当数据同步完成后即可开始将应用切换至新数据库资源集群 数据同步完成后，旧系统中关闭要拆出的那个应用的所有写交易开关，只留下读交易 然后切断新集群中master与旧集群中master的主从连接， 测试版一组接入新数据库资源进行测试，测试版读写交易均可进行 通过后将正式版二组切换至新数据库资源测试 二组测试通过上第三组，否回退 开启写交易开关验证写交易 切换正式版一组 开始全面业务验证 引发问题 水平拆分后的count() 操作： count相加，单个count在相加，效率慢 更新记录数表，写压力增大，容易不一致 定时更新记录数表（前两者结合） 跨库事务难以实现 要避免在一个事务中同时修改数据库db0和数据库db1中的表，因为操作起来很复杂 切分维度导致的查询问题： 聚合分片查询结果：查询排序分页—使用到了归并排序—最大分页限制 冗余多份数据：全局表，冗余表，字段冗余]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型无处不在]]></title>
    <url>%2F2018%2F11%2F04%2F%E6%B3%9B%E5%9E%8B%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%2F</url>
    <content type="text"><![CDATA[Generic 泛型的使用 泛型的实现 泛型的改进 泛型的使用&lt;\T&gt; 类型参数T：用来表示不确定的某种类型；基本类型无法作为类型参数，但是Java5以后具有了自动组包拆包的功能。 泛型接口 创建对象时必须指定类型参数的值，一旦类型指定就不能在改变了 public interface Demo{ T t;} 泛型方法 泛型方法优先级高于泛型接口，即优先考虑使用泛型方法，再使用泛型接口 泛型方法由于类型参数推断能力，每次调用都相当于重新判定其类型参数的值 public void display(T t){} 可变参数和泛型方法 1234567891011121314151617181920212223public &lt;T&gt; List&lt;T&gt; display(T... args)&#123; List&lt;T&gt; list = new LinkedList&lt;&gt;(); for(T item : args)&#123; list.add(item); &#125; return list;&#125;//生成器Generatorclass BaseGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; private Class&lt;T&gt; type; public BaseGenerator(Class&lt;T&gt; type)&#123; this.type = type; &#125; public T next()&#123; try &#123; return type.newInstance(); &#125;catch(Exception e)&#123;e.printStackTrace();&#125; return null; &#125; public &lt;T&gt; Generator&lt;T&gt; create(Class&lt;T&gt; type)&#123; return new BaseGenerator&lt;T&gt;(type); &#125;&#125; Set泛型工具类(瞅瞅enmuset的用法) 1234567891011121314151617181920class Sets&#123; public static &lt;T&gt; Set&lt;T&gt; union(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a);//不改变原参数，复制一个新值 result.addAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; intersction(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a); result.retainAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; differences(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; Set&lt;T&gt; result = new HashSet&lt;&gt;(a); result.removeAll(b); return result; &#125; public static &lt;T&gt; Set&lt;T&gt; complements(Set&lt;T&gt; a,Set&lt;T&gt; b)&#123; return differences(union(a,b),intersction(a,b)); &#125;&#125; 匿名内部类和泛型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647泛型前interface Animal&#123; void next();&#125;class Dog implements Animal&#123; public void next()&#123;&#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal animal1 = new Animal() &#123; @Override public void next() &#123; &#125; &#125;;&#125;泛型后interface Animal&lt;T&gt;&#123; void next(T t);&#125;class Dog&lt;T&gt; implements Animal&lt;T&gt;&#123; public void next(T t)&#123;&#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal&lt;T&gt; animal1 = new Animal&lt;T&gt;() &#123; @Override public void next(T t) &#123; &#125; &#125;;&#125;lambda表达式与泛型interface Animal&lt;T&gt;&#123; void next(T t);&#125;class Dog&lt;T&gt; implements Animal&lt;T&gt;&#123; public void next(T t)&#123; System.out.println(t.toString()); &#125;&#125;public void display()&#123; Animal animal = new Dog(); Animal&lt;T&gt; animal1 = (T t)-&gt;&#123; System.out.println(t.toString()); &#125;;&#125; 泛型+元组 可用于一次方法调用返回多个对象的应用需求 12345678910111213public class Twotuple&lt;A,B&gt;&#123; public static A a; public static B b; public Twotuple(A a,B b)&#123; this.a = a; this.b = b; &#125;&#125;public class Tuple&#123; public static &lt;A,B&gt; TwoTuple&lt;A,B&gt; tuple(A a,B b)&#123; return new TwoTuple&lt;A,B&gt;(a,b); &#125;&#125; 泛型的实现 类型擦除 java泛型的实现是通过擦除来实现，由于不是从语言诞生一开始就引入的特性，所以具有一定的局限性 类型擦除：顾名思义任何具体的类型信息都被擦除了，我们将无法获取这些信息 由于类型信息的擦除，参数T将丧失某些操作能力，如转型，instanceof操作，new表达式等操作，但是针对各个缺失均由相应的补偿措施 边界 在泛型的参数类型上设置限制条件成为泛型的边界设置 关键字extends（多个继承关系存在时，类在前，接口在后） ,, 泛型参数无法设置超类边界 可用于扩展复杂结构层次 通配符 通配符的作用是用来修饰、限制泛型参数类型的，其含义相当于Object的作用 有界通配符 &lt;? extends Class&gt; &lt;? super Class&gt;、&lt;? super T&gt; 无界通配符 &lt;?&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//擦除导致泛型所缺失的操作能力如下class Erased&lt;T&gt;&#123; public void f(Object arg)&#123; if (arg instanceof T)&#123;&#125;//error1无法类型判断 T var = new T();//error2（C++中该操作相当正确）无法实例化 T[] array = new T[5];//error3无法创建泛型数组 T[] arrayO = (T[]) new Object[5];//unchecked warning泛型转型警告 &#125;&#125;//error1的补偿实现：引入类型标签（其实就是将obj instanceof class改为了class.isInstance(obj)）class Erased&lt;T&gt;&#123; Class&lt;T&gt; type; Erased(Class&lt;T&gt; type)&#123; this.type = type; &#125; public boolean f(Object arg)&#123; return type.isInstance(arg); &#125;&#125;//error2的补偿实现：传入一个工厂对象，例如Class对象，使用newInstance()来创建泛型类型对象class Erased&lt;T&gt;&#123; T t; public void f(Class&lt;T&gt; type)throws Exception&#123; t = type.newInstance(); &#125;&#125;//自己编写一个显示的工厂类public class Main &#123; public static void main(String[] agrs)&#123; FactoryA factoryA = new FactoryInteger(); new FactoryProxy(factoryA); &#125; interface FactoryA&lt;T&gt;&#123; T create(); &#125; static class FactoryProxy&#123; &lt;F extends FactoryA&lt;T&gt;&gt; FactoryProxy(F factory)&#123; factory.create(); &#125; &#125; static class FactoryInteger implements FactoryA&lt;Integer&gt;&#123; @Override public Integer create() &#123; return new Integer(10); &#125; &#125; class FactoryString implements FactoryA&lt;String&gt;&#123; @Override public String create() &#123; return new String(&quot;hello&quot;); &#125; &#125;&#125;//error3补偿实现方式：使用ArrayList代替数组List&lt;T&gt; list = new ArrayList&lt;T&gt;(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//样例1：java编译无法通过（C++编译器却可以通过）class Hasf&#123; public void display()&#123;&#125;&#125;class Manipulator&lt;T&gt;&#123; T obj; Manipulator(T t)&#123; this.obj = t; &#125; public void manipulator()&#123; obj.display();//编译器无法知道参数类型具体到底是谁，所以无法进行方法调用 &#125;&#125;public void check()&#123; Hasf hasf = new Hasf(); Manipulator&lt;Hasf&gt; manipulator = new Manipulator&lt;&gt;(hasf); manipulator.manipulator();&#125;//样例2：将类型参数值加上边界java编译即可通过class Hasf&#123; public void display()&#123;&#125;&#125;class Manipulator&lt;T extends Hasf&gt;&#123;//指定参数类型的边界后，类型擦除实际上是将T擦除到了Hasf类型，等价于class Manipulator&lt;Hasf&gt; T obj; Manipulator(T t)&#123; this.obj = t; &#125; public void manipulator()&#123; obj.display();//由于指定了类型边界，编译器便可以知道具体类型 &#125;&#125;public void check()&#123; Hasf hasf = new Hasf(); Manipulator&lt;Hasf&gt; manipulator = new Manipulator&lt;&gt;(hasf); manipulator.manipulator();&#125;//样例3：使用泛型&lt;T extends Hasf&gt;比直接使用&lt;Hasf&gt;的好处在于：当一个类有一个返回T的方式时，该方法可以返回具体确切的类型class Manipulator&lt;T extends Hasf&gt;&#123; T obj; public T getManipultor()&#123; return obj; &#125; &#125;//样例4：instanceof验证public &lt;T&gt; void checkBaseType(T t)&#123; if(t instanceof String)&#123;//这种写法是可行的，但是var instanceof T这种是不可行的 System.out.println(&quot;T 类型为字符串类型&quot;); &#125; if(t instanceof Integer)&#123; System.out.println(&quot;T 类型为整型类型&quot;); &#125; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125;&#125;//等价于public void checkBaseType(Object t)&#123; if(t instanceof String)&#123; System.out.println(&quot;T 类型为字符串类型&quot;); &#125; if(t instanceof Integer)&#123; System.out.println(&quot;T 类型为整型类型&quot;); &#125; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125;&#125;//样例4.1public &lt;T extends Hasf&gt; void checkBaseType(T t)&#123; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125; if(t instanceof HasfB)&#123; System.out.println(&quot;T 类型为HasfB类型&quot;); &#125;&#125;等价于public void checkBaseType(Hasf t)&#123; if(t instanceof HasfA)&#123; System.out.println(&quot;T 类型为HasfA类型&quot;); &#125; if(t instanceof HasfB)&#123; System.out.println(&quot;T 类型为HasfB类型&quot;); &#125;&#125;//样例5：转型验证 public class Main &#123; public static void main(String[] agrs)&#123; String[] str = create(String.class,5); Arrays.fill(str,&quot;hello&quot;); System.out.println(Arrays.toString(str)); &#125; public static &lt;T&gt; T[] create(Class&lt;T&gt; type,int size)&#123; T[] array = (T[])Array.newInstance(type,size); return array; &#125;&#125; 泛型的改进 类型参数推断 从泛型参数列表中一个参数推断出另一个参数（编译器从8开始支持） Map map = new HashMap();—之前，为了避免重复性的代码，可以使用工具类New Map map = new HashMap&lt;&gt;();—之后 任何基本类型不能作为类型参数（自动组包拆包解决了该问题） 一个类不能实现同一个泛型接口的两种变体（由于擦除原因会被认为是两个相同的接口） 方法的重载（由于擦除原因会被认为是两个相同的方法） java5泛型之前，我们存入容器中的内容均被向上转型为object，当取出时，必须向下转型为具体的类型 123456789101112class New&#123; public static &lt;K,V&gt; Map&lt;K,V&gt; map()&#123; return new HashMap&lt;K,V&gt;(); &#125; public static &lt;K&gt; List&lt;K&gt; list()&#123; return new LinkedList&lt;K&gt;(); &#125; public static &lt;K&gt; Set&lt;K&gt; set()&#123; return new HashSet&lt;K&gt;(); &#125;&#125;Map&lt;String,String&gt; map = New.map(); 12Map map = new HashMap()//不采用泛型，可存放任意类型的键值对Map&lt;String,String&gt; map = new HashMap&lt;&gt;();//采用泛型指定参数类型只能存放字符串类型的键值对]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Generic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introspector]]></title>
    <url>%2F2018%2F10%2F28%2FJAVA_%E5%86%85%E7%9C%81%2F</url>
    <content type="text"><![CDATA[Introspector 内省(Introspector) 是Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”。方法比较少。这些信息储存在类的私有变量中，通过set()、get()获得。 反射就是运行时获取一个类的所有信息，可以获取到.class的任何定义的信息（包括成员 变量，成员方法，构造器等）可以操纵类的字段、方法、构造器等部分。 内省基于反射实现，主要用于操作JavaBean，通过内省 可以获取bean的getter/setter 生活中 反射就像我们照镜子，照镜子时候 你的所有信息会毫无出错毫无保留的反射到镜子中，而java中反射就像是运行时用一把镜子去照.class字节码 将这个类的所有信息照出来，‘照’出的结果是客观的，是正确的；内省就像我们反省自己，通常我们是针对犯错而进行反省，根据所犯错误反省总结出结论，这个结论是主观的，不一定正确的，有时候你觉得你自己做错了，但可能事实上自己无可厚非。java中内省，是针对javaBean进行的，目的是为了找出bean的getter和setter以便操作这个bean。只要看到有getter或者setter 就认为这个类有那么一个字段，比如看到getName() 内省就会认为这个类中有name字段，但事实上并不一定会有name； 应用：将map转换成object bean对象123456789101112131415161718192021222324252627282930313233343536373839404142public &lt;T&gt; T mapToBean(Map map, Class&lt;T&gt; tClass) &#123; if (map == null) &#123; return null; &#125; else &#123; Object object = null; try &#123; object = tClass.newInstance(); BeanInfo beanInfo = Introspector.getBeanInfo(tClass); PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); PropertyDescriptor[] arr$ = propertyDescriptors; int len$ = propertyDescriptors.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; PropertyDescriptor propertyDescriptor = arr$[i$]; if (propertyDescriptor.getReadMethod() != null &amp;&amp; propertyDescriptor.getWriteMethod() != null) &#123; String propertyTypeName = propertyDescriptor.g Object value = map.get(JsonUtils.convertUpperCase(propertyTypeName)); if (value != null) &#123; if (propertyDescriptor.getPropertyType() != Long.class &amp;&amp; propertyDescriptor.getPropertyType() != Long.TYPE) &#123; if (propertyDescriptor.getPropertyType() != Double.TYPE &amp;&amp; propertyDescriptor.getPropertyType() != Double.class) &#123; if (propertyDescriptor.getPropertyType() != Integer.TYPE &amp;&amp; propertyDescriptor.getPropertyType() != Integer.class) &#123; propertyDescriptor.getWriteMethod().invoke(object, value); &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseInt(value)); &#125; &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseDouble(value)); &#125; &#125; else &#123; propertyDescriptor.getWriteMethod().invoke(object, BatchUtils.parseLong(value)); &#125; &#125; &#125; &#125; &#125; catch (Exception var12) &#123; ; &#125; return object; &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Introspector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC BATCH]]></title>
    <url>%2F2018%2F10%2F21%2FJDBC_Batch%2F</url>
    <content type="text"><![CDATA[JDBC BATCH JDBC基础知识复盘 JDBC BATCH 批处理执行sql JDBC基础知识复盘 复盘（使用jdbc增删改查） 12345678910111213141516171819202122232425//1. 引入对应数据库的驱动jar包//2. 加载数据库驱动Class.forName(&quot;sun.jdbc.odbc.JdbcOdbcDriver&quot;);//3. 与数据库建立连接Connection con = DriverManager.getConnection(&quot;jdbc:odbc:wombat&quot;,&quot;login&quot;,&quot;password&quot;);//4. 编写执行sqlString sql = &quot;INSERT INTO TABLEX VALUES(?, ?)&quot;;//5.1 预编译sql，防止sql注入（PreparedStatement extends Statement）PreparedStatement stmt = con.prepareStatement(sql); //5.2 设置sql语句的参数实际值stmt.setInt(1, 1);stmt.setString(2, &quot;Cujo&quot;); /** 或者使用非预编译方式（不推荐使用）：Statement stmt = con.createStatement(); *///6. 执行sql返回结果/** executeQuery执行查询类sql，返回结果集ResultSet * executeUpdate执行维护类sql，返回行数int * execute执行所给sql，返回boolean，适用于动态执行sql，返回结果有多种的情况 */ResultSet rs = stmt.executeQuery(sql);//ResultSet rs = stmt.executeUpdate(sql);while (rs.next()) &#123; int x = rs.getInt(&quot;a&quot;); String s = rs.getString(&quot;b&quot;); float f = rs.getFloat(&quot;c&quot;);&#125; Tip！！！ 为了避免像以下这种情况（单一重复性的工作，将数据库表对象的记录值存放到java对象中）的出现，衍生了数据库表和javaBean对象之间的映射关系框架123456789101112&gt; String selectSql = &quot;SELECT * FROM employees&quot;; ResultSet resultSet = stmt.executeQuery(selectSql); List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); while (resultSet.next()) &#123; Employee emp = new Employee(); emp.setId(resultSet.getInt(&quot;emp_id&quot;)); emp.setName(resultSet.getString(&quot;name&quot;)); emp.setPosition(resultSet.getString(&quot;position&quot;)); emp.setSalary(resultSet.getDouble(&quot;salary&quot;)); employees.add(emp); &#125;&gt; 盲区 使用jdbc调用存储过程 123456789101112//调用存储过程String preparedSql = &quot;&#123;call insertEmployee(?,?,?,?)&#125;&quot;;CallableStatement cstmt = con.prepareCall(preparedSql);//设置入参cstmt.setString(2, &quot;ana&quot;);cstmt.setString(3, &quot;tester&quot;);cstmt.setDouble(4, 2000);//设置出参cstmt.registerOutParameter(1, Types.INTEGER);//执行存储过程，获取出参cstmt.execute();int new_id = cstmt.getInt(1); 修改ResultSet 12345678Statement updatableStmt = con.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_UPDATABLE);ResultSet updatableResultSet = updatableStmt.executeQuery(selectSql);updatableResultSet.moveToInsertRow();updatableResultSet.updateString(&quot;name&quot;, &quot;mark&quot;);updatableResultSet.updateString(&quot;position&quot;, &quot;analyst&quot;);updatableResultSet.updateDouble(&quot;salary&quot;, 2000);updatableResultSet.insertRow(); 获取数据库表信息 123456DatabaseMetaData dbmd = con.getMetaData();//getTables该方法返回TABLE_TYPE, TABLE_SCHEM TABLE_NAME这几个表描述信息，其他信息可参考源码ResultSet tablesResultSet = dbmd.getTables(null, null, &quot;%&quot;, null);while (tablesResultSet.next()) &#123; LOG.info(tablesResultSet.getString(&quot;TABLE_NAME&quot;));&#125; 获取ResultSet中的列总数和列名 123456789ResultSetMetaData rsmd = rs.getMetaData();int nrColumns = rsmd.getColumnCount();IntStream.range(1, nrColumns).forEach(i -&gt; &#123; try &#123; LOG.info(rsmd.getColumnName(i)); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;&#125;); Transactions事务操作 12345678910111213141516171819202122232425//操作一String updatePositionSql = &quot;UPDATE employees SET position=? WHERE emp_id=?&quot;;PreparedStatement pstmt = con.prepareStatement(updatePositionSql);pstmt.setString(1, &quot;lead developer&quot;);pstmt.setInt(2, 1);//操作二 String updateSalarySql = &quot;UPDATE employees SET salary=? WHERE emp_id=?&quot;;PreparedStatement pstmt2 = con.prepareStatement(updateSalarySql);pstmt.setDouble(1, 3000);pstmt.setInt(2, 1);//获取当前连接自动提交状态，true或者falseboolean autoCommit = con.getAutoCommit();try &#123; //取消默认每执行一条sql语句就自动提交，改为手动提交状态 con.setAutoCommit(false); pstmt.executeUpdate(); pstmt2.executeUpdate(); //手动提交，操作一，操作二作为一整个原子操作执行 con.commit();&#125; catch (SQLException exc) &#123; con.rollback();&#125; finally &#123; //还原默认提交状态 con.setAutoCommit(autoCommit);&#125; JDBC BATCH 批处理执行sql Batch Processing Using Statement 123456789Statement statement = connection.createStatement();statement.addBatch(&quot;INSERT INTO EMPLOYEE(ID, NAME, DESIGNATION) &quot; + &quot;VALUES (&apos;1&apos;,&apos;EmployeeName&apos;,&apos;Designation&apos;)&quot;);statement.addBatch(&quot;INSERT INTO EMP_ADDRESS(ID, EMP_ID, ADDRESS) &quot; + &quot;VALUES (&apos;10&apos;,&apos;1&apos;,&apos;Address&apos;)&quot;);statement.executeBatch();``` - ### Batch Processing Using PreparedStatement String[] EMPLOYEES = new String[]{“Zuck”,”Mike”,”Larry”,”Musk”,”Steve”};String[] DESIGNATIONS = new String[]{“CFO”,”CSO”,”CTO”,”CEO”,”CMO”};String insertEmployeeSQL = “INSERT INTO EMPLOYEE(ID, NAME, DESIGNATION) “ “VALUES (?,?,?)”;PreparedStatement employeeStmt = connection.prepareStatement(insertEmployeeSQL);for(int i = 0; i &lt; EMPLOYEES.length; i++){ String employeeId = UUID.randomUUID().toString(); employeeStmt.setString(1,employeeId); employeeStmt.setString(2,EMPLOYEES[i]); employeeStmt.setString(3,DESIGNATIONS[i]); employeeStmt.addBatch();}employeeStmt.executeBatch();```]]></content>
      <categories>
        <category>JDBC</category>
      </categories>
      <tags>
        <tag>JDBC</tag>
        <tag>BATCH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux File Transfer]]></title>
    <url>%2F2018%2F10%2F21%2FLinux%20File%20Transfer%2F</url>
    <content type="text"><![CDATA[Linux File Transfer scp rsync nc ssh SCPNAMEscp - secure copy (remote file copy program) SYNOPSISscp [-1246BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2 DESCRIPTION 使用ssh协议进行数据传输 不像rcp，ssh协议要求密码或秘钥如果需要认证 目标文件如果已存在，直接覆盖 常用参数 -B 批处理模式，避免询问密码或秘钥 -C 开启压缩模式，可加快传输速度 -P port 连接远程主机端口号 -p 保留源文件的修改时间，访问时间，和模式 -q 安静模式：禁用进度表以及警告和来自ssh（1）的诊断消息。 -r 整个文件夹传输，包含当前文件夹（默认为文件夹下的所有内容，不包含文件夹本身） -v 打印过程日志，便于debug EXAMPLE 将本地文件拷贝到远程服务器： scp -P port ufile user@host:~/ufile 将远程服务器中的文件拷贝到本地的用法： scp -P port user@host:~/ufile ufile 将本机sql文件传输到192.168.184.132主机的/home/liufein/mysql路径下 scp -C ifp_table.sql root@192.168.184.132:/home/liufein/mysql 将本机文件夹test传输到192.168.184.132主机的/home/liufein路径下 scp -r -C test root@192.168.184.132:/home/liufein RSYNCNAMErsync -- a fast, versatile, remote (and local) file-copying tool SYNOPSISLocal: rsync [OPTION...] SRC... [DEST] Access via remote shell: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST Access via rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST COMMON PARAMETERS -q, 安静模式，只打印错误信息 -c, 跳过基于checknum的检测 -r, 递归目录 -R, 使用相对路径名 -d, 传输目录而不递归 -p, 保留权限 -z, 传输过程压缩文件 -f, –filter=RULE 添加文件过滤规则 -v, 增加传输过程中的信息显示 -a, 递归保留所有的内容 EXAMPLE rsync with ssh(通过SSH通道传输数据) rsync使用SSH通道传输数据时，配置比较简单，只要配置好了SSH，就直接可用，不需要额外的操作，正是这个原因，很多人更喜欢使用这种方式来使用rsync。与直接使用SSH传输数据时间基本一样。 本地到远程：rsync -zav --rsh=&apos;ssh -p 22&apos; ufile user@host:path 远程到本地：rsync -zav --rsh=&apos;ssh -p 22&apos; user@host:path ufile rsync with daemon(通过与服务器的rsync守护者(daemon)进程建立连接来传输数据) 不同于SCP和SFTP，rsync是一套独立的软件，除了通过SSH通道传输数据以外，还可以通过rsync的守护者进程进行数据传输。（该命令实现较为复杂，需配置配置文件，这里不做详细介绍，只是简单介绍一下执行命令） rsync -avz ufile user@host::module_name NCNAMEnc - arbitrary TCP and UDP connections and listens SYNOPSISnc [-46DdhklnrStUuvzC] [-i interval] [-p source_port] [-s source_ip_address] [-T ToS] [-w timeout] [-X proxy_protocol] [-x proxy_address[:port]] [hostname] [port[s]] COMMON PARAMETERS -D 允许debug -d 不从stdin中读取内容 -i interval 内容传输的时间间隔 -k 当前连接结束后强制监听另一连接 -n Do not do any DNS or service lookups on any specified addresses, hostnames or ports. -p source_port端口 -r 随机选择端口 -S Enables the RFC 2385 TCP MD5 signature option. -s source_ip_address源IP地址 -u 使用udp而不是默认的tcp -v 更详细的日志输出 -w timeout超时 -z 只监听，不发送数据 -l 用于指定nc应侦听传入连接，而不是启动与远程主机的连接。 DATA TRANSFER The example in the previous section can be expanded to build a basic data transfer model. Any information input into one end of the connection will be output to the other end, and input and output can be easily captured in order to emulate file transfer. Start by using nc to listen on a specific port, with output captured into a file: $ nc -l 1234 &gt; filename.out Using a second machine, connect to the listening nc process, feeding it the file which is to be transferred: $ nc host.example.com 1234 &lt; filename.in After the file has been transferred, the connection will close automatically. EXAMPLES首先在数据接收方的机器上侦听指定端口 在本机8210端口侦听TCP连接，将收到的数据写入文本文件 nc -l -p 8210 &gt; demo.txt 在本机8210端口侦听TCP连接，将收到的数据写成压缩文件 nc -l -p 8210 &gt; demo.tar.bz2 然后在数据发送方机器上向指定地址(ip+port)以TCP方式发送数据 向ip为dest_ip的机器的8210端口发送demo.txt文件 nc dest_ip 8210 &lt; demo.txt 压缩后发送 nc dest_ip 8210 &lt; $(tar -jcvf demo.tar.bz2 demo.txt) SSH 将本地的数据传输到远程服务器的用法： gzip -c ufile | ssh -p port user@host &#39;gunzip &gt;ufile&#39; 将远程服务器传输到本地的用法 ssh -p port user@host &quot;gzip -c ufile&quot; | gunzip -c &gt; ufile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SCP</tag>
        <tag>NC</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java SizeOf]]></title>
    <url>%2F2018%2F10%2F14%2FJAVA_SizeOf%2F</url>
    <content type="text"><![CDATA[Java SizeOf 计算java中对象所占内存空间大小 Java对象结构 内存对齐 Jvm中对象字段的排列顺序 Instrumentation的getObjectSize()方法获取对象的大小 Java对象结构普通对象的结构如下（按64位机器的长度计算） 对象头(_mark)， 8个字节 Oop指针，如果是32G内存以下的，默认开启对象指针压缩，4个字节 数据区 Padding(内存对齐)，按照8的倍数对齐，每8个字节为一组 数组对象结构如下 对象头(_mark)， 8个字节 Oop指针，如果是32G内存以下的，默认开启对象指针压缩，4个字节 数组长度，4个字节 数据区 Padding(内存对齐)，按照8的倍数对齐，每8个字节为一组 对象属性中根据基本类型算，将结果相加，但要考虑引用指针占用的空间（64位 JVM 压缩指针，不压缩） 当JVM最大内存小于32GB时，自动打开压缩指针特性 内存对齐 为什么需要内存对齐？32位cpu一次性可以读取32bit的数据（也就是四个字节），64位cpu一次性可以读取64bit的数据（也就是8个字节），如果不采用内存对齐，本来可以一次性就读取完成的数据可能需要两次读取才能完成，所以为了提高cpu读取数据性能，提出了内存对齐的概念。 内存对齐算法 初级算法: 1234567//n为起始地址，align为字节对齐数unsigned int calc_align(unsigned int n,unsigned align) &#123; if ( n / align * align == n) return n; return (n / align + 1) * align; &#125; 大神算法： 12345678910111213141516171819202122232425262728293031323334unsigned int calc_align(unsigned int n,unsigned align) &#123; return ((n + align - 1) &amp; (~(align - 1))); &#125; ``` &gt; ### 大神思路是这样的：&gt; 2字节对齐，要求地址位为2,4,6,8...，要求二进制位最后一位为0（2的1次方）4字节对齐，要求地址位为4,8,12,16...，要求二进制位最后两位为0（2的2次方）8字节对齐，要求地址位为8,16,24,32...，要求二进制位最后三位为0（2的3次方）16字节对齐，要求地址位为16,32,48,64...，要求二进制位最后四位为0（2的4次方）...由此可见，我们只要对数据补齐对齐所需最少数据，然后将补齐位置0就可以实现对齐计算。（1）(align-1)，表示对齐所需的对齐位，如：2字节对齐为1，4字节为11，8字节为111，16字节为1111...（2）(x+(align-1))，表示x补齐对齐所需数据 （3）&amp;~(align-1)，表示去除由于补齐造成的多余数据（4） (x+(align-1))&amp;~(align-1)，表示对齐后的数据## Jvm中对象字段的排列顺序- 默认的顺序如下：从长到短排列，引用排最后: long/double –&gt; int/float –&gt; short/char –&gt; byte/boolean –&gt; Reference- 这个顺序可以使用JVM参数: -XX:FieldsAllocationSylte=0(默认是1)来改变。（直接按照实际顺序排列）## Instrumentation的getObjectSize()方法获取对象的大小- Shallow Size，即遇到引用时，只计算引用的长度，不计算所引用的对象的实际大小。如果要计算所引用对象的实际大小，可以通过递归的方式去计算- Instrumentation的实例必须通过指定javaagent的方式才能获得 - 1. 定义一个类，提供一个premain方法: public static void premain(String agentArgs, Instrumentation instP) 2. 创建META-INF/MANIFEST.MF文件，内容是指定PreMain的类是哪个： Premain-Class: sizeof.ObjectShallowSize 3. 把这个类打成jar，然后使用jvm参数 -javaagent java-agent-sizeof.jar 启动main类 4. 在idea中引入java-agent-sizeof.jar包，然后编写启动类，设置启动jvm参数如下，运行 4. -javaagent:D:\Administrator\Tools\maven\repository\dcits\liufein\java-agent-sizeof.jar&gt; jar打包命令：jar cvfm java-agent-sizeof.jar META-INF/MANIFEST.MF - 三方工具开源的sizeOf.jar （实现原理就是Instrumentation的getObjectSize）可直接使用 ### 具体类编写如下 //jvm启动参数jar包中的类，用于使用Instrumentationpackage sizeof;import java.lang.instrument.Instrumentation;public class ObjectShallowSize { private static Instrumentation inst; public ObjectShallowSize() { } public static void premain(String agentArgs, Instrumentation instP) { inst = instP; } public static long sizeOf(Object obj) { return inst.getObjectSize(obj); }}//jvm启动参数jar包中的配置文件MANIFEST.MF内容Premain-Class: sizeof.ObjectShallowSize//实际启动类（实际需要调用Instrumentation方法getObjectSize的类）public static void main(String [] args){ System.out.println(sizeof.ObjectShallowSize.sizeOf(new ObjectA())); }``` 扩展 使用Runtime不精确计算对象占用内存空间 Runtime run = Runtime.getRuntime(); run.totalMemory()-run.freeMemory()) Runtime.getRuntime().gc();手动GC 通过sun.misc.Unsafe对象的objectFieldOffset(field)等方法结合反射来定位对象字段排列顺序 通过反射获取到对象的field 然后通过unsafe的objectFieldOffset(field)方法获取每个field的offset（偏移量，可以定位field的排列顺序）-javaagent 参数 这个参数是 JDK5 引入的，可以通过 java -h 查看其帮助信息 通过使用 -javaagent 参数，用户可以在执行 main 函数前执行指定 javaagent 包中的特定代码，甚至可以动态的修改替换类中代码。 javaagent 的代码与你的 main 方法在同一个 JVM 中运行，并被同一个 system classloader 装载，被同一的安全策略（security policy） 和上下文（context）所管理。 noverify 参数 通过使用 -noverify 参数，关闭 Java 字节码的校验功能。 当 ClassLoader 加载的Java 字节码时，字节码首先接受校验器（verifier）的校验。校验器负责检查那些指令无法执行的明显的破坏性的操作。校验器执行的检查操作： 变量要在使用之前进行初始化。 方法调用与对象应用类型之间要匹配。 访问私有数据和方法的规则没有被违反。 对本地变量的访问都在运行时堆栈内。 运行时堆栈没有溢处。 manifest（MANIFEST.MF）是什么配置文件？ 这个 manifest 文件定义了与扩展和包相关的数据，例如： 一般属性 应用程序相关属性 小程序(Applet)相关属性 扩展标识属性 包扩展属性 签名相关属性 自定义属性 ### Java中无论是汉字还是英文字母都是用Unicode编码来表示的，一个Unicode码是16位，每字节是8位，所以一个Unicode码占两字节，英文字母比较特殊，源自于8位（1字节）的ASCII码。 Java——————-MySql byte：1字节———–TINYINT 1 short：2字节———-SMALLINT 2 MEDIUMINT 3 int：4字节————-INT 4 long：8字节———–BIGINT 8 float：4字节———-FLOAT(M,D) double：8字节——–DOUBLE(M,D) char/String———–CHAR()/VARCHAR()]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SizeOf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell Learning]]></title>
    <url>%2F2018%2F10%2F07%2FShell%20Learning%2F</url>
    <content type="text"><![CDATA[Shell Learning linux常用命令 输入输出重定向 管道符 | 编写shell脚本 定时任务 周期任务 /dev/zero和/dev/null linux常用命令 man ls：查看ls命令详解（/aaa搜索文档，？aaa模糊搜索文档，n查看下一个匹配项，N产看上一个匹配项，q退出文档） echo 字符串、$变量：输出到终端命令 date：日期命令，常用与将其与备份文件命名相结合，使其文件名清晰明了 reboot、poweroff：重启、关机 wget 参数（-P指定目录） 下载地址：下载网络文件 ps命令 用于报告当前系统的进程状态。可以搭配kill指令随时中断、删除不必要的程序 top：查看系统负载情况（cup，内存。。。） pidof service：查看service的pid值 kill 2456：杀死指定服务进程 killall service：杀死指定服务所有进程 ifconfig：查看网络状态信息 uname -a：查看系统内核版本信息 uptime：查看系统负载情况 free：查看当前内存使用量 who、last、history：当前用户信息、上一次登录信息、历史命令 pwd、cd、ls、 cat：查看纯文本内容（内容较少） more：查看纯文本（内容较多） head：查看文本前几行 tail：查看文本后几行（-f参数实时更新） tr source target：替换文本字符（支持正则表达式[a-z]） wc：统计文本行数-l，单词数-w，字节数-c stat filename：查看文件的存储信息和时间等 cut 参数 文本：按列提取文字符（-d:参数-d以：为间隔符，-f2 按列搜索两列） diff 参数 fileA fileB：比较文件AB的不同（–brief显示对比结果是否相同，-c显示具体的不同） touch：创建空白文件，修改设置文件时间（-a修改读取时间atime，-修改修改时间mtime，-d同时修改atime和mtime） mkdir：创建空白目录（-p递归创建） cp 参数 source target：复制文件（target是目录复制到目录中，是文件覆盖询问，不存在直接执行） mv 参数 source target：剪贴文件 rm：删除文件、目录（-f强制删除，-r删除目录） dd：按照指定大小和个数复制或转换文件（if=输入文件名，of=输出文件名，bs=块的大小，count=块的个数） dd if=/dev/zero of=560_file bs=560M count=2 tar：打包命令（-c创建压缩文件，-x解开压缩文件，-t查看压缩包内有哪些文件，-z用Gzip压缩或者解压，-j用bzip压缩或者解压，-v显示压缩解压过程，-f目标文件名，-P保留原始属性权限，-p使用绝对路径来压缩，-C指定解压目录） tar -czvf etc.tar.gz /etc 压缩文件夹etc下的内容 tar -xzvf etc.tar.gz -C /root/liufei 解压文件etc.tar.gz到文件夹/root/liufei grep：文本内容搜索（-b将可执行文件当做文本文件搜索，-c仅显示找到的行数，-i忽略大小写，-n显示行号，-v反向匹配找到没有关键字的行，-A10匹配的后十行，-B10前十行） find：文件搜索** netstat -anop，端口占用查看，列出所有端口的情况 netstat -anop|findstr “49157” 精确查询端口情况，查看被占用端口对应的PID（windows下） netstat -anop|grep 21666 精确查询端口情况，查看被占用端口详情（linux下） kill pid 根据pid杀掉进程（linux下） tasklist|findstr “102760” 根据pid查询占用服务（windows下） taskkill /f /t /im Tencentdl.exe：结束占用进程（windows下） w：该命令显示的信息很丰富，第一行从左至右显示的信息一次为：时间、系统运行时间、登录用户数、平均负载，这些数据里最应该关注当为load average后的3个数值。第一个数值表示1分钟内系统的平均负载值，第二个数值表示为5分钟内系统的平均负载值，第三个表示15分钟内系统的平均负载值。这里着重看第一个值，它表示单位时间段内使用CPU的活动进程数，值越大就说明服务器压力越大，一般情况下只要这个值不超过服务器的CPU数量就没有关系。如果服务器CPU数量为8，那么值小于8就说明当前服务器没有压力，否则就要关注一下。 cat /proc/cpuinfo：查看服务器有几个CPU vmstat：查看当前系统具体是哪里有压力，显示的结果共分为六部分：procs、memory、swap、io、system、cpu。（vmstat 1每隔一秒输出一次；vmstat 1 5每隔一秒输出一次，共五次） sar：（yum install -y sysstat安装命令）可以监控系统几乎所有资源的状态 sar -n DEV：查看网卡流量输入输出重定向 标准输入重定向：stdin 0标准输出重定向：stdout 1错误输出重定向：stderr 2 重定向符号的使用 命令 &lt; 文件：文件作为命令的标准输入 命令 &lt;&lt; 分界符：从标准输入中读取，知道遇到分界符 命令 &lt; 文件1 &gt; 文件2：文件1作为命令的标准输入，并将标准输出到文件2 命令 &gt; 文件：标准输出到文件，覆盖 命令 2&gt; 文件：错误输出到文件，覆盖 命令 &gt;&gt; 文件：标准输出到文件，追加 命令 2&gt;&gt; 文件：错误输出到文件，追加 命令 &amp;&gt;&gt; 文件：错误和标准输出到文件，追加 管道符 |将前一个命令的标准输出到后一个命令的标准的输入 ls /liufein | wc -l 配置主机名称：/etc/hostname配置网卡信息：ifconfig+cd /etc/sysconfig/network-scripts/+vi+ service network restart/systemctl restart network shell脚本的编写 接收用户参数：./example.sh 参数1 参数2 参数3 … vi example.sh $0对应脚本名称 $#对应总参数个数 $*对应所有的参数值 $1,$2…对应第n个参数 条件表达式：[空格+表达式+空格] 测试参数 -d：是否为目录 -e：文件是否存在 -f：是否为一般文件 -r、w、x：是否拥有可读、可写、可执行权限 -eq：是否等于 -ne：是否不等于 -gt：是否大于 -lt：是否小于 -ge：是否大于等于 -le：是否小于等于 123456789101112131415161718192021222324252627282930313233343536373839# 单条件 if [空格+表达式+空格] then 。。。 else 。。。fi# 多条件if [空格+表达式+空格] then 。。。elif [空格+表达式+空格] then ...else ...fi# for循环for user in usersdo ...done# while循环while [空格+表达式+空格]do ...done# case条件case 变量 in模式1) .... ;;模式2) .... ;;...*) 默认执行esac 定时任务命令 at 时间点 Ctrl+d结束定时任务编写 at -l：查看所有定时任务 atrm 序号：删除定时任务 周期任务命令（分，时，日，月，星期（0和7均表示周日），命令） crontab -e：创建周期任务 crontab -l：查看周期任务 crontab -r：删除周期任务 crontab -u：root用户可修改其他人的周期任务 *星号表示占位符，没有具体值，逗号分割表示多个值-连字符表示一段连续值/n表示每隔n执行一次分不能为空或*，日和星期不能同时使用命令一定要使用绝对路径，使用whereis 命令查看 /dev/null 在类Unix系统中，/dev/null，或称空设备，是一个特殊的设备文件，它丢弃一切写入其中的数据（但报告写入操作成功），读取它则会立即得到一个EOF。 在程序员行话，尤其是Unix行话中，/dev/null 被称为位桶(bit bucket)或者黑洞(black hole)。空设备通常被用于丢弃不需要的输出流，或作为用于输入流的空文件。当你读它的时候，它会提供无限的空字符(NULL, ASCII NUL, 0x00)。 /dev/zero 像/dev/null一样，/dev/zero也是一个伪文件，但它实际上产生连续不断的null的流（二进制的零流，而不是ASCII型的）。写入它的输出会丢失不见，/dev/zero主要的用处是用来创建一个指定长度用于初始化的空文件，像临时交换文件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DECODE]]></title>
    <url>%2F2018%2F09%2F30%2FDECODE%20Function%2F</url>
    <content type="text"><![CDATA[DECODE FUNCTION Oracle 中的decode()函数，用来替代sql语句中的if-else逻辑 Oracle DECODE() function语法：DECODE (e , s1, r1[, s2, r2], ...,[,sn,rn] [, d]); 实例SELECT DECODE(1, 1, &apos;One&apos;) FROM table_a; //等价于 SELECT (IF 1 = 1 THEN RETURN &apos;One&apos;; END IF) FROM table_a; 目标值与单个值的比较DECODE(var1, var2, value)：如果var1=var2，返回value，否返回nullDECODE(var1, var2, value1,value2)：如果var1=var2，返回value1，否返回value2 SELECT DECODE(2,1,&apos;ONE&apos;,2,&apos;NOT ONE&apos;) FROM table_a; SELECT (IF 2 = 1 THEN RETURN &apos;ONE&apos;; ELSEIF 2 = 2 THEN RETURN &apos;NOT ONE&apos;; END IF) FROM table_a; 目标值与多个值的比较DECODE(var1, var2, value2,var3,value3…)：如果var1 = var2，返回value2，如果var1 = var3，返回value3…以此类推DECODE(var1, var2, value2,var3,value3…,defaultValue)：如果var1 = var2，返回value2，如果var1 = var3，返回value3…以此类推，如果没有一个匹配上，则返回默认值defaultValue]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle DECODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Executor]]></title>
    <url>%2F2018%2F09%2F23%2FExecutor%2F</url>
    <content type="text"><![CDATA[ExecutorExecutor接口 接口只有一个execute(Runnable command)方法来执行所给线程 ExecutorService接口 继承自接口Executor 提供了管理线程生命周期的方法，运行 关闭和终止三种状态。 AbstractExecutorService抽象类 实现了接口ExecutorService 新增了两个newTaskFor方法来实现父接口的submit等线程执行方法 调用execute方法执行线程 将其结果返回到Future中 ForkJoinPool 继承自抽象类AbstractExecutorService 内部类WorkQueue（工作队列） 其实就是维护了一个ForkJoinTask类型的数组 ForkJoinWorkerThread的run方法负责去执行WorkQueue中的ForkJoinTask任务 两个主要的执行任务的抽象类。RecursiveAction与RecursiveTask (继承自ForkJoinTask(实现了Futrue))。 RecursiveAction ：没有返回值的接口。 RecursiveTask ：带有返回值的接口。 ForkJoinTask fork方法负责分解创建子任务（将创建的子任务ForkJoinTask扔进WorkQueue中的数组中，再由ForkJoinWorkerThread线程取出执行） join方法负责阻塞等待子任务结果 invokeAll方法避免了当任务众多时逐一去调用fork和join，将多任务作为参数传入统一执行，同时invokeAll方法可以充分利用当前线程去处理任务，减少一个task放入WorkQueue，再由ForkJoinWorkerThread取出执行的时间，效率更高一些（等效于当有两个任务时，1.fork；2.doInvoke；1.join；按照这样的顺序执行效率最高） 核心思想就是分治。Fork分解任务，Join收集数据。 ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。 实现原理：将一个大的任务分解为多个小的任务（默认cpu核数），这样一个线程负责一个任务的执行，每一个小的任务还可以继续细分为多个task，就相当于一个线程负责若干个task的执行，每个线程拥有一个双向队列数据结构来承载各自的task，该双向队列只有三个操作，从队列头取出一个task供线程执行，当队列中task又细分出另外的task时，将该task放入队列头中（注意不是放入队列尾），相当于该双向队列的队列头是一个栈的作用，而当其他线程提前将自己的task全部执行完成后，会去帮助其他还未完成的线程，从其双向队列的队尾取出一个task帮助其完成（注意：从其他线程的队列尾取出task操作需要加锁，避免多个线程同时去执行取task这个操作）。 应用场景：适用于基于event的异步消息处理执行框架 注意：选择合适的子任务粒度 ThreadPoolExecutor（核心类） 继承自抽象类AbstractExecutorService 重点负责线程池的创建和管理 负责线程生命周期的管理，线程的执行，线程执行结果的返回 内部类Worker继承了AbstractQueuedSynchronizer（用于构建锁或者其他相关同步装置的基础框架）实现了runnable接口 构造方法构造线程池，submit方法提交执行线程任务 ScheduledExecutorService接口 继承自接口ExecutorService 新增基于时间计划的线程执行方法 结果返回在ScheduledFuture&lt;?&gt;中 ScheduledThreadPoolExecutor实现类 继承自ThreadPoolExecutor 实现了接口ScheduledExecutorService System.nanoTime()返回纳秒 Executors 调用ThreadPoolExecutor，ForkJoinPool，ScheduledThreadPoolExecutor三个核心类来创建指定的线程池 newFixedThreadPool(int nThreads) 创建一个指定线程数量的线程池 ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); newWorkStealingPool() 创建一个可以偷其他线程task执行的线程池（1.8新增） ForkJoinPool(Runtime.getRuntime().availableProcessors(),ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); newSingleThreadExecutor() 创建一个单一工作线程的executor new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue())); newCachedThreadPool() 创建一个缓存线程池，线程可复用 ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,new SynchronousQueue()); newScheduledThreadPool创建一个时间计划线程池 newSingleThreadScheduledExecutor创建一个基于时间计划的单一工作线程的executor ForkJoinWorkerThread（ForkJoin工作线程） 继承自Thread 负责执行ForkJoinPool中队列里面的任务task 最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目 实战演练环节123ForkJoinPool一个线程一个任务，该任务必须是可切分的，切分后的task均被放入自己的所属线程的队列中去JVM可用的处理器个数Runtime.getRuntime().availableProcessors()=当前设备的CPU个数 批量文件量太大，分部读入处理，放入集合中内容不能太多]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Executor</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CompletableFuture]]></title>
    <url>%2F2018%2F09%2F16%2FCompletableFuture%2F</url>
    <content type="text"><![CDATA[CompletableFuture Callable/Runnable Future FutureTask CompletionStage CompletableFuture Appendix Callable/Runnable The Callable interface is similar to Runnable, in that both are designed for classes whose instances are potentially executed by another thread. A Runnable, however, does not return a result and cannot throw a checked exception. callable和runnable的实例都是设计用来被其他线程所执行的，区别在于runnable没有返回值，也不能抛出错误 callable和runnable都是接口，只会构造出一个另外的线程实例，但不会去自己执行，需要一个调度器excuter来提交执行或者一个实现了该接口的实例类去自己调用run/call方法来启动线程。Thread有自己的start方法来自我启动 12public interface Callable&lt;V&gt;（V为返回值的类型）public interface Runnable Future 承载线程执行结果的接口，定义了以下方法 cancel()取消线程执行操作 get()获取线程执行结果返回值 get(long timeout, TimeUnit unit)规定时间内返回结果（完成返回值，未完成报错超时） isCancelled()线程执行操作是否取消 isDone()线程是否执行完成 Future的弊端 只能通过阻塞或者轮询的方式得到任务的结果 很难直接表述多个Future 结果之间的依赖性 将多个异步计算的结果合并成一个 等待Future集合中的所有异步任务都完成 Future完成事件（即，异步任务完成以后触发执行动作） 应用举例12345678使用Future获取异步操作结果ExecutorService executor = Executors.newSingleThreadExecutor(); Future&lt;String&gt; future = executor.submit(()-&gt;&#123; System.out.println(&quot;异步操作执行 &quot;); return &quot;hello&quot;; &#125;); System.out.println(&quot;原交易正常执行 &quot;); System.out.println(&quot;获取异步操作返回值&quot; + future.get()); FutureTaskRunnableFuture 该接口继承了runnable和future，FutureTask又是该接口的唯一实现类，因此FutureTask不仅可以获取线程执行的结果，还拥有了启动线程执行的能力。 FutureTask A FutureTask can be used to wrap a Callable or Runnable object.一个FutureTask能包裹一个callable或者runnable对象（构造方法实现） 没有无参构造方法 可以提交至executor执行，也可以调用自己的run方法执行 由于实现了runnale接口，构造方法参数又有runnable/callable，所以可以启动两个线程，自身线程和入参线程 FutureTask代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void futureTaskDisplay()&#123; //使用匿名内部类书写 executor.submit(new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;); //使用lambda表达式书写 executor.submit(new FutureTask&lt;String&gt;(()-&gt; &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(()-&gt; &#123; System.out.println(&quot;callable&quot;); return &quot;param callable&quot;; &#125;)&#123; @Override public void run() &#123; super.run(); System.out.println(&quot;runnable&quot;); &#125; &#125;; futureTask.run(); System.out.println(&quot;是否完成&quot; + futureTask.isDone()); System.out.println(&quot;是否取消&quot; + futureTask.isCancelled()); try &#123; System.out.println(futureTask.get()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;catch (ExecutionException e)&#123; e.printStackTrace(); &#125; &#125; CompletableFuture 1.8新增功能类 实现了接口CompletionStage和Future 只有无参构造方法CompletableFuture() 典型应用 1.acceptEither(2,3) 1.applyToEither(2,3) 1.handle(2) 1.runAfterBoth(2,3) 1.runAfterBoth(2,3) Appendix CompletionStage接口所有方法解读 CompletableFuture acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 1.acceptEither(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动 CompletableFuture acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 1.acceptEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动（以1默认异步执行工具执行） CompletableFuture acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor) 1.acceptEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，操作3就拿完成的那个结果作为入参开始行动（用提供的executor去执行） static CompletableFuture allOf(CompletableFuture&lt;?&gt;… cfs) 1.allOf(2,3,4….)：当234等所有的CompletableFuture全部完成，返回完成的1 static CompletableFuture anyOf(CompletableFuture&lt;?&gt;… cfs) 1.anyOf(2,3,4….)：当234等任意的一个CompletableFuture完成，就可以返回完成的1 CompletableFuture applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 1.applyToEither(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动 CompletableFuture applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 1.applyToEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动（以1默认异步执行工具执行） CompletableFuture applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor) 1.applyToEitherAsync(2,3)：1和2两个CompletionStage只要有一个正常完成了，函数3就拿完成的那个结果作为入参开始行动（用提供的executor去执行） boolean cancel(boolean mayInterruptIfRunning) 取消异步操作 boolean complete(T value) 如果调用时未完成，设置value作为完成结果对接其他 static CompletableFuture completedFuture(U value) 返回一个已完成的CompletableFuture，结果设置为value boolean completeExceptionally(Throwable ex) 若异步操作未完成中，调用get方法或者其他相关方法，抛出该错误 CompletableFuture exceptionally(Function fn) T get() 获取异步操作的结果值 T get(long timeout, TimeUnit unit) 指定时间内获取异步操作的结果值 T getNow(T valueIfAbsent) 立刻获取异步操作的结果值，已完成直接返回其结果，未完成返回所给参数值 int getNumberOfDependents() 获取其他已完成的但是在等待此CompletableFuture的数量 CompletableFuture handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2 CompletableFuture handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2（以1默认的异步工具执行） CompletableFuture handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor) 1.handle(2)：无论1是正常完成还是异常报错，都将其结果/异常作为函数2的入参，启动2（用所给的executor执行） boolean isCancelled() boolean isCompletedExceptionally() boolean isDone() T join() 正常完成，返回结果值，异常，抛错 void obtrudeException(Throwable ex) void obtrudeValue(T value) CompletableFuture runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3 CompletableFuture runAfterBothAsync(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3（以1默认的异步工具执行） CompletableFuture runAfterBothAsync(CompletionStage&lt;?&gt; other, Runnable action, Executor executor) 1.runAfterBoth(2,3)：当1和2全部正常完成后，执行3（用所给的executor执行） CompletableFuture runAfterEither(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2有一个正常完成后，执行3 CompletableFuture runAfterEitherAsync(CompletionStage&lt;?&gt; other, Runnable action) 1.runAfterBoth(2,3)：当1和2有一个正常正常完成后，执行3（以1默认的异步工具执行） CompletableFuture runAfterEitherAsync(CompletionStage&lt;?&gt; other, Runnable action, Executor executor) 1.runAfterBoth(2,3)：当1和2有一个正常正常完成后，执行3（用所给的executor执行） static CompletableFuture runAsync(Runnable runnable) 1.runAsync(2)：当 ForkJoinPool.commonPool()中1的task完成后异步的执行2 static CompletableFuture runAsync(Runnable runnable, Executor executor) 1.runAsync(2,3)：当 3中1的task完成后异步的执行2 static CompletableFuture supplyAsync(Supplier supplier) 返回由ForkJoinPool.commonPool（）中运行的任务异步完成的新CompletableFuture，其中包含通过调用给定供应商获得的值。 static CompletableFuture supplyAsync(Supplier supplier, Executor executor) 返回由executor运行的任务异步完成的新CompletableFuture，其中包含通过调用给定供应商获得的值。 CompletableFuture thenAccept(Consumer&lt;? super T&gt; action) 1.thenAccept(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenAcceptAsync(Consumer&lt;? super T&gt; action) 1.thenAcceptAsync(2)：1正常完成后，2以1的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor) 1.thenAcceptAsync(2)：1正常完成后，2以1的结果为入参执行（用所给的executor执行） CompletableFuture thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行 CompletableFuture thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action, Executor executor) 1.thenAcceptBoth(2,3)：12都正常完成后，3以12的结果为入参执行（用所给的executor执行） CompletableFuture thenApply(Function&lt;? super T,? extends U&gt; fn) 1.thenApply(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenApplyAsync(Function&lt;? super T,? extends U&gt; fn) 1.thenApplyAsync(2)：1正常完成后，2以1的结果为入参执行（以1默认的异步工具执行） CompletableFuture thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 1.thenApplyAsync(2)：1正常完成后，2以1的结果为入参执行（用所给的executor执行） CompletableFuture thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) 1.thenCombine(2,3)：12都正常完成后，3以12的结果为入参执行 CompletableFuture thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) CompletableFuture thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor) CompletableFuture thenCompose(Function&lt;? super T,? extends CompletionStage&gt; fn) 1.thenCompose(2)：1正常完成后，2以1的结果为入参执行 CompletableFuture thenComposeAsync(Function&lt;? super T,? extends CompletionStage&gt; fn) CompletableFuture thenComposeAsync(Function&lt;? super T,? extends CompletionStage&gt; fn, Executor executor) CompletableFuture thenRun(Runnable action) 1.thenRun(2)：1正常完成后，2执行 CompletableFuture thenRunAsync(Runnable action) CompletableFuture thenRunAsync(Runnable action, Executor executor) CompletableFuture toCompletableFuture() 返回这个CompletableFuture CompletableFuture whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action) 1.whenComplete(2)：1完成后（正常或者报错），2执行 CompletableFuture whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action) CompletableFuture whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)]]></content>
      <categories>
        <category>Asynchronous</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>Asynchronous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BlockingQueue]]></title>
    <url>%2F2018%2F09%2F09%2FBlockingQueue%2F</url>
    <content type="text"><![CDATA[BlockingQueue 阻塞队列源于队列，先把队列数据结构熟悉后再来了解阻塞队列事半功倍 所有方法均类似的会涉及到一个指定时间计划的参数 队列的存取实际就是基于生产者消费者的最基本模型 公平锁/非公平锁也就是可否抢夺资源 生产者/消费者公用一把锁还是各用一把锁 队列的有界/无界性其实就是对生产者的一种限制，避免无限生产导致资源耗尽 阻塞队列类分析 接口BlockingQueue 继承自接口 Queue add方法添加元素，成功返回true，若队列已满抛错 offer方法添加元素，成功返回true，若队列已满返回false put方法添加元素，若队列已满，等待队列腾出空间后插入 take取出队列头元素，若无可取元素，等待直到有元素进入将其取出 drainTo方法将队列中元素抽取到所给的集合中去 ArrayBlockingQueue 有界队列 数组模拟循环队列，当队尾达到数组边界时，索引index返回数组下标为0的地方 使用Object[]数组盛放队列元素 ReentrantLock加锁执行每一次元素的存取 内部类Itr实现了Iterator接口，迭代遍历元素使用 内部类Itrs维护了多个Iterator在链表中，作用不懂？ LinkedBlockingQueue 有界队列（默认Integer.MAX_VALUE） 使用链表节点node承载队列元素 双向链表，有头结点也有尾节点 入队列在链表尾，出队列取链表头 ReentrantLock加锁执行每一次元素的存取 内部类Itr实现了Iterator接口，迭代遍历元素使用 PriorityBlockingQueue（优先阻塞队列） 无界队列（注意：当生产者速度远大于消费者时，会导致队列的无限扩容，最终耗尽空间资源） 使用Object[]数组承载队列元素，用数组实现的堆heap来实现优先级 默认初始数组空间为11 数组扩容oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : (oldCap &gt;&gt; 1)); 优先级实现原理参照优先队列 DelayQueue（延迟队列） 实现延迟获取的无界队列 创建元素时，指定延迟一定时间才能从队列中获取该元素 内部使用非线程安全的优先队列 采用了leader/follower模式 若干个线程组成线程池来处理大量的事件 有一个线程作为领导者leader，等待事件的发生；其他的线程作为追随者follower，仅仅是睡眠。 假如有事件需要处理，领导者会从追随者中指定一个新的领导者，自己去处理事件，状态变为processer。 唤醒的追随者作为新的领导者等待事件的发生。 处理事件的线程处理完毕以后，就会成为追随者的一员，直到被唤醒成为领导者。 假如需要处理的事件太多，而线程数量不够(能够动态创建线程处理另当别论)，则有的事件可能会得不到处理。 应用场景 缓存有效期：将某个缓存的有效期存入延迟队列中，使用一线程轮训访问该延迟队列，一旦能取出该有效期，则表示有效期到了 定时任务调度：一旦可以从延迟队列中取出该任务时，就开始执行 SynchronousQueue（同步队列） 队列中不存储元素 每一个值插入的操作必将等待一个取值操作，否则不能插入元素 Executors.newCachedThreadPool()使用了SynchronousQueue LinkedBlockingDeque 有界队列 使用链表节点node承载队列元素 双向链表，有头结点也有尾节点 链表双向均可插入取出元素 实战演练环节12]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Queue</tag>
        <tag>BlockingQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[F5]]></title>
    <url>%2F2018%2F09%2F02%2FF5%2F</url>
    <content type="text"><![CDATA[F5F5 Networks(纳斯达克: FFIV) ，全球领先的应用交付网络（ADN）领域的厂商，F5是个公司的名称！ 引言 工作以后耳边总会时不时的响起一些生疏的代名词，今天这个叫F5。这次词已经不止一次的进入到的我的耳朵里，但每次总是一闪而过，并伴随着硬件负载均衡器这个解释。直到前段时间这个词真正出现在了我面前，忍不住查阅了一翻资料才发现之前的认知有多么的草率。 正文 F5为什么会被叫做硬件负载均衡器？ 真正的硬件负载均衡器是谁？ 负载均衡的功能包括哪些？ F5公司的介绍和该公司的产品介绍可自行google了解，官网地址如下：https://www.f5.com/ F5为什么会被叫做硬件负载均衡器 1996年，F5 Networks创立。1997年，F5 推出的第一款产品是BIG-IP 负载均衡器 。1999年，F5在美国NASDAQ成功上市，掀起了应用交付网络的强劲龙卷风。 F5是负载均衡产品的一个品牌，除了F5以外，Radware、Array、A10、Cisco、深信服等都是负载均衡的牌子，但由于F5在这类产品中影响最大，所以经常说F5负载均衡。 真正的硬件负载均衡器是谁F5公司旗下的产品众多，包括 BIG-IP平台 F5 BIG-IP本地流量管理器(LTM)：一款出色的应用流量管理系统，可提供业内最智能、最具适应性的解决方案来保护、优化和交付应用，从而确保企业能够在保持高效运营的同时提高其竞争力。 F5 BIG-IP应用安全管理器(ASM)：一个先进的Web应用防火墙，可显著减少和控制数据、知识产权和Web应用丢失或损坏的风险。BIG-IP ASM通过一个将应用交付与网络和应用加速及优化结合在一起的平台，提供了无与匹敌的应用和网站防护、完整的攻击专家系统，并且可以满足关键的法规要求。 F5 BIG-IP链路控制器(LC)：无缝地监控多条WAN ISP连接的可用性与性能，以智能地管理到某站点的双向流量，从而提供出色的容错性和优化的互联网访问。 BIG-IP iSeries平台：全新F5 BIG-IP iSeries硬件平台具备可编程性、广泛的生态系统集成编排功能、以及创纪录的软件定义硬件性能。 VIPRION威普龙平台：一款独立且功能强大的应用交付控制器，它采用模块化高性能板卡，且插拔模块板卡时不会中断应用运行。 F5 BIG-IP 企业管理器… F5 ⅥPRION威普龙应用交付控制器… BIG-IP虚拟版本（VE）… F5 Advanced WAF(API安全 - 新一代WAF)… BIG-IP Cloud Edition（BIG-IP云版本）… F5 WANJet广域网加速器… F5 BIG-IP Web应用加速器(Web Accelerator)… F5 BIG-IP安全接入管理器(SAM)… F5 BIG-IP广域流量管理器(GTM)… 硬件负载均衡器==F5 BIG-IP LTM（本地流量管理器） F5 BIG-IP LTM（本地流量管理器）是一台对流量和内容进行管理分配的设备。它提供12种灵活的算法将数据流有效地转发到它所连接的服务器群。而面对用户，只是一台虚拟服务器。用户此时只需访问定义于BIG-IP LTM上的一台服务器，即虚拟服务器（Virtual Server）。但他们的数据流却被BIG-IP灵活地均衡到所有的物理服务器。BIG-IP LTM可以通过多种负载均衡算法对流量进行分配。 负载均衡的功能包括哪些？ 降低服务器负载方面 内容转换 OneConnect 高速缓存 SSL加速和卸载 应用优化方面 智能应用交换 智能压缩 灵活的第7层速率整形 TCPExpress iSessions WAN优化模块(插件模块) 安全的应用方面 资源隐藏和内容安全 定制的应用攻击过滤 基础防火墙功能—数据包过滤 隔离协议攻击 网络攻击防护 有选择的加密 Cookie加密 高级SSL加密标准 先进的客户端验证模块(插件模块) 垃圾邮件过滤模块(插件模块) 协议安全模块(插件模块)]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Load Balance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DMZ]]></title>
    <url>%2F2018%2F08%2F26%2FDMZ%2F</url>
    <content type="text"><![CDATA[DMZ 什么是DMZ？ 有哪些用途？ 什么是DMZ？两个防火墙之间的空间被称为DMZ。 DMZ是英文“demilitarized zone”的缩写，中文名称为“隔离区”，也称“非军事化区”。它是为了解决安装防火墙后外部网络的访问用户不能访问内部网络服务器的问题，而设立的一个非安全系统与安全系统之间的缓冲区。该缓冲区位于企业内部网络和外部网络之间的小网络区域内。在这个小网络区域内可以放置一些必须公开的服务器设施，如企业Web服务器、FTP服务器和论坛等。另一方面，通过这样一个DMZ区域，更加有效地保护了内部网络。因为这种网络部署，比起一般的防火墙方案，对来自外网的攻击者来说又多了一道关卡。 外网—&gt;外网防火墙—&gt;DMZ—&gt;内网防火墙—&gt;内网DMZ空间中包含堡垒主机，modem池，公共服务器 堡垒主机：堡垒主机是一种被强化的可以防御进攻的计算机，作为进入内部网络的一个检查点，以达到把整个网络的安全问题集中在某个主机上解决，从而省时省力，不用考虑其它主机的安全的目的。堡垒主机是网络中最容易受到侵害的主机，所以堡垒主机也必须是自身保护最完善的主机。一个堡垒主机使用两块网卡，每个网卡连接不同的网络。一块网卡连接你公司的内部网络用来管理、控制和保护，而另一块连接另一个网络，通常是公网也就是Internet。堡垒主机经常配置网关服务。网关服务是一个进程来提供对从公网到私有网络的特殊协议路由，反之亦然。 modem池：调制解调器，是一种计算机硬件，它能把计算机的数字信号翻译成可沿普通电话线传送的模拟信号，而这些模拟信号又可被线路另一端的另一个调制解调器接收，并译成计算机可懂的语言。这一简单过程完成了两台计算机间的通信 公共服务器：如web，ftp，mail等公司必须对外开放的一些公共服务器，无敏感数据，代理数据访问的主机服务器 有哪些用途？ 三层保护，攻击者如果想要进入到内网，将通过外网防火墙，DMZ区域，内网防火墙三层关卡，内网数据安全性更高 防火墙来完成外网到DMZ，DMZ到内网的地址转换工作，即NAT，以保证隐藏服务器真实网络地址 解决安装防火墙后外部网络的访问用户不能访问内部网络服务器的问题，而设立的一个非安全系统与安全系统之间的缓冲区。]]></content>
      <categories>
        <category>NetWork</category>
      </categories>
      <tags>
        <tag>DMZ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSO原理]]></title>
    <url>%2F2018%2F08%2F19%2FSSO%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[SSO原理 需求缘起 实现原理 什么是Cookie？ 什么是session？ 什么是Token？ 需求缘起Web应用系统演变史 从单一功能到多功能 从单一系统到多系统 Web互联网应用逐渐发展为多系统共同支持的应用群 不同系统间功能相对独立，但又存在着联系 用户眼中只有应用群一个概念，群内的各个系统应该对用户保持透明 如何保证用户信息在各个系统间的一致性，也就是说在应用群内一处验证，随处可用 单Web应用系统如何实现登录登出 Web应用，系统采用B/S架构，Browser和Server之间的通信协议是http协议 http协议为无状态协议，即每个http请求都是单一独立的，不考虑是否源自同一会话 用户登陆应用到登出的之间这一段称之为一次会话交互 要想实现http请求的会话识别可以通过传递参数或者cookie两种方式 推荐cookie方式，服务器端http响应设置好后，浏览器以后每次请求会自动带上cookie返回给服务端进行是否同一会话验证 Web应用服务器一般俊辉提供这种会话基础服务，如tomcat的session机制，避免了开发人员的手动cookie创建维护删除管理 cookie作用域，由属性Domain和Path共同决定，path是访问路径，可以设置为/根路径使其作用于所有路径，但是Domain我们不能定义顶级域名，最大只能定义到二级域名，所以当应用群中存在多个二级域名时便会出现cookie失效情况 当请求超过cookie作用域时，请求不会携带cookie 服务器session机制只适用于单一应用范围内 不同系统之间的异构性会导致session实现机制不尽相同 共享session机制会对原系统侵入性很大 一次完整的用户和系统间http交互过程 用户发出登录请求 系统验证用户信息，信息无误，授权用户相关权限，登录成功响应，设置会话id-cookie 登录成功后继续请求，携带会话id-cookie 系统验证会话id-cookie，返回请求资源 用户请求登出 系统取消会话id-cookie 实现原理大致思路 抽象每个单Web应用系统中的用户登录验证阶段成一个独立的认证中心系统 将浏览器对应用系统的用户登录请求重定向到认证中心系统 认证中心认证完成后再将请求重定向回应用系统 应用系统检测到认证成功予以登录，授权用户后续操作 存在问题及解决方案 登录信息传递：认证中心认证通过后如何将消息回传给应用系统，由于cookie不能跨域，所以只能传递参数；可以将认证通过消息制作成令牌token传递。 令牌token正确性验证：应用系统如何判别令牌是从认证中心发出，且有效正确。因此需要应用系统和认证系统之间进行通信验证令牌 登录状态判断：首次登录验证成功后用户浏览器和认证中心建立起了会话，但是应用系统与用户之间没有，所以登录成功后的每次请求验证均需通过认证中心，导致效率低下。因此可以在应用系统和用户之间也建立会话，称之为局部会话（与认证中心之间的称之为全局会话），局部会话依附于全局会话而存在。 登出状态判定：当用户在其中一个应用系统登出之后，该应用系统局部会话销毁，认证中心的全局会话销毁，同时认证中心下放通知各个应用系统销毁该用户的局部会话 什么是Cookie？ cookie指的就是浏览器里面能永久存储数据的一种数据存储功能。 cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的cookie数量是有限的。 当用户访问同一个 Web 服务器时，浏览器首先要检查本地的Cookies，并将其原样发送给 Web 服务器。 Cookie有什么功能特点呢？在同一个页面中设置 Cookie，实际上是按从后往前的顺序进行的。如果要先删除一个 Cookie，再写入一个 Cookie，则必须先写写入语句，再写删除语句，否则会出现错误 。 Cookie是面向路径的。缺省路径 (path) 属性时，Web 服务器页会自动传递当前路径给浏览器，指定路径强制服务器使用设置的路径。在一个目录页面里设置的 Cookie 在另一个目录的页面里是看不到的 。 Cookie 必须在 HTML 文件的内容输出之前设置；不同的浏览器 (Netscape Navigator、Internet Explorer) 对 Cookie 的处理不一致，使用时一定要考虑；客户端用户如果设置禁止 Cookie，则 Cookie 不能建立。 并且在客户端，一个浏览器能创建的 Cookie 数量最多为 300 个，并且每个不能超过 4KB，每个 Web 站点能设置的 Cookie 总数不能超过 20 个 。 Cookie的生命周期呢？：Cookie可以保持登录信息到用户下次与服务器的会话，换句话说，下次访问同一网站时，用户会发现不必输入用户名和密码就已经登录了（当然，不排除用户手工删除Cookie）。而还有一些Cookie在用户退出会话的时候就被删除了，这样可以有效保护个人隐私。Cookie在生成时就会被指定一个Expire值，这就是Cookie的生存周期，在这个周期内Cookie有效，超出周期Cookie就会被清除。有些页面将Cookie的生存周期设置为“0”或负值，这样在关闭浏览器时，就马上清除Cookie，不会记录用户信息，更加安全。 建议开发人员在向客户端 Cookie 输出敏感的内容时（譬如：该内容能识别用户身份）： 设置该 Cookie 不能被脚本读取，这样在一定程度上解决上述问题。 对 Cookie 内容进行加密，在加密前嵌入时间戳，保证每次加密后的密文都不一样（并且可以防止消息重放）。 客户端请求时，每次或定时更新 Cookie 内容（即：基于第2小条，重新加密） 每次向 Cookie 写入时间戳，数据库需要记录最后一次时间戳（防止 Cookie 篡改，或重放攻击）。 客户端提交 Cookie 时，先解密然后校验时间戳，时间戳若小于数据数据库中记录，即意味发生攻击。 基于上述建议，即使 Cookie 被窃取，却因 Cookie 被随机更新，且内容无规律性，攻击者无法加以利用。另外利用了时间戳另一大好处就是防止 Cookie 篡改或重放。 什么是session？ session就是会话。这个就类似于你和一个人交谈，你怎么知道当前和你交谈的是张三而不是李四呢？对方肯定有某种特征（长相等）表明他就是张三。 session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识sessionID”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识sessionID”，服务器就知道这个请求来自于谁了。至于客户端怎么保存这个“身份标识sessionID”，可以有很多种方式，对于浏览器客户端，大家都默认采用 cookie 的方式。 服务器使用session把用户的信息临时保存在了服务器上，用户离开网站后session会被销毁。这种用户信息存储方式相对cookie来说更安全，可是session有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。 JSP使用一个叫HttpSession的对象实现同样的功能。HTTPSession 是一个建立在cookies 和URL-rewriting上的高质量的界面。Session的信息保存在服务器端，Session的id保存在客户机的cookie中。事实上，在许多服务器上，如果浏览器支持的话它们就使用cookies，但是如果不支持或废除了的话就自动转化为URL-rewriting，session自动为每个流程提供了方便地存储信息的方法。 什么是Token？ Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。 使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。流程是这样的： 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>SSO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Annotation]]></title>
    <url>%2F2018%2F08%2F12%2FJava%20Annotation%2F</url>
    <content type="text"><![CDATA[Annotation 基本语法 编写注解处理器 使用apt处理注解 基于观察者模式的apt 基本语法内置 注解 @Override：当前方法覆盖超类方法 @Deprecated：表示不应该再使用的方法，使用会发出警告信息 @SuppressWarnings：关闭不当的编译器警告信息 all 关闭所有警告 boxing 关闭装箱拆箱警告 cast 关闭类型转换警告 dep-ann 关闭弃用注解警告 deprecation 关闭弃用警告 fallthrough 关闭switch中缺失breaks的警告 finally 关闭finally中不能正常返回的警告 hiding to suppress warnings relative to locals that hide variable incomplete-switch to suppress warnings relative to missing entries in a switch statement (enum case) nls to suppress warnings relative to non-nls string literals null to suppress warnings relative to null analysis rawtypes to suppress warnings relative to un-specific types when using generics on class params restriction to suppress warnings relative to usage of discouraged or forbidden references serial to suppress warnings relative to missing serialVersionUID field for a serializable class static-access o suppress warnings relative to incorrect static access synthetic-access to suppress warnings relative to unoptimized access from inner classes unchecked to suppress warnings relative to unchecked operations unqualified-field-access to suppress warnings relative to field access unqualified unused to suppress warnings relative to unused code 注解定义 @Target(ElementType.METHOD)：注解可用位置 CONSTRUCTOR：构造器 FIELD：域（属性） LOCAL_VARIABLE：局部变量 METHOD：方法 PACKAGE：包 PARAMETER：参数 TYPE：类，接口，注解，enum @Retention(RetentionPolicy.RUNTIME)：注解保留级别 SOURCE：注解在原文件中可用，会被编译器丢失 CLASS：注解在class文件中可用，会被VM丢失 RUNTIME：VM将在运行期也保留注解，可通过反射机制读取 @Documented：将此注解包含在javadoc中 @Inherited：允许子类继承父类的注解 注解元素 类似方法定义 可用类型：所有基本类型，String，Class，enum，annotation，以上类型数组 元素值必须确定，要么默认值，要么提供值 自定义默认值负数或者空字符串以表示某个不存在的元素 注解不支持继承 每一个自定义的注解都需要自己的处理器代码样例123456789/** 代码样例 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface MyAnnotation &#123; int id() default -1; String description() default &quot;annotation&quot;;&#125; 编写注解处理器基于反射的运行时注解处理器 由于反射提供了对注解的相关操作，所以我们可以通过反射遍历所有的类文件来判定哪些类文件标注了具体哪些注解，然后根据实际情况做相应的决策，最简单粗暴的注解处理器由此而来。 12345678910111213public class MyReflection &#123; public static void main(String [] args)throws Exception&#123; Class clazz = Class.forName(&quot;dcits.liufein.springboot.java.simple.MyService&quot;); MyService myService = (MyService) clazz.newInstance(); for (Method method : clazz.getMethods())&#123; MyAnnotation annotation = method.getAnnotation(MyAnnotation.class); if(annotation!=null)&#123; System.out.println(annotation.id() + &quot;---&quot; + annotation.description()); method.invoke(myService,null); &#125; &#125; &#125;&#125; ### 使用apt处理注解（编译时注解处理器） apt设计为操作java源文件，而不是编译后的文件，默认apt会在处理完成源文件后同一编译；实际上，apt还会检测有没有新的源文件生成（由注解处理器生成），经过一轮又一轮的检测，知道没有新的源文件生成，然后同一编译。 通过AnnotationProcessorFactory，apt能够为每一个发现的注解生成一个正确的处理器 apt生成注解处理器时，我们无法使用java的反射机制，因为我们操作的是源代码，而不是编译后的类文件 mirror API能够在未编译的源代码中查看方法，域，以及类型 apt-mirror-api-0.1.jar 基于观察者模式的apt]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql DROP DATABASE Syntax]]></title>
    <url>%2F2018%2F08%2F05%2FMySql%20DROP%20DATABASE%20Syntax%2F</url>
    <content type="text"><![CDATA[MySql DROP DATABASE Syntax DROP DATABASE Syntax TRUNCATE TABLE Syntax DDL/DML/DCL/TCL DROP DATABASE Syntax https://dev.mysql.com/doc/refman/8.0/en/drop-database.html DROP {DATABASE | SCHEMA} [IF EXISTS] db_name 当数据库drop掉的时候，其库的权限不会自动删除，需要手动drop删除 If you use DROP DATABASE on a symbolically linked database, both the link and the original database are deleted.使用drop的时候，如果该库含有同步连接数据库，即存在主从关系（集群），连接库以及原始库都将删除 drop命令执行返回的是所删除的表的总数 drop命令删除库的相关文件和文件夹，其中包括（.BAK.DAT.HSH.MRG.MYD.MYI.cfg.db.ibd.ndb），如果出了这些文件还有其他文件存在，执行drop命令后数据库文件夹不能被删除，除非手动删除文件夹内文件后才能删除 drop命令不会删除临时表，临时表在session连接结束后自动删除 TRUNCATE TABLE SyntaxTRUNCATE [TABLE] tbl_name 该命令等同于delete所有行数据，等同于drop table + create table 跳过DML方法，不会触发在delete上的触发器 Innodb存储引擎下的表如果存在外键关系，则无法执行，且不能信箱DML 操作那样执行回退 truncate使用原子DDL支持存储引擎实现全部成功提交或者失败全部回滚 不同于delete 速度比delete快，尤其体现在海量数据 不可回退 当连接持有活动状态的表锁时不能执行 innodb下有外键时不能执行 不返回有意义的值 只要表结构定义正确，即使数据文件或者索引文件损坏，truncate操作完成后也能创建空表 自增值重置为原始值， MyISAM and InnoDB均是 不会触发delete触发器 支持操作损坏的innodb 表 与分区表一起使用时，TRUNCATE TABLE保留分区; 也就是说，数据和索引文件被删除并重新创建，而分区定义不受影响。 DDL/DML/DCL/TCLDDL(Data Definition Language) 数据定义语言, 用于定义/修改/删除数据对象(如表)的数据结构。DDL语言操作的对象是数据库中的对象而非对象所包含的数据。 DDL用于操作对象和对象的属性，这种对象包括数据库本身，以及数据库对象，像：表、视图等等，DDL对这些对象和属性的管理和定义具体表现在Create、Drop和Alter上。特别注意：DDL操作的“对象”的概念，”对象“包括对象及对象的属性，而且对象最小也比记录大个层次。以表举例：Create创建数据表，Alter可以更改该表的字段，Drop可以删除这个表。 DDL包含以下语句： CREATE : 在数据库中创建新的数据对象 ALTER : 修改数据库中对象的数据结构 DROP : 删除数据库中的对象（可以删除数据表、索引、触发程序、条件约束以及数据表的权限等） DISABLE/ENABLE TRIGGER : 修改触发器的状态 UPDATE STATISTIC : 更新表/视图统计信息 TRUNCATE TABLE : 清空表中数据 COMMENT : 给数据对象添加注释 RENAME : 更改数据对象名称 唯一需要注意的是TRUNCATE，尽管从功能上看相当于DELETE表中所有数据，但由于它所操作的对象是table这个级别而非row（如由于某种原因不能立即删除表数据时，TRUNCATE会锁定整张表，而DELETE锁定的则是row)，所以归在DDL中。 DML(Data Manipulation Language) 数据操作语言，用于添加/修改/查询数据库中数据。 DML用于操作数据库对象中包含的数据，也就是说操作的单位是记录。 DML包含以下语句： - INSERT ：将数据插入到表或视图 DELETE ：从表或视图删除数据 SELECT ：从表或视图中获取数据 UPDATE ：更新表或视图中的数据 MERGE ： 对数据进行合并操作(插入/更新/删除) DCL(Data Control Language) DCL用来向用户赋予/取消对数据对象的控制权限。 DCL包含以下语句： GRANT : 赋予用户某种控制权限 REVOKE ：取消用户某种控制权限 TCL(Transaction Control Language) 事务控制语句，用来对事务进行管理。 TCL包含以下语句： COMMIT : 保存已完成事务动作结果 SAVEPOINT : 保存事务相关数据和状态用以可能的回滚操作 ROLLBACK : 恢复事务相关数据至上一次COMMIT操作之后 SET TRANSACTION : 设置事务选项 DQL]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>DROP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Distributed Tracing Design and Architecture]]></title>
    <url>%2F2018%2F07%2F29%2F%E8%B0%83%E7%94%A8%E9%93%BE%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[调用链实现原理 调用链的产生 调用链跟踪原理 调用链系统设计与实现 调用链的产生 简单来说：微服务架构中系统众多，系统间的交互复杂，调用关系错综复杂，导致在特殊情况下难以快速定位和解决问题，因此，调用链应用而生。 举个简单的例子：客户反馈问题，开发和运维人员从服务A开始查起，确定服务A没有问题，然后将问题传递到服务B中开始排查，确认服务B没有问题后，又将问题传到服务C排查…以此类推，知道排查出问题所在。如果问题出在A服务，我们可以很快的定位到问题并解决问题，但是如果问题在最后一个被调用的服务，那么我们需要将之前所有的服务全部排查一遍才能定位到问题，不仅浪费时间，而且做了很多的无用功。倘若有了调用链，我们可以直接定位到问题所在的服务，节省时间又避免无用功的发生。 调用链跟踪原理每一个微服务架构系统即使再复杂都会有一个入口，而这个入口我们可以将其看作一棵树的树根root，之后所发生的所有调用关系我们可以看作是由树根衍生出来的树干与树枝，这样所有的系统调用关系就被抽象成了一颗复杂的树，而基于树 的特性，我们可以沿着某一分叉找到一条完整的调用关系，因此我们可以给每个不同的分叉定义不用的唯一标识来区分不同的调用链，这样每一条的完整的调用链关系就被我们抽象了出来，但是调用链内的各个服务调用顺序还没有明确，虽然有些服务的调用顺序并不会对最终结果造成影响，但是有些却会产生对系统致命的影响，所以我们再次利用树的层次特性来给同一分支中不同节点定义先后顺序。这样，复杂的微服务系统之间的调用关系就变得一目了然。 谷歌dapper为例：采用http协议头携带标记信息（信息包含调用链唯一流水id=traceID（用于找寻所有属于同一请求的调用点放入同一集合中），调用层次spanID，调用顺序parentSpanID（用于将处在同一调用链中的不同点分层和记录调用顺序）；最后形成完整的树形调用链供可视化，同时便于记录出错节点和各个节点详细信息） spanID=64位整型值：产生策略 随机数[-2^63,2^63-1] 分布式全局唯一流水号（发号器） spanID携带所有父类节点时会携带太多的冗余信息 调用链系统设计与实现调用链系统的构成 采集器：从业务系统中将远程服务的调用信息收集并发送给处理器 处理器；接受从采集器传递过来的服务调用信息并聚合调用链，将其存储到分布式数据存储中，以及对调用链进行分析输出给监控和报警系统。 分布式存储系统：存储海量的调用链数据，并支持灵活的查询和搜索的功能。 调用链展示系统：查询展示调用链信息 traceID，spanID的传递： java应用内：本地线程传递 服务间：通信协议中传递，restful风格使用http头传递，rpc使用序列化协议上增加定制化字段 主子线程，非核心链路异步处理，创建子线程时，traceID和spanID一同传递下去 消息队列传递：调用链跟踪失效，采用更改队列底层协议或者业务侵入手动增加字段实现 缓存数据库：将调用链traceID和spanID与访问数据关联 调用链信息的采集（将traceID，spanID等信息传到采集器处理）： 侵入业务代码，代码中编写（不推荐） AOP推送，同样侵入了业务代码，但是AOP可独立开发 javaAgent字节码增强（虚拟机级别支持的AOP实现方式） 调用信息随日志推送到日志中心然后再处理 采集器数据的推送 采集器收集的数据必须从业务系统中推送到调用链的处理器上，并且推送过程中必须保证不能影响业务系统的正常运行，及绝对不能直接使用业务线程来发送调用信息，一般采用异步线程池发送，同时异步线程池与处理器之间必须采用有界队列做缓冲，避免出现数据积压后导致应用内存耗光的情况。 kafka消息队列（处于采集器和处理器中间，面对大流量高峰采集信息起到消峰作用） UDP推送：无连接传输层协议，效率比tcp或之上的协议高得多 不同的调用链组成业务链（多个请求建立连接（例如，下单，支付，退款），多个树形调用链组成森林业务链）]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed Tracing</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Commands]]></title>
    <url>%2F2018%2F07%2F22%2FRedis%20Commands%2F</url>
    <content type="text"><![CDATA[Redis Commands APPEND key value：若key存在，在其value（必须为string类型）后面追加字符串 AUTH password：服务器访问权限设置，在配置文件redis.conf中配置requirepass 字段的值即可实现服务器的加密操作，客户端需使用命令auth password来获取权限才能执行命令 BGREWRITEAOF BGSAVE BITCOUNT key [start end]：计算key中位为1的数量 * BITFIELD：* BITOP：按位操作，与，或，异或，非 BITOP AND destkey srckey1 srckey2 srckey3 … srckeyN BITOP OR destkey srckey1 srckey2 srckey3 … srckeyN BITOP XOR destkey srckey1 srckey2 srckey3 … srckeyN BITOP NOT destkey srckey BITPOS key bit [start] [end]：返回key中第一位为1或者0的位置（可自定义范围） BLPOP key [key …] timeout：返回非空list（key）的第一个元素 BRPOP key [key …] timeout：返回非空list（key）的最后一个元素 BRPOPLPUSH source destination timeout：source非空时，等效于命令RPOPLPUSH source destination，source为空时，阻断连接至超时 RPOPLPUSH source destination：将source的最后一个元素移除放置到destination的第一元素位置 BZPOPMIN key [key …] timeout：从第一个非空排序sets（key）中返回并移除最小值 BZPOPMAX key [key …] timeout：从第一个非空排序sets（key）中返回并移除最大值 CLIENT ID：返回当前客户端id CLIENT KILL [ip:port] [ID client-id] [TYPE normal|master|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]：关闭指定客户端连接 CLIENT LIST [TYPE normal|master|replica|pubsub]：获取客户端连接列表 CLIENT GETNAME：获取当前连接名 CLIENT PAUSE timeout：暂停客户端一段时间 CLIENT REPLY ON|OFF|SKIP：设置服务器对客户端的响应 CLIENT SETNAME connection-name：设置当前连接的客户端名称 CLIENT UNBLOCK client-id [TIMEOUT|ERROR]： CLUSTER ADDSLOTS slot [slot …]：集群模式下，将slot槽位分配给客户端节点 CLUSTER COUNT-FAILURE-REPORTS node-id：统计集群中，节点失败报告的次数，用来判定该节点是否不可达 CLUSTER COUNTKEYSINSLOT slot：统计某一槽位slot中key的数量 CLUSTER DELSLOTS slot [slot …]：删除集群中节点对应服务器的槽位 CLUSTER FAILOVER [FORCE|TAKEOVER]：该命令只能发送给集群中的复制节点来手动故障转移moster主节点 CLUSTER FORGET node-id：从集群节点表中移除该节点，即将该节点从集群中踢出去，由于集群中所有节点都能感知到其他节点的存在，所以想要完全从集群中移除，需要给所有的已存在节点发送该命令 CLUSTER GETKEYSINSLOT slot count：获取指定槽位slot中指定数量count的key值数组集合 CLUSTER INFO：集群节点信息 CLUSTER KEYSLOT key：获取key所在的槽位slot CLUSTER MEET ip port：强制与其他节点连接交互 CLUSTER NODES：获取集群节点配置 CLUSTER REPLICATE node-id：重新配置一个节点作为moster的复制节点 CLUSTER RESET [HARD|SOFT]：重置集群节点，Note that this command does not work for masters if they hold one or more keys CLUSTER SAVECONFIG：强制节点保存节点配置到本地磁盘 CLUSTER SET-CONFIG-EPOCH config-epoch： CLUSTER SETSLOT slot IMPORTING|MIGRATING|STABLE|NODE [node-id]： MIGRATING subcommand: Set a hash slot in migrating state. IMPORTING subcommand: Set a hash slot in importing state. STABLE subcommand: Clear any importing / migrating state from hash slot. NODE subcommand: Bind the hash slot to a different node. CLUSTER SLAVES node-id：列出moster节点的复本节点 CLUSTER REPLICAS node-id：列出moster节点的复本节点 CLUSTER SLOTS：返回集群槽位与redis实例匹配的详细信息 COMMAND：获取命令细节 COMMAND COUNT：统计命令总数 COMMAND GETKEYS：获取命令中的key数组 COMMAND INFO command-name [command-name …]：命令的具体信息 CONFIG GET parameter：获取配置参数的值 CONFIG REWRITE：重新写配置文件 CONFIG SET parameter value：设置配置参数为value CONFIG RESETSTAT：重置配置文件信息 DBSIZE：返回当前所选数据库中key的数量 DEBUG OBJECT key：获取key的debug信息 DEBUG SEGFAULT：让服务器崩溃 DECR key：key的值减一 DECRBY key decrement：key值减少指定值 DEL key [key …]：删除key（可多个） DISCARD：刷新事务中所有先前排队的命令，并将连接状态恢复为正常。 DUMP key：序列化key中的value值以redis特定格式，并将其返回 ECHO message：输出所给的字符串 EVAL script numkeys key [key …] arg [arg …]： EVALSHA sha1 numkeys key [key …] arg [arg …]： EXEC：执行事务中所有先前排队的命令，并将连接状态恢复为正常。 EXISTS key [key …]：判定key是否存在 EXPIRE key seconds：设置key的生存周期 EXPIREAT key timestamp：设置key的生存周期（timestamp表示以unix时间为基准，1970.01.01） FLUSHALL [ASYNC]：移除所有数据库中所有key FLUSHDB [ASYNC]：移除当前数据库中所有key GEOADD key longitude latitude member [longitude latitude member …]： GEOHASH key member [member …]： 。。。 GET key：获取key值 GETBIT key offset：返回偏移后的位值 GETRANGE key start end：获取字串 GETSET key value：设置新值，返回旧值 HDEL key field [field …]：从key中存储的哈希中删除指定的字段 HEXISTS key field：判定key中存储的哈希中是否存在指定的字段 HGET key field：从key中存储的哈希中获取指定的字段 HGETALL key：获取key存储哈希中所有的字段值 HINCRBY key field increment：将key存储的哈希值中给定字段增加给定的数值（integer） HINCRBYFLOAT key field increment：将key存储的哈希值中给定字段增加给定的数值（float） HKEYS key：返回key中存储的哈希值中所有字段的值 HLEN key：获取key中存储的哈希值中的字段数量 HMGET key field [field …]：从key中存储的哈希中获取指定的字段的值 HMSET key field value [field value …]：从key中存储的哈希中设定多个指定的字段以指定的值 HSET key field value：从key中存储的哈希中设定指定的字段以指定的值 HSETNX key field value：从key中存储的哈希中设定指定的字段以指定的值（当且仅当field不存在是成立，否则，不做任何操作） HSTRLEN key field：获取key中存储的哈希中设定指定字段值的长度 HVALS key：获取key中存储的哈希的所有值 INCR key：key值自增加一 INCRBY key increment：key值自增指定值 INCRBYFLOAT key increment：key值自增指定值（float） INFO [section]：获取服务器信息数据 KEYS pattern：找到所有的与所给pattern相匹配的key LASTSAVE：返回最后一次成功保存到磁盘的unix时间戳 LINDEX key index：获取list中第index个元素 LINSERT key BEFORE|AFTER pivot value：在list中某元素前或者后插入元素 LLEN key：获取list的长度 LPOP key：获取并移除list中第一个元素 LPUSH key value [value …]：在list头不插入多个元素 LPUSHX key value：list头中key元素存在时给key赋值value，否则不做任何操作 LRANGE key start stop：获取list中所给范围的值 LREM key count value： count &gt; 0: Remove elements equal to value moving from head to tail. count &lt; 0: Remove elements equal to value moving from tail to head. count = 0: Remove all elements equal to value. LSET key index value：给list中第index个key赋值为value LTRIM key start stop：给list中所给范围内的元素去空格trim操作 MEMORY DOCTOR：报告内存问题及意见 MEMORY HELP：返回描述不同子命令的帮助文档 MEMORY MALLOC-STATS：提供内存分配器的内部统计报告。 MEMORY PURGE：要求内存分配器释放空间 MEMORY STATS：显示内存使用详细内容 MEMORY USAGE key [SAMPLES count]：显示key的内存使用 MGET key [key …]：返回多个key的值 MIGRATE host port key|”” destination-db timeout [COPY] [REPLACE] [KEYS key [key …]]：redis实例之间的转换 MONITOR：实时监听服务器所有的请求 MOVE key db：移动key到另一个数据库 MSET key value [key value …]：设置多个key的值 MSETNX key value [key value …]：设置多个key的值，仅当所有的key都不存在时成立 MULTI：标记事务块的开始 OBJECT subcommand [arguments [arguments …]]： OBJECT REFCOUNT returns the number of references of the value associated with the ecified key. This command is mainly useful for debugging. OBJECT ENCODING returns the kind of internal representation used in order to store the value associated with a key. OBJECT IDLETIME returns the number of seconds since the object stored at the specified key is idle (not requested by read or write operations). While the value is returned in seconds the actual resolution of this timer is 10 seconds, but may vary in future implementations. This subcommand is available when maxmemory-policy is set to an LRU policy or noeviction. OBJECT FREQ returns the logarithmic access frequency counter of the object stored at the specified key. This subcommand is available when maxmemory-policy is set to an LFU policy. OBJECT HELP returns a succint help text. PERSIST key：去除key中含有的timeout设置 PEXPIRE key milliseconds：设置key的timeout，单位milliseconds而不是秒 PEXPIREAT key milliseconds-timestamp：设置key的timeout已unix时间为准，单位milliseconds PFADD key element [element …]：将所有元素参数element添加到存储在指定为第一个参数key的变量名称的HyperLogLog数据结构中。 PFCOUNT key [key …]： PFMERGE destkey sourcekey [sourcekey …]：合并多个hyberloglog为一个 PING [message]：ping通服务器 PSETEX key milliseconds value：设置key的value中和timeout PSUBSCRIBE pattern [pattern …]：监听发布到渠道的消息中与所给格式匹配的消息 PUBSUB subcommand [argument [argument …]]：检测pub、sub子系统的状态 PTTL key：获取key的timeout，单位milliseconds PUBLISH channel message：发布一个消息到渠道 PUNSUBSCRIBE [pattern [pattern …]]：停止监听发布到渠道的消息中与所给格式匹配的消息 QUIT：关闭连接 RANDOMKEY：从当前数据库中随机返回一个key READONLY：允许连接对集群复制节点进行读操作 READWRITE：禁止连接对集群子节点的读操作 RENAME key newkey：重命名key RENAMENX key newkey：重命名key，并且新名字不存在 RESTORE key ttl serialized-value [REPLACE]：创建一个key，其值为从提供的序列化的值 ROLE：返回当前实例的角色 RPOP key：返回并移除list的最后一个元素 RPOPLPUSH source destination：从source list移除最后一个元素放入destination list中，并返回改元素 RPUSH key value [value …]：在list末尾插入多个元素 RPUSHX key value：仅当list存在时，插入元素key SADD key member [member …]：添加一个元素到set中 SAVE：同步保存数据库到本地磁盘 SCARD key：获取set中元素的数量 SCRIPT DEBUG YES|SYNC|NO：对当前执行的脚本设置debug模式 SCRIPT EXISTS sha1 [sha1 …]：在脚本缓存中检测执行脚本的存在性 SCRIPT FLUSH：清空脚本缓存 SCRIPT KILL：停止当前执行的脚本 SCRIPT LOAD script：加载lua脚本到脚本缓存中 SDIFF key [key …]：返回第一个set中元素与其他所有set中的元素不相同的元素set集合 SDIFFSTORE destination key [key …]：将第一个set中元素与其他所有set中的元素不相同的元素放入目标destination key中 SELECT index：切换redis的逻辑数据库 SET key value [expiration EX seconds|PX milliseconds] [NX|XX]：设置key一个string类型的value值 SETBIT key offset value：设置key中所存储的值的特定偏移的位的值 SETEX key seconds value：设置一个key的value值和timeout（单位秒） SETNX key value：设置key的值，仅当key不存在的时候 SETRANGE key offset value：从给定的偏移出开始，覆盖key中的value值 SHUTDOWN [NOSAVE|SAVE]：同步保存数据库到本地磁盘然后停止服务 SINTER key [key …]：返回多个set中公共的元素集合 SINTERSTORE destination key [key …]：返回多个set中的公共元素到指定元素的destination中 SISMEMBER key member：如果member在key中，返回1，否则返回0； SLAVEOF host port： REPLICAOF host port： SLOWLOG subcommand [argument]：管理redis的慢查询日志，读取或者重置。 SMEMBERS key：返回set中所有的元素 SMOVE source destination member：将member从源set移动到目标set SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern …]] [ASC|DESC] [ALPHA] [STORE destination]：排序集合中的元素 SPOP key [count]：从set中随机返回并移除一个或者多个元素 SRANDMEMBER key [count]：获取set中的一个或多个随机元素 SREM key member [member …]：移除一个或多个set中的元素 STRLEN key：获取key中value值的长度 SUBSCRIBE channel [channel …]：监听发布到给定渠道的消息 SUNION key [key …]：合并多个set集合 SUNIONSTORE destination key [key …]：合并多个set集合到指定元素中 SWAPDB index index：交换两个数据库 TIME：返回服务器当前时间 TOUCH key [key …]：修改key的最后一次访问时间，返回修改key的个数 TTL key：获取key的timeout TYPE key：返回key的类型 UNSUBSCRIBE [channel [channel …]]：停止监听发布到给定渠道的消息 UNLINK key [key …]：用不同线程将key从keyspace移除，真正的删除操作最后同步 UNWATCH：清空所有的监听 WAIT numreplicas timeout：暂停当前客户端操作直到所有的写命令成功执行并且被特定数量的复制节点知道 WATCH key [key …]：设置监听 ZADD key [NX|XX] [CH] [INCR] score member [score member …]：添加一个或几个member到排序set中，若已存在key，则更新 ZCARD key：获取排序set中的元素数量 ZCOUNT key min max：统计排序set中key的值在min和max之间的key的数量 ZINCRBY key increment member：给排序set中的member元素的值增加increment ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]： ZLEXCOUNT key min max：当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序，此命令返回键中有序集合中元素的数量，其值介于min和max之间。 ZPOPMAX key [count]：返回并移除排序set中key的值最大的哪一个元素 ZPOPMIN key [count]：返回并移除排序set中key的值最小的哪一个元素 ZRANGE key start stop [WITHSCORES]：返回排序set中给定范围的元素 ZRANGEBYLEX key min max [LIMIT offset count]：返回排序set中给定范围的元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序） ZREVRANGEBYLEX key max min [LIMIT offset count]：返回排序set中给定范围的元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序）顺序从高到低 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]：返回排序set中给定key的score值范围的元素 ZRANK key member：返回排序set中给定元素的index ZREM key member [member …]：从排序set中删除一个或多个元素 ZREMRANGEBYLEX key min max：删除排序set中给定范围的所有元素（当排序集中的所有元素都插入相同的分数时，为了强制执行词典排序） ZREMRANGEBYRANK key start stop：根据index删除排序set中给定范围的元素 ZREMRANGEBYSCORE key min max：根据score值删除排序set中给定范围的元素 ZREVRANGE key start stop [WITHSCORES]：返回按照index给定范围的排序set中元素，score顺序由高到低 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]：返回按照score给定范围的排序set中元素，score顺序由高到低 ZREVRANK key member：返回排序set中按照score由高到低排好序后的给定的member的index ZSCORE key member：返回排序set中元素的score ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]：存储多个排序set到指定destination中 SCAN cursor [MATCH pattern] [COUNT count]：逐步迭代key space元素集合。 SSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代set元素集合。 HSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代hash filed和value。 ZSCAN key cursor [MATCH pattern] [COUNT count]：逐步迭代set元素和对应的score值。 XINFO [CONSUMERS key groupname] [GROUPS key] [STREAM key] [HELP]：检索有关流和关联的使用者组的不同信息 XADD key ID field string [field string …]：在已有的key实体流后衔接实体流，key不存在则创建一个新的 XTRIM key MAXLEN [~] count： XDEL key ID [ID …]：从流中删除指定的实体 XRANGE key start end [COUNT count]：返回流中给定范围的元素 XREVRANGE key end start [COUNT count]：返回流中给定范围的元素（逆序） XLEN key：返回流中实体的数量 XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]：从一个或多个流中读取数据，只返回ID大于调用者报告的最后一个接收ID的条目 XGROUP [CREATE key groupname id-or-$] [SETID key groupname id-or-$] [DESTROY key groupname] [DELCONSUMER key groupname consumername]：创建，销毁，管理使用者组 XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]： XACK key group ID [ID …]： XCLAIM key group consumer min-idle-time ID [ID …] [IDLE ms] [TIME ms-unix-time] [RETRYCOUNT count] [FORCE] [JUSTID]： XPENDING key group [start end count] [consumer]：]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式通信]]></title>
    <url>%2F2018%2F07%2F15%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[分布式通信所有的通信过程可以抽象为以下几步 服务端服务，并将其通过某个服务机的端口暴露出去供客户端调用。 客户端程序，客户端通过指定服务所在的主机和端口号、将请求封装并序列化，最终通过网络协议发送到服务端。 服务端解析和反序列化请求，调用服务端上的服务，将结果序列化并返回给客户端。 客户端接收并反序列化服务端返回的结果，反馈给用户。 机器通信，归根到底是网络的通信，网络通信需要做的就是将流从一台计算机传输到另外一台计算机，基于传输协议和网络IO来实现，其中传输协议比较出名的有http、tcp、udp等等，http、tcp、udp都是在基于Socket概念上为某类应用场景而扩展出的传输协议，网络IO，主要有bio、nio、aio三种方式，所有的分布式应用通讯都基于这个原理而实现，只是为了应用的易用性，各种语言通常都会提供一些更为贴近应用易用的应用层协议。 一台计算机发起请求，另外一台机器在接收到请求后进行相应的处理并将结果返回给请求端，将请求转换成流，通过传输协议传输至远端，远端计算机在接收到请求的流后进行处理，处理完毕后将结果转化为流，并通过传输协议返回给调用端。 Socket通信12345678910111213141516171819202122位于Java.net包中服务端：ServerSocket server = new ServerSocket(9091);Socket client = server.accept();BufferedReader input = new BufferedReader(new InputStreamReader(client.getInputStream()));String line = input.readLine();String returnMess = execute(line);PrintWriter output = new PrintWriter(client.getOutputStream(), true);output.println(returnMess);客户端：Socket client = new Socket("127.0.0.1", 9091);//通过ip:port与服务器建立连接PrintWriter output = new PrintWriter(client.getOutputStream(), true);//创建输出流，给服务器发送消息output.println(jsonString);output.flush();//刷新缓冲区client.shutdownOutput();//关闭输出流BufferedReader input = new BufferedReader(new InputStreamReader(client.getInputStream()));//创建输入流，接收服务器发送的消息String line = input.readLine();/*while(line!=null)&#123;System.out.println(line);line = input.readLine();&#125;*/client.close(); RPC（Remote Procedure Call Protocol） RPC是在Socket的基础上实现的。 RMI（底层实现还是socket） Stub和Skeleton：这两个的身份是一致的，都是作为代理的存在。客户端的称作Stub，服务端的称作Skeleton。要做到对程序员屏蔽远程方法调用的细节，这两个代理是必不可少的，包括网络连接等细节。 Registry：顾名思义，可以认为Registry是一个“注册所”，提供了服务名到服务的映射。如果没有它，意味着客户端需要记住每个服务所在的端口号，这种设计显然是不优雅的。 RMI 采用stubs 和 skeletons 来进行远程对象(remote object)的通讯。stub 充当远程对象的客户端代理，有着和远程对象相同的远程接口，远程对象的调用实际是通过调用该对象的客户端代理对象stub来完成的，通过该机制RMI就好比它是本地工作，采用tcp/ip协议，客户端直接调用服务端上的一些方法。优点是强类型，编译期可检查错误，缺点是只能基于JAVA语言，客户机与服务器紧耦合； 1234567891011121314151617181920创建远程接口-直接或间接继承java.rmi.Remote接口；-接口中的所有方法声明抛出java.rmi.RemoteException异常或父异常。创建远程实现类，实现远程接口；-继承java.rmi.server.UnicastRemoteObject类，构造器必须抛出java.rmi.RemoteException异常。-或者使用UnicastRemoteObject.exportObject(this/实现类对象实例, 0);创建服务器程序，在rmiregistry注册表中注册远程对象；LocateRegistry.createRegistry(1099);//定义暴露服务接口HelloService service = new HelloServiceImpl("service");//实例化服务实现类Naming.bind("rmi://localhost:1099/HelloService", service);//绑定实现类在服务器上对应的接口-bind(String name, Object obj): 注册对象，把对象与服务名绑定。如果该服务名已与其他对象绑定，则会抛出NameAlreadyBoundException异常。-rebind(String name, Object obj): 注册对象，把对象与服务名绑定。如果该服务名已与其他对象绑定，不会抛异常，而是将新的对象绑定到该服务名上。-lookup(String name): 查找对象，返回与指定名称相同的对象。创建客户端程序，负责定位远程对象，并且调用远程方法。HelloService serv = (HelloService) Naming.lookup(url + "HelloService1");//定位远程服务serv.service(“Hello ”);//调用远程服务客户端和服务端通过Stub和Skeleton建立了socket连接，后面的操作直接通过这个连接完成就结了！ WebService Web Service提供的服务是基于web容器的，底层使用http协议，类似一个远程的服务提供者，就是通过一个servlet，提供服务出去。首先客户端从服务器的到WebService的WSDL，同时在客户端声称一个代理类(Proxy Class) 这个代理类负责与WebService服务器进行Request 和Response 当一个数据（XML格式的）被封装成SOAP格式的数据流发送到服务器端的时候，就会生成一个进程对象并且把接收到这个Request的SOAP包进行解析，然后对事物进行处理，处理结束以后再对这个计算结果进行SOAP包装，然后把这个包作为一个Response发送给客户端的代理类(Proxy Class)，同样地，这个代理类也对这个SOAP包进行解析处理，继而进行后续操作。这就是WebService的一个运行过程。Web Service大体上分为5个层次: Http传输信道 XML的数据格式 SOAP封装格式 WSDL的描述方式 UDDI UDDI是一种目录服务，企业可以使用它对Webservices进行注册和搜索 JMS（Java Messaging Service） Java消息服务是一个与具体平台无关的API（activeMQ是jms的其中一种开源实现类），绝大多数MOM提供商都对JMS提供支持。JMS是Java的消息服务，JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS支持两种消息模型：Point-to-Point（P2P）和Publish/Subscribe（Pub/Sub），即点对点和发布订阅模型。优点：支持异步通信、消息produce和recept松耦合。在JMS编程模型中，JMS客户端使用connectionFactory对象创建一个连接，向消息服务发送消息以及从消息服务接收消息均是通过此连接来进行。Connection是客户端与消息服务的活动连接，创建连接时将分配通信资源以及验证客户端。大多数客户端均使用一个连接来进行所有的消息发送。连接用于创建会话，Session是一个用于生成和使用消息的单线程上下文。它用于创建发送的生产者和接收消息的消费者，并为所发送的消息定义发送顺序，会话通过大量确认选项或通过事务来支持可靠发送。客户端使用 MessageProducer 向指定的物理目标（在 API 中表示为目标身份对象）发送消息。生产者可指定一个默认传送模式（持久性消息与非持久性消息）、优先级和有效期值，以控制生产者向物理目标发送的所有消息。 同样，客户端使用 MessageConsumer 对象从指定的物理目标（在 API 中表示为目标对象）接收消息。消费者可使用消息选择器，借助它，消息服务可以只向消费者发送与选择标准匹配的那些消息。消费者可以支持同步或异步消息接收。异步使用可通过向消费者注册 MessageListener 来实现。当会话线程调用 MessageListener 对象的 onMessage 方法时，客户端将使用消息。 RPC与RMI （1）RPC 跨语言，而 RMI只支持Java。（2）RMI 调用远程对象方法，允许方法返回 Java 对象以及基本数据类型，而RPC 不支持对象的概念，传送到 RPC服务的消息由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。只有由 XDR 定义的数据类型才能被传递， 可以说 RMI 是面向对象方式的 Java RPC 。（3）在方法调用上，RMI中，远程接口使每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口上，那么这个新方法就不能被RMI客户方所调用。在RPC中，当一个请求到达RPC服务器时，这个请求就包含了一个参数集和一个文本值，通常形成“classname.methodname”的形式。这就向RPC服务器表明，被请求的方法在为 “classname”的类中，名叫“methodname”。然后RPC服务器就去搜索与之相匹配的类和方法，并把它作为那种方法参数类型的输入。这里的参数类型是与RPC请求中的类型是匹配的。一旦匹配成功，这个方法就被调用了，其结果被编码后返回客户方。 JMS与RMI JMS 服务，对象是在物理上被异步从网络的某个JVM 上直接移动到另一个JVM 上（是消息通知机制）而RMI 对象是绑定在本地JVM 中，只有函数参数和返回值是通过网络传送的（是请求应答机制）。RMI一般都是同步的，也就是说，当client调用Server的一个方法的时候，需要等到对方的返回，才能继续执行client端，这个过程调用本地方法感觉上是一样的，这也是RMI的一个特点。JMS 一般只是一个点发出一个Message到Message Server,发出之后一般不会关心谁用了这个message。所以，一般RMI的应用是紧耦合，JMS的应用相对来说是松散耦合应用。 JNDI（Java naming and Directory Interface） Java命名与目录接口，包含两个服务，命名服务奖名称和对象联系起来，使得我们可以用名称访问对象，目录服务是一种命名服务，在这种服务里，对象不但有名称，还有属性。使用JNDI，一个J2EE应用程序可以存储和动态获取任何类型的命名Java对象。因为JNDI不依赖于任何特定的执行，应用程序可以使用JNDI访问各种命名目录服务，包括现有的诸如LDAP、NDS、DNS、NIS、COS命名和RMI注册等服务。这使得J2EE应用程序可以和传统的应用程序和系统共存。从JNDI的架构中可以看出，JNDI分为三部分，应用程序编程接口（API）和服务供应商接口（SPI），前者Java应用程序访问各种命名和目录服务，开发上层应用的程序员就不必去关心底层具体的技术细节，后者则是设计来供任意一种服务的供应商（也包括目录服务供应商）使用，这一层一般由供应商去完成。]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>RPC</tag>
        <tag>RMI</tag>
        <tag>WebService</tag>
        <tag>JMS</tag>
        <tag>EJB</tag>
        <tag>JNDI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper]]></title>
    <url>%2F2018%2F07%2F08%2FZookeeper%2F</url>
    <content type="text"><![CDATA[Zookeeper What is Zookeeper ? Why use Zookeeper ? Theory Leader Election Deploy How to use ? Command Line API Curator What is Zookeeper ? ZK被多数人认为是一个注册中心，在分布式架构中像服务提供者和服务消费者之间的一个枢纽站，服务提供者将服务注册在注册中心以供服务消费者来获取消费，支持一对一，一对多，多对一，多对多等模式，其原理简单来讲，就是服务提供者在注册中心注册自己的服务地址，并通过一定端口将自己的服务暴露出去，消费者想要使用提供者所提供的服务时，首先需要去注册中心匹配相应的服务以获取该具体服务提供的地址，然后才能去访问该服务提供者以消费该服务，多对多模式中，如果同一时间消费者大量的涌入注册中心去访问同一服务，ZK还具有负载均衡的作用来有效的分配大量的请求流量。 Why use Zookeeper ? 问：为什么不直接用消费者去调用服务提供者，加一层类似中间件的注册中心有什么好处，有哪些实际应用场景，即ZK存在的理由 ? 答：首先明确一点，就是所有的中间件的诞生都是基于将某些公共的，重复的内容抽取出来简化过程，ZK的诞生同样也不例外。 集群的管理：所谓集群管理，无外乎两点，是否有机器加入和退出，选举master，ZK的leader选举规则（此处为超链接）。 公共配置的管理：分布式环境或者是集群环境中，将同一个应用系统部署到多台服务器上，或者一个应用系统需要多台服务器一起运行是非常常见的情况，那么一定会存在大量的配置是公共的，重复性的存在于多台服务器上，一旦配置发生变动，那配置的更改将变得非常繁琐，并且容易出现错误，这时我们就想要将所有的公共的配置全部都提取出来共同维护，ZK将所有的公共配置全部注册到它的服务器上，并且让所有用到该配置的其他服务启用监听，每当ZK服务器上的配置发生变动时，所有监听的服务就会收到ZK的通知，然后监听服务只需要从ZK服务器更新配置文件即可，免去了人工手动更改大量重复配置文件的繁琐操作，同时也降低了错误发生的概率。 共享锁/分布式锁：锁服务可以分为两类，一种是独占锁，一种是时序锁。 在同一个进程中锁往往很容易实现，但是在跨进程和跨服务之间就不容易实现了，因为感知其他进程和服务的锁的使用情况变得复杂，但是Zookeeper 却很容易实现这个功能，因为它可以将各个进程或者服务对锁的使用情况再次变得简单起来 利用节点名称唯一性来实现 思路: 利用名称唯一性，加锁操作时，只需要所有客户端一起创建/test/Lock节点，只有一个创建成功，成功者获得锁。解锁时，只需删除/test/Lock节点，其余客户端再次进入竞争创建节点，直到所有客户端都获得锁。 缺点：会产生“惊群”效应，假如许多客户端在等待一把锁，当锁释放时候所有客户端都被唤醒，仅仅有一个客户端得到锁。 利用临时顺序节点来实现 Zookeeper中有一种节点叫做顺序节点ZooKeeper中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZooKeeper集群断开连接，则该节点自动被删除。 客户端调用create()方法创建名为“locknode/guid-lock-”的节点，需要注意的是，这里节点的创建类型需要设置为EPHEMERAL_SEQUENTIAL。 客户端调用getChildren(“locknode”)方法来获取所有已经创建的子节点，同时在这个节点上注册上子节点变更通知的Watcher。客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。 如果在步骤3中发现自己并非是所有子节点中最小的，说明自己还没有获取到锁，就开始等待，直到下次子节点变更通知的时候，再进行子节点的获取，判断是否获取锁。 临时顺序节点改进 方法2的缺点：客户端接受到过多的和自己不相关的事件通知，这如果在集群规模大的时候，会对Server造成很大的性能影响，并且如果一旦同一时间有多个节点的客户端断开连接，这个时候，服务器就会像其余客户端发送大量的事件通知——这就是所谓的惊群效应。 改进：由原来的监视所有节点变成监视一个节点。 思路：对于加锁操作，可以让所有客户端都去/lock目录下创建临时顺序节点，如果创建的客户端发现自身创建节点序列号是/lock/目录下最小的节点，则获得锁。否则，监视比自己创建节点的序列号小的节点（比自己创建的节点小的最大节点），进入等待。 释放锁很简单，只要删除前面它自己所创建的目录节点就行了。 Theory ZK中的角色定义： server角色 Leader：负责投票的发起和决议，更新系统状态 Flower：接收客户请求并返回结果，在选主过程过程中参与投票 Observe：接收客户端请求，转发给leader，且不参与选主过程，只是同步leader状态。其存在目的是为了扩展系统，提高读取速度。 Client角色 Client：发送请求 工作原理： 我们知道各服务是通过启用监听来保持和ZK服务器上公共配置的一致性，但是ZK内部自己是如何保持在集群状态下的各个leader和flower之间的同步以及leader的产生，即选主。 对应着ZK中两种模式来分别实现，恢复模式：即在集群平衡状态被打破后需要重新选举产生leader并完成选举后的同步；广播模式：即集群在平衡状态下leader与各flower之间的同步。 为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增。 ZXID=32(高位epoch，leader编号)+32（低位proposal事务编号） 这里的事务主要指的是写请求，因为读请求不会导致节点数据更新，即不会引发同步操作，只有当遇到写请求时才会导致同步发生，并且，flower只有处理读请求的权限，当遇到写请求时，flower会将请求转发给leader来处理，然后由leader来发起同步操作更新集群状态。 消息广播 集群正常运转情况下：消息广播协议，当flower接受到数据改动请求，及写请求后，会将其转发给leader，然后leader将其请求以事务 的形式广播发给所有的flower，flower收到后以事务日志的形式存入本地磁盘，成功写入后然后回传给leader一个ack消息，leader收到ack响应后并且响应数量超过半数服务器数量后，便继续广播一个commit提交事务给所有的flower，flower收到后开始提交事务，同时leader也开始提交事务，以此达到数据同步的效果。 崩溃恢复 Leader宕机之后如何恢复并选举出新的leader：首先，leader宕机后或者TCP连接中断后，所有的flower和leader均变成looking状态，即选举leader状态。 从所有的flower中选出ZXID最大的作为新leader，因为新leader上任后需要应对缺失事务proposal补充和多余事务的丢弃，而由于ZXID 为一个全局的唯一ID，ZXID 最大意味着最高事务编号，也就意味着其包含了所有的成功已提交事务，省去了检查事务提交和缺失丢弃的步骤。 Leader选举后的数据同步和数据丢弃 数据同步：leader将那些flower没有的事务proposal通过队列下发给所有的flower，flower将其同步到本地数据库中，成功后leader将其列入可用flower列表中。 数据丢弃：leader根据自己的proposal和flower和proposal比较，结果必然是flower进行回退，丢弃自己的proposal，回退到一个集群中过半数flower提交的最新的事务proposal。 Leader Election 首先明确zookeeper选举规则的先决条件; 可用节点数量 &gt; 总节点数量/2 。注意 是 &gt; , 不是 ≥。 注：为什么规则要求 可用节点数量 &gt; 集群总结点数量/2 ？（为什么集群数量一般为奇数） 如果不这样限制，在集群出现脑裂的时候，可能会出现多个子集群同时服务的情况（即子集群各组选举出自己的leader）， 这样对整个zookeeper集群来说是紊乱的。 换句话说，如果遵守上述规则进行选举，即使出现脑裂，集群最多也只能回出现一个子集群可以提供服务的情况（能满足节点数量&gt; 总结点数量/2 的子集群最多只会有一个）。所以要限制 可用节点数量 &gt; 集群总结点数量/2 。 什么是脑裂？集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，小集群各自选出自己的master节点，导致原有的集群出现多个master节点的情况，这就是脑裂。 官方文档地址：https://zookeeper.apache.org/doc/current/recipes.html 内容如下： Leader ElectionA simple way of doing leader election with ZooKeeper is to use the SEQUENCE|EPHEMERAL flags when creating znodes that represent “proposals” of clients. The idea is to have a znode, say “/election”, such that each znode creates a child znode “/election/n“ with both flags SEQUENCE|EPHEMERAL. With the sequence flag, ZooKeeper automatically appends a sequence number that is greater that any one previously appended to a child of “/election”. The process that created the znode with the smallest appended sequence number is the leader.That’s not all, though. It is important to watch for failures of the leader, so that a new client arises as the new leader in the case the current leader fails. A trivial solution is to have all application processes watching upon the current smallest znode, and checking if they are the new leader when the smallest znode goes away (note that the smallest znode will go away if the leader fails because the node is ephemeral). But this causes a herd effect: upon of failure of the current leader, all other processes receive a notification, and execute getChildren on “/election” to obtain the current list of children of “/election”. If the number of clients is large, it causes a spike on the number of operations that ZooKeeper servers have to process. To avoid the herd effect, it is sufficient to watch for the next znode down on the sequence of znodes. If a client receives a notification that the znode it is watching is gone, then it becomes the new leader in the case that there is no smaller znode. Note that this avoids the herd effect by not having all clients watching the same znode.Here’s the pseudo code:Let ELECTION be a path of choice of the application. To volunteer to be a leader:Create znode z with path “ELECTION/n“ with both SEQUENCE and EPHEMERAL flags;Let C be the children of “ELECTION”, and i be the sequence number of z;Watch for changes on “ELECTION/n_j”, where j is the largest sequence number such that j &lt; i and n_j is a znode in C;Upon receiving a notification of znode deletion:Let C be the new set of children of ELECTION;If z is the smallest node in C, then execute leader procedure;Otherwise, watch for changes on “ELECTION/n_j”, where j is the largest sequence number such that j &lt; i and n_j is a znode in C;Note that the znode having no preceding znode on the list of children does not imply that the creator of this znode is aware that it is the current leader. Applications may consider creating a separate znode to acknowledge that the leader has executed the leader procedure. 大意为：选举的一种简单方式为利用ZK中的临时顺序节点，具体思路为有一个名为/election的节点，然后所有节点开始在该节点下创建子节点/election/n_，类型为临时顺序节点，创建成功后ZK自动在节点后衔接一个顺序号，顺序号最小的即为leader，同时，所有节点启动对/election节点的监视，当该节点发生变动时，检测自己的节点顺序号是否为最小，是则晋升为leader，否则继续监视。 与分布式锁遇到的问题雷同，所有节点监视/election节点，相当于监视所有节点在该节点下的子节点，当该节点发生变动时，所有节点都会接收到通知，但其实只有一个节点晋升为leader，意味着其他节点会接受到大量的无用通知，当服务器数量较为庞大时，便会引起”惊群效应”。改进措施同样与分布式锁解决方案一样，将对/election节点的监视更改为对该节点下顺序号比自己小的最大节点的监视。可对比分布式锁理解。 Deploy 单机模式： 下载zookeeper到本地（PC端），解压后可看到zookeeper的目录结构，/bin中存放着一些.sh或者.cmd的命令（如启动服务器命令和客户端连接服务器命令等），/conf中存放着配置文件，其中有一个zoo.sample.cfg的配置文件，我们需要将其复制一份命名为zoo.cfg，然后在其中添加两行（官网说默认在日志和数据存放在一个文件中，但是考虑到性能问题，建议还是分开存放） dataDir=../data 用于存放snapshot文件dataLogDir=../log 用于存放日志log文件 客户端端口默认为2181，一般无需修改，除非自己本机出现端口占用问题 。clientPort=2181 我们下载的zookeeper文件夹中有一个zookeeper.jar包，我们可以理解为zookeeper的客户端API，我们可以将该jar包导入工程项目中来连接zookeeper的服务器并对其进行相关操作。 还有一个客户端我们可以使用——Curator（https://curator.apache.org/） 集群模式： 在不同的服务器上分别安装zookeeper，并对其进行相关配置，在zoo.cfg配置文件中我们需要加上相同的几行配置（下面的意思为让zookeeper的集群服务器之间相互知道对方的存在，由于在不同的服务器上，所以端口号无需修改，但是服务器ip一定不能相同） server.1=server.ip1:2888:3888server.2=server.ip2:2888:3888server.3=server.ip3:2888:3888 然后我们还需要在存放snapshot文件的data文件夹中创建myid文件并在其中写入一行配置，即自己的服务器序号，就是配置文件中自己ip前面的服务器序号（server.1的1，其范围是1到255） 伪集群模式： 即在一个物理服务器上搭建多个逻辑上的zookeeper集群，其部署方式与真正集群相似，不同的是在同一个服务器上，所以配置文件中的ip均相同，但是端口号需要改为不同的端口号，其余均与集群配置一致。 server.1=server.ip:2888:3888server.2=server.ip:2889:3889server.3=server.ip:2890:3890 How to use ? 命令行指令 在ZK中，ZK客户端对服务器每一个数据节点的写操作，ZK会认为都是一次完整的事务操作，要么成功，要么失败，保证了数据的原子性。而每次事务都会分配一个唯一的事务id，以标识这次事务操作的数据信息。下面详细理解一下节点状态各个字段的含义：cZxid：创建节点的事务idctime：创建节点的时间mZxid：修改节点的事务idmtime：修改节点的时间pZxid：子节点列表最后一次修改的事务id。删除或添加子节点，不包含修改子节点的数据。cversion：子节点的版本号，删除或添加子节点，版本号会自增dataVersion：节点数据版本号，数据写入操作，版本号会递增aclVersion：节点ACL权限版本，权限写入操作，版本号会递增ephemeralOwner：临时节点创建时的事务id，如果节点是永久节点，则它的值为0dataLength：节点数据长度（单位：byte），中文占3个bytenumChildren：子节点数量 服务器启动命令：./zkServer.sh start 服务器检测状态：./zkServer.sh status 客户端连接本地服务器：./zkCli.sh -server 127.0.0.1:2181 显示节点：ls /（或者ls2 /） 创建节点：create /liufein（节点名） liufei（节点值） 获取节点信息：get /liufein 设置节点信息：set /liufein stefan（节点新值）【信息中数据版本字段会随着数据更改次数而自增】 删除节点信息：delete /liufein（子节点不为空不能删除）删除节点命令，此命令与delete命令不同的是delete不可删除有子节点的节点，但是rmr命令可以删除，注意路径为绝对路径。该命令现在也可执行，但会有提示使用deleteall命令来替代 查看节点状态信息。如stat /zookeeper 显示配额：如listquota /zookeeper 查看节点权限Acl：如getAcl /zookeeper/node1 SetAcl命令，设置权限 （ACL权限控制:注意:删除权限的作用范围为其子节点，而非其本身，意味着当你给某一节点设置了删除权限后，你依然可以随意的删除该节点，但是其子节点不能。） acl由三部分组成：1为scheme，2为user，3为permission，一般情况下表示为scheme:id:permissions。 world: 它下面只有一个id, 叫anyone, world:anyone代表任何人，zookeeper中对所有人有权限的结点就是属于world:anyone的 auth: 它不需要id, 只要是通过authentication的user都有权限（zookeeper支持通过kerberos来进行authencation, 也支持username/password形式的authentication) digest: 它对应的id为username:BASE64(SHA1(password))，它需要先通过username:password形式的authentication。（由于使用digest时，密码会经过SHA1和BASE64的两层编码转换，所以我们可以使用命令：echo -n lf:lf | openssl dgst -binary -sha1 | openssl base64用于输出密码所对应的BASE64(SHA1(password))编码之后的值，然后使用该值进行权限的设置，这样在我们使用授权的时候就可以直接使用编码前的字符，避免使用编码后的复杂难记忆的字符，例如setAcl /liufein digest:lf:shTM7tNH6fVkpZWS9MbSN6xaJEM=:rwdca设置授权命令，addauth digest lf:lf添加权限命令） ip: 它对应的id为客户机的IP地址，设置的时候可以设置一个ip段，比如ip:192.168.1.0/16, 表示匹配前16个bit的IP段 super: 在这种scheme情况下，对应的id拥有超级权限，可以做任何事情(cdrwa) Permissions CREATE(c): 创建权限，可以在在当前node下创建child node DELETE(d): 删除权限，可以删除当前的node READ(r): 读权限，可以获取当前node的数据，可以list当前node所有的child nodes WRITE(w): 写权限，可以向当前node写数据 ADMIN(a): 管理权限，可以设置当前node的permission 综上，一个简单使用setAcl命令，则可以为：setAcl/zookeeper/node1 world:anyone:cdrw Digest:先设置权限，其中密码使用的是编码的格式setAcl /zookeeper digest:username:BASE64(SHA1(password)):rwadc然后添加访问权限，此时密码使用的明文字符addauth digest lf:lf添加权限后才能进行相关操作 Auth：先添加权限，密码为明文addauth digest username:password然后设置权限，密码同样为明文setAcl /zookeeper auth:username:passeword:rwadc 可以添加监听watajch的命令有(即可以使用以下命令来设置watch) Stat path [watch] Ls path [watch] Ls2 path [watch] Get path [watch] API使用指南 API官方地址：https://zookeeper.apache.org/doc/r3.4.6/api/org/apache/zookeeper/ZooKeeper.html Zk中为我们提供了一个原生的jar包来供我们依赖使用，其位置就在/zookeeper/下 我们在开发环境中，新建工程，将其导入即可使用其来操作zk服务器中节点数据，如下为简单的一些实际操作 连接zk 客户端和zk服务端链接是一个异步的过，当连接成功后后，客户端会收的一个watch通知 参数：connectString：连接服务器的ip字符串，比如: “192.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181”可以是一个ip，也可以是多个ip，一个ip代表单机，多个ip代表集群，也可以在ip后加路径 sessionTimeout：超时时间，心跳收不到了，那就超时 watcher：通知事件，如果有对应的事件触发，则会收到一个通知；如果不需要，那就设置为null canBeReadOnly：可读，当这个物理机节点断开后，还是可以读到数据的，只是不能写，此时数据被读取到的可能是旧数据，此处建议设置为false，不推荐使用 sessionId：会话的id sessionPasswd：会话密码 当会话丢失后，可以依据 sessionId 和 sessionPasswd 重新获取会话 1234ZooKeeper zk = new ZooKeeper(ZK_SERVER_PATH, TIME_OUT, new ZKConnection()); long sessionId = zk.getSessionId(); byte[] sessionPassword = zk.getSessionPasswd(); ZooKeeper zkSession = new ZooKeeper(ZK_SERVER_PATH,TIME_OUT,new ZKConnection(), sessionId,sessionPassword); 节点创建 123456789101112131415161718192021222324252627282930313233/** * 同步或者异步创建节点，都不支持子节点的递归创建，异步有一个callback函数 * 参数： * path：创建的路径 * data：存储的数据的byte[] * acl：控制权限策略 * Ids.OPEN_ACL_UNSAFE --&gt; world:anyone:cdrwa * CREATOR_ALL_ACL --&gt; auth:user:password:cdrwa * createMode：节点类型, 是一个枚举 * PERSISTENT：持久节点 * PERSISTENT_SEQUENTIAL：持久顺序节点 * EPHEMERAL：临时节点 * EPHEMERAL_SEQUENTIAL：临时顺序节点 */ /*同步创建*/ result = zookeeper.create(path, data, acls, CreateMode.PERSISTENT); /*异步创建*/ String ctx = "&#123;'create':'success'&#125;"; zookeeper.create(path, data, acls, CreateMode.PERSISTENT, new CreateCallBack(), ctx); ``` - Callback回调函数： - 通知和回调的区别： - 通知是ZooKeeper中注册了监视点的客户端收到的事件报告消息 - 回调是基于异步思想的,通过回调函数来确定操作的完成情况 &gt; ZK中回调函数均由某些接口定义，我们需要实现该接口，并实现其中的processResult方法，其中接口的实现随功能而定，如以下创建和删除方法中的回调接口便不一致（方法内参数也不同），具体可参考官方API - 参数中有一个Object ctx，该参数为回调信息，类型为Object意味着回调类型可以为任意类型。 ```java create(String path, byte[] data, List&lt;ACL&gt; acl, CreateMode createMode, AsyncCallback.StringCallback cb, Object ctx) delete(String path, int version, AsyncCallback.VoidCallback cb, Object ctx) Watcher通知事件： ZooKeeper中实现对接点的监控,需要实现Watcher接口类,实现其中的process方法 12345public class WatcherDemo implements Watcher&#123; public void process(WatchedEvent event) &#123; 监视事件发生后进行的操作 &#125; &#125; 监视事件的设置，如： 12Zookeeper.exists(String path, Watcher watcher)方法， 具体使用为：Zookeeper.exists("/dubbo", new WatcherDemo() ) 意味着给节点/dubbo实行监视，当他存在即创建时，监视事件WatcherDemo被触发，引发该类的process()方法被执行。其余均类似，可参考官方API中具体有那些方法可以设置通知事件Watcher 权限设置 任何人可以访问： zkServer.createZKNode("/aclimooc", "test".getBytes(), Ids.OPEN_ACL_UNSAFE); 1 自定义用户认证访问： 1234567List&lt;ACL&gt; acls = new ArrayList&lt;ACL&gt;(); Id imooc1 = new Id("digest",DigestAuthenticationProvider.generateDigest("imooc1:123456")); Id imooc2 = new Id("digest",DigestAuthenticationProvider.generateDigest("imooc2:123456")); acls.add(new ACL(Perms.ALL, imooc1)); acls.add(new ACL(Perms.READ, imooc2)); acls.add(new ACL(Perms.DELETE | Perms.CREATE, imooc2)); zkServer.createZKNode("/aclimooc/testdigest", "testdigest".getBytes(), acls); 注册过的用户必须通过addAuthInfo才能操作节点，参考命令行 addauth： 123456zkServer.getZookeeper().addAuthInfo("digest", "imooc1:123456".getBytes()); zkServer.createZKNode("/aclimooc/testdigest/childtest","childtest".getBytes(),Ids.CREATOR_ALL_ACL); Stat stat = new Stat(); byte[] data = zkServer.getZookeeper().getData("/aclimooc/testdigest", false, stat); System.out.println(new String(data)); zkServer.getZookeeper().setData("/aclimooc/testdigest", "now".getBytes(), 1); Ip方式的acl： 1234List&lt;ACL&gt; aclsIP = new ArrayList&lt;ACL&gt;(); Id ipId1 = new Id("ip", "192.168.1.6"); aclsIP.add(new ACL(Perms.ALL, ipId1)); zkServer.createZKNode("/aclimooc/iptest6", "iptest".getBytes(), aclsIP); DigestAuthenticationProvider.generateDigest(id);转码操作，类似于命令行的echo -n lf:lf | openssl dgst -binary -sha1 | openssl base64 Curator客户端使用指南]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Zookeeper</tag>
        <tag>Provider</tag>
        <tag>Consumer</tag>
        <tag>RegistrationCenter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeanCopy]]></title>
    <url>%2F2018%2F07%2F01%2FBeanCopy%2F</url>
    <content type="text"><![CDATA[Bean类的复制 当bean对象中属性字段较少时，我们通常手动使用置取方法来完成一个bean对象的复制，但是实际项目中往往一个bean类中含有大量的属性字段，所以手动复制变得不太现实，beancopy技术因此应用而生。 Apache的两个版本：（原理：反射机制） org.apache.commons.beanutils.PropertyUtils.copyProperties(Object dest, Object orig) org.apache.commons.beanutils.BeanUtils.copyProperties(Object dest, Object orig)Spring版本：（原理：反射机制） org.springframework.beans.BeanUtils.copyProperties(Object source, Object target, Class editable, String[] ignoreProperties)cglib版本：（原理：字节码+动态代理，效率最高） net.sf.cglib.beans.BeanCopier.copy(Object paramObject1, Object paramObject2, Converter paramConverter) 反射原理我们都很熟，也很常见，字节码可能听着较为生疏，所以这里主要聊一聊cglib版本的beancopy（这是cglib用到的两个jar包：cglib-nodep-3.2.7.jar和asm-4.0.jar） 使用指南：1234SourceBean sourceBean = new SourceBean();TargetBean targetBean = new TargetBean(); BeanCopier copier = BeanCopier.create(SourceBean.class, TargetBean.class, false); copier.copy(sourceBean, targetBean, null); BeanCopier中Create对象过程： 产生sourceClass-》TargetClass的拷贝代理类，放入jvm中，所以创建的代理类的时候比较耗时，最好保证这个对象的单例模式。 创建过程：源代码见jdk：net.sf.cglib.beans.BeanCopier.Generator.generateClass(ClassVisitor) 获取sourceClass的所有public get 方法-》PropertyDescriptor[] getters 获取TargetClass 的所有 public set 方法-》PropertyDescriptor[] setters 遍历setters的每一个属性，执行4和5 按setters的name生成sourceClass的所有setter方法-》PropertyDescriptor getter【不符合javabean规范的类将会可能出现空指针异常】 PropertyDescriptor[] setters-》PropertyDescriptor setter 将setter和getter名字和类型 配对，生成代理类的拷贝方法。 Copy属性过程：调用生成的代理类，代理类的代码和手工操作的代码很类似，效率非常高。 从多字段向少字段（层层筛选）的拷贝，从少字段的向多字段（层层叠加）的拷贝均可实现，其核心都是target.setXXX(source.getXXX()),所以源类的get方法和目标类的set方法不可缺少，否则值将拷贝不过去。 后续延伸 cglib是一款比较底层的操作java字节码的框架CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。除了CGLIB包，脚本语言例如Groovy和BeanShell，也是使用ASM来生成java的字节码。当然不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflection</tag>
        <tag>Bean</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro Integration]]></title>
    <url>%2F2018%2F05%2F20%2FShiro%20Integration%2F</url>
    <content type="text"><![CDATA[Shiro Integration springboot集成shiro（非web应用） springboot集成shiro（web应用） spring集成shiro（web应用） springboot集成shiro（非web应用） shiro-spring-boot-starter包为我们省去了好多设置 编写myrealm（可继承jdbcRealm或者Realm） AuthenticationInfo配置验证 AuthorizationInfo配置授权 可编写多个myrealm，但是会涉及到验证策略 编写配置类 shiroConfig 配置Realm bean 可设置密码加密，加密算法有MD5… 如果有多个realm需要设置验证策略 也可以自定义验证策略，使用自己的策略 缓存设置（否则每个请求都将触发验证查询数据库操作） 记住我设置） 编写CommandLineRunner来设置securityManager启动shiro 编写授权服务，可使用注解对服务进行权限设定 运行测试 springboot集成shiro（web应用） shiro-spring-boot-web-starter依赖引入 测试使用thymeleaf前端，引入thymeleaf和servlet的包 编写myrealm（与非web应用同理） 编写配置类 Realm 加密算法HashedCredentialsMatcher 过滤器链ShiroFilterChainDefinition（url路径权限设置） modelattribute设置（subject）与ui交互 编写控制层controller application.properties参数配置 验证失败重定向url配置 shiro接管session配置 禁止session重写配置 spring集成shiro（javaconfig方式） web配置类（实现WebApplicationInitializer接口，重写onStartUp方法） 获取AnnotationConfigWebApplicationContext实例注册配置文件（包括mvc配置，shiro配置），设置ServletContext DelegatingFilterProxy过滤器注册 springMVC的DispatcherServlet注册 mvc配置 视图层解析配置（jsp、html） 静态资源配置 shiro配置 realm实例 shiro bean生命周期管理实例LifecycleBeanPostProcessor 注解功能开启 shiroFilter过滤器 验证失败重定向url页面配置 未授权重定向url 过滤器链url授权配置 securityManager 缓存ehcache（需要配置缓存xml配置文件） sessionManager cookie记住我管理 simpleCookie]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web.xml]]></title>
    <url>%2F2018%2F05%2F13%2FWeb.xml%2F</url>
    <content type="text"><![CDATA[Web.xml web.xml javaconfig配置 springboot配置web web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot;&gt; &lt;!-- icon元素指出IDE和GUI工具用来表示Web应用的一个和两个图像文件的位置。 --&gt; &lt;icon&gt; &lt;small-icon&gt;/images/small-book.gif&lt;/small-icon&gt; &lt;large-icon&gt;/images/tome.jpg&lt;/large-icon&gt; &lt;/icon&gt; &lt;!-- display-name元素提供GUI工具可能会用来标记这个特定的Web应用的一个名称。 --&gt; &lt;display-name&gt;&lt;/display-name&gt; &lt;!-- description元素给出与此有关的说明性文本。 --&gt; &lt;description&gt;&lt;/description&gt; &lt;!-- context-param元素声明应用范围内的初始化参数，所有servlet全都可以获取使用该参数 --&gt; &lt;context-param&gt; &lt;param-name&gt;support-email&lt;/param-name&gt; &lt;param-value&gt;blackhole@mycompany.com&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- filter 过滤器元素将一个名字与一个实现javax.servlet.Filter接口的类相关联。 --&gt; &lt;filter&gt; &lt;filter-name&gt; &lt;filter-class&gt; &lt;/filter&gt; &lt;!-- filter-mapping 一旦命名了一个过滤器，就要利用filter-mapping元素把它与一个或多个servlet或JSP页面相关联。 --&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;Reporter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; 过滤所有路径 或者 &lt;filter-name&gt;Reporter&lt;/filter-name&gt; &lt;servlet-name&gt;SomeServletName&lt;/servlet-name&gt; 关联servlet &lt;/filter-mapping&gt; &lt;!-- listener 对事件监听程序的支持，事件监听程序在建立、修改和删除会话或servlet环境时得到通知。Listener元素指出事件监听程序类。 --&gt; &lt;listener&gt; &lt;listener-class&gt; &lt;/listener&gt; &lt;!-- servlet 在向servlet或JSP页面制定初始化参数或定制URL时，必须首先命名servlet或JSP页面。Servlet元素就是用来完成此项任务的。 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;Search&lt;/servlet-name&gt; &lt;servlet-class&gt;myPackage.SearchServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; 启动时装载（默认请求时装载，若初始化时消耗时间较长，则可以考虑启动时装载） &lt;init-param&gt; 单个servlet所需要的初始化参数 &lt;param-name&gt;firstName&lt;/param-name&gt; &lt;param-value&gt;Larry&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;!-- servlet-mapping 服务器一般为servlet提供一个缺省的URL：http://host/webAppPrefix/servlet/ServletName。但是，常常会更改这个URL，以便servlet可以访问初始化参数或更容易地处理相对URL。在更改缺省URL时，使用servlet-mapping元素。 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt; PageName &lt;/servlet-name&gt; &lt;url-pattern&gt;/UrlTest2/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- session-config 如果某个会话在一定时间内未被访问，服务器可以抛弃它以节省内存。可通过使用HttpSession的setMaxInactiveInterval方法明确设置单个会话对象的超时值，或者可利用session-config元素制定缺省超时值。 --&gt; &lt;session-config&gt; &lt;session-timeout&gt;180&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;!-- mime-mapping 如果Web应用具有想到特殊的文件，希望能保证给他们分配特定的MIME类型，则mime-mapping元素提供这种保证。 --&gt; &lt;mime-mapping&gt;&lt;/mime-mapping&gt; &lt;!-- welcome-file-list元素指示服务器在收到引用一个目录名而不是文件名的URL时，使用哪个文件。 --&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- error-page元素使得在返回特定HTTP状态代码时，或者特定类型的异常被抛出时，能够制定将要显示的页面。 --&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/errors/servererror.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;!-- resource-env-ref元素声明与资源相关的一个管理对象。 --&gt; &lt;resource-env-ref&gt;&lt;/resource-env-ref&gt; &lt;!-- resource-ref元素声明一个资源工厂使用的外部资源。 --&gt; &lt;resource-ref&gt;&lt;/resource-ref&gt; &lt;!-- security-constraint元素制定应该保护的URL。它与login-config元素联合使用 --&gt; &lt;security-constraint&gt;&lt;/security-constraint&gt; &lt;!-- 用login-config元素来指定服务器应该怎样给试图访问受保护页面的用户授权。它与sercurity-constraint元素联合使用。 --&gt; &lt;login-config&gt;&lt;/login-config&gt; &lt;!-- security-role元素给出安全角色的一个列表，这些角色将出现在servlet元素内的security-role-ref元素的role-name子元素中。分别地声明角色可使高级IDE处理安全信息更为容易。 --&gt; &lt;security-role&gt;&lt;/security-role&gt; &lt;!-- env-entry元素声明Web应用的环境项。 --&gt; &lt;env-entry&gt;&lt;/env-entry&gt; &lt;!-- ejb-ref元素声明一个EJB的主目录的引用。 --&gt; &lt;ejb-ref&gt;&lt;/ejb-ref&gt; &lt;!-- ejb-local-ref元素声明一个EJB的本地主目录的应用。 --&gt; &lt;ejb-local-ref&gt;&lt;/ejb-local-ref&gt;&lt;/web-app&gt; javaconfig配置12345678910111213141516171819202122232425public class WebInitConfig implements WebApplicationInitializer &#123; @Override public void onStartup(ServletContext container) throws ServletException &#123; AnnotationConfigWebApplicationContext appContext = new AnnotationConfigWebApplicationContext(); appContext.register(WebMvcConfig.class); appContext.setServletContext(container); container.setInitParameter(&quot;&quot;,&quot;&quot;);//设置初始化参数 //设置过滤器 FilterRegistration.Dynamic shiroFilter = container.addFilter(&quot;shiroFilter&quot;, DelegatingFilterProxy.class); shiroFilter.setInitParameter(&quot;targetFilterLifecycle&quot;, &quot;true&quot;); shiroFilter.addMappingForUrlPatterns(EnumSet.allOf(DispatcherType.class), false, &quot;/*&quot;); container.addListener(EnvironmentLoaderListener.class); //设置监听器 //设置servlet ServletRegistration.Dynamic dispatcher = container.addServlet(&quot;DispatcherServlet&quot;, new DispatcherServlet(appContext)); dispatcher.setLoadOnStartup(1); dispatcher.addMapping(&quot;/&quot;); container.setSessionTimeout();//设置session超时时间 &#125;&#125; 自定义servlet1234public class InitServlet extends HttpServlet &#123; public void init() &#123;&#125; public void doGet(HttpServletRequest request,HttpServletResponse response)throws ServletException, IOException &#123;&#125; &#125; 自定义过滤器12345public class ReportFilter implements Filter &#123; public void doFilter(ServletRequest request,ServletResponse response,FilterChain chain)throws ServletException, IOException &#123; &#125; public void init(FilterConfig config)throws ServletException &#123;&#125; public void destroy() &#123;&#125; &#125; springboot配置web 注解扫描方式 @WebServlet、@WebListener、@WebFilter @ServletComponentScan(value = “dcits.liufein”) 组建注册方式 123456789101112131415161718@Bean public FilterRegistrationBean getFilterRegistrationBean()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(new DelegatingFilterProxy()); bean.addInitParameter(); bean.addServletNames(); bean.addUrlPatterns(); &#125; @Bean public ServletListenerRegistrationBean getServletListenerRegistrationBean()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(new MySessionActivationListener()); bean.setOrder(1); &#125; @Bean public ServletRegistrationBean getServletRegistrationBean()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new DefaultServlet()); bean.addUrlMappings(&quot;/secondServlet&quot;); return bean; &#125; 部分xml元素使用springboot中application.properties配置文件中配置，例如session超时，context-para初始化参数]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web_Listener]]></title>
    <url>%2F2018%2F05%2F06%2FWeb_Listener%2F</url>
    <content type="text"><![CDATA[Web_Listener Listener实现 基于组合关系的监听器实现 基于观察者模式的监听器实现 基于观察者模式和代理模式的监听器实现 Web Listener javaweb中监听器的分类 实现原理 案例实践 Listener实现 监听器，顾名思义用于监听某一对象（可以是类，方法，数据等）变化的工具，根据变化从而可以做出相对应的措施。 基于组合关系的监听器实现123456789101112131415/** * 监听器listener负责监听类Source中的init方法* 当init方法被调用时触发监听器执行beforeInit方法进行一些初始化操作前的必要操作 */public class Source&#123; /** 被监听方法 */ public void init()&#123; Listener.beforeInit(); ... &#125;&#125;/** 监听类 */public class Listener&#123; public static void beforeInit()&#123;&#125;&#125; 以上代码通过类之间的组合关系实现了监听器的功能，该版本为最初始版本，接下来进行改造优化。（无论多么复杂的代码均是由最简单的代码一步步演化而来） 基于观察者模式的监听器实现123456789101112131415161718192021222324252627282930/** 监听接口 */public interface Listener&#123; void beforeInit();&#125;/** 主题接口 */public interface Source&#123; void addListener(Listener listener);&#125;/** 监听实现 */public class ListenerImpl implements Listener&#123; /** 构造方法中注入主题接口并调用该添加监听方法将自身加入到主题的监听列表中 */ public ListenerImpl(Source source)&#123; source.addListener(this); &#125; public void beforeInit()&#123;&#125;&#125;/** 主题实现 */public class SourceImpl implements Source&#123; List&lt;Listener&gt; listenerList; public void addListener(Listener listener)&#123; listenerList.add(listener); &#125; public void doListeners()&#123; for(Listener listener ：listenerList)&#123;listener.beforeInit();&#125; &#125; public void init()&#123; doListeners(); ... &#125;&#125; 上面代码将监听和主题各自抽象出一个接口以实现多态特性，同时在监听实现注入主题接口以实现监听的开启功能，但是监听和主题之间还存在着一定的耦合，所以我们需要进行解耦优化。 基于观察者模式和代理模式的监听器实现1234567891011121314151617181920212223242526272829303132333435363738394041424344/** 监听接口 */public interface Listener&#123; void beforeInit();&#125;/** 主题接口 */public interface Source&#123; void addListener(Listener listener);&#125;/** 代理接口 */public class Event&#123; private Object source; public Event(Object source)&#123;this.source = source;&#125; public Object getObject()&#123;return source;&#125;&#125;/** 代理实现 */public class EventImpl extends Event&#123; public EventImpl(Source sourcee)&#123;super(source)&#125; public Source getSource()&#123;(Source)super.getObject()&#125;&#125;/** 监听实现 */public class ListenerImpl implements Listener&#123; /** 构造方法中注入主题接口并调用该添加监听方法将自身加入到主题的监听列表中 */ public ListenerImpl(EventImpl eventImpl)&#123; eventImpl.getSource().addListener(this); &#125; public void beforeInit(EventImpl eventImpl)&#123; Source source = eventImpl.getSource(); ... &#125;&#125;/** 主题实现 */public class SourceImpl implements Source&#123; List&lt;Listener&gt; listenerList; public void addListener(Listener listener)&#123; listenerList.add(listener); &#125; public void doListeners()&#123; for(Listener listener ：listenerList)&#123;listener.beforeInit();&#125; &#125; public void init()&#123; doListeners(); ... &#125;&#125; Web Listenerjavaweb中有8个监听器，主要负责监听ServletContext,HttpSession,ServletRequest三个域对象状态，可大致分为三类 一类:监听三个域对象的创建和销毁的监听器 对象类型 对应的监听器 ServletContext ServletContextListener HttpSession HttpSessionListener HttpServletRequest ServletRequestListener 二类:监听三个域对象的属性变更的监听器.(属性添加,属性移除,属性替换) 对象类型 对应的监听器 ServletContext ServletContextAttributeListener HttpServletRequest ServletRequestAttributeListener HttpSession HttpSessionAttributeListener 三类:监听HttpSession对象中的JavaBean的状态的改变.(绑定,解除绑定,钝化和活化)2个 对象类型 对应的监听器 HttpSession HttpSessionBindingListener(绑定,解除绑定) HttpSession HttpSessionActivationListener(序列化和反序列化) HttpSessionBindingListener和HttpSessionListener的区别 所谓对session进行数据绑定，就是调用session.setAttribute()把 HttpSessionBindingListener保存进session中。 HttpSessionListener设置一次就可以监听所有 session HttpSessionBindingListener通常都是一对一的 实现原理（以ServletContextListener为例）12345678910111213141516171819202122232425262728293031323334/** 监听接口，内含域对象初始化和销毁方法 */public interface ServletContextListener implements EventListener&#123; default void contextInitialized(ServletContextEvent sce) &#123;&#125; default void contextDestroyed(ServletContextEvent sce) &#123;&#125;&#125;/** 监听实现，自定义实现方法内容 */public class MySerConListener implements ServletContextListener&#123; void contextInitialized(ServletContextEvent sce) &#123; ... &#125;&#125;/** 监听与被监听之间的代理层，监听程序通过该代理获取被监听实例 */public class ServletContextEvent extends EventObject &#123; public ServletContextEvent(ServletContext source) &#123; super(source); &#125; public ServletContext getServletContext() &#123; return (ServletContext)super.getSource(); &#125;&#125;/** 被监听接口 */public interface ServletContext &#123;&#125;/** 被监听实现 ，内含addListener负责添加自定义监听*/public class ApplicationContext implements ServletContext &#123; public &lt;T extends EventListener&gt; void addListener(T t) &#123;&#125;&#125;/** 监听程序实际被调用的地方 */public class StandardContext extends ... implements ...&#123; public boolean listenerStart() &#123; ... listener.contextInitialized(event); ... &#125;&#125; 案例实践 基于springboot的自定义servletListener实现（相当于web.xml中配置监听） 自定义监听类添加注解@WebListener(第三类不需要使用注解) 启动类添加扫面注解@ServletComponentScan(value = “dcits.liufein”) 详细案例代码地址如下：https://github.com/LFstefan/spring-boot-web-listener springboot设置session持久化不起作用，待解决。。。 ## 附：与监听器相对应的过滤器，servlet配置均相似 springboot配置web.xml中的listener，servlet，filter两种方式 注解扫描方式 @WebServlet、@WebListener、@WebFilter @ServletComponentScan(value = “dcits.liufein”) 组建注册方式 123456789101112131415161718@Bean public FilterRegistrationBean getFilterRegistrationBean()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(new DelegatingFilterProxy()); bean.addInitParameter(); bean.addServletNames(); bean.addUrlPatterns(); &#125; @Bean public ServletListenerRegistrationBean getServletListenerRegistrationBean()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(new MySessionActivationListener()); bean.setOrder(1); &#125; @Bean public ServletRegistrationBean getServletRegistrationBean()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new DefaultServlet()); bean.addUrlMappings(&quot;/secondServlet&quot;); return bean; &#125;]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>Listener</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列化框架]]></title>
    <url>%2F2018%2F04%2F29%2F%E5%BA%8F%E5%88%97%E5%8C%96%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[序列化框架 Hessian Protobuf Kryo FSTSerialize Json Schema，即XML Schema，XSD (XML Schema Definition)，指出如何形式描述XML文档的元素。由于SOAP协议的结构问题会使封装的数据膨胀数倍。当传输数据量比较小时，问题不是那么明显，但是当进行大数据量传输时就会导致Web服务的传输性能在实际运用中降低了很多。这对于经常有大数据量数据交换的应用系统来说是不适用的。所以催生了其他的各种轻量级协议，如Hessian协议（其实就是一个格式，双方达成共识后变成了协议）。 Hessian 序列化格式：二进制，下面是序列化语法（即二进制如何与java对象信息实现一一对应关系）文档地址 Hessian语法 无需额外的schema或者接口定义 版本控制： 无语言依赖性 数据类型 Hessian’s object serialization has 8 primitive types: raw binary data boolean 64-bit millisecond date 64-bit double 32-bit int 64-bit long null UTF8-encoded string It has 3 recursive types: list for lists and arrays map for maps and dictionaries object for objects Finally, it has one special contruct: ref for shared and circular object references. Hessian 2.0 has 3 internal reference maps: An object/list reference map. An class definition reference map. A type (class name) reference map. Hessian 2.0草案规范增加了对Hessian消息周围的包络的支持。 这些信封可以提供其他功能，如压缩，加密和消息签名。 信封还可用于将路由和可靠性信息附加到消息。 由于信封是可嵌套的，因此每个信封可以很简单，并在组合时提供强大的功能。 例如，安全消息传递系统可以压缩，加密然后安全地签名消息。使用信封的API是wrap（）用于编写消息，而unwrap（）用于读取消息。 应用程序序列化代码本身是相同的，因为信封只是在原始流周围创建一个Hessian2Input或Hessian2Output包装器。Hessian采用引用取代重复遇到的对象。使用引用取代重复遇到的对象可以避免对重复对象的编码，而且也减少了编码后的数据量。 Hessian使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Car &#123; private int year; private Model model; private Color color;&#125;public enum Model &#123; CIVIC, EDSEL, MODEL_T,&#125;public enum Color &#123; BLACK, GREEN, BLUE,&#125;//序列化ByteArrayOutputStream bos = new ByteArrayOutputStream();Hessian2Output out = new Hessian2Output(bos);out.startMessage();out.writeInt(2);Car car1 = new Car(Model.EDSEL, Color.GREEN, 1954);out.writeObject(car1);Car car2 = new Car(Model.MODEL_T, Color.BLACK, 1937);out.writeObject(car2);out.completeMessage();out.close();byte []data = bos.toByteArray();//反序列化ByteArrayInputStream bin = new ByteArrayInputStream(data);Hessian2Input in = new Hessian2Input(bin);in.startMessage();ArrayList list = new ArrayList();int length = in.readInt();for (int i = 0; i &lt; length; i++) &#123; list.add(in.readObject());&#125;in.completeMessage();in.close();bin.close();//压缩Deflation envelope = new Deflation();ByteArrayOutputStream bos = new ByteArrayOutputStream();Hessian2Output out = new Hessian2Output(bos);out = out.wrap(out);out.startMessage();Car car1 = new Car(Model.EDSEL, Color.GREEN, 1954);out.writeObject(car1);out.completeMessage();out.close();byte []data = bos.toByteArray();//解压Deflation envelope = new Deflation();ByteArrayInputStream bin = new ByteArrayInputStream(data);Hessian2Input in = new Hessian2Input(bin);in = envelope.unwrap(in);in.startMessage();Object value = in.readObject();in.completeMessage(); Protobuf（Protocol Buffers） 自定义.proto文件来定制序列化格式，需要学习其语法才能编写.proto文件 Protocol Buffer Language Guide：官方文档学习如何编写.proto文件 Java API Reference Java Generated Code Guide Encoding Reference：详细编码规则 拥有自己的编译器protocol buffer compiler 12345678910111213141516//.proto文件样例message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phone = 4;&#125; KryoFSTSerialize使用指南github地址 所需依赖12345&lt;dependency&gt; &lt;groupId&gt;de.ruedigermoeller&lt;/groupId&gt; &lt;artifactId&gt;fst&lt;/artifactId&gt; &lt;version&gt;2.56&lt;/version&gt;&lt;/dependency&gt; 使用样例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//用法一（线程安全）将对象序列化为byte数组，从byte数组反序列化回对象static FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration();// write序列化byte barray[] = conf.asByteArray(mySerializableObject);// read反序列化MyObject object = (MyObject)conf.asObject(barray);/** 为了可以确认反序列化数据的完整性，序列化时先序列化数据的长度，然后是数据本身 */// writebyte barray[] = conf.asByteArray(mySerializableObject);stream.writeInt(barray.length);stream.write(barray);[..flush..]// readint len = stream.readInt();int orglen = len;byte buffer[] = new byte[len]; // this could be reused !while (len &gt; 0) len -= in.read(buffer, buffer.length - len, len);// skipped: check for stream closeObject readObj = conf.getObjectInput(buffer).readObject();//方法二：使用FSTObjectOutput,FSTObjectInput替换ObjectOutputStream, ObjectInputStream；直接从流中反序列化或序列化为流public MyClass myreadMethod( InputStream stream ) throws IOException, ClassNotFoundException &#123; FSTObjectInput in = new FSTObjectInput(stream); MyClass result = (MyClass)in.readObject();//或者MyClass result = in.readObject(MyClass.class); in.close(); // required ! return result;&#125;public void mywriteMethod( OutputStream stream, MyClass toWrite ) throws IOException &#123; FSTObjectOutput out = new FSTObjectOutput(stream); out.writeObject( toWrite );//或者out.writeObject( toWrite, MyClass.class ); out.close(); // required !&#125;//方法三：为了优化对象重用和线程安全，FSTConfiguration 提供了两种简单的方式获取input/outputStream对象实例static FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration();...public MyClass myreadMethod(InputStream stream) throws IOException, ClassNotFoundException&#123; FSTObjectInput in = conf.getObjectInput(stream); MyClass result = in.readObject(MyClass.class); // DON&apos;T: in.close(); here prevents reuse and will result in an exception stream.close(); return result;&#125;public void mywriteMethod( OutputStream stream, MyClass toWrite ) throws IOException &#123; FSTObjectOutput out = conf.getObjectOutput(stream); out.writeObject( toWrite, MyClass.class ); // DON&apos;T out.close() when using factory method; out.flush(); stream.close();&#125;//方法四：将对象序列化为byte数组，或从byte数组反序列化回对象（ 以下DefaultCoder非线程安全，建议使用ThreadLocal&lt;DefaultCoder&gt;）DefaultCoder coder = new DefaultCoder(); // reuse this (per thread)/** 为了提升速度，DefaultCoder可以预注册一些常用的序列化类* DefaultCoder coder =new DefaultCoder(true,* Car.class, CarBench.Engine.class, * CarBench.Model.class,* CarBench.Accel.class, CarBench.PerformanceFigures.class,* CarBench.FueldData.class, CarBench.OptionalExtras.class);* /byte serialized[] = coder.toByteArray( someObject );Object deserialized = coder.toObject( serialized ); FSTConfigurationu解析 在序列化时定义编码解码，一般只需创建一个全局单例 123456public class MyApplication &#123; static FSTConfiguration singletonConf = FSTConfiguration.createDefaultConfiguration(); public static FSTConfiguration getInstance() &#123; return singletonConf; &#125;&#125; 序列化多版本兼容 使用注解@Version(n) Json重复对象的引用问题 fastjson支持循环引用，并且是缺省打开的。 当序列化后的JSON传输到浏览器或者其他语言中，这些json解析器不支持循环引用，从而导致数据丢失。你可以关闭fastjson的循环引用支持。关闭引用检测，还能够提升序列化时的性能。 全局配置关闭 JSON.DEFAULT_GENERATE_FEATURE |= SerializerFeature.DisableCircularReferenceDetect.getMask(); 非全局配置关闭 JSON.toJSONString(obj, SerializerFeature.DisableCircularReferenceDetect); 引用语法语法———————————–描述{“$ref”:”$”}—————————引用根对象{“$ref”:”@”}————————–引用自己{“$ref”:”..”}—————————引用父对象{“$ref”:”../..”}————————-引用父对象的父对象{“$ref”:”$.members[0].reportTo”}—基于路径的引用 序列化/反序列化版本问题部分序列化/指定序列化 JSONField 若属性是私有的，必须有set*方法。否则无法反序列化。 JSONField使用指南 123456789101112public @interface JSONField &#123; // 配置序列化和反序列化的顺序，1.1.42版本之后才支持 int ordinal() default 0; // 指定字段的名称 String name() default &quot;&quot;; // 指定字段的格式，对日期格式有用 String format() default &quot;&quot;; // 是否序列化 boolean serialize() default true; // 是否反序列化 boolean deserialize() default true;&#125; JSONField配置方式 配置在getter/setter上 配置在field上 123456789101112131415//配置在getter/setter上 public class A &#123; private int id; @JSONField(name=&quot;ID&quot;) public int getId() &#123;return id;&#125; @JSONField(name=&quot;ID&quot;) public void setId(int value) &#123;this.id = id;&#125; &#125;//配置在field上 public class A &#123; @JSONField(name=&quot;ID&quot;) private int id; public int getId() &#123;return id;&#125; public void setId(int value) &#123;this.id = id;&#125; &#125; 使用format配置日期格式化 12345public class A &#123; // 配置date序列化和反序列使用yyyyMMdd日期格式 @JSONField(format=&quot;yyyyMMdd&quot;) public Date date; &#125; 使用serialize/deserialize指定字段不序列化 12345678public class A &#123; @JSONField(serialize=false) public Date date; &#125;public class A &#123; @JSONField(deserialize=false) public Date date; &#125; 使用ordinal指定字段的顺序 默认按照字段字母排序 12345678public static class VO &#123; @JSONField(ordinal = 3) private int f0; @JSONField(ordinal = 2) private int f1; @JSONField(ordinal = 1) private int f2;&#125; 使用serializeUsing制定属性的序列化类 在fastjson 1.2.16版本之后，JSONField支持新的定制化配置serializeUsing，可以单独对某一个类的某个属性定制序列化 123456789101112public static class Model &#123; @JSONField(serializeUsing = ModelValueSerializer.class) public int value;&#125;public static class ModelValueSerializer implements ObjectSerializer &#123; @Override public void write(JSONSerializer serializer, Object object, Object fieldName, Type fieldType,int features) throws IOException &#123; Integer value = (Integer) object; String text = value + &quot;元&quot;; serializer.write(text); &#125;&#125;]]></content>
      <categories>
        <category>Json</category>
      </categories>
      <tags>
        <tag>Json</tag>
        <tag>Serializetion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Json与序列化]]></title>
    <url>%2F2018%2F04%2F29%2FJson%E4%B8%8E%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Json与序列化 序列化：序列化是将对象状态转换为可保持或传输的格式的过程。与序列化相对的是反序列化，它将流转换为对象。这两个过程结合起来，可以轻松地存储和传输数据。 JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。它基于 ECMAScript (欧洲计算机协会制定的js规范)的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。 Json 对象表示为键值对 数据由逗号分隔 花括号保存对象 方括号保存数组 1234String str = JSON.toJSONString(person);JSONObject jObject = JSON.parseObject(str);Person p = JSONObject.toJavaObject(jObject, Person.class);System.out.println(person.getName()); json的实现有很多，这里使用的fastjson，较其速度相对来说是所有实现中最快的，使用json代码较为简洁干练，并且其生成的字符串体积较小，易于传输。 序列化/反序列化 当程序运行时，有关对象的信息就存储在了内存当中，但是当程序终止时，对象将不再继续存在。我们需要一种储存对象信息的方法，使我们的程序关闭之后他还继续存在，当我们再次打开程序时，可以轻易的还原当时的状态。这就是对象序列化的目的。 所谓序列化，就是定义一种格式来与内存中对象信息构造一种一一对应的关系，从而可以把内存中对象信息以某种格式来保存到任意地方；而序列化/反序列化就是对这种格式的解析 java的对象序列化将那些实现了Serializable接口的对象转换成一个字节序列，并且能够在以后将这个字节序列完全恢复为原来的对象，甚至可以通过网络传播。 这意味着序列化机制自动弥补了不同OS之间的差异. 如此，java实现了“轻量级持久性”，为啥是轻量级，因为在java中我们还不能直接通过一个类似public这样的关键字直接使一个对象序列化，并让系统自动维护其他细节问题。因此我们只能在程序中显示地序列化与反序列化 对象序列化不仅保存了对象的“全景图”，而且能够追踪对象内所包含的所有引用，并保存这些对象；接着又能对对象内包含的每个这样的引用进行追踪；以此类推。这种情况有时被称为“对象网”。 如何使用序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*序列化对象到临时性存储介质，如字符串临时变量*/ByteArrayOutputStream byteOut = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteOut);/*序列化对象到永久性存储介质，如本地文件ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream("D:/序列化.txt"));*/objectOutputStream.writeObject(person);System.out.println("序列化后对象的值为："+byteOut.toString());//System.out.println("序列化后对象的值为："+byteOut.toString("ISO-8859-1")); /*从文件反序列化对象ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream("D:/序列化.txt"));*//*从字符串反序列化对象*/ByteArrayInputStream byteIn = new ByteArrayInputStream(byteOut.toString().getBytes()); ObjectInputStream objectInputStream = new ObjectInputStream(byteIn);try &#123; Person readPerson = (Person)objectInputStream.readObject(); System.out.println(readPerson.getName());&#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace();&#125;/** 使用序列化实现加密解密 ，实现Serializable接口的类中添加writeObject()和readObject()可以实现数据的修改和加密解密操作* 因为底层调用的时候会先行检查实现Serializable接口的类中是否含有这两个方法，有则调用，没有直接调用默认方法*/class Person implements Serializable &#123; ... private void writeObject(ObjectOutputStream out) &#123; try &#123; PutField putFields = out.putFields(); password = "encryption";//模拟加密 putFields.put("password", password); out.writeFields(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void readObject(ObjectInputStream in) &#123; try &#123; GetField readFields = in.readFields(); Object object = readFields.get("password", ""); password = "pass";//模拟解密,需要获得本地的密钥 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; serialize后字符串包含了子串的长度，这可能是速度方面的优化 至于两者的速度各有千秋，因不同的场景，不同的条件而定 java序列化底层实现原理 java.io.ObjectOutputStream：表示对象输出流； 它的writeObject(Object obj)方法可以对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中； java.io.ObjectInputStream：表示对象输入流； 它的readObject()方法源输入流中读取字节序列，再把它们反序列化成为一个对象，并将其返回； 被序列化对象必须实现序列化接口Serializable才能被序列化；Serializable接口这是一个标识，告诉程序所有实现了”我”的对象都需要进行序列化 static和transient字段不能被序列化。 当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口 序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。为它赋予明确的值。显式地定义serialVersionUID有两种用途： 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。 java的远程方法调用（RMI），序列化使存活于其他计算机上的对象使用起来就像存活于本机上一样。当远程对象发送消息时，需要通过对象序列化来传输参数和返回值。 Java 序列化机制为了节省磁盘空间，具有特定的存储规则，当写入文件的为同一对象时，并不会再将对象的内容进行存储，而只是再次存储一份引用 序列化写入过程 写入过程会调用底层的字节数据容器 bout = new BlockDataOutputStream(outputStream);（bout表示底层的字节数据容器） 用特定的字节序列的值来表示不同的对象，字段或者等等其他，也就是建立一个字节序列和需要被序列化的内容的一一对应关系； 序列化/反序列化实质就是对字节序列的解析 第一步先写入magic number魔法数字 第二步写入对test类的描述 第三步写入对test父类的描述 第四步写入test父类中定义的字段的数据 第五步写入test类中定义的字段的数据 第六步写入test内部类的描述 第七步写入test内部类中定义的字段的数据 序列化的控制（部分/指定序列化） 通过实现Externalizable接口——代替实现Serializable接口——来对序列化过程进行控制。 可以实现指定字段的序列化（Serializable不能） Externalizable接口继承了Serializable接口，增加了两个方法，writeExternal()和readExternal()，这两个方法会在序列化和反序列化还原的过程中被自动调用。 Externalizable对象，在还原的时候所有普通的默认构造器都会被调用（包括在字段定义时的初始化）(只有这样才能使Externalizable对象产生正确的行为)，然后调用readExternal(). 如果我们从一个Externalizable对象继承，通常需要调用基类版本的writeExternal()和readExternal()来为基类组件提供恰当的存储和恢复功能。 为了正常运行，我们不仅需要在writeExternal()方法中将来自对象的重要信息写入，还必须在readExternal（）中恢复数据 防止对象的敏感部分被序列化，两种方式： 将类实现Externalizable，在writeExternal()内部只对所需部分进行显示的序列化 实现Serializable，用transient(瞬时)关键字（只能和Serializable一起使用）逐个字段的关闭序列化，他的意思：不用麻烦你保存或恢复数据——我自己会处理。 重复对象循环引用 Java 序列化机制为了节省磁盘空间，具有特定的存储规则，当写入文件的为同一对象时，并不会再将对象的内容进行存储，而只是再次存储一份引用 数据加密解密 向实现Serializable接口的类中添加writeObject()和readObject()可以实现数据的修改和加密解密操作 序列化/反序列化版本问题 序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。]]></content>
      <categories>
        <category>Json</category>
      </categories>
      <tags>
        <tag>Json</tag>
        <tag>Serializetion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2018%2F04%2F22%2FJVM%2F</url>
    <content type="text"><![CDATA[步入java虚拟机的世界 内存管理 运行时数据区域 内存分配与回收 虚拟机对象 垃圾回收 垃圾回收算法 垃圾收集器 GC日志 class文件 类加载机制 建议读者自行了解java的技术体系结构以及java虚拟机的历史发展，这里不做叙述！ 包括一套字节码指令集、一组寄存器、一个栈、 一个垃圾回收，堆 和 一个存储方法 内存管理运行时数据区域 程序计数器(线程私有) PC寄存器（pc计数器） 通过计数器来知道下一条应该执行的指令，精准记录各个线程正在执行的当前字节码指令地址 虚拟机栈（线程私有） 也可以叫做JAVA栈 ，代表了处理逻辑 ，每当启动一个新线程时，JAVA虚拟机就会为他分配一个JAVA栈（以栈帧为单位保存线程的运行状态）。单位为栈帧 （每调用一个方法时，都会创建一个新的栈帧） ，由局部变量表 （存储方法参数和局部变量 ，所需内存空间编译器完成，运行期间不变），操作数栈 ，动态链接 （指向运行时常量池中该栈帧所属方法的引用 ），方法返回值 四部分组成。 本地方法栈（线程私有） 虚拟机执行native方法，hotspot中将本地方法栈和虚拟机栈合二为一，作用类似 java堆（线程共享） 堆 ，代表了数据，运行时动态分配内存 一个JAVA程序在运行时创建的所有的类实例或数组都放在同一个堆里面。 一个JAVA虚拟机实例中只会存在一个堆空间，所有的线程共享这个堆空间。 一个JAVA 程序独占一个JAVA虚拟机实例。 所以每个JAVA程序都有自己的堆空间，彼此互不干扰。 堆中的的分代： YoungGen（新生代，存放新生对象或年龄不大的对象）{Eden(8/10) + From Survivor(1/10) + To Survivor(1/10)}，占堆的1/3 OldGen（老生代，存放大对象或者年龄较大的对象），占堆的2/3 方法区 方法区—编译后代码的存储区，存储了每一个java类的结构信息，逻辑上独立，物理上属于堆的一部分 运行时常量区 运行时常量池—方法区的一部分，用于存放编译器生成的字面量和符号引用 直接内存 本地函数库直接分配内存，由堆中一个DirectorByteBuffer指向引用操作 永久代 PermGen 指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被 放入永久区域，它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这 也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。 JAVA8与元数据 在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间 的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用 本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 native memory, 字符串池和类的静态变量放入 java 堆中，这样可以加载多少类的元数据就不再由 MaxPermSize控制, 而由系统的实际可用空间来控制。 内存分配与回收 大多数情况下，对象直接在Eden区域分配，如果该区域不够，则虚拟机进行一次minorGC minorGC：新生代GC，由于新生代对象生命周期较短，朝生夕灭，所以minorGC较为频繁，速度较快 以复制算法为例，minorGC一次的全过程如下 eden 、 servicorFrom 复制到 ServicorTo ，年龄 + 1：首先，把Eden和ServivorFrom区域中存活的对象复制到ServicorTo区域（如果有对象的年 龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不 够位置了就放到老年区）； 清空 eden 、 servicorFrom 然后，清空Eden和ServicorFrom中的对象； ServicorTo和 ServicorFrom互换：最后，ServicorTo和ServicorFrom互换，原ServicorTo成为下一次GC时的ServicorFrom 区。 majorGC：老年代GC，大对象，周期较长，不频繁，速度比minorGC慢十倍左右，一般majorGC的发生总会伴随着至少一次的minorGC 大对象直接在老年代分配（应该尽量避免短命大对象） 对象年龄计数器：在Eden出生经过一次minorGC并且被survivor接收的话（如果survivor不接受则进入老年代），进入survivor后年龄设置为1，然后每熬过一次minorGC，年龄加一，到达一定年龄后进入老年代，默认年龄是15岁进入老年代。 动态年龄判定：survivor中相同年龄的对象大小总和大于survivor空间大小的一半时，所有大于等于该年龄的对象进入老年代 空间分配担保：minorGC前会判断老年代中空闲空间大小是否大于新生代所有对象所占空间总和，大于则绝对安全（即使minorGC后新生代对象所有都进入老年代，也可以容的下），否则需要风险担保，由于具体进入老年代的对象所占空间大小在minorGC之后才能确定，所以在此之前，老年代会采用之前数据的平均值来预估是否可以容下即将进入老年代的所有对象，故存在一定风险导致容不下，而导致发生fullGC（我们的目标是尽量减少fullgc，因为耗时太久）。 虚拟机对象 对象的创建 这里指的是普通对象的创建，即我们最常使用的关键字new创建对象的过程（不包括数组对象和class对象） 首先在常量池中定位该类的符号引用是否存在 存在紧接着判定是否加载过（即经历了加载，解析，初始化三个阶段） 加载过然后堆中分配内存空间，具体大小加载中已计算出来 这里涉及到堆中分配策略：主要有两种，指针碰撞和空闲列表 指针碰撞：堆内存空间规整，已分配/未分配空间区域有明确分界线，这时只需要将指针向一个未分配区域方向移动所需空间大小即可实现对象的堆中内存空间分配 空闲列表：堆内存空间不规整，这样的话就得维护一个列表，负责记录空闲空间，然后从列表中找出一个符合分配对象大小的空间分配给它 堆空间的规整与否，取决于垃圾回收器是否有压缩整理功能 考虑到并发操作的安全性，提出了两种解决方案：1. cas原子性操作，2. 本地线程分配缓冲池TLAB—java堆区域中一块线程私有区域，包含在Eden空间中，用于快速分配策略（每一个线程在堆中的一小块内存空间，操作系统中称为快表，因为线程私有，所以线程安全，只有TLAB分配完后才从共享堆中执行原子性操作分配空间） TlAB分配失败直接在Eden中分配，Eden也失败则执行GC，如果是大对象直接在老年代中分配 内存空间分配好后初始化内存空间 然后设置对象头（对象头用于存放类的各种信息，类比报文头理解） init() 对象访问定位 栈中reference引用数据指向堆中对象(具体访问实现调用由虚拟机实现，因此不同虚拟机实现不同,主流有两种，句柄，直接指针。见下图理解） 句柄实现如下： 直接指针实现如下： 垃圾回收如何判定对象可以进行回收 引用计数法：简而言之就是记录对象的引用数，为零时可回收，但是该方法无法解决对象的循环引用问题 可达性分析算法（简单来说，就是图的根节点如果无法间接相连到该节点，则说明该节点不可达，回收，如下图所示） 引用分类（由于以前引用的定义过于狭隘，而现实中我们想实现一种“空间充足，则对象存在，空间紧迫，则对象回收”的美好愿景，于是引用分类由此而生） 强引用 软引用：有用非必须，内存溢出之前进行回收 弱引用：只能存活到下一次垃圾回收之前 虚引用（依次递减）：无法通过该引用获得实例对象，其存在的唯一目的就是进行垃圾回收时会收到一个系统通知 一个对象的死亡之路： 首先可达性分析—–&gt;不可达—–&gt;第一次标记，筛选（即一次miniorGC过程）——&gt;若没有覆盖finalize()方法/或已执行finalize方法——&gt;否——&gt;执行finalize方法—–&gt;放入F-queue队列中—-&gt;一定时间后执行二次标记（在此之前如果队列中对象可以再次获取引用，则到时候出队列躲过被回收的命运，否则就真的被回收） 垃圾回收算法 标记清除算法：先标记回收对象，然后统一回收，效率较低，导致内存碎片过多，使得内存利用率降低 复制算法：将内存空间对半分为相等的两部分，一半使用，另一半保留，当需要回收时将使用过的那一半中的对象复制到保留未使用的一般中，然后清空那一半空间保留下一次回收时使用。此方法可以避免内存碎片，提高内存利用率。 标记整理算法：先标记，后移动可用空间到一起，然后统一清除剩下的 分代回收算法：按生存周期划分内存空间，不同空间采用不同的回收算法。新生代（复制算法）老年代（对象存活率高，采用标记清除/整理算法） 垃圾收集器：内存回收的具体实现- serial：单线程+stop the world-----新生代收集器（单线程、复制算法） - parnew：多线程版本的serial-----新生代收集器（Serial+多线程） - paralel scavenge：关注点在高吞吐量，提高cpu效率，新生代收集器（多线程复制算法、高效） - seri old：serial的老年代收集器版本，（单线程标记整理算法 ） - paralel old：paralel scavenge的老年代收集器版本，多线程 - cms：（多线程标记清除算法）强调一次GC过程的最短停顿时间，老年代收集器 - g1：最前沿成果，基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 GC日志阅读 GC日志的阅读有助于处理遇到的内存问题，就好比看日志调试bug一样 认识class文件 虚拟机不与包括java在内的所有语言绑定，而是与class文件绑定，意味着和虚拟机打交道的是class文件 首先了解class文件是一组以8位字节为基础单位的二进制流； 其编译原理过程较为复杂，这里不做深究，大致过程为：词法分析（生成Token序列）—语法分析（生成抽象语法树）—语义分析（完善语法树）—生成最终字节码 本章节重点了解class文件的结构组成： （其结构如下图所示） （U1,U2,U4分别表示1，2，4个字节的无符号数）ClassFile表结构是class文件的最外层结构，即class文件的格式 第一项为魔数：CA-FE-BA-BE（cafebabe）（对应的十进制为202-254-186-190），用于判定是否为java-class文件。 第二项是主次版本号（；不同版本的jvm编译下的class文件在其他版本的jvm下不适用） 第三项是常量池（常量池数量+常量池数组），存在于方法区中，由11种基本的常量项（常量表）组成，Java程序的一个类中的所有常量数据都将存储在这里，像类名，方法名，返回类型等等 1234项的通用格式 cp_info&#123; u1 tag； u1 info[]; &#125; 第四项：access_flags 第五项：this_class，记录当前类的全限定名（包名+类名），其值指向常量池中对应的索引值 第六项：supper_class 记录当前类的父类的全限定名， 第七项：interface_count，记录当前类的实现的接口数量 第八项：interface，记录当前类实现的接口 第九项：field_count，记录当前类的定义的变量的总数量 第十项：field 变量详细信息 字段表代码结构如下： 1234567Filed_info&#123; u2 access_flags;（访问权限和基本属性的掩码标志） u2 name_index; u2 descriptor_index; u2 attributes_counts; Attribute_info attributes[attributes_counts]; &#125; 方法表代码结构如下： 1234567method_info&#123; u2 access_flags;（访问权限和基本属性的掩码标志） u2 name_index; u2 descriptor_index; u2 attributes_counts; Attribute_info attributes[attributes_counts]; &#125; 注：类和接口的名称采用全限定形式 ；方法，字段名，局部变量采用非全限定形式 Class文件校验 Class文件加载过程：装载—链接（验证(确保类型格式)—准备(分配内存)—解析(常量池中的符号链接转换为直接引用)）—初始化(赋予初值)方法 注：类型的初始化方法，jvm决定加载某个类型时调用该方法类的构造函数，jvm决定实例化某个类型时调用该方法 类加载机制类加载过程 加载-（验证-准备-解析（只有该阶段执行顺序不一定，可变））统称为连接-初始化-使用-卸载 加载： 通过一个类 的全限定名来获取的此类的二进制字节流 将这字节流所代表的静态存储结构转化为方法区运行时数据结构 在内存中生成一个代表这个类的class对象，作为方法区这个类的各种数据的访问入口 验证：连接第一步，保证class文件中字节流包好信息符合虚拟机要求，其中包括文件格式，元数据验证，字节码验证，符号引用验证 准备：类变量分配内存（包好static，不包含实例变量），初始化变量值 解析：虚拟机将 常量池内符号引用替换为直接引用 符号引用：与虚拟机布局无关，引用目标不一定加载到内存中，class文件中明确规定 直接引用：与虚拟机布局有关，引用目标必然存在于内存中 初始化：执行类构造器方法的过程 方法详解 编译器自动收集类中所有的类变量的赋值动作和静态语句块中语句合并而成（静态语句块中只能访问到定义在静态语句块之前的变量，定义在之后的只能赋值，不能访问） 不同于构造函数（init()函数），它不会显示的调用父类构造器，虚拟机保证在子类的clinit之前父类clinit已经执行完毕，所以虚拟机中第一个执行的肯定是object的clinit 如果一个类或者接口中没有静态语句块，并且没有对变量的赋值操作，编译器可以不生成clinit方法 类加载器 ”通过一个类的全限定名来获取描述此类的二进制字节流“这个动作在虚拟机外部实现， 同一份class文件，不同的类加载器加载后形成的类不一样 启动类加载器：BoostropClassLoader，c++实现，虚拟机自身一部分 其他所有类加载器：java实现，虚拟机外部 扩展类加载器 应用程序加载器 自定义加载器 双亲委派模型：类加载器收到类加载请求后，将请求委派给父加载器，所有的请求最终被传送到启动类加载器上，只有父加载器自己无法完成加载后，子加载器才会自己加载， Jvm参数生产实例-UCC-server ：选择服务器应用程序运行时优化。 目录服务器将需要更长的时间来启动和“预热”，但将进行更积极的优化以产生更高的吞吐量。-d64 ：仅适用于64位的机器，默认是32位机器-Xmx8g ：jvm最大堆内存空间大小-Xms8g ：jvm最小堆内存空间大小-Xmn1g ：年轻代占内存大小-XX:PermSize=512m 设置永久代大小，避免内存泄露异常java.lang.OutOfMemoryError: PermGen space-Xss2m ：分配给单个线程的空间-XX:+DisableExplicitGC ：防止外部应用程序强制进行昂贵的垃圾收集。 如果使用jstatd或其他基于RMI的应用程序来监视Oracle Unified Directory，则应考虑使用此选项以避免意外暂停。-XX:+UseConcMarkSweepGC ：选择CMS垃圾收集器。 此垃圾收集器设置为低暂停时间。 这将导致Java应用程序具有较低的平均吞吐量，但CPU密集型垃圾收集要短得多。 在具有响应时间限制的环境中，此选项是必需的。-XX:+CMSParallelRemarkEnabled-XX:+UseCMSCompactAtFullCollection-XX:LargePageSizeInBytes=128m-XX:+UseFastAccessorMethods-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=70 ：选择GC开始的级别。 默认值为68％。-XX:+PrintGCDetails ：打印GC细节-XX:+PrintGCTimeStamps ：打印垃圾收集时间戳以帮助调试。-Xloggc:./logs/gc.log-XX:-HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./logs” 生产实例-CMC-server-Xmx8g-Xms8g-Xmn256m-Xss256k-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-Xloggc:./logs/gc.log-XX:-HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./logs” 垃圾收集器参数-XX:+UseSerialGC-XX:+UseParallelGC-XX:+USeParNewGC-XX:+UseG1GC-XX:+UseParallelOldGC ：选择并行的老年代垃圾收集器。 此垃圾收集器设置为高吞吐量。 它将使import-ldif实用程序的平均吞吐量最大化，代价是偶尔停止世界的垃圾收集。 GC日志参数-XX:+UseGCLogFileRotation-XX:NumberOfGCLogFiles=&lt; number of log files &gt;-XX:GCLogFileSize=&lt; file size &gt;[ unit ]-Xloggc:/path/to/gc.log 内存溢出参数-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./java_pid.hprof-XX:OnOutOfMemoryError=”&lt; cmd args &gt;;&lt; cmd args &gt;” -XX:OnOutOfMemoryError=”shutdown -r”-XX:+UseGCOverheadLimit 其他参数-XX:+UseStringDeduplication ：Java 8u20引入了这个JVM参数，通过创建相同String的太多实例来减少不必要的内存使用; 这通过将重复的String值减少到单个全局char []数组来优化堆内存-XX:LargePageSizeInBytes ：设置用于Java堆的大页面大小; 它采用GB / MB / KB的参数; 通过更大的页面大小，我们可以更好地利用虚拟内存硬件资源; 但是，这可能会导致PermGen的空间大小增加，从而可以强制减小Java堆空间的大小-XX:MaxHeapFreeRatio：在GC之后设置堆的最大自由百分比以避免收缩。-XX:MinHeapFreeRatio ：GC后设置堆的最小自由百分比以避免扩展; 监视堆使用情况，您可以使用JDK附带的VisualVM。-XX:SurvivorRatio ：eden/survivor空间大小的比例-XX:+UseStringCache: 字符串缓存-XX:+UseCompressedStrings:压缩字符串 扩展Categories of JVM arguments （Jvm参数分类） Standard Options (-D but not only).These are the most commonly used options that are supported by all implementations of the JVM.You use -D to specify System properties but most of them don’t have any prefix :-verbose, -showversion, and so for… Non-Standard Options (prefixed with -X)These options are general purpose options that are specific to the Java HotSpot Virtual Machine.For example : -Xmssize, -Xmxsize Advanced Runtime Options (prefixed with -XX)These options control the runtime behavior of the Java HotSpot VM. Advanced JIT Compiler Options (prefixed with -XX)These options control the dynamic just-in-time (JIT) compilation performed by the Java HotSpot VM. Advanced Serviceability Options (prefixed with -XX)These options provide the ability to gather system information and perform extensive debugging. Advanced Garbage Collection Options (prefixed with -XX)These options control how garbage collection (GC) is performed by the Java HotSpot VM.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>Heap</tag>
        <tag>Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Compile JDK]]></title>
    <url>%2F2018%2F04%2F15%2FCompile%20JDK%2F</url>
    <content type="text"><![CDATA[动手编译JDK README-builds.html，每一份源码内均存在的编译指南，英语基础好的童鞋可直接参考该文档，比起网络上的资源，官方文档始终应该作为第一选择！ 前言 如果你是linux操作系统小白，上来就想挑战编译jdk，那么你将会遇到重重困难，但是这同时也是一个非常好的学习机会，因为你会突然间接触到非常多的新知识，过程中的每一个坑，每一次失败都将成为你进步的垫脚石，期间需要你非常耐心的去面对和处理每一个问题，分析其原因并总结经验教训，切记不可急躁，你所花费的每一分钟都将会有所收获，急躁只会打乱你的思考，导致考虑问题的轨道产生偏差，从而绕其弯路，文章只会告诉你如何编译jdk，但不会告诉你怎么操作才能看到最后的成功标志，需要你自己去一遍思考一遍了解为何这样做，祝各位旅途愉快，到达成功的终点。（大佬们请自动忽略我的废话，直接找寻你们的目标信息即可） 目录 材料准备 编译jdk 过程总结 涉及知识清单 正文材料准备 linux操作系统 系统中常用的工具及依赖自行安装，如不清楚编译jdk需要哪些依赖及工具可参考附录 系统网络状态正常，因为编译中途会涉及到下载相关依赖 openjdk7，用于后续的jdk编译（这里的jdk不同于后续待编译的jdk，这里jdk是我们平时正常使用的jdk，因为jdk各个组成部分有的是用c/c++写的，有的是用java写的，所以后续编译java代码时需要用到） openjdk源码（此为我们后续编译的jdk源代码，版本自行选择，这里使用的7） 获取 OpenJDK 源码大致有两种方式 通过 Mercurial 代码版本管理工具从 Repository 中直接取得源码，这就需要我们先安装工具Mercurial，安装过程自行查阅资料。 注意：使用Mercrial工具下载源码时，结果可能由于网络原因导致源码文件有所缺失，从而后续命令失败。 从网站上下载： http://download.java.net/openjdk/jdk7/promoted/b147/openjdk-7-fcs-src-b147-27_jun_2011.zip 编译jdk 环境变量配置 编辑环境变量命令：vi /etc/profile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748语言选项,这个必须设置,否则编译好后会出现一个HashTable的NPE错export LANG=CBootstrap JDK的安装路径。必须设置export ALT_BOOTDIR=/usr/local/java/jdk1.8.0_101 允许自动下载依赖export ALLOW_DOWNLOADS=true并行编译的线程数,设置为和CPU内核数量一致即可export HOTSPOT_BUILD_J0BS=6export ALT_PARALLEL_COMPILE_JOBS=6 比较本次build出来的映像与先前版本的差异。这对我们来说没有意义, 必须设置为false,香则sanity检查会报缺少先前版本JDK的映像的错误提示。 如桌已经设置dev或者DEV_ONLY=true,这个不显式设置也行export SKIP_COMPARE_IMAGES=true使用预编译头文件,不加这个编译会更慢一些export USE_PRECOMPILED_HEADER=true要编译的内容export BUILD_LANGTOOLS=trueexport BUILD_JAXP=falseexport BUILD_JAXWS=fa1seexport BUILD_CORBA=falseexport BUILD_HOTSPOT=trueexport BUILD_JDK=true要编译的版本export SKIP_DEBUG_BUILD=falseexport SKIP_FASTDEBUG_BUILD=trueexport DEBUG_NAME=debug把它设置为false可以避开javaws和浏览器Java插件之类的部分的buildBUILD_DEPLOY=false把它设置为false就不会build出安装包。因为安装包里有些奇怪的依赖, 但即便不build出它也已经能得到完整的JDK映像,所以还是别build它好了BUILD_INSTALL=false编译结果所存放的路径export ALT_OUTPUTDIR=/root/openjdk7/build这两个环境变量必须去掉,不然会有很诡异的事情发生（我没有具体查过这些 "诡异的事情” ,Makefile脚本裣查到有这2个变量就会提示警告)unset JAVA_HOMEunset CLASSPATHmake 2&gt;&amp;1 | tee $ALT_OUTPUTDIR/build.log 生效环境变量命：source /etc/profile 编译 编译前的检测：进入到openjdk源码目录下执行命令：make sanity检测编译环境是否可行，出现Sanity check passed.结果表示测试通过可以进行编译，否则根据报错进行修改。 开始编译：在openjdk源码目录下执行命令：make开始编译，过程时间长短由你所配置的环境变量有关，本次时长大约十三分钟，出现以下命令时表示编译成功。 12345678910111213成功标志：-- Build times ----------Target all_product_buildStart 2018-09-14 10:45:08End 2018-09-14 10:57:5400:00:05 corba00:00:05 hotspot00:00:03 jaxp00:00:05 jaxws00:12:25 jdk00:00:03 langtools00:12:46 TOTAL------------------------- 编译结果 进入存放编译结果目录（环境变量已配置）/root/openjdk7/build下的j2sdk-image目录 cd /root/openjdk7/build/j2sdk-image 更换JAVA_HOME路径（j2sdk-image路径下的内容就和我们平时用的jdk内容大致一样） export JAVA_HOME=/root/openjdk7/build/j2sdk-image export PATH=$PATH:$JAVA_HOME/bin 检测编译结果 java -version 出现版本号等信息说明编译成功可用 运行编译后的虚拟机： 进入目录/root/openjdk7/build/hotspot/outputdir/linux_amd64_compiler2/product 修改文件env.sh：vi env.sh LD_LIBRARY_PATH=.:${JAVA_HOME}/jre/lib/amd64/native_threads:${JAVA_HOME}/jre/lib/amd64:（有则不管，无则加入） export LD_LIBRARY_PATH（有则不管，无则加入） 修改JAVA_HOME路径为编译后的jdk，即JAVA_HOME=/root/openjdk7/build/j2sdk-image 运行命令：source ./env.sh和./gamma -version 出现结果如下说明成功1234Using java runtime at: /root/openjdk7/build/j2sdk-image/jreopenjdk version "1.7.0-internal"OpenJDK Runtime Environment (build 1.7.0-internal-openjdk_2017_05_13_11_17-b00)OpenJDK 64-Bit Server VM (build 24.80-b07, mixed mode) 过程总结 首先linux系统一定要够熟练，基本命令的使用，操作系统的了解，包括jvm和jdk的组成生态环境，都对你的整个编译过程有很大的帮助 前面提到过编译过程中会有相关依赖的下载（总共有三个，分别为：jaxp145_01.zip，jdk7-jaxws2_2_4-b03-2011_05_27.zip ，jdk7-jaf-2010_08_19.zip），但是实际上下载会失败，将链接地址拷贝出来到网页是可以下载的，但是编译过程中不行，本次编译实现两种解决方案，一种是将下载链接地址换成其他例如，网盘，七牛云等，一种是自行下载好放入相应文件夹中 方法一需修改配置文件 其一位置为：/root/openjdk7/jaxp/jaxp.properties，其二位置为：/root/openjdk7/jaxws/jaxws.properties 将上述配置文件中jaxws_src.master.bundle.url.base=http://download.java.net/glassfish/components/jax-ws/openjdk/jdk7后面的url地址换成自己的地址即可 方法二将以下三个文件下载后置于OpenJDK解压后根目录下的drop目录下，并在环境变量中加入配置：export ALT_DROPS_DIR=/usr/local/src/openjdk7/drop # 注意目录Path https://netix.dl.sourceforge.net/project/jdk7src/input-archives/jdk7-jaf-2010_08_19.zip http://download.java.net/glassfish/components/jax-ws/openjdk/jdk7/jdk7-jaxws2_2_4-b03-2011_05_27.zip http://download.java.net/jaxp/1.4.5/jaxp145_01.zip 错误：Error: time is more than 10 years from present: 1136059200000 需要修改源码目录中的一个文件，这个文件是/jdk/src/share/classes/java/util/CurrencyData.properties。 我们需要做的是把文件中以下的时间改为10年内的一个时间： 错误：JAVA_HOME must point to a valid JDK/JRE to run gamma 解决：export JAVA_HOME=/root/openjdk7/build/j2sdk-image（使用我们刚刚自己编译的jdk） echo $JAVA_HOME 编译jvmg版本的jdk。 make jvmg jvmg1 2&gt;&amp;1 | tee $ALT_OUTPUTDIR/build.log 上面我的命令只是编译jvmg版的hotspot。所以除了jvmg目录，其他目录下是没有hotspot的。 最后通过gamma启动器来启动hotspot。 知识扩展 MD5 CheckSum：在一些场景中，比如文件传输（如插件、固件升级包等），MD5 CheckSum的作用就是用于检查文件完整性，检测文件是否被恶意篡改。编译过程中的依赖下载就用到了该技术，在配置文件/root/openjdk7/jaxp/jaxp.properties，其二位置为：/root/openjdk7/jaxws/jaxws.properties中可以看到该字段配置 附录编译涉及依赖及工具安装命令： yum install build-essential gawk m4 openjdk-6-jdk libasound2-dev libcups2-dev libxrender-dev xorg-dev xutils-dev xllproto-print-dev binutils libmotif3 libmotif-dev ant 各个依赖工具作用： build-essential：作用是提供编译程序必须软件包的列表信息也就是说 编译程序有了这个软件包它才知道 头文件在哪 才知道库函数在哪还会下载依赖的软件包 最后才组成一个开发环境 gawk (gnu awk) ：linux下查找替换文本工具按行(或者其他文本单元)搜索文件内容,包含一个匹配模式。当有文本行匹配，awk在此行进行特别的操作。Program告诉awk该去做什么; m4 ：将输入拷贝到输出,同时将宏展开. 宏可以是内嵌的也可以是用户定义的. 除了可以展开宏,m4还有一些内建的函数,用来引用文件,执行Unix命令,整数运算,文本操作,循环等. m4既可以作为编译器的前端也可以单独作为一个宏处理器。 libasound2-dev： 这是Advanced Linux Sound Architecture (ALSA)相关的依赖。 libcups2-dev： 这是Common UNIX Printing System (CUPS)相关的依赖。 binutils：GNU binutils是一组二进制工具集。包括：addr2line ar gprof nm objcopy objdump ranlib size strings strip. 本文归纳他们的常用法。ar用于建立、修改、提取档案文件(archive)。archive是一个包含多个被包含文件的单一文件（也称之为库文件），其结构保证了可以从中检索并得到原始的被包含文件（称之为archive中的member）。member的原始文件内容、模式（权限）、时间戳、所有者和组等属性都被保存在 archive中。member被提取后，他们的属性被恢复到初始状态。 待补充。。。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识REST]]></title>
    <url>%2F2018%2F04%2F15%2F%E5%88%9D%E8%AF%86REST%2F</url>
    <content type="text"><![CDATA[初识REST rest是什么，来源，起因，未来 restAPI接口设计 get方法，接口中添加注解@GET，实现类无需再添加注解，安全（读取资源不会对其状态做改动），幂等（外系统对接口的多次访问，得到的资源状态是一致的） 资源命名，面向资源，名词为主（rpc，面向动作，动词为主） head，option方法与get方法类似 put，http写请求方法，用于更新或添加资源，幂等，不安全（凡是涉及写请求的http方法都不是安全的） delete，幂等， post，不幂等，不安全，rpc中所有写请求操作均使用该方法，rest中只用来添加资源 jersey的AOP功能：HK2依赖实现，无需配置，实现接口即可 Providers：jersey支持多种表述类型，其原因为底层实现提providers具备对不同格式的处理能力，其内部提供了丰富的MessageBodyReader和MessageBodyWriter接口实现类来处理不同的格式表述。 MessageBodyReader消息体处理器接口：用于将传输流转换成java类型对象，业务系统启用该实现类有两种方式，一为：使用注解@Provider定义实现类，业务系统启动时自动探测并加载，二为：编码注册到Application类或者其子类中，业务系统启动时加载Application类或其子类时一并加载 MessageBodyReader接口中定义了两个方法，isReadable()判定是否可以反序列化，和readFrom()具体反序列化操作 MessageBodyReader接口，负责将java对象转换为流，即序列化过程，包含方法isWriteable()和wroteTo() 上下文provider：ContextResolver接口的方法getContext()，入参表述对象类型，出参上下文泛型 请求流程：流程角色：用户，rest客户端，rest服务器 用户提交请求，客户端接收请求（客户端请求过滤器） 客户端拦截器，对客户端序列化操作的的拦截 客户端消息体写处理器执行序列化，流程过度到服务器 服务器接收请求，服务器前置请求过滤器 根据请求匹配资源，服务器后置请求过滤器 服务器读拦截器，拦截服务器的反序列化操作 服务器消息体读处理器，对数据流反序列化，执行匹配的资源方法 请求资源处理完毕，服务器响应过滤器 服务器写拦截器，对服务器序列化到客户端的操作进行拦截 服务器消息体写处理器执行序列化，流程返回客户端 客户端接收响应，客户端响应过滤器 客户端响应实例response返回用户一侧，用户执行respinse.readEntity，客户端读拦截器，对客户端反序列化进行拦截 客户端消息体读处理器执行反序列化 rest和rpc的区别rest的web服务提供的方法信息存在http方法中rpc的web服务提供的方法信息存在http信封中 rest和soap的区别Stack Overflow上看到一个回答觉得很到位 SOAP and REST can’t be compared directly, since the first is a protocol (or at least tries to be) and the second is an architectural style. This is probably one of the sources of confusion around it, since people tend to call REST any HTTP API that isn’t SOAP.Pushing things a little and trying to establish a comparison, the main difference between SOAP and REST is the degree of coupling between client and server implementations. A SOAP client works like a custom desktop application, tightly coupled to the server. There’s a rigid contract between client and server, and everything is expected to break if either side changes anything. You need constant updates following any change, but it’s easier to ascertain if the contract is being followed.A REST client is more like a browser. It’s a generic client that knows how to use a protocol and standardized methods, and an application has to fit inside that. You don’t violate the protocol standards by creating extra methods, you leverage on the standard methods and create the actions with them on your media type. If done right, there’s less coupling, and changes can be dealt with more gracefully. A client is supposed to enter a REST service with zero knowledge of the API, except for the entry point and the media type. In SOAP, the client needs previous knowledge on everything it will be using, or it won’t even begin the interaction. Additionally, a REST client can be extended by code-on-demand supplied by the server itself, the classical example being JavaScript code used to drive the interaction with another service on the client-side.I think these are the crucial points to understand what REST is about, and how it differs from SOAP:REST is protocol independent. It’s not coupled to HTTP. Pretty much like you can follow an ftp link on a website, a REST application can use any protocol for which there is a standardized URI scheme.REST is not a mapping of CRUD to HTTP methods. Read this answer for a detailed explanation on that.REST is as standardized as the parts you’re using. Security and authentication in HTTP are standardized, so that’s what you use when doing REST over HTTP.REST is not REST without hypermedia and HATEOAS. This means that a client only knows the entry point URI and the resources are supposed to return links the client should follow. Those fancy documentation generators that give URI patterns for everything you can do in a REST API miss the point completely. They are not only documenting something that’s supposed to be following the standard, but when you do that, you’re coupling the client to one particular moment in the evolution of the API, and any changes on the API have to be documented and applied, or it will break.REST is the architectural style of the web itself. When you enter Stack Overflow, you know what a User, a Question and an Answer are, you know the media types, and the website provides you with the links to them. A REST API has to do the same. If we designed the web the way people think REST should be done, instead of having a home page with links to Questions and Answers, we’d have a static documentation explaining that in order to view a question, you have to take the URI stackoverflow.com/questions/, replace id with the Question.id and paste that on your browser. That’s nonsense, but that’s what many people think REST is.This last point can’t be emphasized enough. If your clients are building URIs from templates in documentation and not getting links in the resource representations, that’s not REST. Roy Fielding, the author of REST, made it clear on this blog post: REST APIs must be hypertext-driven.With the above in mind, you’ll realize that while REST might not be restricted to XML, to do it correctly with any other format you’ll have to design and standardize some format for your links. Hyperlinks are standard in XML, but not in JSON. There are draft standards for JSON, like HAL.Finally, REST isn’t for everyone, and a proof of that is how most people solve their problems very well with the HTTP APIs they mistakenly called REST and never venture beyond that. REST is hard to do sometimes, especially in the beginning, but it pays over time with easier evolution on the server side, and client’s resilience to changes. If you need something done quickly and easily, don’t bother about getting REST right. It’s probably not what you’re looking for. If you need something that will have to stay online for years or even decades, then REST is for you. rest和mvc的区别 rest应用开发demo 实体类 @XmlRootElement定义类，@XmlElementWapper等其他注解 资源路径定义，也就是springMVC中的路径问题 资源类==controller，@Path（”/类路径”）， @Path（”/方法路径”）@GET/@PUT方法类型，@Produce（）返回json需要使用@Produces注解，@Concumer（）接收json，需要使用@Consumes，该注解标注在类上事务，表示该类中所有的方法均遵循该注解配置，一般建议建议将注解标注在接口中，实现显得干净整洁一些 集成spring用的包为jersey-spring 这里的jersey是和spring一起使用的，将jersey的webservice交给spring管理。因此容器这一块，必须选择：com.sun.jersey.spi.spring.container.servlet.SpringServlet而不是org.glassfish.jersey.servlet.ServletContainer 体会心得 jaxp标准：包括dom，sax，stax三种解析xml的技术，各不相同，需要手写解析过程 dom：面向文档，加载进内存，映射为树木和节点 sax：事件驱动的流解析技术，监听注册事件，触发回调实现解析 stax拉式流解析技术，相当于sax的时间驱动推送技术，该读取过程可以主动推进当前xml位置的指针而不是被动获得解析中的xml数据 jsxb标准：利用pojo中的注解来实现xml文件的自动解析，免去了手写程序解析xml的过程]]></content>
      <categories>
        <category>REST</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>REST</tag>
        <tag>Restful</tag>
        <tag>SOAP</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedisTheory]]></title>
    <url>%2F2018%2F04%2F08%2FRedisTheory%2F</url>
    <content type="text"><![CDATA[Redis底层技术实现与原理 本篇以《Rdeis设计与实现》为阅读基础，总结提炼其中一些知识点 底层数据结构 内存回收机制 对象共享 单机数据库 RDB持久化 AOF持久化 事件 复制 redis集群 &lt;- more -&gt; 基本底层实现SDS动态字符串（redis内部自定义字符串）12345Struct sdshdr&#123; Int len;字符串长度，不包括结束符‘/0’ Int free;字符串剩余空间，同样不包括结束符 Char buf[];字节数组，分配空间时多分配一个为结束符 &#125; 优势： 常数时间获取字符串长度（len） 避免了缓冲区溢出（free，先检测free空间是否充足在执行操作） 减少修改字符串带来的内存重分配次数，采用空间预分配，若修改后的sds.len1MB，则buf的长度等于30MB+1MB+1byte，即len=30MB，free=1MB；同时采用惰性空间释放策略，当缩小字符串长度时，并不是立马释放缩小空间，而是加到free中来供后续为字符串增加长度做准备。 双向链表1234567891011121314Typedef struct listNode&#123; Struct listNode *prev; Struce listNode *next; Void *value; &#125;listNode; Typedef struct list&#123; listNode *head;头节点 listNode *tail;尾节点 Unsigned long len;节点数量 Void *(*dup) (void *ptr);节点值复制函数 Void *(*free) (void *ptr);节点值释放函数 int (*match) (void *ptr ,void *key);节点值对比函数 &#125; 特点： 双向（prev，next），双指针（表头，表尾） 无环，表头的prev和表尾的next均指向null，访问以null为结束 O（1）获取链表长度 可保存不同类型的值 哈希表123456789101112131415161718Typedef struct dictht&#123; dicEntry **table;哈希表数组 Unsigned long size;哈希表大小 Unsigned long sizemask;哈希表大小掩码，用于计算索引值（=size-1） Unsigned long used;哈希表已有节点数量 &#125; Typedef struct dicEntry&#123; void *key;键 Union&#123;值可以有三种类型 Void *val;指针 Uint64_tu64;无符号整数 Int64_ts64;有符号整数 &#125;v; Struct dicEntry *next;下一个哈希表节点，链地址法解决冲突 &#125;dicEntry; 字典123456Typedef struct dict&#123; dictType *type;类型特定函数，为用途不同的字典设置不同的类型特定函数，如复制键函数，复制值函数，计算哈希值函数等 Void *private;为类型特定函数提供参数 Dictht ht[2];哈希表两个，正常只用第一个ht[0]，ht[1]在rehash的时候用 Int rehashidx;rehash状态判定，rehash不在进行时值为-1 &#125;dict; 哈希索引值index = hash &amp; dict-&gt;ht[x].sizemask Rehash操作： rehashidx值置为0，表示rehash工作正式开始，为字典的ht[1]分配空间 如果是扩展操作，ht[1]的大小为第一个大于等于ht[0].used*2的2的n次方幂 如果是收缩操作，ht[1]的大小为第一个大于等于ht[0].used的2的n次方幂 将ht[0]中的内容重新计算哈希值和索引值迁移到ht[1]中，ht[0]变为空表，然后释放ht[0] 将ht[1]更改为ht[0]，重新创建一个新的表空间ht[1]为下次rehash做准备，rehash工作完成，rehashidx值置为-1 当数量较为庞大时，rehash过程为渐进式，而不是一次性，将rehash操作均摊到每一次的字典的增删改查操作上 跳跃表-（有序数据结构，在一个接点中维持有多个指向其他节点的指针，从而实现跳跃性访问节点，可代替平横树）12345678910Typedef struct zskiplistNode&#123; Struct zskiplistLevel&#123; Struct zskiplistNode *forward; Unsigned int span;跨度，节点间的距离 &#125;level[];层，表示一个节点维持有几个指向其他节点的指针，即level数组的个数 Struct zskiplistNode *backward; Double score;保存对象值 Robj *obj;保存对象 &#125;zskiplistNode; 整数集合压缩列表对象-(redis五大基本对象：字符串对象，列表对象，哈希对象，集合对象，有序集合对象)123456Typedef struct redisObject&#123; Unsigned type:4;类型 Undigned encoding:4;编码 Void *ptr;指向底层实现数据结构的指针 … &#125; 字符串对象 编码有三种：int，raw，embatr 当字符串对象存的时整数值，编码为int 当字符串对象存的是长度大于32 的字符串时，编码为raw 当字符串对象存的是小于等于32 的字符串时，编码为embstr embstr编码时专门用来保存短字符串的一种优化编码方式，raw会调用两次内存分配函数来分别创建redisObject和sdshdr，而embstr只会调用一次内存分配函数分配一块连续的空间供redisObject和sdshdr使用，降低了内存分配和释放次数，同时所有数据保存在连续的内存中，能更好的利用缓存带来的优势） 列表对象 编码有两种：ziplist（压缩列表实现底层），linkedlist（双向列表实现底层） 当列表对象保存的所有字符串元素的长度都小于64字节并且元素数量小于512个时，使用ziplist编码，否则使用linkedlist编码 哈希对象 编码有两种：ziplist，hashtable（字典实现底层） 当列表对象保存的所有键值对的键和值的长度都小于64字节并且键值对数量小于512个时，使用ziplist编码（使用ziplist编码时，键值两个节点始终相邻，键节点在前，值节点在后）否则使用linkedlist编码 集合对象 编码有两种：intset（整数集合实现底层），hashtable 使用hashtable编码时，字典的每个键都是一个包含集合元素的字符串对象，而字典的值全都置为null 当集合对象保存的所有对象均为整数时且集合中元素数量不超过512个时使用intset编码，否则使用hashtable编码 有序集合对象1234Typedef struct zset&#123; Skiplist *zsl;跳跃链表 Dict *dict;字典 &#125; 编码有两种：ziplist，skiplist（zset结构实现底层） 使用ziplist编码时，每个集合元素使用两个紧邻的压缩列表节点来保存，第一个保存元素成员，第二个保存元素的分值 Zset结构同时使用跳跃链表（有序排列集合元素，可实现范围型操作）和字典（O(1)复杂度查找集合元素值） 当集合每个元素的长度都小于64字节并且元素数量小于128个时，使用ziplist编码，否则使用skiplist编码 Bit arrays位数组 Bitmaps are not an actual data type, but a set of bit-oriented operations defined on the String type. 位数组并属于真正的数据类型，只是字符类型的一种位操作方式 二进制安全，最大长度为512M，可以设置2^32中不同的位 可单一操作，设置某一位为1或0，或者获取某一位的位值，也可一组位进行的操作，例如将某一范围的位值设置为1或0 极大的节约内存空间 用户访问网站记录，访问记为1，否记为0，可节约非常大的内存空间，同时可以快速计算出用户访问网站的总天数 To split a bitmap across different keys instead of setting all the bits into a key, a trivial strategy is just to store M bits per key and obtain the key name with bit-number/M and the Nth bit to address inside the key with bit-number MOD M. HyperLogLogs HyperLogLog是用于计算唯一事物的概率数据结构（从技术上讲，这被称为估计集合的基数）。 内存回收机制 不会立马回收内存 内存使用量取决于峰值内存使用量 内存分配器会机智的合理利用尚未回收的内存 若不设置最大内存，将会耗尽机器内存资源 引用计数技术 对象共享 对象的空转时长（当前时间-lru） 12345Typedef struct redisObject&#123; … Undigned lru:22;记录对象最后一次被命令程序访问的时间 … &#125; 当服务器的内存占用数超过maxmemory时，空转时长较高的会优先被服务器释放 单机数据库 Redis客户端默认目标数据库为0号数据库，可以使用SELECT命令来切换目标数据库 Set data “2013.12.03” 添加信息 Del data 删除信息 Set massage “hello” (将massage的值改为hello)或者 hset book page 80（将book中的page改为80）修改信息 Get message 查找信息 Expire/pexpire key 5 设置键的生存时间/过期时间 过期键的删除策略 定时删除：定时器 惰性删除：放任不管，只有当每次取键时检查是否过期，是删除，否返回 定期删除 RDB持久化（通过保存数据库中的键值对来记录数据库的不同状态） 手动或定期 .rdb 文件 压缩的二进制文件 Rdb文件的创建与载入 Save命令会阻塞redis服务器进程，直到rdb文件创建完成，期间服务器不能处理任何请求 Bgsave命令会派生出一个子进程执行创建rdb文件，父进程继续执行请求处理 Bgsave命令阶段，save，bgsave，bgrewriteaof这三种命令不能执行，其他请求可以执行 默认条件为（当满足条件就执行bgsave命令） Save 900 1 服务器在900秒之内至少对数据库修改1次 Save 300 10服务器在300秒之内至少对数据库修改10次 Save 60 10000服务器在60秒之内至少对数据库修改10000次 Dirty计数器：记录上一次成功执行save/bgsave命令之后服务器对数据库的修改次数 Lastsave：时间戳，记录上一次成功执行/bgsave命令的时间 serverCron函数每隔100毫秒就执行一次，其中一项就是检查save/bgsave条件是否满足 AOF持久化（通过保存服务器执行的写命令来记录数据库的状态） 三步走：命令追加-&gt;文件写入-&gt;文件同步 每次执行完相应的命令会将命令以一定格式追加到aot_buf缓冲区的末尾 Redis服务器进程就是一个事件循环，每结束一个循环都会调用相应的函数考虑是否将aot_buf缓冲区的内容写入AOF文件，上次同步时间距离现在超过一秒就再次执行同步 Aof文件重写，随着时间的推移，aof文件的大小会迅速增加，其中会包括很多的冗余命令，所以需要重写来减小文件大小 原理：从数据库读取当前的键值，然后用命令来记录键值对，替换之前冗余的命令 子进程执行该过程，不会影响服务器的请求处理 Aof执行期间，服务器依旧会将执行过的写命令追加到aof缓冲区，同时还会将执行过的写命令追加到aof重写缓冲区 事件：redis服务器就是一个事件驱动程序 文件事件：redis通过套接字与客户端进行链接，文件事件就是服务器对套接字操作的抽象，服务器和客户端的通信会产生相应的文件事件，而服务器通过监听并处理这些事件来完成网络通信操作（读事件，写事件两类） 套接字（准备好链接应答，写入，读取，关闭等操作时）-&gt;I/O多路复用（将套接字以队列的形式往后传递）-&gt;文件事件派发器（根据套接字产生的事件类型调用相应的事件处理器执行）-&gt;事件处理器（命令请求处理器…） 时间事件：服务器对定时操作的抽象 定时事件，周期事件 所有时间事件存放在一个无序链表（不按照when属性排列）中，每当时间事件执行时都必须遍历整个链表来找到已到达时间事件（新事件的插入总是插入到表头） 两事件均同步，有序，原子执行，不会出现中断，抢占现象，需要时会主动让出执行权。 复制 （slaveof命令）从服务器&gt; slaveof 主服务器 旧版复制=同步+命令传播 同步： 从向主发送sync命令 主收到sync命令后执行bgsave命令，后台生成一个rdb文件，并使用缓冲区记录从现在开始的所有写命令 主将rdb文件发给从服务器，从服务器接受并载入rdb文件，根据此文件将自己的数据库状态更新至主服务器状态 主将缓冲区内容发给从，从执行缓冲区命令更新自己 命令传播：当同步执行完成之后，主服务器只需要一直保持将自己的写命令发给从服务器，从服务器接受并更新即可保持主从一直 复制分两种情况，初次复制，断线后重复制（低效，因为不能实现从断线处继续复制，而是重新复制），新版将同步分为完整同步和部分同步来优化断线后重新复制 redis集群 节点连接命令：cluster meet Cluster-enabled=yes开启服务器的集群模式 槽指派：redis集群通过分片方式来保存数据库中的键值对，整个数据库被分为16384个槽位，数据库中每一个键都属于槽的其中一个，每个节点可以处理0个或者16384个，当所有槽位均有节点在处理时，集群属于上线状态，否则属于下线状态 命令cluster addslots [slot…]将一个或者多个槽位指派给节点负责 16384/8个字节，包含16384个二进制位来保存节点负责的槽位信息，为1，表示该节点负责处理该槽位，否则不负责处理 重新分片发布订阅Dict&lt;被订阅频道，List&lt;订阅者链表&gt;&gt;事物multi命令开始，中间执行命令，exec命令结束提交事务watch命令是一个乐观锁，在exec命令之前监视任意数量的数据库键是否至少有一个被修改过，是则拒绝事务Lua脚本排序sort命令排序。。。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Redis</tag>
        <tag>Catch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java描绘数据统计图]]></title>
    <url>%2F2018%2F04%2F01%2FJava%E6%8F%8F%E7%BB%98%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Java描绘数据统计图ECharts 最近需要实现一个数据曲线对比的小任务，于是想试试描绘数据统计图，了解到可以使用echarts和hcharts，这里使用的是echarts，首先官方实例很好，容易理解且上手快，但是都是静态的，我要实现的是动态获取后台数据来前台显示数据曲线对比，所以会涉及到ajax和json的相关内容（读者自行了解）！ 代码展示 首先是html最终呈现效果页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html lang="zh-CN"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 初始化移动浏览显示 --&gt; &lt;meta name="Author" content="Dreamer-1."&gt; &lt;title&gt;- 观测数据 -&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 初始化一块区域来显示Echarts图表 --&gt; &lt;div style="height:410px;min-height:100px;margin:0 auto;" id="main"&gt;&lt;/div&gt; &lt;!-- 引入相关js文件 --&gt; &lt;script type="text/javascript" src="js/jquery-3.3.1.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="js/echarts.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('main')); var companyName = []; //类别数组（每个企业名称） var mar = []; //隐患级别数组（企业每月隐患级别） var apr = []; var may = []; var jun = []; var jul = []; var aug = []; var sep = []; $.ajax(&#123; //使用JQuery内置的Ajax方法 type : "post", //post请求方式 async : true, //异步请求（同步请求将会锁住浏览器，用户其他操作必须等待请求完成才可以执行） url : "returnJsonData", //请求发送到returnJsonData的servlet处理 data : &#123;&#125;, dataType : "json", //返回数据形式为json success : function(result) &#123; //请求成功时执行该函数内容，result即为服务器返回的json对象 if (result != null &amp;&amp; result.length &gt; 0) &#123; for(var i=0;i&lt;result.length;i++)&#123; companyName.push(result[i].name); //挨个取出类别并填入类别数组 mar.push(result[i].mar); //挨个取出每个月份的隐患级别插入数组 apr.push(result[i].apr); may.push(result[i].may); jun.push(result[i].jun); jul.push(result[i].jul); aug.push(result[i].aug); sep.push(result[i].sep); &#125; //循环显示不同的曲线 var series = []; for(var i=0;i&lt;companyName.length;i++)&#123; series.push(&#123; "name":companyName[i], "type":"line", //折线图表示 "data":[mar[i],apr[i],may[i],jun[i],jul[i],aug[i],sep[i],] //数据值通过Ajax动态获取 &#125;); &#125; // 指定图表的配置项和数据 var option = &#123; title: &#123; //图表标题 text: '隐患数据表' &#125;, legend: &#123; //图表上方的类别显示 show:true, data : companyName &#125;, color:[ '#FF3333', //各曲线颜色 '#53FF53', '#B15BFF', ], toolbox: &#123; //工具栏显示 show: true, feature: &#123; saveAsImage: &#123;&#125; //显示“另存为图片”工具 &#125; &#125;, xAxis: &#123; //X轴 type: 'category', data: ["Mar","Apr","May","Jun","Jul","Aug","Sep"] &#125;, yAxis : [ &#123; type : 'value', name : '隐患级别', axisLabel : &#123; formatter: '&#123;value&#125; -level' //控制输出格式 &#125; &#125;, ], series : series &#125;; myChart.setOption(option); //载入图表 &#125; else &#123; //返回的数据为空时显示提示信息 alert("图表请求数据为空！"); myChart.hideLoading(); &#125; &#125;, error : function(errorMsg) &#123; //请求失败时执行该函数 alert("图表请求数据失败，可能是服务器开小差了"); myChart.hideLoading(); &#125; &#125;) &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 接下来是servlet后台获取数据并回传给前台显示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class returnJsonData extends HttpServlet &#123; private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public returnJsonData() &#123; super(); // TODO Auto-generated constructor stub &#125; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub doPost(request,response); &#125; /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub request.setCharacterEncoding("UTF-8"); //设定客户端提交给servlet的内容按UTF-8编码 response.setCharacterEncoding("UTF-8"); //设定servlet传回给客户端的内容按UTF-8编码 response.setContentType("text/html;charset=UTF-8"); //告知浏览器用UTF-8格式解析内容 //构造返回数据 List&lt;company&gt; list = new LinkedList&lt;company&gt;(); company com = new company(); company com1 = new company(); company com2 = new company(); list.add(fun(com,"企业一")); list.add(fun(com1,"企业二")); list.add(fun(com2,"企业三")); ObjectMapper mapper = new ObjectMapper(); //提供java-json相互转换功能的类 String json = mapper.writeValueAsString(list); //将list中的对象转换为Json格式的数组 //System.out.println(json);//打印验证json数据格式 //将json数据返回给客户端 response.setContentType("text/html; charset=utf-8"); response.getWriter().write(json); &#125; public company fun(company com, String str)&#123; com.setName(str); com.setMar(Math.random()); com.setApr(Math.random()); com.setMay(Math.random()); com.setJun(Math.random()); com.setJul(Math.random()); com.setAug(Math.random()); com.setSep(Math.random()); return com; &#125;&#125; 最后附上完整实例代码：https://github.com/LFstefan/LineChart_example]]></content>
      <categories>
        <category>ECharts</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ECharts</tag>
        <tag>Ajax</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle命令集]]></title>
    <url>%2F2018%2F03%2F25%2FOracle%E5%91%BD%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Oracle命令集 基本命令 INSERT ALL /FIRST,MERGE INTO maven使用oracle依赖指南 启动监听，供客户端链接：lsnrctl start 以管理员身份接入：sqlplus / as sysdba 以用户名/密码接入：sqlplus GAEA/GAEA 启动实例：startup 使用@或者start执行sql脚本文件：@TEST/START TEST 判定数据库版本位数：select * from v$version 创建临时表空间 CREATE TEMPORARY TABLESPACE TABLESPACE_NAME LOGGING TEMPFILE &#39;D:\LIUFEIN\..&#39; SIZE 50M AUTOEXTED ON NEXT 50M MAXSIZE 100M EXTEND MANAGEMENT LOCAL UNIFORM SIZE 1M; 创建数据表空间 CREATE TABLESPACE TABLESPACE_NAME LOGGING DATAFILE &#39;D:/&#39; SIZE 50M AUTOEXTED ON NEXT 50M MAXSIZE UNLIMITED EXTEND MANAGEMENT LOCAL AUTOALLOCATE; 删除表空间： DROP TABLESPACE TABLESPACE_NAME DROP TABLESPACE TABLESAPCE_NAME INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINT（包含数据文件级联关系） 创建用户并制定默认表空间 CREATE USER ADMIN IDENTIFIED BY 123 DEFAULT TABLESPACE TABLESPACE_NAME 修改用户默认表空间 ALTER USER USER_NAME DEFAULT TABLESPACE TABLESPACE_NAME 用户授权 GRANT CONNECT,RESOURCE,DBA TO ADMIN GRANT CONNECT,RESOURCE,DBA TO ADMIN WITH ADMIN OPTION 删除用户及级联关系 DROP USER AMMIN CASCADE 查看系统所有表空间 SELECT TABLESPACE_NAME FROM DBA_TABLESPACES; 查看当前用户下的所有表空间 SELECT TABLESPACE_NAME FROM USER_TABLESPACES; 查看所有用户 SELECT USERNAME FROM DBA_USERS; 查看当前用户下所有的数据表 SELECT TABLE_NAME FROM USER_TABLES; 查看系统中所有的数据表 SELECT TABLE_NAME FROM DBA_TABLES; 查看表结构 DESC GAEA.DEMO_LF; 查看系统权限和对象权限 select * from dba_sys_privs; select * from dba_tab_privs; 多表插入,之间的界限必须明确，否则会发生数据重复插入，多个表中可以条件插入，也可无条件插入 INSERT ALL INTO SMALL_ORDER VALUES () INTO MIDDLE_ORDER VALUES () INTO LARGE_ORDER VALUES () SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 使用all多表中可能存在重复数据行 INSERT ALL WHEN SUM_ORDER &lt; 100 THEN INTO SMALL_ORDER WHEN SUM_ORDER &gt;=100 AND SUM_ORDER &lt;=500 THEN INTO MIDDLE_ORDER ELSE INTO LARGE_ORDER SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 使用first多表中不可能存在重复数据行 INSERT FIRST WHEN SUM_ORDER &lt; 100 THEN INTO SMALL_ORDER WHEN SUM_ORDER &gt;=100 AND SUM_ORDER &lt;=500 THEN INTO MIDDLE_ORDER ELSE INTO LARGE_ORDER SELECT ORDER_ID,SUM(ORDER) FROM ORDER_TABLE GROUP BY ORDER_ID; 解决insertOrUpdate这种需求而应用而生的新语法 Merge Into的原理是，从using 搜出来的结果逐条与on条件匹配， 然后决定是update还是Insert。 当USING后面的sql没有查询到数据的时候，Merge Into语句是不会执行update和Insert操作的。 所以要想让Merge Into正常运行，要保证USING 后面的SELECT有数据。12345678910MERGE INTO TABLE_TEMP TUSING( SELECT TABLE_ID TABLE_NAME FROM TABLE_DATA WHERE TABLE_NAME=&apos;&apos;) EON (T.ID=E.ID)WHEN MATCHED THEN UPDATE ... DELETE ...WHEN NOT MATCHED THEN INSERT INTO ... maven使用oracle依赖指南 maven安装oracle驱动命令： cd 驱动包目录下或者写明具体驱动包位置 maven环境变量配置好或者进入maven的bin目录下执行命令 mvn install:install-file -DgroupId=com.oracle -DartifactId=oracle7 -Dversion=7.0.0 -Dpackaging=jar -Dfile=D:\Administrator\Tools\maven\repository\com\oracle\oracle7\7.0.0\oracle7-7.0.0.jar 执行完命令后去对应的文件夹下验证是否安装成功]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql命令集]]></title>
    <url>%2F2018%2F03%2F18%2FMySql%E5%91%BD%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[MySql命令集 安装/更新/启动/登陆/授权 从建库到删库 复杂查询 安装/更新/启动/登陆/授权 下载mysql包：wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm 安装mysql包：rpm -ivh mysql57-community-release-el7-8.noarch.rpm 安装mysql：yum install mysql MySQL授权：chmod 775 更新mysql：yum update mysql 启动mysql：service mysqld start 首次登陆查看临时密码：grep “password” /var/log/mysqld.log 使用临时密码登陆mysql：mysql -uroot -p 登陆远程mysql：mysql -host 192.168.184.132 -P 3306 -uroot -p 修改管理员登陆密码：alter user ‘root’@’localhost’ identified by ‘Root!123’ 创建用户：create user ‘repl’@’192.168.184.132’ identified by ‘password’; 用户授权： grant replication slave on . to ‘repl’@’192.168.184.132’; grant all on . to ‘repl’@’192.168.184.132’; grant all privileges on . to john@localhost identified by ‘123’; grant select,insert,update,delete,create,drop on test.hr to john@192.168.10.1 identified by ‘123’; priv代表权限：select,insert,update,delete,create,drop,index,alter,grant,references,reload,shutdown,process,file等14个权限 GRANT（当数据库存在用户的时候GRANT会对用户进行授权，但当数据库不存在该用户的时候，就会创建相应的用户并进行授权 查看权限： show grants for 用户; show createdatabase dbname; 这个可以看到创建数据库时用到的一些参数。 show createtable tickets; 可以看到创建表时用到的一些参数 撤销权限：revoke all on . from ‘dba’@’localhost’; 权限刷新：flush privileges; 从建库到删库 显示所有数据库：show databases 切换使用数据库：use database_name 设置编码：set names utf8 显示当前库中所有表：show tables 显示表结构：desc table_name 创建数据库：CREATE DATABASE database-name 删除数据库：DROP DATABASE dbname 修改数据库的名称：sp_renamedb ‘old_name’,’new_name’ 创建新表 1234567891011121314151617181920212223242526 DROP TABLE IF EXISTS `zf_jg_statistics`; CREATE TABLE `zf_jg_statistics` ( `id` varchar(50) NOT NULL, `corp_id` varchar(255) DEFAULT NULL COMMENT '企业id', `corp_name` varchar(50) DEFAULT NULL COMMENT '企业名称', `gname` varchar(50) DEFAULT NULL COMMENT '行业名称，无默认值', `gmjj` varchar(50) DEFAULT NULL COMMENT '行业分类', `aname` varchar(50) DEFAULT NULL COMMENT '地区名称', `area` varchar(50) DEFAULT NULL COMMENT '地区编号', `total` int(50) DEFAULT '0' COMMENT '风险防控点数，默认值为0', `type` int(2) DEFAULT NULL COMMENT '每日查还是月查', `scount` int(50) DEFAULT '0' COMMENT '应查询点数，默认值为0', `detail_count` int(50) DEFAULT '0' COMMENT '实查询点数，默认值为0', `warm` varchar(50) DEFAULT NULL COMMENT '警示标示', `frequency` varchar(50) DEFAULT NULL COMMENT '覆盖率', `time` date DEFAULT NULL COMMENT '查询时间，无默认值', `sync_timestamp` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '时间戳', `ybtotal` int(255) DEFAULT '0', `ybzg` int(255) DEFAULT '0', `yb` varchar(255) DEFAULT NULL, `zdtotal` int(255) DEFAULT '0', `zzgl` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `corp_id` (`corp_id`), KEY `time` (`time`) USING BTREE) ENGINE=MyISAM DEFAULT CHARSET=utf8; 根据已有的表创建新表： A：create table tab_new like tab_old B：create table tab_new as select col1,col2…from tab_old definition only 删除新表：drop table tabname 增加一个列：Alter table tabname add column col_name col_type（注：列增加后将不能删除） 添加主键：Alter table tabname add primary key(col) 删除主键：Alter table tabname drop primary key(col) 创建索引：create [unique] index idxname on tabname(col….) 删除索引：drop index idxname（注：索引是不可更改的，想更改必须删除重新建） 创建视图：create view viewname as select statement 删除视图：drop view viewname 选择：select *from table1 where 范围 插入：insert into table1(field1,field2) values(value1,value2) 删除：delete from table1 where 范围 清表：truncate table table_name 更新：update table1 set field1=value1 where 范围 查找：select *from table1 where field1 like ’%value1%’—like的语法很精妙，查资料! 排序：select *from table1 order by field1,field2 [desc] 总数：select count as totalcount from table1 求和：select sum(field1) as sumvalue from table1 平均：select avg(field1) as avgvalue from table1 最大：select max(field1) as maxvalue from table1 最小：select min(field1) as minvalue from table1 复杂查询 UNION 运算符通过组合其他两个结果表(例如TABLE1 和 TABLE2)并消去表中任何重复行而派生出一个结果表。当 ALL 随UNION 一起使用时(即UNION ALL)，不消除重复行。两种情况下，派生表的每一行不是来自TABLE1 就是来自 TABLE2。 EXCEPT 运算符EXCEPT 运算符通过包括所有在TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随EXCEPT 一起使用时(EXCEPT ALL)，不消除重复行。 INTERSECT 运算符INTERSECT 运算符通过只包括TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随INTERSECT 一起使用时(INTERSECT ALL)，不消除重复行。注：使用运算词的几个查询结果行必须是一致的。 内连接：A inner join B on A.a=B.b（结果为AB两表的交集） 左外连接(左连接)：left (outer)join（结果集既包括连接表的匹配行，也包括左连接表的所有行） SQL:select a.a,a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 右外连接(右连接)：right (outer)join（结果集既包括连接表的匹配连接行，也包括右连接表的所有行） 全外连接：full/cross (outer)join（不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录） between：between限制查询数据范围时包括了边界值,not between不包括 select *from table1 where time between time1 and time2 select a,b,c, from table1 where a not between 数值1 and 数值2 distinct：select distinct *into temp from tablename（去重） in：select *from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) top：select top 10 * form table1 where 范围 select top 5 from (select top 15 from table order by id asc) table_别名 order by id desc（选择从10到15的记录） 在线视图查询：select * from (SELECT b,c FROM a) T where t.a &gt; 1;]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven_SettingsReference]]></title>
    <url>%2F2018%2F03%2F11%2FMaven_SettingsReference%2F</url>
    <content type="text"><![CDATA[Settings Referencemaven配置文件settings.xml可能存在于两个位置 The Maven install: ${maven.home}/conf/settings.xml—全局设置 A user’s install: ${user.home}/.m2/settings.xml—用户设置 当两者共存时，配置信息合并，用户设置优先 配置文件settings中有如下一些配置元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;localRepository/&gt;本地仓库位置 &lt;interactiveMode/&gt;是否允许交互模式,默认false &lt;offline/&gt;是否离线模式构建工程，默认false &lt;pluginGroups&gt;插件组 ...自动包含org.apache.maven.plugins and org.codehaus.mojo &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.mortbay.jetty&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; ... &lt;pluginGroups/&gt; &lt;servers/&gt; &lt;server&gt; &lt;id&gt;server001&lt;/id&gt;与maven尝试连接的仓库/镜像服务器id &lt;username&gt;my_login&lt;/username&gt; &lt;password&gt;my_password&lt;/password&gt;可加密 &lt;privateKey&gt;$&#123;user.home&#125;/.ssh/id_dsa&lt;/privateKey&gt;私钥 &lt;passphrase&gt;some_passphrase&lt;/passphrase&gt;私钥密码（可加密） &lt;filePermissions&gt;664&lt;/filePermissions&gt;创建文件权限 &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt;创建目录权限 &lt;configuration&gt;&lt;/configuration&gt; &lt;/server&gt; &lt;servers/&gt; &lt;mirrors/&gt; &lt;mirror&gt; &lt;id&gt;planetmirror.com&lt;/id&gt; &lt;name&gt;PlanetMirror Australia&lt;/name&gt; &lt;url&gt;http://downloads.planetmirror.com/pub/maven2&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;proxies/&gt; &lt;proxy&gt; &lt;id&gt;myproxy&lt;/id&gt; &lt;active&gt;true&lt;/active&gt;代理是否开启，同时只能有一个处于开启状态 &lt;protocol&gt;http&lt;/protocol&gt; &lt;host&gt;proxy.somewhere.com&lt;/host&gt; &lt;port&gt;8080&lt;/port&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;password&gt;somepassword&lt;/password&gt; &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt;无需代理主机集合 &lt;/proxy&gt; &lt;profiles/&gt; &lt;profile&gt;pom文件中的truncate版本，处于active状态将覆盖pom中配置 &lt;id&gt;test&lt;/id&gt; &lt;activation&gt;激活profile的条件如下，有一个满足即可激活 &lt;activeByDefault&gt;false&lt;/activeByDefault&gt;默认状态false &lt;jdk&gt;1.5&lt;/jdk&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;property&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;file&gt; &lt;exists&gt;$&#123;basedir&#125;/file2.properties&lt;/exists&gt; &lt;missing&gt;$&#123;basedir&#125;/file1.properties&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; ... &lt;properties&gt;参数设置，所有参数可在pom中直接引用$&#123;user.install&#125; &lt;user.install&gt;$&#123;user.home&#125;/our-project&lt;/user.install&gt; &lt;/properties&gt; ... &lt;repositories&gt;寻找匹配的正式版或快照版远程仓库 &lt;repository&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always/daily&lt;/updatePolicy&gt;总是/每天 &lt;checksumPolicy&gt;ignore/fail/warn&lt;/checksumPolicy&gt;忽略/失败/警告 &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; 与repository类似，插件仓库配置 &lt;pluginRepository/&gt; ... &lt;/pluginRepositories&gt; ... &lt;/profile&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;env-test&lt;/activeProfile&gt;profile id为env-test的将被激活 &lt;/activeProfiles&gt;&lt;/settings&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql DataType]]></title>
    <url>%2F2018%2F03%2F04%2FMySql%20Data%20Type%2F</url>
    <content type="text"><![CDATA[MySql DataType Numeric Type Date and Time Type String Type Numeric Type BIT(M)：M表示每个值的位数，范围1-64，默认为1，将value自动转换为M位的二进制存入，当value转成二进制后的位数大于已设定的位数时，bit值为设定位数的最大二进制值 TINYINT(M)：无符号范围0-255，有符号范围-128-127 BOOL：等价于 TINYINT(1)，0-false，1-true，默认为true SMALLINT(M)：无符号范围0-65535，有符号范围-32768-32767 MEDIUMINT(M)：无符号范围0-16777215，有符号范围-8388608-8388607 INT(M)：无符号范围0-4204967295，有符号范围-2147483648-2147483647 INTEGER(M)：等价于INT BIGINT(M)：无符号范围0-18446744073709551615，有符号范围-9223372036854775808-9223372036854775807. DECIMAL(M,D)：M总位数，D小数位数 DEC：等价于DECIMAL(M,D) FLOAT(M,D)：理论范围 -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLE(M,D)：理论范围-1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308. DOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL], REAL[(M,D)] [UNSIGNED] [ZEROFILL]：等价于DOUBLE，如果 REAL_AS_FLOAT SQL模式开启，REAL等价于FLOAT FLOAT(p) [UNSIGNED] [ZEROFILL]：用于判别结果数据类型使用FLOAT还是DOUBLE，p属于0-24，用FLOAT，p属于25-53，使用DOUBLE Type Storage (Bytes) Minimum Value Signed Minimum Value Unsigned Maximum Value Signed Maximum Value Unsigned TINYINT 1 -128 0 127 255 SMALLINT 2 -32768 0 32767 65535 MEDIUMINT 3 -8388608 0 8388607 16777215 INT 4 -2147483648 0 2147483647 4294967295 BIGINT 8 -2^63 0 2^63-1 2^64-1 Date and Time Type DATE：范围’1000-01-01’ 到 ‘9999-12-31’，支持STRING和NUMBER类型，NUMBER类型最多支持8位数字（四位表示年份，两位表示月份，两位表示天数），任何非法数字都会自动将值设置为默认值 DATETIME[(fsp)]：范围’1000-01-01 00:00:00.000000’ to ‘9999-12-31 23:59:59.999999’，支持STRING和NUMBER类型，fsp给定范围0-6来指定小数的精度 TIMESTAMP[(fsp)]：范围’1970-01-01 00:00:01.000000’ UTC to ‘2038-01-19 03:14:07.999999’ UTC， TIMESTAMP and DATETIME的自动初始化和更新1234CREATE TABLE t1 ( ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, dt DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP); TIME[(fsp)]：范围’-838:59:59.000000’ to ‘838:59:59.000000’ YEAR[(4)]：支持STRING和NUMBER类型 As a 4-digit number in the range 1901 to 2155. As a 4-digit string in the range ‘1901’ to ‘2155’. As a 1or 2-digit number in the range 1 to 99. MySQL converts values in the ranges 1 to 69 and 70 to 99 to YEAR values in the ranges 2001 to 2069 and 1970 to 1999. As a 1or 2-digit string in the range ‘0’ to ‘99’. MySQL converts values in the ranges ‘0’ to ‘69’ and ‘70’ to ‘99’ to YEAR values in the ranges 2000 to 2069 and 1970 to 1999. The result of inserting a numeric 0 has a display value of 0000 and an internal value of 0000. To insert zero and have it be interpreted as 2000, specify it as a string ‘0’ or ‘00’. Data Type “Zero” Value DATE ‘0000-00-00’ TIME ‘00 : 00 : 00’ DATETIME ‘0000-00-00 00 : 00 : 00’ TIMESTAMP ‘0000-00-00 00 : 00 : 00’ YEAR 0000 String Type CHAR[(M)]：M范围0-255，默认为1 VARCHAR(M)：M范围0-65535，默认为1 BINARY[(M)]：和char类似，只不过存储的是二进制位字符串，char存储的是非二进制字符串 VARBINARY(M)：类似于varchar TINYBLOB：最大长度255位，存储时用一个位的长度前缀来存储value的总位数 TINYTEXT：最大长度255个字符，存储时用一个位的长度前缀来存储value的总位数 BLOB[(M)]：最大长度65535位，存储时用两个位的长度前缀来存储value的总位数 TEXT[(M)]：最大长度65535个字符，存储时用两个位的长度前缀来存储value的总位数 MEDIUMBLOB：最大长度16777215位，存储时用三个位的长度前缀来存储value的总位数 MEDIUMTEXT：最大长度16777215个字符，存储时用三个位的长度前缀来存储value的总位数 LONGBLOB：最大长度4,294,967,295位，存储时用四个位的长度前缀来存储value的总位数 LONGTEXT：最大长度4,294,967,295个字符，存储时用四个位的长度前缀来存储value的总位数 ENUM(‘value1’,’value2’,…)：最多含有65535个不重复元素 SET(‘value1’,’value2’,…)：最多含有64个不重复成员 Value CHAR(4) Storage Required VARCHAR(4) Storage Required ‘’ ‘ ‘ 4 bytes ‘’ 1 byte ‘ab’ ‘ab ‘ 4 bytes ‘ab’ 3 bytes ‘abcd’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes ‘abcdefgh’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>DataType</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁-悲观锁]]></title>
    <url>%2F2018%2F02%2F25%2F%E4%B9%90%E8%A7%82%E9%94%81-%E6%82%B2%E8%A7%82%E9%94%81%2F</url>
    <content type="text"><![CDATA[乐观锁-悲观锁 乐观锁 悲观锁 乐观锁含义 乐观锁是一种思想，顾名思义，乐观锁看待所有的操作均持乐观的态度，即认为所有当前操作均不会造成数据信息的变更，操作不会加锁，只有当涉及到数据更新时才会将原始数据和库中实时数据进行比对，如果相同，说明当前操作期间没有其他并发操作对数据进行改动，执行更新操作，否则阻止该操作。 实现 基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 基于时间戳（ timestamp ）记录机制实现。为数据增加一个时间戳标识，为数据库表增加一个timestamp类型的字段来实现。同理如上。 CAS（Compare and Swap） CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 缺点：ABA问题（将引用和标志位同时作为检测项即可解决ABA问题），自旋CAS（不成功，就一直循环执行，直到成功）， 只能保证一个共享变量的原子操作（可以把多个变量放在一个对象里来进行CAS操作或者合并多个变量为一个） 优点 如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进行修改时（如更改用户帐户余额），如果采用悲观锁机制，也就意味着整个操作过 程中（从操作员读出数据、开始修改直至提交修改结果的全过程，甚至还包括操作 员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对几百上千个并发，这样的情况将导致怎样的后果。 乐观锁机制避免了长事务中的数据库加锁开销（操作员 A和操作员 B 操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系统整体性能表现。 缺点 乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。 应用 Hibernate 在其数据访问引擎中内置了乐观锁实现 12345678&lt;hibernate-mapping&gt;&lt;class name=&quot;org.hibernate.sample.TUser&quot; table=&quot;t_user&quot; dynamic-update=&quot;true&quot; dynamic-insert=&quot;true&quot; optimistic-lock=&quot;version&quot; &gt;&lt;id name=&quot;id&quot; column=&quot;id&quot; type=&quot;java.lang.Integer&quot;&gt;&lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt;&lt;/id&gt;&lt;version column=&quot;version&quot; name=&quot;version&quot; type=&quot;java.lang.Integer&quot;/&gt;……&lt;/class&gt; 悲观锁含义 悲观锁，正如其名，具有强烈的独占和排他特性。它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 应用 典型的倚赖数据库的悲观锁调用（使用for update）： select * from account where name=”Erica” for update 这条 sql 语句锁定了 account 表中所有符合检索条件（ name=”Erica” ）的记录。 本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。 Hibernate 的悲观锁，也是基于数据库的锁机制实现。 query.setLockMode(“user”,LockMode.UPGRADE); // 加锁]]></content>
      <categories>
        <category>Lock</category>
      </categories>
      <tags>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Word Search II]]></title>
    <url>%2F2017%2F11%2F25%2FLintCode_WordSearch_II%2F</url>
    <content type="text"><![CDATA[Description Given a matrix of lower alphabets and a dictionary. Find all words in the dictionary that can be found in the matrix. A word can start from any position in the matrix and go left/right/up/down to the adjacent position. One character only be used once in one word. No same word in dictionary 思路 一般来说，类似的匹配问题最会归结为以谁为主，或者是说拿谁去匹配谁；本例中，我们可以用所给单词去字母矩阵中深度搜索匹配，或者我们使用字母矩阵中字母组成的单词去所给单词中使用前缀法匹配。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180/** DFS实现 * 使用dfs要注意几点 * 1.每到一个字母矩阵点，可选位移有上下左右四个，要注意数组的边界值约束 * 2.矩阵中字母只能使用一次，故此需要记录每个位置字母的使用情况，使用置为1，未使用置为0，要注意深度搜 * 索过程中出现的回退现象，回退后相应位置字母的使用情况要重置为0 * 3.当有多个分支dfs时，例如矩阵中上下左右四个方向的分支dfs，要注意分支之间的关系，本例中只要其中一个 * 满足条件后其他分支便可以剪掉，所以各个分支因该是互斥的关系 * 4.递归出口的选择 * 5.所有的操作一定要有非空判定，不仅可以避免异常，还能提高性能，少做无用功public class Solution &#123; public static List&lt;String&gt; wordSearchII(char[][] board, List&lt;String&gt; words) &#123; // write your code here List&lt;String&gt; list = new LinkedList&lt;&gt;(); words.forEach((word)-&gt;&#123; if(findTheFirstChar(word,board))&#123; list.add(word); &#125; &#125;); return list; &#125; public static boolean findTheFirstChar(String word,char[][] board)&#123; boolean boo = false; out:for(int i = 0;i&lt;board.length;i++)&#123; for (int j = 0;j&lt;board[0].length;j++)&#123; if(word.charAt(0)==board[i][j])&#123; if(dfs(word,board,new char[board.length][board[0].length],word.length(),0,i,j,new char[word.length()])) &#123; boo = true; break out; &#125; &#125; &#125; &#125; return boo; &#125; public static boolean dfs(String word,char[][] board,char[][] flag,int length,int i,int k,int k1,char[] result)&#123;// System.out.println(new String(result)); if (word.equals(new String(result))) return true; else &#123; if (i &lt; length) &#123; char c = word.charAt(i); if (c == board[k][k1] &amp;&amp; flag[k][k1] != 1) &#123; result[i] = board[k][k1]; flag[k][k1] = 1;//标志该位置字母已被使用，矩阵中每个字母只允许使用一次，否则容易出现死循环 if (k - 1 &gt;= 0 &amp;&amp; dfs(word, board, flag, length, i + 1, k - 1, k1, result) == true) &#123; return true; &#125; else if (k1 + 1 &lt; board[0].length &amp;&amp; dfs(word, board, flag, length, i + 1, k, k1 + 1, result) == true) &#123; return true; &#125; else if (k + 1 &lt; board.length &amp;&amp; dfs(word, board, flag, length, i + 1, k + 1, k1, result) == true) &#123; return true; &#125; else if (k1 - 1 &gt;= 0 &amp;&amp; dfs(word, board, flag, length, i + 1, k, k1 - 1, result) == true) &#123; return true; &#125; else &#123; flag[k][k1] = 0;//状态回退，还原使用标志 return word.equals(new String(result)) ? true : false; &#125; &#125; else &#123; return word.equals(new String(result)) ? true : false; &#125; &#125; else return word.equals(new String(result)) ? true : false; &#125; &#125; public static void main(String[] args)&#123; List&lt;String&gt; words = new LinkedList&lt;&gt;();// words.add(&quot;dog&quot;);// words.add(&quot;dad&quot;);// words.add(&quot;dgdg&quot;);// words.add(&quot;can&quot;);// words.add(&quot;again&quot;);// words.add(&quot;ab&quot;);// words.add(&quot;eeda&quot;); words.add(&quot;babcbababcacabbbccbaaabcccacaccbaabbbccacc&quot;);// char[][] board = new char[][]&#123;&#123;&apos;d&apos;,&apos;o&apos;,&apos;a&apos;,&apos;f&apos;&#125;,&#123;&apos;a&apos;,&apos;g&apos;,&apos;a&apos;,&apos;i&apos;&#125;,&#123;&apos;d&apos;,&apos;c&apos;,&apos;a&apos;,&apos;n&apos;&#125;&#125;;// char[][] board = new char[][]&#123;&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;e&apos;&#125;,&#123;&apos;s&apos;,&apos;f&apos;,&apos;c&apos;,&apos;s&apos;&#125;,&#123;&apos;a&apos;,&apos;d&apos;,&apos;e&apos;,&apos;e&apos;&#125;&#125;;// char[][] board = new char[][]&#123;&#123;&apos;a&apos;,&apos;c&apos;&#125;,&#123;&apos;c&apos;,&apos;b&apos;&#125;&#125;; char[][] board = new char[][]&#123;&quot;babcbababcacab&quot;.toCharArray(),&quot;cacccbaaabccbb&quot;.toCharArray(),&quot;accbaabbbccacc&quot;.toCharArray(),&quot;acbaabcabcbbab&quot;.toCharArray(),&quot;caacaaabbcaaca&quot;.toCharArray(),&quot;bbacbcccbcacbc&quot;.toCharArray(),&quot;acaccacabacaca&quot;.toCharArray(),&quot;bcacbbcabbaaaa&quot;.toCharArray(),&quot;cccaacbcbaacba&quot;.toCharArray(),&quot;acaccacaccbabb&quot;.toCharArray(),&quot;bacacbbccaabcb&quot;.toCharArray(),&quot;aaccacbacabcca&quot;.toCharArray(),&quot;abcbcbbbabcaba&quot;.toCharArray(),&quot;bbcacbcaaababa&quot;.toCharArray(),&quot;acaabccabbcaab&quot;.toCharArray()&#125;;// System.out.println(Arrays.deepToString(board)); Long startTime = System.currentTimeMillis(); wordSearchII(board,words); System.out.println(System.currentTimeMillis()-startTime); Long startT = System.currentTimeMillis(); wordSearchIIPre(board,words); System.out.println(System.currentTimeMillis()-startT); List&lt;String&gt; list = wordSearchII(board,words); list.forEach((e)-&gt;&#123; System.out.println(e); &#125;); List&lt;String&gt; listPre = wordSearchIIPre(board,words); listPre.forEach((e)-&gt;&#123; System.out.println(e); &#125;); &#125;&#125;//使用hashmap构建前缀表实现public class Solution &#123; public static int[] dx = &#123;0, 1, -1, 0&#125;; public static int[] dy = &#123;1, 0, 0, -1&#125;; /** * @param board: A list of lists of character * @param words: A list of string * @return: A list of string */ public List&lt;String&gt; wordSearchII(char[][] board, List&lt;String&gt; words) &#123; if (board == null || board.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; if (board[0] == null || board[0].length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; boolean[][] visited = new boolean[board.length][board[0].length]; Map&lt;String, Boolean&gt; prefixIsWord = getPrefixSet(words); Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; board.length; i++) &#123; for (int j = 0; j &lt; board[i].length; j++) &#123; visited[i][j] = true; dfs(board, visited, i, j, String.valueOf(board[i][j]), prefixIsWord, wordSet); visited[i][j] = false; &#125; &#125; return new ArrayList&lt;String&gt;(wordSet); &#125; private Map&lt;String, Boolean&gt; getPrefixSet(List&lt;String&gt; words) &#123; Map&lt;String, Boolean&gt; prefixIsWord = new HashMap&lt;&gt;(); for (String word : words) &#123; for (int i = 0; i &lt; word.length() - 1; i++) &#123; String prefix = word.substring(0, i + 1); if (!prefixIsWord.containsKey(prefix)) &#123; prefixIsWord.put(prefix, false); &#125; &#125; prefixIsWord.put(word, true); &#125; return prefixIsWord; &#125; private void dfs(char[][] board, boolean[][] visited, int x, int y, String word, Map&lt;String, Boolean&gt; prefixIsWord, Set&lt;String&gt; wordSet) &#123; if (!prefixIsWord.containsKey(word)) &#123; return; &#125; if (prefixIsWord.get(word)) &#123; wordSet.add(word); &#125; for (int i = 0; i &lt; 4; i++) &#123; int adjX = x + dx[i]; int adjY = y + dy[i]; if (!inside(board, adjX, adjY) || visited[adjX][adjY]) &#123; continue; &#125; visited[adjX][adjY] = true; dfs(board, visited, adjX, adjY, word + board[adjX][adjY], prefixIsWord, wordSet); visited[adjX][adjY] = false; &#125; &#125; private boolean inside(char[][] board, int x, int y) &#123; return x &gt;= 0 &amp;&amp; x &lt; board.length &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; board[0].length; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Longest Consecutive Sequence]]></title>
    <url>%2F2017%2F11%2F18%2FLintCode_LongestConsecutiveSequence%2F</url>
    <content type="text"><![CDATA[Description Given an unsorted array of integers, find the length of the longest consecutive elements sequence.Clarification：Your algorithm should run in O(n) complexity. Example Given [100, 4, 200, 1, 3, 2],The longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4. 思路 一开始想到的就是先排序，然后求最长连续序列，但是快排都需要nlogn的时间消耗，同时还需要去重操作，所以我想到的是用Map来存放数组元素，Map的key和value均为数组元素值，这样同时满足了排序和去重的需求，而且所耗时间为n（此处我忽略了map中key对负数的处理，导致我的代码只对数组中元素均为正数的情况有效），然后遍历map判定其下一个元素是否在map中存在，以此来找出最长连续序列，代码如下： 123456789101112131415161718192021public int longestConsecutive(int[] nums) &#123; if(nums.length==0) return 0; if(nums.length==1) return nums[0]; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i],nums[i]); &#125; int maxLength = 1; int tempLength = 1; for(Map.Entry&lt;Integer,Integer&gt; entry : map.entrySet())&#123; if(map.get(entry.getKey()+1)!=null)&#123; tempLength++; &#125;else&#123; maxLength = maxLength &gt; tempLength ? maxLength : tempLength; tempLength = 1; &#125; &#125; return maxLength; &#125; 改进：map改用set去重，然后遍历数组，然后利用set找出以该元素为中心的连续序列的上下限为多少（之前用map的好处是已经排好序，只需找出上限即可），实现代码如下： 123456789101112131415161718192021222324252627public class Solution &#123; /** * @param nums: A list of integers * @return an integer */ public int longestConsecutive(int[] nums) &#123; HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; set.add(nums[i]); &#125; int longest = 0; for (int i = 0; i &lt; nums.length; i++) &#123; int down = nums[i] - 1; while (set.contains(down)) &#123; set.remove(down); down--; &#125; int up = nums[i] + 1; while (set.contains(up)) &#123; set.remove(up); up++; &#125; longest = Math.max(longest, up - down - 1); &#125; return longest; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Merge K Sorted Lists]]></title>
    <url>%2F2017%2F11%2F11%2FLintCode_MergeKSortedLists%2F</url>
    <content type="text"><![CDATA[Description Merge k sorted linked lists and return it as one sorted list.Analyze and describe its complexity. 思路 合并K个有序链表，且不去重，首先联想到的是合并两个有序单链表的思路，然年顺势往下推，遍历K个有序单链表，依次与前面的结果相合并，最后返回结果，实现代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940public class Solution &#123; /** * @param lists: a list of ListNode * @return: The head of one sorted list. */ public ListNode mergeKLists(List&lt;ListNode&gt; lists) &#123; // write your code here ListNode listNode = null; if (lists == null) return listNode; if(lists.size() == 0 || lists.isEmpty()) return listNode; for (ListNode node : lists) &#123; if (node == null) continue; listNode = mergeList(listNode,node); &#125; return listNode; &#125; public ListNode mergeList(ListNode tempNode,ListNode tempNode1)&#123; ListNode listNode = new ListNode(0); ListNode tempListNode = listNode; while(tempNode!=null&amp;&amp;tempNode1!=null)&#123; if(tempNode.val&lt;tempNode1.val)&#123; tempListNode.next = tempNode; tempListNode = tempNode; tempNode = tempNode.next; &#125;else&#123; tempListNode.next = tempNode1; tempListNode = tempNode1; tempNode1 = tempNode1.next; &#125; &#125; if(tempNode!=null) tempListNode.next = tempNode; if(tempNode1!=null) tempListNode.next = tempNode1; return listNode.next; &#125;&#125; 改进，上述由于是直接遍历List，所以循环次数（即合并次数）为n，但是我们可以通过两两合并（参照二叉树结构从子节点向上合并，最终到达根节点）来降低黑冰次数为n/2，参考答案代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Solution &#123; /** * @param lists: a list of ListNode * @return: The head of one sorted list. */ public ListNode mergeKLists(List&lt;ListNode&gt; lists) &#123; if (lists.size() == 0) &#123; return null; &#125; return mergeHelper(lists, 0, lists.size() - 1); &#125; //借助递归来实现List的不断二等分 private ListNode mergeHelper(List&lt;ListNode&gt; lists, int start, int end) &#123; if (start == end) &#123; return lists.get(start); &#125; int mid = start + (end - start) / 2; ListNode left = mergeHelper(lists, start, mid); ListNode right = mergeHelper(lists, mid + 1, end); return mergeTwoLists(left, right); &#125; private ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; ListNode dummy = new ListNode(0); ListNode tail = dummy; while (list1 != null &amp;&amp; list2 != null) &#123; if (list1.val &lt; list2.val) &#123; tail.next = list1; tail = list1; list1 = list1.next; &#125; else &#123; tail.next = list2; tail = list2; list2 = list2.next; &#125; &#125; if (list1 != null) &#123; tail.next = list1; &#125; else &#123; tail.next = list2; &#125; return dummy.next; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_Min Stack]]></title>
    <url>%2F2017%2F11%2F04%2FLintCode_MinStack%2F</url>
    <content type="text"><![CDATA[Description Implement a stack with min() function, which will return the smallest number in the stack.It should support push, pop and min operation all in O(1) cost. 思路 最直接的想法，遍历求最小值，每次入栈和出栈都会造成遍历的发生 改进：从一开始就比较每一个入栈的值，将最小值存入MIN中，但是，出栈依然会导致MIN值的缺失，从而触发遍历求最小值，我只想到这里。。。代码入下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class MinStack &#123; private Stack&lt;Integer&gt; stack = null; private int MIN = Integer.MIN_VALUE; public MinStack() &#123; // do intialization if necessary stack = new Stack&lt;Integer&gt;(); &#125; /* * @param number: An integer * @return: nothing */ public void push(int number) &#123; // write your code here if(MIN==Integer.MIN_VALUE)&#123; MIN = number; &#125;else&#123; MIN = number&gt;MIN?MIN:number; &#125; stack.push(number); &#125; /* * @return: An integer */ public int pop() &#123; // write your code here int topValue = stack.pop(); if(topValue==MIN)&#123; MIN = getMin(); &#125; return topValue; &#125; /* * @return: An integer */ public int min() &#123; // write your code here return MIN; &#125; public int getMin()&#123; if(stack.isEmpty())&#123; MIN = Integer.MIN_VALUE; &#125;else&#123; MIN = stack.peek(); for(Integer value:stack)&#123; MIN = value&gt;MIN?MIN:value; &#125; &#125; return MIN; &#125;&#125; 动态规划的思路，同样是从一开始就比较每一个入栈的值，然后将当前栈中的最小值存入另一个栈中，这样在入栈的时候就记录好了该元素发生入栈操作和出栈操作时候栈中的最小值，避免了遍历找寻最小值的时间，代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); minStack = new Stack&lt;Integer&gt;(); &#125; public void push(int number) &#123; stack.push(number); if (minStack.isEmpty()) &#123; minStack.push(number); &#125; else &#123; minStack.push(Math.min(number, minStack.peek())); &#125; &#125; public int pop() &#123; minStack.pop(); return stack.pop(); &#125; public int min() &#123; return minStack.peek(); &#125;&#125;// version 2, save more space. but space complexity doesn't change.//相同最小值将不会重复存入栈中，节省栈空间public class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); minStack = new Stack&lt;Integer&gt;(); &#125; public void push(int number) &#123; stack.push(number); if (minStack.empty() == true) minStack.push(number); else &#123; // 这里考虑的相等的情况也会继续push if (minStack.peek() &gt;= number) minStack.push(number); &#125; &#125; public int pop() &#123; if (stack.peek().equals(minStack.peek()) ) minStack.pop(); return stack.pop(); &#125; public int min() &#123; return minStack.peek(); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_ImplementQueueByTwoStacks]]></title>
    <url>%2F2017%2F10%2F28%2FLintCode_ImplementQueueByTwoStacks%2F</url>
    <content type="text"><![CDATA[Description As the title described, you should only use two stacks to implement a queue’s actions.The queue should support push(element), pop() and top() where pop is pop the first(a.k.a front) element in the queue.Both pop and top methods should return the value of first element. 思路 第一反应就是一个栈来存正序入队列的值，另一个存反序，入队列的时候往正序栈中添加，出队列的时候从反序栈中取栈顶，但是，两个栈的关系一直没有梳理清晰，直到看了提供标准答案才豁然卡朗，还是智商有点捉急啊。 两个栈的关系其实跟我一开始想的一样，栈A用来存入队列正序值，栈B用来存逆序，入队列的值负责往A中进入，出队列的时候先判定B是否为空，不为空，说明之前入队列进来的值还没有走光，B可以继续进行出队列操作，若B为空，则需要将A中值逆序放入B中，然后在进行出队列操作！ 注意：这里的正序和逆序指的是元素的先来后到的顺序，不是大小顺序 后来发现java提供的栈方法就可以很简洁的实现队列的操作（相当于底层方法帮助我们实现了这个功能）代码入下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ImplementQueuebyTwoStacks &#123; private Stack&lt;Integer&gt; queue = null; public void MyQueue() &#123; // do intialization if necessary queue = new Stack&lt;Integer&gt;(); &#125; /* * @param element: An integer * @return: nothing */ public void push(int element) &#123; // write your code here queue.push(element); &#125; /* * @return: An integer */ public int pop() &#123; // write your code here int headValue = queue.firstElement();//获取栈底元素 queue.remove(0);//移除栈底元素 return headValue; &#125; /* * @return: An integer */ public int top() &#123; // write your code here return queue.firstElement(); &#125;&#125;//以下是官方标准代码public class MyQueue &#123; private Stack&lt;Integer&gt; stack1; private Stack&lt;Integer&gt; stack2; public MyQueue() &#123; // do initialization if necessary stack1 = new Stack&lt;Integer&gt;(); stack2 = new Stack&lt;Integer&gt;(); &#125; private void stack2ToStack1()&#123; while(! stack2.isEmpty())&#123; stack1.push(stack2.pop()); &#125; &#125; public void push(int element) &#123; // write your code here stack2.push(element); &#125; public int pop() &#123; // write your code here if(stack1.empty() == true)&#123; this.stack2ToStack1(); &#125; return stack1.pop(); &#125; public int top() &#123; // write your code here if(stack1.empty() == true)&#123; this.stack2ToStack1(); &#125; return stack1.peek(); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8新特性]]></title>
    <url>%2F2017%2F10%2F21%2Fjava8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[java8新特性 本文参考自官方文档What’s New in JDK 8，内容有所筛选！ 目录 Java Programming Language Lambda Expressions（Lambda表达式） Method references （方法引用） Default methods （默认方法） Repeating Annotations （重复注释） Improved type inference（更好的类型推断） Method parameter reflection（方法参数反射） Collections（集合） Tool（工具） Javac tool Javadoc tool Internationalization（国际化） Date-Time Package （日期时间） IO and NIO java.lang and java.util Packages Parallel Array Sorting（并行数组排序） Standard Encoding and Decoding Base64（标准编码和解码Base64） Unsigned Arithmetic Support（无符号算术支持） JDBC The JDBC-ODBC Bridge has been removed. JDBC 4.2 introduces new features. Concurrency（并发） HotSpot 正文Java编程语言 Lambda表达式 Lambda表达式是一种新的语言功能，已在此版本中引入。它们使您能够将功能视为方法参数，或将代码视为数据。使用Lambda表达式可以更简洁地表达单方法接口（称为函数接口）的实例。 Lambda表达式可由逗号分隔的参数列表、-&gt;符号和语句块组成（其中参数列表中的参数e的类型可以由编译器推理得出的，也可以显式指定该参数的类型），例如： 1234567891011//基本语法://(params) -&gt; expression//(params) -&gt; statement//(params) -&gt; &#123; statements &#125;Arrays.asList( "a", "b", "d" ).forEach( e -&gt; System.out.println( e ) );//等价于Arrays.asList( "a", "b", "d" ).forEach( ( String e ) -&gt; System.out.println( e ) );Arrays.asList( "a", "b", "d" ).forEach( e -&gt; &#123; System.out.print( e ); System.out.print( e );&#125; ); Lambda表达式可以引用类成员和局部变量（会将这些变量隐式得转换成final），但是不能在lambda内部修改定义在域外的变量。同时Lambda表达式有返回值，返回值的类型也由编译器推理得出。如果Lambda表达式中的语句块只有一行，则可以不用使用return语句，例如 12345678(final) String separator = ",";Arrays.asList( "a", "b", "d" ).forEach( ( String e ) -&gt; System.out.print( e + separator ) );//Lambda表达式中语句块只有一行，可以不用使用return语句Arrays.asList( "a", "b", "d" ).sort( ( e1, e2 ) -&gt; e1.compareTo( e2 ) );Arrays.asList( "a", "b", "d" ).sort( ( e1, e2 ) -&gt; &#123; int result = e1.compareTo( e2 ); return result;&#125; ); 函数接口 函数接口指的是只有一个函数的接口，这样的接口可以隐式转换为Lambda表达式。java.lang.Runnable和java.util.concurrent.Callable是函数式接口的最佳例子。在实践中，函数式接口非常脆弱：只要某个开发者在该接口中添加一个函数，则该接口就不再是函数式接口进而导致编译失败。为了克服这种代码层面的脆弱性，并显式说明某个接口是函数式接口，Java 8 提供了一个特殊的注解@FunctionalInterface（Java 库中的所有相关接口都已经带有这个注解了），举个简单的函数式接口的定义： 1234@FunctionalInterfacepublic interface Functional &#123; void method();&#125; 不过有一点需要注意，默认方法和静态方法不会破坏函数式接口的定义，因此如下的代码是合法的。 1234567891011121314@FunctionalInterfacepublic interface FunctionalDefaultMethods &#123; void method(); default void defaultMethod() &#123; &#125; &#125;@FunctionalInterfacepublic interface FunctionalStaticMethods &#123; void method(); Static void defaultMethod() &#123; &#125; &#125; lambda表达式替换匿名类 1234567891011121314151617181920212223// Java 8之前：new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("Before Java8, too much code for too little to do"); &#125;&#125;).start();//Java 8方式：new Thread( () -&gt; System.out.println("In Java8, Lambda expression rocks !!") ).start();// Java 8之前：Collections.sort(list, new Comparator&lt;Object&gt;() &#123; public int compare(Object arg0, Object arg1) &#123; String s1 = (String)arg0; String s2 = (String)arg1; return s1.compareTo( s2 ); &#125; &#125;);//Java 8方式： Collections.sort(list,(arg0,arg1) -&gt; &#123; String s1 = (String)arg0; String s2 = (String)arg1; return s1.compareTo( s2 ); &#125;); ####Stream stream()Stream filter(Predicate&lt;? super T&gt; predicate) Stream map(Function&lt;? super T,? extends R&gt; mapper)void forEach(Consumer&lt;? super T&gt; action) 1 方法引用 方法引用为已有名称的方法提供易读的lambda表达式。lambda表达式内可以使用方法引用，仅当该方法不修改lambda表达式提供的参数。 （引用静态方法）ContainingClass :: staticMethodName 1Arrays.sort(rosterAsArray, MyComparisonProvider::staticCompare); （引用特定对象的实例方法）containsObject :: instanceMethodName 12//ComparisonProvider myComparisonProvider = new ComparisonProvider();Arrays.sort(rosterAsArray, myComparisonProvider::normalCompare); （引用特定类型任意对象的实例方法）ContainingType :: methodName 123String[] stringArray = &#123; "Barbara", "James", "Mary", "John", "Patricia", "Robert", "Michael", "Linda" &#125;;Arrays.sort(stringArray, String::compareToIgnoreCase); （引用一个构造函数）ClassName :: new 1Set&lt;Person&gt; rosterSet = transferElements(roster, HashSet::new); 默认方法 默认方法可以将新功能添加到库的接口，并确保与为这些接口的旧版本编写的代码的二进制兼容性。 12345678910public interface TimeClient &#123; //通过接口直接调用该静态方法 static void dispaly () &#123; System.out.println("static"); &#125; //该接口的实现类不强制要求重写default方法，使得接口可以添加新功能而不影响其实现类 default void dispaly() &#123; System.out.println("default"); &#125; &#125; 重复注释 重复注释提供了将同一注释类型多次应用于相同的声明或类型使用的功能。Java8之前的注解有一个很大的限制是：在同一个地方不能多次使用同一个注解。Java 8打破了这个限制，引入了重复注解的概念，允许在同一个地方多次使用同一个注解。在Java 8中使用@Repeatable注解定义重复注解，实际上，这并不是语言层面的改进，而是编译器做的一个trick，底层的技术仍然相同。 12345678910@Schedule(dayOfMonth="last")@Schedule(dayOfWeek="Fri", hour="23")public void doPeriodicCleanup() &#123; ... &#125;//The annotation type must be marked with the @Repeatable meta-annotation@Repeatable(Schedules.class)public @interface Schedule &#123; String dayOfMonth() default "first"; String dayOfWeek() default "Mon"; int hour() default 12;&#125; 更好的类型推断 12345678//Java 8方式： List&lt;String&gt; stringList = new ArrayList&lt;&gt;();stringList.add("A");stringList.addAll(Arrays.asList());//Java 8之前： List&lt;String&gt; stringList = new ArrayList&lt;&gt;();stringList.add("A");stringList.addAll(Arrays.&lt;String&gt;asList()); 方法参数反射 您可以使用方法java.lang.reflect.Executable.getParameters获取任何方法或构造函数的形式参数的名称。 （类Method和构造函数扩展了类Executable，因此继承了方法Executable.getParameters。）但是，.class文件默认不存储形式参数名称。 要将正式参数名称存储在特定的.class文件中，从而使Reflection API能够检索正式的参数名称，请使用javac编译器的-parameters选项编译源文件。 12345678public class ParameterNames &#123; public static void main(String[] args) throws Exception &#123; Method method = ParameterNames.class.getMethod( "main", String[].class ); for( final Parameter parameter: method.getParameters() ) &#123; System.out.println( "Parameter: " + parameter.getName() ); &#125; &#125;&#125; 集合 新的java.util.stream包中的类提供了一个Stream API来支持元素流上的函数式操作。 Stream API集成到Collections API中，可以对集合进行批量操作，例如顺序或并行的map-reduce转换。 java.util.stream.Stream部分方法如下 Stream filter(Predicate&lt;? super T&gt; predicate)（过滤） Stream map(Function&lt;? super T,? extends R&gt; mapper)（转换） IntStream mapToInt(ToIntFunction&lt;? super T&gt; mapper) Stream distinct()（返回由此流的不同元素，去重） Stream sorted()（默认排序） Stream sorted(Comparator&lt;? super T&gt; comparator)（排序） Stream peek(Consumer&lt;? super T&gt; action) 1234567//This method exists mainly to support debugging, where you want to see the elements as they flow past a certain point in a pipeline:Stream.of("one", "two", "three", "four") .filter(e -&gt; e.length() &gt; 3) .peek(e -&gt; System.out.println("Filtered value: " + e)) .map(String::toUpperCase) .peek(e -&gt; System.out.println("Mapped value: " + e)) .collect(Collectors.toList()); Stream limit(long maxSize)（限制） Stream skip(long n)（跳过前n个元素） void forEach(Consumer&lt;? super T&gt; action)（迭代） void forEachOrdered(Consumer&lt;? super T&gt; action) Object[] toArray()（转换成数组） 1Person[] men = people.stream().filter(p -&gt; p.getGender() == MALE).toArray(Person[]::new); T reduce(T identity,BinaryOperator accumulator)（合并） Optional reduce(BinaryOperator accumulator) U reduce(U identity,BiFunction accumulator,BinaryOperator combiner) R collect(Supplier supplier,BiConsumer accumulator,BiConsumer combiner) 1234//The following will accumulate strings into an ArrayList:List&lt;String&gt; asList = stringStream.collect(ArrayList::new, ArrayList::add,ArrayList::addAll);//The following will take a stream of strings and concatenates them into a single string:String concat = stringStream.collect(StringBuilder::new, StringBuilder::append,StringBuilder::append).toString(); R collect(Collector&lt;? super T,A,R&gt; collector) 123456//The following will accumulate strings into an ArrayList:List&lt;String&gt; asList = stringStream.collect(Collectors.toList());//The following will classify Person objects by city:按照城市分组Map&lt;String, List&lt;Person&gt;&gt;peopleByCity= personStream.collect(Collectors.groupingBy(Person::getCity));//The following will classify Person objects by state and city, cascading two Collectors together:按照国家和城市两项进行分组Map&lt;String, Map&lt;String, List&lt;Person&gt;&gt;&gt; peopleByStateAndCity= personStream.collect(Collectors.groupingBy(Person::getState,Collectors.groupingBy(Person::getCity))); Optional min(Comparator&lt;? super T&gt; comparator)（最小值） Optional max(Comparator&lt;? super T&gt; comparator)（最大值） long count()（计数） boolean anyMatch(Predicate&lt;? super T&gt; predicate)（匹配） boolean allMatch(Predicate&lt;? super T&gt; predicate) boolean noneMatch(Predicate&lt;? super T&gt; predicate) Optional findFirst() Optional findAny() static Stream empty() static Stream of(T t)（返回包含单个元素的顺序流。） static Stream of(T… values)（返回顺序排列的流，其元素是指定的值。） static Stream concat(Stream&lt;? extends T&gt; a,Stream&lt;? extends T&gt; b)（连接） forEach对列表进行迭代 12345678910// Java 8之前：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");for (String feature : features) &#123; System.out.println(feature);&#125;// Java 8之后：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");features.forEach(n -&gt; System.out.println(n));// 使用Java 8的方法引用更方便features.forEach(System.out::println); map将对象进行转换，reduce结果合并 123456789101112131415161718192021// Java 8之前：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; System.out.println(price);&#125;// Java 8之后：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).forEach(System.out::println);// Java 8之前：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double total = 0;for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; total = total + price;&#125;System.out.println("Total : " + total);// Java 8之后：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println("Total : " + bill); filter元素过滤 123// 创建一个字符串列表，每个字符串长度大于2List&lt;String&gt; filtered = strList.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList());System.out.printf("Original List : %s, filtered list : %s %n", strList, filtered); 具有关键冲突的HashMap性能改进 工具 Javac工具javac命令的-parameters选项可用于存储形式参数名称并使Reflection API检索正式参数名称。 Java语言规范（JLS）第15.21节中的相等运算符的类型规则现在可以通过javac命令正确执行。 Javadoc工具javadoc工具支持新的DocTree API，使您能够将Javadoc注释作为抽象语法树来遍历。 javadoc工具支持新的Javadoc Access API，使您可以直接从Java应用程序调用Javadoc工具，而无需执行新的过程。有关更多信息，请参阅javadoc什么是新页面。 现在，javadoc工具支持检查javadoc注释的内容，以解决可能导致运行javadoc时生成的文件中的各种问题（例如无效的HTML或可访问性问题）的问题。该功能默认启用，也可以通过新的-Xdoclint选项进行控制。有关更多详细信息，请参阅运行“javadoc -X”的输出。在javac工具中也可以使用此功能，但默认情况下它未启用。 国际化 Unicode增强功能，包括对Unicode 6.2.0的支持 采用Unicode CLDR数据和java.locale.providers系统属性 新的日历和区域设置API 能够将自定义资源包安装为扩展 日期时间包 - 一组提供全面日期 - 时间模型的新包。 IO和NIO 基于Solaris事件端口机制的Solaris新增SelectorProvider实现。要使用，使用设置为值sun.nio.ch.EventPortSelectorProvider的系统属性java.nio.channels.spi.Selector运行。 减小 /jre/lib/charsets.jar文件的大小 提高了java.lang.String（byte []，*）构造函数和java.lang.String.getBytes（）方法的性能。 java.lang和java.util包 并行数组排序 标准编码和解码Base64 无符号算术支持 JDBC- JDBC-ODBC Bridge已被删除。 - JDBC 4.2引入了新功能。 并发 类和接口已被添加到java.util.concurrent包中。 已经将方法添加到java.util.concurrent.ConcurrentHashMap类中，以支持基于新添加的流设施和lambda表达式的聚合操作。 已将类添加到java.util.concurrent.atomic包以支持可伸缩的可更新变量。 方法已被添加到java.util.concurrent.ForkJoinPool类中以支持公共池。 已添加java.util.concurrent.locks.StampedLock类以提供基于能力的锁，其中有三种控制读/写访问的模式。 HotSpot 硬件内在函数被添加到使用高级加密标准（AES）。 UseAES和UseAESIntrinsics标志可用于启用英特尔硬件的基于硬件的AES内在函数。硬件必须是2010年或更新的Westmere硬件。例如，要启用硬件AES，请使用以下标志：-XX：+ UseAES -XX：+ UseAESIntrinsics，要禁用硬件AES，请使用以下标志：-XX：-UseAES -XX：-UseAESIntrinsics 去除PermGen。 Java编程语言中的缺省方法由方法调用的字节码指令支持。]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO详解]]></title>
    <url>%2F2017%2F10%2F21%2FIO%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[java8新特性 本文参考自官方文档What’s New in JDK 8，内容有所筛选！ 目录 BufferedInputStream BufferedInputStream(InputStream in)Creates a BufferedInputStream and saves its argument, the input stream in, for later use. BufferedInputStream(InputStream in, int size)Creates a BufferedInputStream with the specified buffer size, and saves its argument, the input stream in, for later use. BufferedOutputStream BufferedOutputStream(OutputStream out)Creates a new buffered output stream to write data to the specified underlying output stream. BufferedOutputStream(OutputStream out, int size)Creates a new buffered output stream to write data to the specified underlying output stream with the specified buffer size. BufferedReader BufferedReader(Reader in)Creates a buffering character-input stream that uses a default-sized input buffer. BufferedReader(Reader in, int sz)Creates a buffering character-input stream that uses an input buffer of the specified size. BufferedWriter BufferedWriter(Writer out)Creates a buffered character-output stream that uses a default-sized output buffer. BufferedWriter(Writer out, int sz)Creates a new buffered character-output stream that uses an output buffer of the given size. ByteArrayInputStream ByteArrayInputStream(byte[] buf)Creates a ByteArrayInputStream so that it uses buf as its buffer array. ByteArrayInputStream(byte[] buf, int offset, int length)Creates ByteArrayInputStream that uses buf as its buffer array. ByteArrayOutputStream ByteArrayOutputStream()Creates a new byte array output stream. ByteArrayOutputStream(int size)Creates a new byte array output stream, with a buffer capacity of the specified size, in bytes. CharArrayReader CharArrayReader(char[] buf)Creates a CharArrayReader from the specified array of chars. CharArrayReader(char[] buf, int offset, int length)Creates a CharArrayReader from the specified array of chars. CharArrayWriter CharArrayWriter()Creates a new CharArrayWriter. CharArrayWriter(int initialSize)Creates a new CharArrayWriter with the specified initial size. Console DataInputStream DataInputStream(InputStream in)Creates a DataInputStream that uses the specified underlying InputStream. DataOutputStream DataOutputStream(OutputStream out)Creates a new data output stream to write data to the specified underlying output stream. File File(File parent, String child)Creates a new File instance from a parent abstract pathname and a child pathname string. File(String pathname)Creates a new File instance by converting the given pathname string into an abstract pathname. File(String parent, String child)Creates a new File instance from a parent pathname string and a child pathname string. File(URI uri)Creates a new File instance by converting the given file: URI into an abstract pathname. FileDescriptor FileInputStream FileInputStream(File file)Creates a FileInputStream by opening a connection to an actual file, the file named by the File object file in the file system. FileInputStream(FileDescriptor fdObj)Creates a FileInputStream by using the file descriptor fdObj, which represents an existing connection to an actual file in the file system. FileInputStream(String name)Creates a FileInputStream by opening a connection to an actual file, the file named by the path name name in the file system. FileOutputStream FileOutputStream(File file)Creates a file output stream to write to the file represented by the specified File object. FileOutputStream(File file, boolean append)Creates a file output stream to write to the file represented by the specified File object. FileOutputStream(FileDescriptor fdObj)Creates a file output stream to write to the specified file descriptor, which represents an existing connection to an actual file in the file system. FileOutputStream(String name)Creates a file output stream to write to the file with the specified name. FileOutputStream(String name, boolean append)Creates a file output stream to write to the file with the specified name. FilePermission FileReader FileReader(File file)Creates a new FileReader, given the File to read from. FileReader(FileDescriptor fd)Creates a new FileReader, given the FileDescriptor to read from. FileReader(String fileName)Creates a new FileReader, given the name of the file to read from. FileWriter FileWriter(File file)Constructs a FileWriter object given a File object. FileWriter(File file, boolean append)Constructs a FileWriter object given a File object. FileWriter(FileDescriptor fd)Constructs a FileWriter object associated with a file descriptor. FileWriter(String fileName)Constructs a FileWriter object given a file name. FileWriter(String fileName, boolean append)Constructs a FileWriter object given a file name with a boolean indicating whether or not to append the data written. FilterInputStream FilterOutputStream FilterReader FilterWriter InputStream InputStream() InputStreamReader InputStreamReader(InputStream in)Creates an InputStreamReader that uses the default charset. InputStreamReader(InputStream in, Charset cs)Creates an InputStreamReader that uses the given charset. InputStreamReader(InputStream in, CharsetDecoder dec)Creates an InputStreamReader that uses the given charset decoder. InputStreamReader(InputStream in, String charsetName)Creates an InputStreamReader that uses the named charset. LineNumberInputStream LineNumberReader ObjectInputStream ObjectInputStream.GetField ObjectOutputStream ObjectOutputStream.PutField ObjectStreamClass ObjectStreamField OutputStream OutputStream() OutputStreamWriter OutputStreamWriter(OutputStream out)Creates an OutputStreamWriter that uses the default character encoding. OutputStreamWriter(OutputStream out, Charset cs)Creates an OutputStreamWriter that uses the given charset. OutputStreamWriter(OutputStream out, CharsetEncoder enc)Creates an OutputStreamWriter that uses the given charset encoder. OutputStreamWriter(OutputStream out, String charsetName)Creates an OutputStreamWriter that uses the named charset. PipedInputStream PipedInputStream()Creates a PipedInputStream so that it is not yet connected. PipedInputStream(int pipeSize)Creates a PipedInputStream so that it is not yet connected and uses the specified pipe size for the pipe’s buffer. PipedInputStream(PipedOutputStream src)Creates a PipedInputStream so that it is connected to the piped output stream src. PipedInputStream(PipedOutputStream src, int pipeSize)Creates a PipedInputStream so that it is connected to the piped output stream src and uses the specified pipe size for the pipe’s buffer. PipedOutputStream PipedOutputStream()Creates a piped output stream that is not yet connected to a piped input stream. PipedOutputStream(PipedInputStream snk)Creates a piped output stream connected to the specified piped input stream. PipedReader PipedReader()Creates a PipedReader so that it is not yet connected. PipedReader(int pipeSize)Creates a PipedReader so that it is not yet connected and uses the specified pipe size for the pipe’s buffer. PipedReader(PipedWriter src)Creates a PipedReader so that it is connected to the piped writer src. PipedReader(PipedWriter src, int pipeSize)Creates a PipedReader so that it is connected to the piped writer src and uses the specified pipe size for the pipe’s buffer. PipedWriter PipedWriter()Creates a piped writer that is not yet connected to a piped reader. PipedWriter(PipedReader snk)Creates a piped writer connected to the specified piped reader. PrintStream PrintWriter PushbackInputStream PushbackReader RandomAccessFile RandomAccessFile(File file, String mode)Creates a random access file stream to read from, and optionally to write to, the file specified by the File argument. RandomAccessFile(String name, String mode)Creates a random access file stream to read from, and optionally to write to, a file with the specified name. Reader Reader()Creates a new character-stream reader whose critical sections will synchronize on the reader itself. protected Reader(Object lock)Creates a new character-stream reader whose critical sections will synchronize on the given object. SequenceInputStream SerializablePermission StreamTokenizer StringBufferInputStream StringReader StringReader(String s)Creates a new string reader. StringWriter StringWriter()Create a new string writer using the default initial string-buffer size. StringWriter(int initialSize)Create a new string writer using the specified initial string-buffer size. Writer Writer()Creates a new character-stream writer whose critical sections will synchronize on the writer itself. protected Writer(Object lock)Creates a new character-stream writer whose critical sections will synchronize on the given object.]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>IO</tag>
        <tag>File</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式文档]]></content>
      <categories>
        <category>Regular_Expression</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Regular_Expression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库优化]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[数据库优化选取最适用的字段属性 数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。 例如，邮政编码字段，CHAR(6)好过CHAR(255)和VARCHAR，同样MEDIUMINT好过BIGIN来定义整型字段（五种整型tinyint，smallint，mediumint，int，bigint）。 把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。 使用连接（JOIN）来代替子查询(Sub-Queries) MySQL从4.1开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接（JOIN）..替代。连接（JOIN）..之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 使用联合(UNION)来代替手动创建的临时表 MySQL从4.0的版本开始支持union查询，它可以把需要使用临时表的两条或更多的select查询合并的一个查询中。在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐、高效。使用union来创建查询的时候，我们只需要用UNION作为关键字把多个select语句连接起来就可以了，要注意的是所有select语句中的字段数目要想同。例如。SELECT Name,Phone FROM client UNION SELECT Name,BirthDate FROM author 事务 尽管我们可以使用子查询（Sub-Queries）、连接（JOIN）和联合（UNION）来创建各种各样的查询，但不是所有的数据库操作都可以只用一条或少数几条SQL语句就可以完成的。更多的时候是需要用到一系列的语句来完成某种工作。但是在这种情况下，当这个语句块中的某一条语句运行出错的时候，整个语句块的操作就会变得不确定起来。设想一下，要把某个数据同时插入两个相关联的表中，可能会出现这样的情况：第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样，就会造成数据的不完整，甚至会破坏数据库中的数据。要避免这种情况，就应该使用事务，它的作用是：要么语句块中每条语句都操作成功，要么都失败。换句话说，就是可以保持数据库中数据的一致性和完整性。事物以BEGIN关键字开始，COMMIT关键字结束。在这之间的一条SQL操作失败，那么，ROLLBACK命令就可以把数据库恢复到BEGIN开始之前的状态。 BEGIN;INSERT INTO salesinfo …;UPDATE inventory SET Quantity = 11 WHERE item = ‘book’;COMMIT; 事务的另一个重要作用是当多个用户同时使用相同的数据源时，它可以利用锁定数据库的方法来为用户提供一种安全的访问方式，这样可以保证用户的操作不被其它的用户所干扰。 锁定表 尽管事务是维护数据库完整性的一个非常好的方法，但却因为它的独占性，有时会影响数据库的性能，尤其是在很大的应用系统中。由于在事务执行的过程中，数据库将会被锁定，因此其它的用户请求只能暂时等待直到该事务结束。如果一个数据库系统只有少数几个用户来使用，事务造成的影响不会成为一个太大的问题；但假设有成千上万的用户同时访问一个数据库系统，例如访问一个电子商务网站，就会产生比较严重的响应延迟。 其实，有些情况下我们可以通过锁定表的方法来获得更好的性能。下面的例子就用锁定表的方法来完成前面一个例子中事务的功能。 LOCKTABLE inventory WRITESELECT Quantity FROM inventory WHERE Item = ‘book’;…UPDATE inventory SET Quantity = 11 WHERE Item = ‘book’;UNLOCKTABLES 这里，我们用一个select语句取出初始数据，通过一些计算，用update语句将新值更新到表中。包含有WRITE关键字的LOCKTABLE语句可以保证在UNLOCKTABLES命令被执行之前，不会有其它的访问来对inventory进行插入、更新或者删除的操作。 使用索引 索引是提高数据库性能的常用方法，它可以令数据库服务器以比没有索引快得多的速度检索特定的行，尤其是在查询语句当中包含有MAX(),MIN()和ORDERBY这些命令的时候，性能提高更为明显。 那该对哪些字段建立索引呢？一般说来，索引应建立在那些将用于JOIN,WHERE判断和ORDERBY排序的字段上。尽量不要对数据库中某个含有大量重复的值的字段建立索引。对于一个ENUM类型的字段来说，出现大量重复值是很有可能的情况 优化的查询语句 首先，最好是在相同类型的字段间进行比较的操作。在MySQL3.23版之前，这甚至是一个必须的条件。例如不能将一个建有索引的INT字段和BIGINT字段进行比较；但是作为特殊的情况，在CHAR类型的字段和VARCHAR类型字段的字段大小相同的时候，可以将它们进行比较。 其次，在建有索引的字段上尽量不要使用函数进行操作。例如，在一个DATE类型的字段上使用YEAE()函数时，将会使索引不能发挥应有的作用。所以，下面的两个查询虽然返回的结果一样，但后者要比前者快得多。 第三，在搜索字符型字段时，我们有时会使用LIKE关键字和通配符，这种做法虽然简单，但却也是以牺牲系统性能为代价的(like ‘xxx%’可以用到索引，但是like ‘%xxx%’不行，通过覆盖索引进行优化)。 例如下面的查询将会比较表中的每一条记录。SELECT FROM books WHERE name like “MySQL%”但是如果换用下面的查询，返回的结果一样，但速度就要快上很多：SELECT FROM books WHERE name＞=”MySQL” and name＜”MySQM” 数据分页处理 客户端(应用程序或浏览器)分页：将数据从应用服务器全部下载到本地应用程序或浏览器，在应用程序或浏览器内部通过本地代码进行分页处理 优点：编码简单，减少客户端与应用服务器网络交互次数 缺点：首次交互时间长，占用客户端内存 适应场景：客户端与应用服务器网络延时较大，但要求后续操作流畅，如手机GPRS，超远程访问（跨国）等等。 应用服务器分页：将数据从数据库服务器全部下载到应用服务器，在应用服务器内部再进行数据筛选。以下是一个应用服务器端Java程序分页的示例： 123List list=executeQuery(“select * from employee order by id”);Int count= list.size();List subList= list.subList(10, 20); 优点：编码简单，只需要一次SQL交互，总数据与分页数据差不多时性能较好。 缺点：总数据量较多时性能较差。 适应场景：数据库系统不支持分页处理，数据量较小并且可控。 数据库SQL分页：采用数据库SQL分页需要两次SQL完成，一个SQL计算总数量，一个SQL返回分页后的数据 优点：性能好 缺点：编码复杂，各种数据库语法不同，需要两次SQL交互。 oracle数据库一般采用rownum来进行分页，常用分页语法有如下两种： 直接通过rownum分页：数据访问开销=索引IO+索引全部记录结果对应的表数据IO 12345select * from ( select a.*,rownum rn from (select * from product a where company_id=? order by status) a where rownum&lt;=20)where rn&gt;10; 采用rowid分页语法：优化原理是通过纯索引找出分页记录的ROWID，再通过ROWID回表返回数据，要求内层查询和排序字段全在索引里。(数据访问开销=索引IO+索引分页结果对应的表数据IO) 12345678create index myindex on product(company_id,status);select b.* from ( select * from ( select a.*,rownum rn from (select rowid rid,status from product a where company_id=? order by status) a where rownum&lt;=20) where rn&gt;10) a, product bwhere a.rid=b.rowid; 减少交互次数 batch DML：数据库访问框架一般都提供了批量提交的接口，jdbc支持batch的提交处理方法，当你一次性要往一个表中插入1000万条数据时，如果采用普通的executeUpdate处理，那么和服务器交互次数为1000万次，按每秒钟可以向数据库服务器提交10000次估算，要完成所有工作需要1000秒。如果采用批量提交模式，1000条提交一次，那么和服务器交互次数为1万次，交互次数大大减少。采用batch操作一般不会减少很多数据库服务器的物理IO，但是会大大减少客户端与服务端的交互次数，从而减少了多次发起的网络延时开销，同时也会降低数据库的CPU开销。 In List 12//我们也可以做一个小的优化， 如下所示，用ID IN LIST的这种方式写SQL：select * from mytable where id in(:id1,id2,...,idn); 通过这样处理可以大大减少SQL请求的数量，从而提高性能。那如果有10000个ID，那是不是全部放在一条SQL里处理呢？答案肯定是否定的。首先大部份数据库都会有SQL长度和IN里个数的限制，如ORACLE的IN里就不允许超过1000个值。 另外当前数据库一般都是采用基于成本的优化规则，当IN数量达到一定值时有可能改变SQL执行计划，从索引访问变成全表访问，这将使性能急剧变化。随着SQL中IN的里面的值个数增加，SQL的执行计划会更复杂，占用的内存将会变大，这将会增加服务器CPU及内存成本。 评估在IN里面一次放多少个值还需要考虑应用服务器本地内存的开销，有并发访问时要计算本地数据使用周期内的并发上限，否则可能会导致内存溢出。 综合考虑，一般IN里面的值个数超过20个以后性能基本没什么太大变化，也特别说明不要超过100，超过后可能会引起执行计划的不稳定性及增加数据库CPU及内存成本，这个需要专业DBA评估。 如果确实想使用IN而且里面数量较多时，这个情况有两种解决方式： 将in列表里面的数据放入一张中间小表，采用两个表Hash Join关联的方式处理； 采用str2varList方法将字段串列表转换一个临时表处理； 设置Fetch Size 当我们采用select从数据库查询数据时，数据默认并不是一条一条返回给客户端的，也不是一次全部返回客户端的，而是根据客户端fetch_size参数处理，每次只返回fetch_size条记录，当客户端游标遍历到尾部时再从服务端取数据，直到最后全部传送完成。所以如果我们要从服务端一次取大量数据时，可以加大fetch_size，这样可以减少结果数据传输的交互次数及服务器数据准备时间，提高性能。 123456789101112//以下是jdbc测试的代码，采用本地数据库，表缓存在数据库CACHE中，因此没有网络连接及磁盘IO开销，客户端只遍历游标，不做任何处理，这样更能体现fetch参数的影响：String vsql ="select * from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql,ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);pstmt.setFetchSize(1000);ResultSet rs = pstmt.executeQuery(vsql);int cnt = rs.getMetaData().getColumnCount();Object o;while (rs.next()) &#123; for (int i = 1; i &lt;= cnt; i++) &#123; o = rs.getObject(i); &#125;&#125; 测试可以看出fetchsize对性能影响还是比较大的，但是当fetchsize大于100时就基本上没有影响了。fetchsize并不会存在一个最优的固定值，因为整体性能与记录集大小及硬件平台有关。根据测试结果建议当一次性要取大量数据时这个值设置为100左右，不要小于40。注意，fetchsize不能设置太大，如果一次取出的数据大于JVM的内存会导致内存溢出，所以建议不要超过1000，太大了也没什么性能提高，反而可能会增加内存溢出的危险。 1234//iBatis的SqlMapping配置文件可以对每个SQL语句指定fetchsize大小，如下所示：&lt;select id="getAllProduct" resultMap="HashMap" fetchSize="1000"&gt; select * from employee&lt;/select&gt; 使用存储过程 大型数据库一般都支持存储过程，合理的利用存储过程也可以提高系统性能。如你有一个业务需要将A表的数据做一些加工然后更新到B表中，但是又不可能一条SQL完成，这时你需要如下3步操作： a：将A表数据全部取出到客户端； b：计算出要更新的数据； c：将计算结果更新到B表。 如果采用存储过程你可以将整个业务逻辑封装在存储过程里，然后在客户端直接调用存储过程处理，这样可以减少网络交互的成本。 当然，存储过程也并不是十全十美，存储过程有以下缺点： a、不可移植性，每种数据库的内部编程语法都不太相同，当你的系统需要兼容多种数据库时最好不要用存储过程。 b、学习成本高，DBA一般都擅长写存储过程，但并不是每个程序员都能写好存储过程，除非你的团队有较多的开发人员熟悉写存储过程，否则后期系统维护会产生问题。 c、业务逻辑多处存在，采用存储过程后也就意味着你的系统有一些业务逻辑不是在应用程序里处理，这种架构会增加一些系统维护和调试成本。 d、存储过程和常用应用程序语言不一样，它支持的函数及语法有可能不能满足需求，有些逻辑就只能通过应用程序处理。 e、如果存储过程中有复杂运算的话，会增加一些数据库服务端的处理成本，对于集中式数据库可能会导致系统可扩展性问题。 f、为了提高性能，数据库会把存储过程代码编译成中间运行代码(类似于java的class文件)，所以更像静态语言。当存储过程引用的对像(表、视图等等)结构改变后，存储过程需要重新编译才能生效，在24*7高并发应用场景，一般都是在线变更结构的，所以在变更的瞬间要同时编译存储过程，这可能会导致数据库瞬间压力上升引起故障(Oracle数据库就存在这样的问题)。 建议：普通业务逻辑尽量不要使用存储过程，定时性的ETL任务或报表统计函数可以根据团队资源情况采用存储过程处理。 使用ResultSet游标处理记录 现在大部分Java框架都是通过jdbc从数据库取出数据，然后装载到一个list里再处理，list里可能是业务Object，也可能是hashmap。由于JVM内存一般都小于4G，所以不可能一次通过sql把大量数据装载到list里。为了完成功能，很多程序员喜欢采用分页的方法处理，如一次从数据库取1000条记录，通过多次循环搞定，保证不会引起JVM Out of memory问题。以下是实现此功能的代码示例，t_employee表有10万条记录，设置分页大小为1000： 12345678910111213141516171819202122232425262728293031d1 = Calendar.getInstance().getTime();//第一次先取出数据总数String vsql = "select count(*) cnt from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql);ResultSet rs = pstmt.executeQuery();Integer cnt = 0;while (rs.next()) &#123; cnt = rs.getInt("cnt");&#125;//第二次分页取数据Integer lastid = 0;Integer pagesize = 1000;System.out.println("cnt:" + cnt);for (int i = 0; i &lt;= cnt / pagesize; i++) &#123; vsql = "select * from (select * from t_employee where id&gt;? order by id) where rownum&lt;=?"; pstmt = conn.prepareStatement(vsql); pstmt.setFetchSize(1000); pstmt.setInt(1, lastid); pstmt.setInt(2, pagesize); rs = pstmt.executeQuery(); int col_cnt = rs.getMetaData().getColumnCount(); Object o; while (rs.next()) &#123; for (int j = 1; j &lt;= col_cnt; j++) &#123; o = rs.getObject(j); &#125; lastid = rs.getInt("id"); &#125; rs.close(); pstmt.close();&#125; 以上代码实际执行时间为6.516秒 很多持久层框架为了尽量让程序员使用方便，封装了jdbc通过statement执行数据返回到resultset的细节，导致程序员会想采用分页的方式处理问题。实际上如果我们采用jdbc原始的resultset游标处理记录，在resultset循环读取的过程中处理记录，这样就可以一次从数据库取出所有记录。显著提高性能。 这里需要注意的是，采用resultset游标处理记录时，应该将游标的打开方式设置为FORWARD_READONLY模式(ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY)，否则会把结果缓存在JVM里，造成JVM Out of memory问题。 123456789101112//代码示例：String vsql ="select * from t_employee";PreparedStatement pstmt = conn.prepareStatement(vsql,ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);pstmt.setFetchSize(100);ResultSet rs = pstmt.executeQuery(vsql);int col_cnt = rs.getMetaData().getColumnCount();Object o;while (rs.next()) &#123; for (int j = 1; j &lt;= col_cnt; j++) &#123; o = rs.getObject(j); &#125;&#125; 调整后的代码实际执行时间为3.156秒 iBatis等持久层框架考虑到会有这种需求，所以也有相应的解决方案，在iBatis里我们不能采用queryForList的方法，而应用该采用queryWithRowHandler加回调事件的方式处理，如下所示：12345678MyRowHandler myrh=new MyRowHandler();sqlmap.queryWithRowHandler("getAllEmployee", myrh);class MyRowHandler implements RowHandler &#123; public void handleRow(Object o) &#123; //todo something &#125;&#125;//iBatis的queryWithRowHandler很好的封装了resultset遍历的事件处理，效果及性能与resultset遍历一样，也不会产生JVM内存溢出。 使用绑定变量 绑定变量是指SQL中对变化的值采用变量参数的形式提交，而不是在SQL中直接拼写对应的值。 非绑定变量写法：Select * from employee where id=1234567 绑定变量写法： Select * from employee where id=? Preparestatement.setInt(1,1234567) Java中Preparestatement就是为处理绑定变量提供的对像，绑定变量有以下优点： 防止SQL注入 提高SQL可读性 提高SQL解析性能，不使用绑定变更我们一般称为硬解析，使用绑定变量我们称为软解析。 数据库SQL执行原理 当一条SQL发送给数据库服务器后，系统首先会将SQL字符串进行hash运算，得到hash值后再从服务器内存里的SQL缓存区中进行检索，如果有相同的SQL字符，并且确认是同一逻辑的SQL语句，则从共享池缓存中取出SQL对应的执行计划，根据执行计划读取数据并返回结果给客户端。如果在共享池中未发现相同的SQL则根据SQL逻辑生成一条新的执行计划并保存在SQL缓存区中，然后根据执行计划读取数据并返回结果给客户端。 为了更快的检索SQL是否在缓存区中，首先进行的是SQL字符串hash值对比，如果未找到则认为没有缓存，如果存在再进行下一步的准确对比，所以要命中SQL缓存区应保证SQL字符是完全一致，中间有大小写或空格都会认为是不同的SQL。 如果我们不采用绑定变量，采用字符串拼接的模式生成SQL,那么每条SQL都会产生执行计划，这样会导致共享池耗尽，缓存命中率也很低。 ORACLE采用自下而上的顺序解析WHERE子句,根据这个原理,表之间的连接必须写在其他WHERE条件之前, 那些可以过滤掉最大数量记录的条件必须写在WHERE子句的末尾.]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Oracle</tag>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BitSet]]></title>
    <url>%2F2017%2F10%2F07%2FBitSet%2F</url>
    <content type="text"><![CDATA[BitSet BitSet：用来操作位的数据结构，可实现指定的位的值反转，设置，获取，清空等；经常用于海量数据中的去重，判重，判存，排序等操作当使用一位表示一个数字时，一个1G的空间，有 8102410241024=8.5810^9bit，也就是可以表示85亿个不同的数。 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161//内部使用long数组来保存位数据，一个long可以保存64位的信息，顺序方向为从低位到高位private long[] words;/** 根据指定位数初始化，构建合适大小的long数组* 通常我们求所需long数组大小的方法为：（nbits/64 + 1）* 但是除法效率远没有位运算高效，这里使用的方法为：（（nbits-1）&gt;&gt; 6）+ 1* 其实平时如果我们的除数正好是2的n次方的时候，均可以使用这种方法来提高效率*/public BitSet(int nbits) &#123; // nbits can&apos;t be negative; size 0 is OK if (nbits &lt; 0) throw new NegativeArraySizeException(&quot;nbits &lt; 0: &quot; + nbits); initWords(nbits); sizeIsSticky = true;&#125;private void initWords(int nbits) &#123; words = new long[wordIndex(nbits-1) + 1];&#125;private final static int ADDRESS_BITS_PER_WORD = 6;private static int wordIndex(int bitIndex) &#123; return bitIndex &gt;&gt; ADDRESS_BITS_PER_WORD;&#125;//bitset的逻辑大小，wordsInUse负责记录当前long数组的大小private transient int wordsInUse = 0;//设置指定位的值为truepublic void set(int bitIndex) &#123; if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); //先计算出指定位在long数组的第几个long中保存的 int wordIndex = wordIndex(bitIndex); //验证long数组是否需要扩容 expandTo(wordIndex); words[wordIndex] |= (1L &lt;&lt; bitIndex); // Restores invariants checkInvariants();&#125;//与当前long数组大小进行比较，判定是否需要扩容private void expandTo(int wordIndex) &#123; int wordsRequired = wordIndex+1; if (wordsInUse &lt; wordsRequired) &#123; ensureCapacity(wordsRequired); wordsInUse = wordsRequired; &#125;&#125;private void ensureCapacity(int wordsRequired) &#123; if (words.length &lt; wordsRequired) &#123; // 扩容后数组大小为：原数组大小翻倍后和所需数组大小的最大值 int request = Math.max(2 * words.length, wordsRequired); //拷贝源数据到新数组中 words = Arrays.copyOf(words, request); sizeIsSticky = false; &#125;&#125;//设置指定位为指定值public void set(int bitIndex, boolean value) &#123; if (value) set(bitIndex); else clear(bitIndex);&#125;private static final long WORD_MASK = 0xffffffffffffffffL;//设置指定区间位的值为truepublic void set(int fromIndex, int toIndex) &#123; checkRange(fromIndex, toIndex); if (fromIndex == toIndex) return; // 判定指定区间是否需要扩容 int startWordIndex = wordIndex(fromIndex); int endWordIndex = wordIndex(toIndex - 1); expandTo(endWordIndex); //WORD_MASK是个64位均为1的常量，用于向左向右位移一定区间位之后与long元素进行或操作实现将一定区间的位置为true long firstWordMask = WORD_MASK &lt;&lt; fromIndex; long lastWordMask = WORD_MASK &gt;&gt;&gt; -toIndex; if (startWordIndex == endWordIndex) &#123; // 其实区间位于同一个long元素上 words[startWordIndex] |= (firstWordMask &amp; lastWordMask); &#125; else &#123; // 其实区间位于不同的long元素上 // 处理第一个long元素上的值 words[startWordIndex] |= firstWordMask; // 处理位于中间的long元素上的值，直接置为1 for (int i = startWordIndex+1; i &lt; endWordIndex; i++) words[i] = WORD_MASK; // 处理最后一个long元素上的值 words[endWordIndex] |= lastWordMask; &#125; checkInvariants();&#125;//set方法默认将位置为true，clear方法默认将位置为false，原理过程基本一样，均是通过位操作完成，这里不再解释其代码//get方法获取指定位的值，其结果为布尔类型public boolean get(int bitIndex) &#123; if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); checkInvariants(); int wordIndex = wordIndex(bitIndex); //若是指定位没超出已有界限并且指定位为1，返回true，否返回false return (wordIndex &lt; wordsInUse)&amp;&amp; ((words[wordIndex] &amp; (1L &lt;&lt; bitIndex)) != 0);&#125;//获取指定区间的位，返回bitsetpublic BitSet get(int fromIndex, int toIndex) &#123;&#125;//返回指定位之后第一个值为true的位索引位置，若没有则返回-1private final static int ADDRESS_BITS_PER_WORD = 6;private final static int BITS_PER_WORD = 1 &lt;&lt; ADDRESS_BITS_PER_WORD;public int nextSetBit(int fromIndex) &#123; if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;fromIndex &lt; 0: &quot; + fromIndex); checkInvariants(); //指定位越界直接返回-1 int u = wordIndex(fromIndex); if (u &gt;= wordsInUse) return -1; //找到指定位所在的long，然后开始循环查找第一个不为0的位 long word = words[u] &amp; (WORD_MASK &lt;&lt; fromIndex); while (true) &#123; //先判定所在long的值是否为0，为0直接查找下一个long，若当前long越界，返回-1 if (word != 0) /** 若当前long不为空，计算该第一个不为0的位的位置索引：一个long64位，u乘以64再加上当前long从低位开始到第一个不为0的位之前的0的个数 * Long.numberOfTrailingZeros(word)：该方法用于计算一个long从低位开始到第一个不为0的位之前0的个数 */ return (u * BITS_PER_WORD) + Long.numberOfTrailingZeros(word); if (++u == wordsInUse) return -1; word = words[u]; &#125;&#125;//返回指定位之后第一个值为false的位索引位置，若没有则返回-1，实现过程与nextSetBit一样，相当于取反后执行nextSetBitpublic int nextClearBit(int fromIndex) &#123;&#125;//返回指定位之前距离最近的第一个值为true的位索引位置，若没有则返回-1，实现原理均与上面雷同public int previousSetBit(int fromIndex) &#123;&#125;//返回指定位之前距离最近的第一个值为false的位索引位置，若没有则返回-1，实现原理均与上面雷同public int previousClearBit(int fromIndex) &#123;&#125;//返回最高位的位置索引public int length() &#123; if (wordsInUse == 0) return 0; return BITS_PER_WORD * (wordsInUse - 1) + (BITS_PER_WORD - Long.numberOfLeadingZeros(words[wordsInUse - 1]));&#125;//不同于length方法，size方法返回当前long数组的容量public int size() &#123; return words.length * BITS_PER_WORD;&#125;//是否为空判定：不是取决于long数组大小，而是看逻辑大小，当前已使用的long个数wordsInUse变量值public boolean isEmpty() &#123; return wordsInUse == 0;&#125;//判定两个bitset是否有交集public boolean intersects(BitSet set) &#123; for (int i = Math.min(wordsInUse, set.wordsInUse) - 1; i &gt;= 0; i--) if ((words[i] &amp; set.words[i]) != 0) return true; return false;&#125;//返回位值为true的总个数，Long.bitCount()方法用于统计long中位为1的个数public int cardinality() &#123; int sum = 0; for (int i = 0; i &lt; wordsInUse; i++) sum += Long.bitCount(words[i]); return sum;&#125;//两个bitset进行与操作，同理还有或操作，异或操作等public void and(BitSet set) &#123;&#125;]]></content>
      <categories>
        <category>BitSet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>BitSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrency]]></title>
    <url>%2F2017%2F10%2F07%2FConcurrency%2F</url>
    <content type="text"><![CDATA[并发，多线程竞态：一个计算结果的正确性与时间有关的现象叫做竞态竞态产生的条件 read-modify-write（例如i++） check-then-act（if条件语句） 原子性 基础类型（除long/double之外）和引用类型变量的写操作都是原子的，long/double变量由于占64位，所以当32位的java虚拟机对这种变量的写操作会被分成两步，先写高位在写低位（或先写低位在写高位），这样就会出现一个线程写高位，而另一个线程写低位的情况，不具备原子性。 使用Lock实现原子性 利用处理器提供的CAS指令（硬件锁） 有序性 重排序：处理器可能不完全按照目标代码所制定的顺序执行指令（对内存访问读写操作的一种的优化，在不影响单线程程序正确性的情况下提高程序的性能），重排序不是必然出现的。 指令重排序（程序顺序与源代码顺序不一致，执行顺序与程序顺序不一致） java平台编译器有两种，静态（javac）和动态（JIT），前者将java源码编译为字节码class文件，后者将字节码动态编译为虚拟机宿主机的本地代码-机器码 例如 Person p = new Person(); 1. objRef = allocate(Person.class); 分配Pserson实例所需的内存空间，并获得一个指向该空间的引用 2. invokeConstrutor(objRef); 调用Person类的构造器初始化objRef引用指向的Person实例 3. p = objRef;3. 将Person实例引用赋值给实例变量p JIT编译器会将操作3排到操作2之前，即JIT编译器在初始化Person实例之前可能已经将该实例的引用写入p实例变量。 处理器的乱序执行，顺序提交：现代处理器为了提高执行效率，往往不是按照程序顺序逐一执行指令，而是动态调整指令的顺序，做到哪条指令准备就绪就先执行哪条，这就是处理器的乱序执行，这些指令执行的结果会先被写入重排序缓冲器（ROB），而不是直接写入寄存器或者内存，重排序缓冲器会将各个指令的执行结果按照相应的指令被读取的顺序提交，即写入到内存或者寄存器中，这就是处理器的顺序提交。也是因此处理器的指令重排序不会影响到单线程程序的正确性。 处理器的猜测执行：向执行if的语句体并将其结果保存在ROB中，然后在判定if的条件体是否成立，若成立，则将ROB中的结果写入到内存中，否则ROB丢弃其结果来实现语句体没有被执行过的效果。 存储子系统重排序（内存重排序）：是一种现象而不是一种动作，并没有真正的改变指令的执行顺序，其排序对象是内存操作的结果。 LoadLoad重排序：处理器的执行顺序为L1-&gt;L2，其他处理器的感知顺序为L2-&gt;L1 StoreStore重排序 LoadStore重排序 StoreLoad重排序 貌似串行语义：重排序并非是任意的，而是遵循一定的规则，从而给单线程造成一种假象（指令按照程序源码顺序执行），这种假象叫做貌似串行语义，其从单线程的角度保证了重排序后的运行结果不会影响到程序的正确性。为了保证串行语义，存在数据依赖，控制依赖的语句不会被重排序。 线程的活性故障 死锁：线程的生命周期状态永远处于非运行状态，相互等待对方 锁死：解锁条件永远得不到满足 活锁：处于运行状态却不执行任务，处于做无用功状态 饥饿：优先级低的线程一直得不到处理器资源 线程的两种创建方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public interface Runnable &#123; public abstract void run();&#125;public class Thread implements Runnable &#123; private static int threadInitNumber; private static synchronized int nextThreadNum() &#123; return threadInitNumber++; &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc) &#123; if (name == null) &#123; throw new NullPointerException("name cannot be null"); &#125; this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; /* Determine if it's an applet or not */ /* If there is a security manager, ask the security managerwhat to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security doesn't have a strong opinion of the matteruse the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; /* checkAccess regardless of whether or not threadgroup isexplicitly passed in. */ g.checkAccess(); //Do we have the required permissions? if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); &#125; //8个构造方法， public Thread(Runnable target) &#123; init(null, target, "Thread-" + nextThreadNum(), 0); &#125; Thread(Runnable target, AccessControlContext acc) &#123; init(null, target, "Thread-" + nextThreadNum(), 0, acc); &#125; public Thread(ThreadGroup group, Runnable target) &#123; init(group, target, "Thread-" + nextThreadNum(), 0); &#125; public Thread(String name) &#123; init(null, null, name, 0); &#125; public Thread(Runnable target, String name) &#123; init(null, target, name, 0); &#125; public Thread(ThreadGroup group, String name) &#123; init(group, null, name, 0); &#125; public Thread(ThreadGroup group, Runnable target, String name) &#123; init(group, target, name, 0); &#125; public Thread(ThreadGroup group, Runnable target, String name,long stackSize) &#123; init(group, target, name, stackSize); &#125; /*run()方法由java虚拟机直接调用，但是，java语言并不阻止我们直接调用，如果我们没有启动线程，而是在应用代码中直接调用线程run()方法，那么这个run()方法其实是运行在当前线程（run()方法的调用代码的执行线程）之中，而不是自身线程中，违背了线程创建的初衷，所以应该避免这样做*/ public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 继承Thread类 12345678public void MyThread extends Thread&#123; public void run()&#123;...&#125;&#125;public static void main(String [] args)&#123; MyThread t = new MyThread(); t.start();&#125; 实现Runnable接口 12345678public void MyThread implements Runnable&#123; public void run()&#123;...&#125;&#125;public static void main(String [] args)&#123; Thread t = new Thread(new MyThread()); t.start();&#125; 线程属于一次性用品，即我们不能通过出重新调用一个已经运行结束的线程的start()方法来使其重新运行，start()方法只能被调用一次，多次调用会导致抛出异常 i++三步走 取i的原值到寄存器r1（load(i,r1)） 执行i+1，即寄存器r1的值加1（increment(r1)） 将结果赋值给i，即将寄存器的值写回i对应的内存空间（store(i,r1)） system.out.println(i++)非线程安全 线程方法 currentThread() 返回代码段正在被那个线程调用 isLive() 判断当前才线程是否处于活跃状态（线程启动尚未终止，正在运行或者准备开始运行） sleep() 在指定的毫秒数内让当前正在执行的线程休眠（如果在sleep状态下停止某一线程，会进入catch语句，并且清除停止状态值，使之变成false）不会释放对象锁 geiId() stop()停止,suspend()暂停,resume()恢复 已作废方法 interrupt() 在当前线程中打一个停止符号，并未真正停止线程 this.interrupted() 测试当前线程（运行this.interrupted()方法的线程）是否中断，如果是中断（true），则会将其状态标识更改为false，再一次执行该方法时则返回非中断false this.Isinterrupted() 测试线程是否中断（不会清除状态标识） yield() 放弃当前CPU 资源，让给其它任务，放弃时间不确定，有其他任务则放弃，无则继续自身线程 setPriority() 设置优先级（1~10级，优先级具有继承性，优先级高的线程大部分先执行完，(并不代表一定全部先执行完)，CPU只是尽量将执行资源让给优先级高的线程，同时，代码的执行顺序与线程的优先级无关） setDaemon(true为守护进程)，必须发生在start()调用之前 守护进程/用户进程线程的生命周期状态1234567891011//最好通过抛异常来停止线程public void run()&#123; try()&#123; for()&#123; if(this.interrupted())&#123; //return；不建议 threw new InterruptedException(); &#125; &#125; &#125;catch(InterruptedException e)&#123;&#125;&#125; 内部锁（非公平锁）——synchronized（同步）/asynchronized（异步） 关键字synchronized取得是对象锁，而不是一段代码或者方法的锁 A线程持有O对象的Lock锁，B线程可以以异步的方式调用O对象中的非synchronized方法，对于synchronized方法则需要同步等待 脏读：在读取实例变量时，该值已被其他线程修改 synchronized锁 重入，即自己可以再次获取自己的内部锁，synchronized方法内部可以调用本类的其他synchronized方法 出现异常，锁自动释放 同步不具有继承性，子类中重写的方法还得加关键字synchronized实现同步 synchronized（this）{}同步代码块，与synchronized方法类似，锁定整个对象 任意对象的对象监视器synchronized（Object，非this对象），只有在保证同一对象的前提下才能保证同步 synchronized关键字加到static静态方法上是给class类上锁（对类的所有实例对象起作用，与synchronized（xxx.class）效果一样），加到非static方法上是给对象上锁 String常量池缓存带来的麻烦 采用同步代码块synchronized（Object1）和synchronized（Object2）来避免同步带来的死循环无线等待 可见性 程序中的变量可能会被分配到寄存器中，而不是主内存中。每个处理器都有其寄存器，而一个处理器无法读取另一个处理器上的寄存器中的内容。处理器对主内存的访问也不是直接访问，而是通过高速缓存子系统进行的。一个处理器上运行的线程对变量的更新可能只是更新到该处理器的写缓冲器中，还没有到达该处理器的高速缓存中，更不用说到主内存中了。而一个写缓冲器中的内容无法被另一个处理器读取。 处理器不是直接与主内存(RAM)打交道而执行内存的读写操作，而是通过寄存器，高速缓存，写缓冲器，和无效队列等部件执行内存的读写操作。 缓存同步：一个处理器不能直接从另一个处理器的高度缓存中读取数据，但是可以通过缓存一致协议来读取处理器高速缓存中的数据，这种方式叫做缓存同步。冲刷处理器缓存：是一个处理器对共享变量的更新最终被写入处理器的高速缓存或主内存中，而不是停留在写缓冲器中。 刷新处理器缓存：一个处理器在读取共享变量时，如果其他处理器在此之前更新了该变量，该处理器必须从其他处理器高速缓存或主内存中对相应的变量进行缓存同步。 写入一个volatile关键字修饰的变量，会使得相应的处理器执行冲刷处理器缓存的动作。 可见性的保证是通过写线程冲刷处理器缓存和读线程刷新处理器缓存这两个动作实现的，java平台中，锁的获得隐含着刷新处理器缓存这个动作，这使得读线程在执行临界区代码前可以将写线程对共享变量的更新同步到该线程执行处理器的高速缓存中，而锁的释放隐含着冲刷处理器缓存的动作，这使得写线程对共享变量的更新能够被推送到该执线程执行处理器的高速缓存中，从而对读线程可以同步。 volatile关键字——使变量在多个线程间可见 解决同步/异步死循环，强制从公共堆栈中获取变量的值，而不是从线程私有数据栈中取得变量值 只能修饰变量 不支持原子性（例如i++） 多线程访问不会发生阻塞 synchronized关键字解决的是多个线程间的访问资源的同步性（同步公共堆栈中变量的值与线程私有数据栈中变量值），而volatile关键字解决的是多个线程间的可见性问题 线程间通信 等待/通知机制 使用sleep()结合whlie(true)死循环实现多个线程间通信 ？？？ 123456789//通过抛异常来停止线程public void run()&#123; try()&#123; while(true)&#123; if(条件成立) threw new InterruptedException(); &#125; &#125;catch(InterruptedException e)&#123;&#125;&#125; wait/notify机制，wait()方法和notify()方法都是Object类的方法，无论是wait还是notify，在执行调用之前都必须获得该对象的对象锁（即只能在同步方法或代码块中调用），wait调用发生后，当前线程自动释放锁进入等待队列，notify调用后（当前线程不会马上释放对象锁，要等程序执行完，即退出synchronized代码块后才会释放对象锁），线程规划器随机挑选一个等待同一资源的呈wait状态的线程（即等待队列），对其发出notify通知，并使其获得该资源的对象锁 wait(long) 等待一段时间是否有线程对锁进行唤醒，超过此时间没有，则自动唤醒 生产者/消费者模式 管道通信，字节流（PipeInputStream，PipeOutStream），字符流（PipeReader，PipeWriter） join()方法——等待线程对象销毁（例如线程A需要用到线程B的结果，则要用到join，A阻塞等到B结束之后才能继续执行，类似于使线程排队） join(long)等待一定时间后自动继续执行（内部使用wait(long)来实现，所以具有释放锁的特点） ThreadLocal——解决的是变量在不同线程间的隔离性，也就是不同线程拥有自己的值，不同的线程中的值可以放入T和readLocal类中进行保存 InheritableThreadLocal类可以使得子线程获取父线程继承下来的值 显示锁（公平/非公平锁）——Lock ReentrantLock类 12345678public void display()&#123; private Lock lock = new ReentrantLock(); //lock()方法获取锁 lock.lock(); ... //unlock()方法释放锁 lock.unlock();&#125; Condition实现等待/通知，一个Lock对象中可以创建多个Conditoin实例（对象监视器），从而实现选择性通知 123456789101112public void display()&#123; private Lock lock = new ReentrantLock(); Conditoin condition1 = lock.newCondition(); //Conditoin condition2 = lock.newCondition(); lock.lock(); condition.await();//等价于Object的wait()方法 //condition.await(long);//等价于Object的wait(long)方法 ... condition.signal();//等价于Object的notify()方法 //condition.signalAll();//等价于Object的notifyAll()方法 lock.unlock();&#125; 公平锁（按照加锁顺序，先来先得），非公平锁（抢占机制，随机分配） getHoldCount() 查询当前线程保持此锁定的个数，也就是调用lock()方法的次数 getQueueLength() 返回正等待获取此锁定的线程估计数 getWaitQueueLength(Condition condition)返回正等待与此锁定相关给定条件Condition的线程估计数 hasQueuedThread(Thread thread) 查询指定线程是否正在等待获取此锁定 hasQueuedThreads() 查询是否有线程正在等待获取此锁定 hasWaiters(Condition condition) 查询是否有线程正在等待获取此锁定有关的condition条件 isFair() 判定是否为公平锁 IsHeldByCurrentThread() 查询当前线程是是否保持此锁定 isLocked() 查询此锁定是否由任意线程保持 tryLock()：尝试申请相应Lock实例锁表示的锁，如果该锁未被其他任何线程所持有，则获得该锁，并返回true，否则什么操作都不做，只是返回false； 123Lock lock = ...if(lock.tryLock())&#123;...&#125;else&#123;...&#125; 使用Condition实现顺序执行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; ... int next = 1; private Lock lock = new ReentrantLock(); Conditoin condition1 = lock.newCondition(); Conditoin condition2 = lock.newCondition(); Conditoin condition3 = lock.newCondition(); Thread thread1 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=1)&#123;condition1.await();&#125; System.out.println(1); next = 2; condition2.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; Thread thread2 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=2)&#123;condition2.await();&#125; System.out.println(2); next = 3; condition3.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; Thread thread3 = new Thread()&#123; public void run()&#123; try&#123; lock.lock(); while(next!=3)&#123;condition3.await();&#125; System.out.println(3); next = 1; condition1.signalAll(); &#125;catch(InterruptedException e)&#123;&#125; finally&#123;lock.unlock();&#125; &#125; &#125;; ...&#125; ReentrantReadWriteLock类-读写锁 读读共享 写写互斥 读写互斥 写读互斥123456private Lock lock = new ReentrantLock();lock.readLock().lock();lock.writeLock().lock();...lock.writeLock().unlock();lock.readLock().unlock();]]></content>
      <categories>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥Set源码]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%88%9D%E7%AA%A5Set%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[SetHashSet（HashMap的HashMap版本）LinkedHashSet（LinkedHashMap的LinkedHashMap版本）TreeSet（TreeMap的TreeMap版本） 123456789101112131415public class HashSet&lt;E&gt;extends AbstractSet&lt;E&gt;implements Set&lt;E&gt;, Cloneable, java.io.Serializable&#123; static final long serialVersionUID = -5024744406713321676L; private transient HashMap&lt;E,Object&gt; map; private static final Object PRESENT = new Object(); //构造方法，直接调用HashMap的构造方法生成entry&lt;E,Object&gt; //类似的所有其他构造方法均直接调用HashMap的构造方法生成 public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125;]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Source_Code</tag>
        <tag>Set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥Map源码]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%88%9D%E7%AA%A5Map%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[MapHashMap Java7实现原理（数组+链表） Java8实现原理（数组+链表+红黑树） 存，取，扩容（数组翻倍，链转树） 负载因子为何为0.75 modCount在hashmap线程安全中的作用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; //默认容量 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认负载因子为0.75，使性能在空间和时间上达到了平衡，只有当表到达3/4满时才会进行再散列，增大负载因子可以降低所需空间，但会增加查找时间 static final float DEFAULT_LOAD_FACTOR = 0.75f; //当链表长度超过8时转换为红黑树 static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; //内部节点类，实现了map接口内的entry接口，所以hashmap中的每一个键值对都是一个Entry&lt;K,V&gt; static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;&#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; ... &#125; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; //构造方法，自定义容量和负载因子 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; //构造方法，自定义容量和默认负载因子 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //构造方法，默认负容量和默认负载因子 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125; public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; //通过key值获取value值 final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; /*判断table数组是否为空，数组长度是否为零，判断所给hash值对应的数组下标中的元素是否为空。它通过 h &amp; (table.length -1) 来得到该对象的保存位，即table数组的下标，而HashMap底层数组的长度总是 2 的 n 次方，这是HashMap在速度上的优化（保证初始化时HashMap的容量总是2的n次方，即底层数组的长度总是为2的n次方）。当length总是 2 的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。*/ if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;(first = tab[(n - 1) &amp; hash]) != null) &#123; //验证数组tab[(n - 1) &amp; hash]中存的第一个节点是否为所需节点，是则返回 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //验证数组table中所存的节点类型是否为红黑树，是则按照红黑树的方式继续查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); /*调用红黑树的查找方法find final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; */ //如果节点类型为链表，则按照链表的方式进行查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; public boolean containsKey(Object key) &#123;return getNode(hash(key), key) != null;&#125; public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //table数组为空或长度为零，重新调整数组大小 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //hash值对应的数组下标的位置为空，则直接构造节点插入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果hash值对应的数组下标的位置中的元素与插入元素相同 if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果hash值对应的数组下标的位置中的元素类型为红黑树，则按照红黑树方式插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果hash值对应的数组下标的位置中的元素类型为链表，则按照链表方式插入 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表插入元素后要检验链表大小是否大于8，实则需将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; /*我们知道java.util.HashMap不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。*/ ++modCount; /*threshold就是在此loadFactor和capacity对应下允许的最大元素数目，超过这个数目就重新resize，以降低实际的负载因子，即扩容 */ if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; //直接将table数组大小至为0并将数组元素均至为空，然后交由GC回收 public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; //entrySet遍历 public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; LinkedHashMap(extends HashMap)继承自HashMap，但是比HashMap多了一组双向链表来维持插入顺序，或者是最近最少使用的次序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class LinkedHashMap&lt;K,V&gt;extends HashMap&lt;K,V&gt;implements Map&lt;K,V&gt;&#123; //节点移除后，双向链表删除该节点 void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b; &#125; //节点插入后， void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125; &#125; //节点访问后，移动节点到链表最后 void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p =(LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125; &#125; public void clear() &#123; super.clear(); //双向链表首尾指针至空 head = tail = null; &#125; TreeMap基于红黑树，由Comparable或Comparator排序而成]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Map</tag>
        <tag>Source_Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥List源码]]></title>
    <url>%2F2017%2F09%2F23%2F%E5%88%9D%E7%AA%A5List%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[ListArrayList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; //Default initial capacity（初始容量为10） private static final int DEFAULT_CAPACITY = 10; //Shared empty array instance used for empty instances. private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //Shared empty array instance used for default sized empty instances. private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; transient Object[] elementData; // non-private to simplify nested class access private int size; //Constructs an empty list with the specified initial capacity. //带有容量参数的构造方法 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; //Constructs an empty list with an initial capacity of ten. //不含参的构造方法，默认初始化大小为10 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; //Constructs a list containing the elements of the specifiedcollection //含参构造方法 public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; //Increases the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance, ifnecessary, to ensure that it can hold at least the number of elementsspecified by the minimum capacity argument. public void ensureCapacity(int minCapacity) &#123; &#125; private void ensureCapacityInternal(int minCapacity) &#123;&#125; private void ensureExplicitCapacity(int minCapacity) &#123; &#125; //The maximum size of array to allocate.数组分配最大值 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //Increases the capacity to ensure that it can hold at least thenumber of elements specified by the minimum capacity argument. private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //最大容量 private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; //数组大小 public int size() &#123;return size;&#125; //判空 public boolean isEmpty() &#123; return size == 0;&#125; //判包含 public boolean contains(Object o) &#123;return indexOf(o) &gt;= 0; &#125; //获取元素下标 public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; //获取最后一次出现的下标 public int lastIndexOf(Object o) &#123; if (o == null) &#123; //倒序循环 for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; //转换成对象数组 public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; //转换成具体类型数组 @SuppressWarnings("unchecked") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; //根据下标获取元素值 public E get(int index) &#123; //边界检查 rangeCheck(index); return elementData(index); &#125; //设置元素值（返回旧值） public E set(int index, E element) &#123; rangeCheck(index); //保留旧值 E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; //添加元素 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; //添加元素到指定位置 public void add(int index, E element) &#123; //检查范围 rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // //数组移动，index之后的元素整体后移一位 System.arraycopy(elementData, index, elementData, index + 1,size - index); elementData[index] = element; size++; &#125; //根据下标移除指定元素，并返回该元素的值 public E remove(int index) &#123; //检查范围 rangeCheck(index); modCount++; E oldValue = elementData(index); //计算需要移动的元素个数 int numMoved = size - index - 1; if (numMoved &gt; 0)&#123; //数组移动 System.arraycopy(elementData, index+1, elementData, index,numMoved); &#125; elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; //移除指定元素 public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; //服务于public boolean remove(Object o) 方法 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index,numMoved); elementData[--size] = null; // clear to let GC do its work &#125;//清空ArrayList，将数组元素全都至为空，数组大小设置为0，然后让GC来回收内存空间 public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; //将一个容器中的元素全部添加到list后 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; //将一个容器中的元素全部插入到list中 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index +numNew,numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; //删除置顶区间的元素 protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex,numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); //数组前移后剩下的位置的值至为空，让GC回收该空间 for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; //数组上边界检查 private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; //添加元素前的数组上下边界检查 private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; public boolean removeAll(Collection&lt;?&gt; c) &#123; //判空 Objects.requireNonNull(c); return batchRemove(c, false); &#125; /*判空requireNonNull()方法源码如下 public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj; &#125; */ public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; &#125; finally &#123; if (r != size) &#123; System.arraycopy(elementData, r,elementData, w,size - r); w += size - r; &#125; if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified; &#125; //元素迭代遍历 public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException("Index: "+index); return new ListItr(index); &#125; public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; //内部类 private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123;&#125; public E next() &#123;&#125; public void remove() &#123;&#125; public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; //内部类 private class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; super(); cursor = index; &#125; public boolean hasPrevious() &#123;&#125; public int nextIndex() &#123;&#125; public int previousIndex() &#123;&#125; public E previous() &#123;&#125; public void set(E e) &#123;&#125; public void add(E e) &#123;&#125; &#125; //返回子数组 public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; //边界检查 subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); &#125; //内部类返回子数组 private class SubList extends AbstractList&lt;E&gt; implements RandomAccess &#123; private final AbstractList&lt;E&gt; parent; private final int parentOffset; private final int offset; int size; SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) &#123; this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount; &#125; public E set(int index, E e) &#123;&#125; public E get(int index) &#123;&#125; public int size() &#123;&#125; public void add(int index, E e) &#123;&#125; public E remove(int index) &#123;&#125; protected void removeRange(int fromIndex, int toIndex) &#123;&#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; public Iterator&lt;E&gt; iterator() &#123; return listIterator(); &#125; public ListIterator&lt;E&gt; listIterator(final int index) &#123; checkForComodification(); rangeCheckForAdd(index); final int offset = this.offset; //匿名内部类 return new ListIterator&lt;E&gt;() &#123; int cursor = index; int lastRet = -1; int expectedModCount = ArrayList.this.modCount; public boolean hasNext() &#123;&#125; public E next() &#123;&#125; public boolean hasPrevious() &#123;&#125; public E previous() &#123;&#125; public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123;&#125; public int nextIndex() &#123;&#125; public int previousIndex() &#123;&#125; public void remove() &#123;&#125; public void set(E e) &#123;&#125; public void add(E e) &#123;&#125; final void checkForComodification() &#123;&#125; &#125;; &#125; &#125; //遍历 public void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings("unchecked") final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123; action.accept(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; LinkedList123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412public class LinkedList&lt;E&gt;extends AbstractSequentialList&lt;E&gt;implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializabl&#123; transient int size = 0; transient Node&lt;E&gt; first;//链首 transient Node&lt;E&gt; last;//链尾 public LinkedList() &#123;&#125; public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; //链首插入元素 private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; &#125; //链尾插入元素 void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; public void addFirst(E e) &#123;linkFirst(e);&#125; public void addLast(E e) &#123;linkLast(e);&#125; public boolean add(E e) &#123;linkLast(e);return true;&#125; //节点前插入 void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; &#125; //去链首 private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; //去链尾 private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125; //移除链首元素 public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; //移除链尾元素 public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125; //去节点 E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; //获取链首元素 public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125; //获取链尾元素 public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125; //判包含 public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; public int size() &#123;return size; &#125; //移除元素o public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123;return addAll(size, c);&#125; public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;//转成数组循环添加&#125; public void clear() &#123;//循环至空，包括值，前指针，后指针 &#125; public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; public E set(int index, E element) &#123;&#125; public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); &#125; public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index)); &#125; private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size; &#125; private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size; &#125; private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; //收尾两个指针目的就是加快查找目标元素 Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; public int lastIndexOf(Object o) &#123;&#125; //队列操作，返回队首元素 public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; public E element() &#123; return getFirst(); &#125; //队列操作，去除队首元素 public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; public E remove() &#123; return removeFirst(); &#125; //队列操作，队尾入队列 public boolean offer(E e) &#123; return add(e); &#125; // 队列操作，队头入队列（双向链表） public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; public boolean offerLast(E e) &#123; addLast(e); return true; &#125; public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; public void push(E e) &#123; addFirst(e); &#125; public E pop() &#123; return removeFirst(); &#125; public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; public boolean removeLastOccurrence(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index); &#125; //迭代遍历内部类 private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; //节点内部类，双向链表 private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; public Iterator&lt;E&gt; descendingIterator() &#123; return new DescendingIterator(); &#125; //反向迭代遍历内部类 private class DescendingIterator implements Iterator&lt;E&gt; &#123; private final ListItr itr = new ListItr(size()); public boolean hasNext() &#123; return itr.hasPrevious(); &#125; public E next() &#123; return itr.previous(); &#125; public void remove() &#123; itr.remove(); &#125; &#125; public Object[] toArray() &#123;&#125; public &lt;T&gt; T[] toArray(T[] a) &#123;&#125;&#125;]]></content>
      <categories>
        <category>Source_Code</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Source_Code</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反射机制]]></title>
    <url>%2F2017%2F09%2F16%2FReflection%2F</url>
    <content type="text"><![CDATA[参考自百度百科-反射机制 反射机制 JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 Java反射机制主要提供了以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法； 在运行时调用任意一个对象的方法； 生成动态代理。 ClassObject 类作为所有Java 类的继承根源，其内声明了12个方法： public Object() public final Class&lt;?&gt; getClass() public final void notify() public final void notifyAll() public final void wait(long timeout)throws InterruptedException public final void wait(long timeout,int nanos)throws InterruptedException public final void wait() throws InterruptedException public int hashCode() public boolean equals(Object obj) protected Object clone()throws CloneNotSupportedException public String toString() protected void finalize()throws Throwable 其中getClass()返回一个Class 对象。Class 类十分特殊。它和一般类一样继承自Object，其实体用以表达Java程序运行时的classes和interfaces，也用来表达enum、array、primitive Java types（boolean, byte, char, short, int, long, float, double）以及关键词void。当一个class被加载，或当加载器（class loader）的defineClass()被JVM调用，JVM 便自动产生一个Class 对象。如果您想借由“修改Java标准库源码”来观察Class 对象的实际生成时机（例如在Class的constructor内添加一个println()），这样是行不通的！因为Class并没有public constructor。Class是Reflection故事起源。针对任何您想探勘的类，唯有先为它产生一个Class 对象，接下来才能经由后者唤起为数十多个的Reflection APIs。这些APIs将在稍后的探险活动中一一亮相。12345678910public final class Class&lt;T&gt; implements Serializable, java.lang.reflect.GenericDeclaration, java.lang.reflect.Type, java.lang.reflect.AnnotatedElement &#123; //私有构造方法 private Class() &#123;&#125; public String toString() &#123; return ( isInterface() ? &quot;interface &quot; : (isPrimitive() ? &quot;&quot; : &quot;class &quot;)) + getName();&#125; Class object 诞生管道 运用getClass() Class c1 = str.getClass(); 运用Class.getSuperclass() Class c2 = c1.getSuperclass(); 运用static method——Class.forName()（最常被使用） Class c1 = Class.forName (“java.lang.String”); 运用primitive wrapper classes的TYPE 语法1234567Class c1 = Boolean.TYPEClass c3 = Character.TYPE;Class c5 = Integer.TYPE;Class c6 = Long.TYPE;Class c7 = Float.TYPE;Class c8 = Double.TYPE;Class c9 = Void.TYPE; Reflection 的三个动态性质： 运行时生成instances public Constructor getDeclaredConstructor(Class&lt;?&gt;… parameterTypes)（同下） public Constructor&lt;?&gt;[] getDeclaredConstructors() public Constructor getConstructor(Class&lt;?&gt;… parameterTypes) public Constructor&lt;?&gt;[] getConstructors()12345678910111213//无参构造函数Class&lt;?&gt; c = Class.forName(&quot;DynTest&quot;);Object obj = null;obj = c.newInstance(); //有参构造函数， 需要获取响应的构造方法Class&lt;?&gt; c = Class.forName(&quot;DynTest&quot;);Class&lt;?&gt;[] pTypes = new Class&lt;?&gt;[] &#123; double.class, int.class &#125;;Constructor&lt;?&gt; ctor = c.getConstructor(pTypes);//Constructor&lt;?&gt; ctor = c.getConstructor(double.class, int.class);Object obj = null;Object[] arg = new Object[] &#123;3.14159, 125&#125;; obj = ctor.newInstance(arg);//obj = ctor.newInstance(3.14159, 125); 执行期唤起methods 索取Method object时不需指定回返类型，因为method overloading机制要求signature（署名式）必须唯一，而回返类型并非signature的一个成份。换句话说，只要指定了method名称和参数列，就一定指出了一个独一无二的method。 public Method getDeclaredMethod(String name,Class&lt;?&gt;… parameterTypes)throws NoSuchMethodException,SecurityException（返回一个Method对象，该对象反映了由此Class对象表示的类或接口的指定已声明方法） public Method getMethod(String name,Class&lt;?&gt;… parameterTypes)throws NoSuchMethodException,SecurityException（返回一个Method对象，该对象反映此Class对象所表示的类或接口的指定公共成员方法） public Method[] getDeclaredMethods()throws SecurityException（返回一个包含Method对象的数组，该对象反映了由此Class对象表示的类或接口的所有已声明方法，包括public，protected，default（package）访问和private方法，但不包括继承方法。） public Method[] getMethods()throws SecurityException（返回一个包含Method对象的数组，该对象反映了由此Class对象表示的类或接口的所有公共方法，包括由类或接口声明的那些以及从超类和超接口继承的那些方法。）123456789101112131415161718public String func(String s, Hashtable ht)&#123; System.out.println(&quot;func invoked&quot;); return s;&#125;public static void main(String args[])&#123; Class c = Class.forName(&quot;Test&quot;); Class ptypes[] = new Class[2]; ptypes[0] = Class.forName(&quot;java.lang.String&quot;); ptypes[1] = Class.forName(&quot;java.util.Hashtable&quot;); //获取指定方法 Method m = c.getMethod(&quot;func&quot;,ptypes); Test obj = new Test(); //Test obj = (Test)c.newInstance(); Object arg[] = new Object[2]; arg[0] = new String(&quot;Hello,world&quot;); arg[1] = null; String r = (String)m.invoke(obj, arg);&#125; 运行时改动fields。 public Field getField(String name)（同上） public Field[] getFields() public Field getDeclaredField(String name) public Field[] getDeclaredFields() 1234567891011public class Test &#123; public double d; public static void main(String args[])&#123; Class c = Class.forName(&quot;Test&quot;); Field f = c.getField(&quot;d&quot;); //指定field 名称 Test obj = new Test(); System.out.println(&quot;d= &quot; + (Double)f.get(obj)); f.set(obj, 12.34); System.out.println(&quot;d= &quot; + obj.d); &#125;&#125; 12345678910111213141516171819202122232425//实际应用样例Class cname=null;Object theInst = null;try &#123; cname = Class.forName (className); 由字符串找到相应的类 theInst=(Object)cname.newInstance(); 实例化初始类&#125;catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; Method[] methodes = cname.getDeclaredMethods(); 获取类中所有的方法for (int i = 0; i &lt; methodes.length; i++)&#123; Method method = methodes[i]; if (method.getName().equals(methodName)) 查找并判定与既定方法相同的方法 &#123; Object result=null; try&#123; System.out.println(method.getName()); result = method.invoke(theInst, arg);执行相应的方法(agr为方法所需要的参数，不止一个可能) &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Reflection</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字节序]]></title>
    <url>%2F2017%2F09%2F09%2F%E5%AD%97%E8%8A%82%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[字节序 顾名思义，字节顺序，又称端序或尾序。在计算机科学领域中，是跨越多字节的程序对象的存储规则。 在几乎所有的机器上，多字节对象都被存储为连续的字节序列。例如在C语言中，一个类型为int的变量x地址为0x100，那么其对应地址表达式&amp;x的值为0x100。且x的四个字节将被存储在存储器的0x100, 0x101, 0x102, 0x103位置。而存储地址内的排列则有两个通用规则。一个多位的整数将按照其存储地址的最低或最高字节排列。如果最低有效位在最高有效位的前面，则称小端序；反之则称大端序。在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以均按照网络标准转化。例如假设上述变量x类型为int，位于地址0x100处，它的十六进制为0x01234567，地址范围为0x100~0x103字节，其内部排列顺序依赖于机器的类型。大端法从首位开始将是：0x100: 01, 0x101: 23,..。而小端法将是：0x100: 67, 0x101: 45,..。大端模式和小端模式的起源 关于大端小端名词的由来，有一个有趣的故事，来自于Jonathan Swift的《格利佛游记》：Lilliput和Blefuscu这两个强国在过去的36个月中一直在苦战。战争的原因：大家都知道，吃鸡蛋的时候，原始的方法是打破鸡蛋较大的一端，可以那时的皇帝的祖父由于小时侯吃鸡蛋，按这种方法把手指弄破了，因此他的父亲，就下令，命令所有的子民吃鸡蛋的时候，必须先打破鸡蛋较小的一端，违令者重罚。然后老百姓对此法令极为反感，期间发生了多次叛乱，其中一个皇帝因此送命，另一个丢了王位，产生叛乱的原因就是另一个国家Blefuscu的国王大臣煽动起来的，叛乱平息后，就逃到这个帝国避难。据估计，先后几次有11000余人情愿死也不肯去打破鸡蛋较小的端吃鸡蛋。这个其实讽刺当时英国和法国之间持续的冲突。Danny Cohen一位网络协议的开创者，第一次使用这两个术语指代字节顺序，后来就被大家广泛接受。 ##什么是大端和小端 小端就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 大端就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。 比如数字0x12 34 56 78在内存中的表示形式为： 大端模式：(低地址 -&gt; 高地址)0x12 | 0x34 | 0x56 | 0x78 小端模式：(低地址 -&gt; 高地址)0x78 | 0x56 | 0x34 | 0x12 可见，大端模式和字符串的存储模式类似。 大端小端没有谁优谁劣，各自优势便是对方劣势： 小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。 大端模式 ：符号位的判定固定为第一个字节，容易判断正负。 为什么会有大小端模式之分呢？ 这是因为在计算机系统中，我们是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8bit。但是在C语言中除了8bit的char之外，还有16bit的short型，32bit的long型（要看具体的编译器），另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着一个如果将多个字节安排的问题。因此就导致了大端存储模式和小端存储模式。例如一个16bit的short型x，在内存中的地址为0x0010，x的值为0x1122，那么0x11为高字节，0x22为低字节。对于大端模式，就将0x11放在低地址中，即0x0010中，0x22放在高地址中，即0x0011中。小端模式，刚好相反。我们常用的X86结构是小端模式，而KEIL C51则为大端模式。很多的ARM，DSP都为小端模式。有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。 如何判断机器的字节序12345678910111213141516171819202122232425BOOL IsBigEndian() &#123; int a = 0x1234; char b = *(char *)&amp;a; //通过将int强制类型转换成char单字节，通过判断起始存储位置。即等于 取b等于a的低地址部分 if( b == 0x12) &#123; return TRUE; &#125; return FALSE; &#125;//联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写：BOOL IsBigEndian() &#123; union NUM &#123; int a; char b; &#125;num; num.a = 0x1234; if( num.b == 0x12 ) &#123; return TRUE; &#125; return FALSE; &#125;]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java创建对象]]></title>
    <url>%2F2017%2F09%2F02%2FJava%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[创建对象的四种方式 new语句 Object.clone()方法 序列化、反序列化 反射手段,调用java.lang.Class 或者 java.lang.reflect.Constructor 类的newInstance()实例方法 new语句调用类的构造方法创建对象person p = new person(8); Object.clone()方法### API中定义为protected Object clone() throws CloneNotSupportedException{}，即意味着该方法只对其子类可见！ 与此同时API还强调Throws:CloneNotSupportedException - if the object’s class does not support the Cloneable interface. Subclasses that override the clone method can also throw this exception to indicate that an instance cannot be cloned.即意味着想要实现复制克隆的类必须实现cloneable接口,而该接口中并无任何方法，其作用可以看做是一个标识！ 浅复制，如需实现深拷贝，则需重新实现clone（）；实例1234567891011121314151617public class Person implements Cloneable&#123; public int number; person(int number)&#123; this.number = number; &#125; public person getInstance() throws CloneNotSupportedException&#123; return (Person) this.clone(); &#125;&#125;public class Test &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Person p = new Person(8); Person temp = p.getInstance(); System.out.println(temp.number); &#125;&#125; 序列化、反序列化ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;Person.java&quot;)); Person p = (Person) in.readObject(); 反射手段,调用java.lang.Class 或者 java.lang.reflect.Constructor 类的newInstance()实例方法 调用java.lang.Class类的newInstance()实例方法 //第一种方式 Person p = (Person) Class.forName(“other.Person”).newInstance(); //第二种方式 Person p1 = Person.class.newInstance(); 调用java.lang.reflect.Constructor 类的newInstance()实例方法 Constructor c = Person.class.getConstructor(); Person p = c.newInstance();]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Visitor Pattern]]></title>
    <url>%2F2017%2F08%2F26%2FVisitorPattern%2F</url>
    <content type="text"><![CDATA[Visitor Pattern（访问者模式）Represent an operation to be performed on the elements of an object structure.Visitor lets you define a new operation without changing the classes of the elements on which it operates.（封装一些作用于某种数据结构中的各种元素，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。） 抽象元素（Element）：一个抽象类，定义了接受访问者的accept方法 具体元素（ConcreteElement）：Element的子类 抽象访问者(Visitor)：一个接口，定义了操作具体元素的方法 具体访问者(ConcreteVisitor)：抽象访问者接口的实现类 应用场景：双重分派（数据的存储和操作解耦）,不同的访问者访问同一元素，进行的操作不同，结果也不同，但访问这一动作共同的，只是传入的对象不同，导致操作/结果不同 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445//Elementpublic abstract class Element&#123; public abstract void accept(Visitor v); public abstract double showElectricAmount(); public abstract void setElectricAmount(double n); &#125;//ConcreteElementpublic class ConcreteElement extends Element&#123; double count; public void accept(Visitor v)&#123; System.out.println(v.visitor(this)); &#125; public double showElectricAmount()&#123; return count; &#125; public void setElectricAmount(double n)&#123; count = n; &#125;&#125;//Visitorpublic interface Visitor&#123; public double visitor(Element element);&#125;//ConcreteVisitorpublic class ConcreteVisitorOne implements Visitor&#123; public double visitor(Element element)&#123; return element.showElectricAmount(); &#125;&#125;public class ConcreteVisitorTwo implements Visitor&#123; public double visitor(Element element)&#123; return element.showElectricAmount()+1; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Element e = new ConcreteElement(); Visitor v = new ConcreteVisitorOne(); e.setElectricAmount(20); e.accept(v); v = new ConcreteVisitorTwo(); e.accept(v); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Template Method Pattern]]></title>
    <url>%2F2017%2F08%2F26%2FTemplateMethodPattern%2F</url>
    <content type="text"><![CDATA[Template Method Pattern（模板方法模式）Define the skeleton of an algorithm in an operation,deferring some steps to subclasses.Template Method lets subclass redefine certain steps of an algorithm without changing the algorithm’s structure. （定义一个操作中的算法框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可以重定义该算法的某些特定步骤。） 抽象模板（AbstractTemplate）：一个抽象类,定义若干方法表示一个算法的步骤，有抽象方法也有非抽象方法，抽象方法表示原子操作，非抽象方法表示原子步骤 具体模板（ConcreteTemplate）：抽象模板的子类，实现抽象模板的原子操作 应用场景：非抽象方法负责定义步骤流程，钩子方法，子类可以按照抽象模板的规定步骤进行（用final修饰来强制继承不能改动），也可重写非抽象方法来自己定义步骤流程，或者还可以在确定什么样的条件下去执行算法的哪些步骤（boolean返回类型的钩子方法的用途） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930//AbstractTemplatepublic abstract class Template&#123; public abstract void first(); public abstract void second(); public abstract void third(); public final void templateMethod()&#123; first(); second(); third(); &#125;&#125;//ConcreteTemplatepublic class ConcreteTemplate extends Template&#123; public void first()&#123; System.out.println("首先"); &#125; public void second()&#123; System.out.println("然后"); &#125; public void third()&#123; System.out.println("其次"); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Template t = new ConcreteTemplate(); t.templateMethod(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Singleton Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FSingletonPattern%2F</url>
    <content type="text"><![CDATA[Singleton PatternEnsure a class has only one instance, and provide a global point of access to it.（确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。） 某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。 省去了new操作符，降低了系统内存的使用频率，减轻GC压力。 有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。 123456789101112131415161718192021public class Singleton &#123; /* 立即加载/恶汉模式 在使用类的时候就已经将对象创建完毕，在调用方法前，实例已经被创建 private static Singleton instance = new Singleton(); 延迟加载/懒汉模式 在调用get()方法时实例才被创建 public static Singleton getInstance() &#123; instance = new Singleton(); &#125; */ //持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 private static Singleton instance = null; //私有构造方法，防止被实例化 private Singleton() &#123;&#125; //静态工程方法，创建实例 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 上面的类在单线程情况下不会出错，但是如果我们把它放入多线程的环境下，就会出现问题了，如何解决？我们可以对getInstance方法加synchronized关键字，如下：123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; 但是，synchronized关键字会锁住整个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都会对对象上锁，事实上，我们只需要在第一次创建对象的时候需要加锁，之后就不需要了，所以，我们进一步改进为：12345678910public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (instance) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; 如果不了解jvm中指令重排的同学可能认为上面的改进已经算是完善了，但是，在Java指令中创建对象和赋值操作是分开进行的，也就是说instance = new Singleton()语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例： a&gt;A、B线程同时进入了第一个if判断 b&gt;A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); c&gt;由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，在写多线程环境下的程序是有一定难度的。我们对该程序做进一步优化：1234567//静态内置类实现单例private static class SingletonFactory&#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonFactory.instance; &#125; 实际上，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们可以暂时总结一个完整的单例模式如下：1234567891011121314151617181920212223242526272829303132333435363738394041public class Singleton &#123; //私有构造方法，防止被实例化 private Singleton() &#123;&#125; //此处使用一个内部类来维护单例 private static class SingletonFactory &#123; private static Singleton instance = new Singleton(); &#125; //获取实例 public static Singleton getInstance() &#123; return SingletonFactory.instance; &#125; &#125; //变形，使用static代码块实现public class Singleton &#123; private static Singleton instance = null； //私有构造方法内放置static代码块，里面实例化对象 private Singleton() &#123; static&#123; instance = new Singleton(); &#125; &#125; //获取实例 public static Singleton getInstance() &#123; return instance; &#125; &#125; //扩展，使用枚举enum实现public class Singleton &#123; public enum EnumSingleton&#123; connectionFactory； private Connection connection; private EnumSingleton&#123; ... connection = DriverManager.getConnection(url,username,password); &#125; public Connection getConnection()&#123; return connection; &#125; &#125; public static Connection getConnection() &#123; return EnumSingleton.connectionFactory.getConnection(); &#125; &#125; 静态内置类可以达到线程安全问题，但是当遇到序列化对象时，使用默认的方式运行得到的结果还是多例的12345678910111213141516171819202122232425262728293031323334353637public class MyObject implements Serializable &#123; private static final long serialVersionUID = 888L; private static class MyObjectHandler &#123; private static final MyObject myObject = new MyObject(); &#125; private MyObject() &#123;&#125; public static MyObject getInstance() &#123; return MyObjectHandler.myObject; &#125; //readResolve()方法解决序列化单例模式 protected Object readResolve() throws ObjectStreamException &#123; System.out.println("调用了readResolve方法！"); return MyObjectHandler.myObject; &#125; &#125; //输出hashCode来验证序列化前后对象是否为同一个public class SaveAndRead &#123; public static void main(String[] args) &#123; try &#123; MyObject myObject = MyObject.getInstance(); FileOutputStream fosRef = new FileOutputStream(new File("myObjectFile.txt")); ObjectOutputStream oosRef = new ObjectOutputStream(fosRef); oosRef.writeObject(myObject); oosRef.close(); fosRef.close(); System.out.println(myObject.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; try &#123; FileInputStream fisRef = new FileInputStream(new File("myObjectFile.txt")); ObjectInputStream iosRef = new ObjectInputStream(fisRef); MyObject myObject = (MyObject) iosRef.readObject(); iosRef.close(); fisRef.close(); System.out.println(myObject.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[State Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FStatePattern%2F</url>
    <content type="text"><![CDATA[State Pattern（状态模式）Allow an object to alter its behavior when its internal state changes.The object will appear to change its class.（当一个对象在状态改变时允许其改变行为，这个对象看起来像改变了其类。） 抽象状态（State）：一个接口或者抽象类 环境（Context）：依赖于策略接口的类（组合关系） 具体状态（ConcreteState）：状态接口（抽象类）的实现类（扩展类） 应用场景：一个对象的状态依赖于它的行为，状态随着行为的改变为改变 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//Statepublic abstract class State&#123; public abstract void shoot(); public abstract void loadBullets();&#125;//Contextpublic class Gun&#123; public State stateThree,stateTwo,stateOne,stateNull; public State state; public Gun()&#123; stateThree = new BulletStateThree(this); stateTwo = new BulletStateTwo(this); stateOne = new BulletStateOne(this); stateNull = new BulletStateNull(this); state = stateThree; &#125; public void setState(State state)&#123; this.state = state; &#125; public void fire()&#123; state.shoot(); &#125; public void load()&#123; state.loadBullets(); &#125;&#125;//ConcreteStatepublic class BulletStateNull extends State&#123; Gun gun; BulletStateNull(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("没有子弹了！"); &#125; public void loadBullets()&#123; System.out.println("装弹-------"); gun.setState(gun.stateThree); &#125;&#125;public class BulletStateOne extends State&#123; Gun gun; BulletStateOne(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateNull); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;public class BulletStateTwo extends State&#123; Gun gun; BulletStateTwo(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateOne); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;public class BulletStateThree extends State&#123; Gun gun; BulletStateThree(Gun gun)&#123; this.gun = gun; &#125; public void shoot()&#123; System.out.println("射出一颗子弹！"); gun.setState(gun.stateTwo); //gun,setState(new BulletStateTwo(gun)); &#125; public void loadBullets()&#123; System.out.println("无法装弹！"); &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; Gun gun = new Gun(); gun.fire(); gun.fire(); gun.fire(); gun.fire(); gun.load(); gun.fire(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Strategy Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FStrategyPattern%2F</url>
    <content type="text"><![CDATA[Strategy Pattern（策略模式）Define a family of algorithms, encapsulate each one, and make them interchangeable.（定义一组算法，将每个算法都封装起来，并且使他们之间可以互换。） 策略（Strategy）：一个接口 上下文（Context）：依赖于策略接口的类（组合关系） 具体策略（ConcreteStrategy）：策略接口的实现类 应用场景：一个类定义了多种行为构成了多个条件分支（封装算法的细节） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//Strategypublic interface Strategy&#123; public double computerAverage(double [] a); &#125;//Contextpublic class AverageScore&#123; //组合 Strategy stratrgy; public void setStrategy(Strategy stratrgy)&#123; this.stratrgy = stratrgy; &#125; public double getAverage(double [] a)&#123; return stratrgy.computerAverage(a); &#125;&#125;//ConcreteStrategypublic class StrategyA implements Strategy &#123; public double computerAverage(double [] a)&#123; double average = 0; for (double i : a) &#123; average += i; &#125; average /=a.length; return average; &#125;&#125;import java.util.Arrays;public class StrategyB implements Strategy &#123; public double computerAverage(double [] a)&#123; double average = 0; Arrays.sort(a); for (int i = 1;i &lt; a.length-1 ;i++ ) &#123; average += a[i]; &#125; average /=(a.length-2); return average; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; double [] tuple = new double[]&#123;90,90,98,87,76,45&#125;; AverageScore ave = new AverageScore(); //策略A ave.setStrategy(new StrategyA()); double score = ave.getAverage(tuple); //策略B ave.setStrategy(new StrategyB()); double score1 = ave.getAverage(tuple); System.out.printf("%10f %10f",score,score1); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Proxy Pattern]]></title>
    <url>%2F2017%2F08%2F19%2FProxypattern%2F</url>
    <content type="text"><![CDATA[Proxy pattern（代理模式）Provide a surrogate (代理) or placeholder for another object to control access to it.（为其他对象提供一种代理以控制对这个对象的访问。） 抽象主题（Subject）：一个接口 实际主题（RealSubject）：实现了抽象主题接口的类 代理(Proxy)：实现了抽象主题接口的类，含有抽象主题声明的变量，来存放实际主题的实例的引用 应用场景：代理的实例用来控制对他所包含的实际主题的实例的访问，即控制他所代理对象的访问权限（java远程代理RMI同理） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627//Subjectpublic interface Employee&#123; public String hearPhone();&#125;//RealSubjectpublic class Boss implements Employee&#123; public String hearPhone()&#123; return "面谈吧"; &#125;&#125;//Proxypublic class Secretary implements Employee&#123; Boss boss; Secretary()&#123; boss = new Boss(); &#125; public String hearPhone()&#123; return "我们老板说："+boss.hearPhone(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Secretary s = new Secretary(); System.out.println(s.hearPhone()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mediator Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FMediatorPattern%2F</url>
    <content type="text"><![CDATA[Mediator Pattern（中介者模式）Define an object that encapsulates how a set of objects interact.Mediator promotes loose couping by keeping objects from referring to each other explicitly, and it lets you vary their interaction independently.（用一个中介对象封装一系列的对象交互，中介者使各对象不需要显示的相互作用，从而使其耦合松散，而且可以独立的改变它们之间的交互。） 中介者（Mediator）：一个接口，定义同事Colleague对象中间用于通信的方法 具体中介者（Invoker）：Mefiator接口的实现类，包含具体同事ConcreteColleague对象的引用 同事（Colleague）：一个接口，定义具体同事要是实现的方法 具体同事（ConcreteColleague）：同事接口的实现类，同事包含中介者的引用，同事之间也可以相互交流 应用场景：避免同事对象之间显示的引用，将同事之间的通信交由中介来负责 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Mediatorpublic interface Mediator&#123; public void registerColleague(Colleague colleague); public void deliverMess(String mess,Colleague... c);&#125;//Invokerimport java.util.ArrayList;public class ConcreteMediator implements Mediator&#123; ArrayList&lt;Colleague&gt; list; ConcreteMediator()&#123; list = new ArrayList&lt;Colleague&gt;(); &#125; public void registerColleague(Colleague colleague)&#123; list.add(colleague); &#125; public void deliverMess(String mess,Colleague... c)&#123; for (Colleague colleague : c) &#123; if(list.contains(colleague)) colleague.receiveMess(mess,colleague); else continue; &#125; &#125;&#125;//Colleaguepublic interface Colleague&#123; public void setName(String name); public String getName(); public void sendMess(String mess,Colleague... c); public void receiveMess(String mess,Colleague c); public void setMediator(Mediator mediator);&#125;//ConcreteColleaguepublic class ConcreteColleague implements Colleague&#123; Mediator mediator; String name; public void setName(String name)&#123; this.name = name; &#125; public String getName()&#123; return name; &#125; public void sendMess(String mess,Colleague... c)&#123; mediator.deliverMess(mess,c); &#125; public void receiveMess(String mess,Colleague c)&#123; System.out.println(this.getName()+":来自"+c.getName()+"的消息"); System.out.println("-----------"+mess); &#125; public void setMediator(Mediator mediator)&#123; this.mediator = mediator; mediator.registerColleague(this); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Mediator m = new ConcreteMediator(); Colleague c = new ConcreteColleague(); Colleague c1 = new ConcreteColleague(); Colleague c2 = new ConcreteColleague(); c.setMediator(m); c1.setMediator(m); c2.setMediator(m); c.setName("C"); c1.setName("C1"); c2.setName("C2"); c.sendMess("Hello!",c1,c2); c1.sendMess("Hi",c); c2.sendMess("Hi!",c); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Observer Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FObserverPattern%2F</url>
    <content type="text"><![CDATA[Observer Pattern（观察者模式）Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.（定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。） 主题（Subject）：一个接口,规定具体主题需要实现的方法 观察者（Observer）：一个接口，规定了具体观察者用来获取数据的方法 具体主题(ConcreteSubject)：主题接口的实现类，该实例包含观察者所关心的数据（经常变动），含有观察者的引用，以便在数据发生变化时通知观察者更新数据 具体观察者(ConcreteObserver)：观察者接口的实现类，含有具体主题的引用，以便于具体主题将自己添加/删除到其集合中去，成为该主题的观察者 应用场景：观察者对于主题中的数据可采用两种方法——“拉”数据或者——-“推”数据,即主题主动将数据更新推送给观察者，或者只是通知观察者数据已更新，观察者自己调用主题方法实现数据更新，适用于一个对象数据更新时需要通知其他对象（或者让其自行更新） javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//Subjectpublic interface Subject&#123; public void addObserver(Observer o); public void deleteObserver(Observer o); public void notifyObservers(); public void setDate(String name,String author,String publisher,float price); public String getName(); public float getPrice(); public String getAuthor(); public String getPublisher();&#125;//Observerpublic interface Observer&#123; public void update();&#125;//ConcreteSubjectimport java.util.LinkedList;public class BookStore implements Subject&#123; private String name,author,publisher; private float price; private LinkedList&lt;Observer&gt; list; BookStore()&#123; list = new LinkedList&lt;Observer&gt;(); &#125; public void addObserver(Observer o)&#123; if(!list.contains(o)) list.add(o); &#125; public void deleteObserver(Observer o)&#123; if(list.contains(o)) list.remove(o); &#125; public void notifyObservers()&#123; for (Observer observer : list) &#123; observer.update(); &#125; &#125; public void setDate(String name,String author,String publisher,float price)&#123; this.name = name; this.author = author; this.publisher = publisher; this.price = price; notifyObservers(); //一旦发生数据更新，随即通知各个观察者 &#125; public String getName()&#123; return name; &#125; public float getPrice()&#123; return price; &#125; public String getAuthor()&#123; return author; &#125; public String getPublisher()&#123; return publisher; &#125;&#125;//ConcreteObserverpublic class CustomerOne implements Observer &#123; private Subject subject; private String bookName; private float price; CustomerOne(Subject subject)&#123; this.subject = subject; subject.addObserver(this); &#125; public void update()&#123; bookName = subject.getName(); price = subject.getPrice(); System.out.println(bookName+"和"+price+"更新了"); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Subject s = new BookStore(); Observer o = new CustomerOne(s); s.setDate("设计模式","刘飞","清华出版社",25); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prototype Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FPrototypePattern%2F</url>
    <content type="text"><![CDATA[Prototype Pattern（原型模式）Specify the kinds of objects to create using a prototypical instance,and create new objects by copying this prototype.（用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。） 抽象原型（Prototype）：一个接口，定义对象复制自身的方法 具体原型（ConcretePrototype）：抽象原型的实现类 应用场景：通过复制原型创建新的对象(序列化/反序列化，Class.clone()克隆，深度克隆) javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//Prototypepublic interface Prototype&#123; public Object cloneMe() throws CloneNotSupportedException;&#125;//ConcretePrototypepublic class CloneA implements Prototype,Cloneable &#123; int a; CloneA(int a)&#123; this.a = a; &#125; public Object cloneMe() throws CloneNotSupportedException&#123; CloneA object = (CloneA)clone(); return object; &#125;&#125;import java.io.*;public class CloneB implements Prototype,Serializable &#123; StringBuffer color; public void setColor(StringBuffer c)&#123; color = c; &#125; public StringBuffer getColor()&#123; return color; &#125; public Object cloneMe() throws CloneNotSupportedException&#123; Object object = null; try&#123; ByteArrayOutputStream outOne = new ByteArrayOutputStream(); ObjectOutputStream outTwo = new ObjectOutputStream(outOne); outTwo.writeObject(this); ByteArrayInputStream inOne = new ByteArrayInputStream(outOne.toByteArray()); ObjectInputStream inTwo = new ObjectInputStream(inOne); object = inTwo.readObject(); &#125;catch(Exception e)&#123;&#125; return object; &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; try&#123; CloneA c = new CloneA(2); CloneA c1 = (CloneA)c.cloneMe(); System.out.print(c.a+"---"+c1.a); CloneB cc = new CloneB(); cc.setColor(new StringBuffer("A")); CloneB cc1 = (CloneB)cc.cloneMe(); cc1.setColor(new StringBuffer("copyA")); System.out.print(cc.getColor()+"---"+cc1.getColor()); &#125;catch(Exception e)&#123;&#125; &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memento Pattern]]></title>
    <url>%2F2017%2F08%2F12%2FMementoPattern%2F</url>
    <content type="text"><![CDATA[Memento Pattern（备忘录模式）Without violating encapsulation， capture and externalize an object’s internal state so that the object can be restored to this state later.（在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样以后就可将该对象恢复到原来保存的状态。）Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//public class Original &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public Original(String value) &#123; this.value = value; &#125; public Memento createMemento()&#123; return new Memento(value); &#125; public void restoreMemento(Memento memento)&#123; this.value = memento.getValue(); &#125; &#125; //public class Memento &#123; private String value; public Memento(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; &#125; //public class Storage &#123; private Memento memento; public Storage(Memento memento) &#123; this.memento = memento; &#125; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125; &#125; //Testpublic class Test &#123; public static void main(String[] args) &#123; // 创建原始类 Original origi = new Original("egg"); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println("初始化状态为：" + origi.getValue()); origi.setValue("niu"); System.out.println("修改后的状态为：" + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println("恢复后的状态为：" + origi.getValue()); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flyweight Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FFlyweightPattern%2F</url>
    <content type="text"><![CDATA[Flyweight Pattern（享元模式）Use sharing to support large numbers of fine-grained objects efficiently.（使用共享对象可有效地支持大量的细粒度对象。） 享元接口（Flyweight）：一个接口，定义了享元对外公开内部数据的方法以及接受外部数据的方法 具体享元（ConcreteFlyweight）：享元接口的实现类的实例 享元工厂(FlyweightFactory)：一个类，负责创建和管理享元实例，其他对象对享元的请求必须通过工厂才能获得一个享元对象的实例引用 应用场景：利用一个叫做享元的对象来为其他对象提供共享的状态，且保证其他对象不能更改享元中的数据 javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//Flyweightpublic interface Flyweight&#123; public double getWeight(); public double getWidth(); public double getLength();&#125;//ConcreteFlyweightpublic class Car&#123; Flyweight flyweight; String color; double power; Car(Flyweight flyweight,String color,double power)&#123; this.flyweight = flyweight; this.color = color; this.power = power; &#125; public void print()&#123; System.out.println(color); System.out.println(power); System.out.println(flyweight.getWeight()); System.out.println(flyweight.getWidth()); System.out.println(flyweight.getLength()); &#125;&#125;//FlyweightFactorypublic class FlyweightFactory&#123; static FlyweightFactory factory = new FlyweightFactory(); static Flyweight intrinsic; private FlyweightFactory()&#123;&#125; public static FlyweightFactory getFactory()&#123; return factory; &#125; public Flyweight getFlyweight()&#123; intrinsic = new DateCar(1.43,1.45,5.21); return intrinsic; &#125; //内部类 class DateCar implements Flyweight&#123; private double weight; private double width; private double length; //私有构造方法，不允许其他程序直接使用享元类来直接创建享元对象 private DateCar(double weight,double width,double length)&#123; this.weight = weight; this.width = width; this.length = length; &#125; public double getWeight()&#123; return weight; &#125; public double getWidth()&#123; return width; &#125; public double getLength()&#123; return length; &#125; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; FlyweightFactory factory = FlyweightFactory.getFactory(); Flyweight carIntrinsic = factory.getFlyweight(); Car one = new Car(carIntrinsic,"red",5000); Car two = new Car(carIntrinsic,"blue",3000); one.print(); two.print(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Decorator Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FDecoratorPattern%2F</url>
    <content type="text"><![CDATA[Decorator Pattern（装饰模式）Attach additional responsibilities to an object dynamically keeping the same interface.Decorators provide a flexible alternative to subclassing for extending functionality.（动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。） 抽象组件（Component）:抽象类，定义需要进行装饰的方法，被装饰角色 具体组件（ConcreteComponent）:抽象组件的一个子类 装饰（Decorator）：也是抽象组件的一个子类，装饰者角色 具体装饰（ConcreteDecorator）：装饰的一个非抽象子类 应用场景：动态的给对象添加一些额外的方法，改进类的某个对象的功能，调用同样的方法，不一样的结果 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142//Componentpublic abstract class Bird&#123; public abstract int fly();&#125;//ConcreteComponentpublic class Sparrow extends Bird&#123; private final static int DISTANCE = 100; public int fly()&#123; return DISTANCE; &#125;&#125;//Decoratorpublic abstract class Decorator extends Bird&#123; Bird bird; Decorator()&#123;&#125; Decorator(Bird bird)&#123; this.bird = bird; &#125;&#125;//ConcreteDecoratorpublic class ConcreteDecorator extends Decorator&#123; private final static int DISTANCE = 50; ConcreteDecorator(Bird bird)&#123; super(bird); &#125; public int fly()&#123; return bird.fly()+DISTANCE; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Bird bird = new Sparrow(); System.out.println(bird.fly()); bird = new ConcreteDecorator(bird); System.out.println(bird.fly()); bird = new ConcreteDecorator(bird); System.out.println(bird.fly()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Facade Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FFacadePattern%2F</url>
    <content type="text"><![CDATA[Facade Pattern（门面模式）Provide a unified interface to a set of interface in a subsystem.Facede defines a higher-level interface that makes the subsystem easier to use.(要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供了一个高层次的接口，使得子系统更容易使用。) 子系统（Subsystem）:若干类的集合，均不包含外观类的实例引用 外观（Facade）：一个含有子系统中全部或者部分类的实例引用的类 应用场景：跟踪系统使用情况（经过同一个接口），更换系统（只需更改外观接口的代码） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//Subsystempublic class CPU &#123; public void startup()&#123; System.out.println("cpu startup!"); &#125; public void shutdown()&#123; System.out.println("cpu shutdown!"); &#125; &#125; public class Memory &#123; public void startup()&#123; System.out.println("memory startup!"); &#125; public void shutdown()&#123; System.out.println("memory shutdown!"); &#125; &#125; public class Disk &#123; public void startup()&#123; System.out.println("disk startup!"); &#125; public void shutdown()&#123; System.out.println("disk shutdown!"); &#125; &#125; //Facadepublic class Computer &#123; private CPU cpu; private Memory memory; private Disk disk; public Computer()&#123; cpu = new CPU(); memory = new Memory(); disk = new Disk(); &#125; public void startup()&#123; System.out.println("start the computer!"); cpu.startup(); memory.startup(); disk.startup(); System.out.println("start computer finished!"); &#125; public void shutdown()&#123; System.out.println("begin to close the computer!"); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println("computer closed!"); &#125; &#125; //Testpublic class Application &#123; public static void main(String[] args) &#123; Computer computer = new Computer(); computer.startup(); computer.shutdown(); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interpreter Pattern]]></title>
    <url>%2F2017%2F08%2F05%2FInterpreterPattern%2F</url>
    <content type="text"><![CDATA[Interpreter Pattern（解释器模式）Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences int the language.（给定一门语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。） 123456789101112131415161718192021222324252627282930313233343536373839404142434445//public interface Expression &#123; public int interpret(Context context); &#125; public class Plus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()+context.getNum2(); &#125; &#125; public class Minus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()-context.getNum2(); &#125; &#125; public class Context &#123; private int num1; private int num2; public Context(int num1, int num2) &#123; this.num1 = num1; this.num2 = num2; &#125; public int getNum1() &#123; return num1; &#125; public void setNum1(int num1) &#123; this.num1 = num1; &#125; public int getNum2() &#123; return num2; &#125; public void setNum2(int num2) &#123; this.num2 = num2; &#125; &#125; //Testpublic class Test &#123; public static void main(String[] args) &#123; // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus() .interpret(new Context(9, 2)), 8))); System.out.println(result); &#125; &#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chain Of Responsibility Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FChainOfResponsibilityPattern%2F</url>
    <content type="text"><![CDATA[Chain Of Responsibility Pattern（责任链模式）Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request.Chain the receiving objects and pass the request along the chain until an object handles it.（使多个对象有机会处理请求，从而避免了请求的发送者和接收者之间的耦合关系 。将这些对象连成一个链，并沿着这条链传递请求，知道有对象处理它为止。） 处理者（Handler）：一个接口,负责规定具体处理者处理用户的请求的方法和具体处理者设置后继对象的方法 具体处理者（ConcreteHandler）：Handler接口的实现类，调用处理者接口规定的方法处理用户的请求，若能处理则进行处理，不能则传给下一节点 应用场景：形成一个处理链，挨个节点判断是否能够进行处理，阶乘的计算（从结果的数据量按需判断那个节点可以容纳结果） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//Handlerpublic interface Handler&#123; public abstract void computerMultiply(String number); public abstract void setNextHandler(Handler handler);&#125;//ConcreteHandlerimport java.util.*;public class UseInt implements Handler&#123; private int result = 1; private Handler handler; public void computerMultiply(String number)&#123; try&#123; int n = Integer.parseInt(number); while(n &gt; 0)&#123; result *=n--; if (result &lt;= 0) &#123; System.out.println("超出int计算范围"); handler.computerMultiply(number); return; &#125; &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;public class UseLong implements Handler&#123; private long result = 1; private Handler handler; public void computerMultiply(String number)&#123; try&#123; long n = Long.parseLong(number); while(n &gt; 0)&#123; result *=n--; if (result &lt;= 0) &#123; System.out.println("超出long计算范围"); handler.computerMultiply(number); return; &#125; &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;import java.util.*;import java.math.BigInteger;public class UseBigInteger implements Handler&#123; private BigInteger result = new BigInteger("1"); private Handler handler; public void computerMultiply(String number)&#123; try&#123; BigInteger n = new BigInteger(number); BigInteger ONE = new BigInteger("1"); while(n.compareTo(ONE) &gt; 0)&#123; result = result.multiply(n); n = n.subtract(ONE); &#125; System.out.println(result); &#125;catch(Exception e)&#123; System.out.println(e.toString()); &#125; &#125; public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125;&#125;//Testimport java.util.*;public class Application&#123; public static void main(String[] args) &#123; Handler uint,ulong,ubint; uint = new UseInt(); ulong = new UseLong(); ubint = new UseBigInteger(); uint.setNextHandler(ulong); ulong.setNextHandler(ubint); uint.computerMultiply("5"); uint.computerMultiply("19"); uint.computerMultiply("30"); uint.computerMultiply("100"); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Command Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FCommandPattern%2F</url>
    <content type="text"><![CDATA[Command Pattern（命令模式）Encapsulate a request as an object,thereby letting you parameterize clients with different requests,queue or log requests, and support undoable operations.（将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和恢复功能。） 命令（Command）：一个接口，封装请求的若干方法 请求者（Invoker）：包含Command接口变量的类的实例（组合关系） 接收者（Receiver）：一个类的实例，执行与请求有关的操作 具体命令（ConcreteCommand）：Command接口的实现类 应用场景：请求者与接收者不直接交互，消除彼此的耦合（将命令拆分），命令的撤销（栈的应用）：”\b” 退格键 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//Commandpublic interface BattleCommand&#123; abstract void execute();&#125;//Invokerpublic class ArmySuperior&#123; public BattleCommand command; public void setBattleCommand(BattleCommand command)&#123; this.command = command; &#125; public void startExecuteCommand()&#123; command.execute(); &#125;&#125;//Receiverpublic interface Army&#123; public void attack();&#125;public class ArmyA implements Army&#123; public void attack()&#123; System.out.println("炮火攻打县城A外围"); System.out.println("坦克进攻"); System.out.println("步兵进攻"); &#125;&#125;public class ArmyB implements Army&#123; public void attack()&#123; System.out.println("在敌人增援路上埋地雷"); System.out.println("在战壕里射击增援的敌人"); &#125;&#125;public class ArmyC implements Army&#123; public void attack()&#123; System.out.println("佯攻县城B"); &#125;&#125;//ConcreteCommandpublic class CommandA implements BattleCommand&#123; Army army; public CommandA(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;public class CommandB implements BattleCommand&#123; Army army; public CommandB(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;public class CommandC implements BattleCommand&#123; Army army; public CommandC(Army army)&#123; this.army = army; &#125; public void execute()&#123; army.attack(); &#125;&#125;//Testpublic class Application &#123; public static void main(String[] args) &#123; ArmySuperior superior = new ArmySuperior(); Army army = new ArmyA(); BattleCommand command = new CommandA(army); superior.setBattleCommand(command); superior.startExecuteCommand(); army = new ArmyB(); command = new CommandB(army); superior.setBattleCommand(command); superior.startExecuteCommand(); army = new ArmyC(); command = new CommandC(army); superior.setBattleCommand(command); superior.startExecuteCommand(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Behavioral_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Builder Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FBuilderPattern%2F</url>
    <content type="text"><![CDATA[Builder Pattern（建造者模式）Separate the construction of a complex object form its representation so that the same construction process can create different representations.（将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。） 产品（Product）：具体生成器要构造的复杂对象 抽象生成器（Builder）：一个接口，有为创建一个产品对象的各个组件定义的若干方法，还有返回产品对象的方法 具体生成器（ConcreteBuilder）：Builder的实现类 指挥者（Director）：一个类，拥有Builder接口声明的变量，负责向用户提供具体生成器 应用场景：将一个复杂对象的构建与表示分离，使得同样的构建可以创建不同的表示 javac -encoding UTF-8 Application.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//Productpublic class Product&#123; //产品假设是一台电脑 public String "主机"； public String "显示器"; public String "键盘";&#125;//Builderpublic interface Builder&#123; public abstract String buildZJ(); public abstract String buildXSQ(); public abstract String buildJP(); public abstract void creat();&#125;//ConcreteBuilderpublic class BuilderOne implements Builder &#123; public String buildZJ()&#123; return "YYY牌主机"; &#125; public String buildXSQ()&#123; return "YYY牌显示器"; &#125; public String buildJP()&#123; return "YYY牌键盘"; &#125; public void creat()&#123; System.out.println(buildZJ()); System.out.println(buildJP()); System.out.println(buildXSQ()); &#125; &#125;public class BuilderTwo implements Builder &#123; public String buildZJ()&#123; return "XXX牌主机"; &#125; public String buildXSQ()&#123; return "XXX牌显示器"; &#125; public String buildJP()&#123; return "XXX牌键盘"; &#125; public void creat()&#123; System.out.println(buildZJ()); System.out.println(buildXSQ()); System.out.println(buildJP()); &#125;&#125;//Directorpublic class Director&#123; private Builder builder; Director(Builder builder)&#123; this.builder = builder; &#125; public void createComputer()&#123; builder.creat(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Builder b = new BuilderOne(); Director d = new Director(b); d.createComputer(); b = new BuilderTwo(); d = new Director(b); d.createComputer(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Command Pattern]]></title>
    <url>%2F2017%2F07%2F29%2FCompositePattern%2F</url>
    <content type="text"><![CDATA[Composite Pattern（组合模式）Compose objects into tree structure to represent part-whole hierarchies.Composite lets clients treat individual objects and compositions of objects uniformly.（将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。） 抽象组件（Component）:一个接口或者抽象类，定义了个体对象和组合对象需要实现的关于原子操作的方法 Composite节点（Composite Node）:实现了Component接口的类，其中可包含其他Composite节点（组合对象） Leaf节点（Leaf Node）：实现了Component接口的类，不可包含其他Composite节点或者Leaf节点（个体对象） 应用场景：个体对象和组合对象实现于同一接口，形成树形结构（部分-整体层次结构） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//Componentimport java.util.*;public interface MilitaryPerson&#123; public void add(MilitaryPerson person); public void remove(MilitaryPerson person); public MilitaryPerson getChild(int index); public Iterator&lt;MilitaryPerson&gt; getAllChild(); public boolean isLeaf(); public double getSalary(); public void setSalary(double salary); &#125;//Composite Nodeimport java.util.*;public class MilitaryOfficer implements MilitaryPerson&#123; private String name; private double salary; private LinkedList&lt;MilitaryPerson&gt; list; MilitaryOfficer(String name,double salary)&#123; this.name = name; this.salary = salary; list = new LinkedList&lt;MilitaryPerson&gt;(); &#125; public void add(MilitaryPerson person)&#123; list.add(person); &#125; public void remove(MilitaryPerson person)&#123; list.remove(person); &#125; public MilitaryPerson getChild(int index)&#123; return list.get(index); &#125; public Iterator&lt;MilitaryPerson&gt; getAllChild()&#123; return list.iterator(); &#125; public boolean isLeaf()&#123; return false; &#125; public double getSalary()&#123; return salary; &#125; public void setSalary(double salary)&#123; this.salary = salary; &#125;&#125;//Leaf Nodeimport java.util.*;public class MilitarySoldier implements MilitaryPerson&#123; private String name; private double salary; MilitarySoldier(String name,double salary)&#123; this.name = name; this.salary = salary; &#125; public void add(MilitaryPerson person)&#123;&#125; public void remove(MilitaryPerson person)&#123;&#125; public MilitaryPerson getChild(int index)&#123;return null;&#125; public Iterator&lt;MilitaryPerson&gt; getAllChild()&#123;return null;&#125; public boolean isLeaf()&#123; return true; &#125; public double getSalary()&#123; return salary; &#125; public void setSalary(double salary)&#123; this.salary = salary; &#125;&#125;//Testimport java.util.*;public class Application&#123; public static void main(String[] args) &#123; MilitaryPerson 连长 = new MilitaryOfficer("连长",5000); MilitaryPerson 营长 = new MilitaryOfficer("营长",4000); MilitaryPerson 班长 = new MilitaryOfficer("班长",3000); MilitaryPerson 士兵 = new MilitarySoldier("士兵",2000); 连长.add(营长); 营长.add(班长); 班长.add(士兵); System.out.println(computerSalary(连长)); &#125; public static double computerSalary(MilitaryPerson person)&#123; double sum = 0; if(person.isLeaf()==true) sum += person.getSalary(); else&#123; sum += person.getSalary(); Iterator&lt;MilitaryPerson&gt; it = person.getAllChild(); while(it.hasNext())&#123; MilitaryPerson p = it.next(); sum += computerSalary(p); &#125; &#125; return sum; &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Abstract Factory Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FAbstractFactoryPattern%2F</url>
    <content type="text"><![CDATA[Abstract Factory Pattern（抽象工厂模式）Provide an interface for creating families of related or dependent objects without specifying their concrete classes.（为创建一组相关或相互依赖的对象提供一个接口，而且无需指定它们的具体类。） 抽象产品（Product）：一个接口或者抽象类，定义、产品必须实现的方法 具体产品（ConcreteProduct）：抽象产品的子类或者实现类 抽象工厂（AbstractFactory）：一个接口或者抽象类，定义若干个抽象方法 具体工厂（ConcreteFactory）：抽象工厂的实现类或者子类，重写抽象方法，使其返回具体产品的实例 应用场景：提供一个创建一系列或相互依赖对象的接口，而无需知道他们具体的类，反射机制+抽象工厂（反射可以灵活地进行实例化） javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//Productpublic abstract class Weapon&#123; protected String type; public abstract void loadBullet(Bullet bullet);&#125;public abstract class Bullet&#123; public abstract void load(String type);&#125;//ConcreteProductpublic class JiQiang extends Weapon&#123; JiQiang()&#123; type = "机枪"; &#125; public void loadBullet(Bullet bullet)&#123; bullet.load(type); &#125;&#125;public class ShouQiang extends Weapon&#123; ShouQiang()&#123; type = "手枪"; &#125; public void loadBullet(Bullet bullet)&#123; bullet.load(type); &#125;&#125;public class JiQiangBullet extends Bullet&#123; public void load(String type)&#123; System.out.println(type+"---装载机枪型子弹"); &#125;&#125;public class ShouQiangBullet extends Bullet&#123; public void load(String type)&#123; System.out.println(type+"---装载手枪型子弹"); &#125;&#125;//Creatorpublic abstract class Factory&#123; public abstract Weapon createWeapon(); public abstract Bullet createBullet();&#125;//ConcreteCreatorpublic class ShouQiangFactory extends Factory &#123; public Weapon createWeapon()&#123; return new ShouQiang(); &#125; public Bullet createBullet()&#123; return new ShouQiangBullet(); &#125;&#125;public class JiQiangFactory extends Factory&#123; public Weapon createWeapon()&#123; return new JiQiang(); &#125; public Bullet createBullet()&#123; return new JiQiangBullet(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; Factory factory = new ShouQiangFactory(); Weapon gun = factory.createWeapon(); Bullet bullet = factory.createBullet(); gun.loadBullet(bullet); factory = new JiQiangFactory(); gun = factory.createWeapon(); bullet = factory.createBullet(); gun.loadBullet(bullet); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bridge Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FBridgePattern%2F</url>
    <content type="text"><![CDATA[Bridge Pattern（桥梁模式）Decouple an abstraction from its implementation so that the two can vary independently.（将抽象和实现解耦，使得两者可以独立的变化。） 抽象（Abstraction）：一个抽象类，含有实现者声明的变量， 实现者（Implementor）：一个接口，定义基本操作 细化抽象（RefinedAbstraction）：抽象的子类 具体实现者（ConcreteImplementor）：实现者的实现类 应用场景：分离实现和抽象，将抽象中方法的重要实现部分交给另外一个抽象类的子类或者接口的类 javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//Abstractionpublic abstract class BookEdit&#123; BookWriter [] author; String [] seriesBookName; public abstract void planBook(String [] s,String [] a); public abstract void releaseBook();&#125;//Implementorpublic interface BookWriter&#123; public void startWriterBook(String bookName); public String getName();&#125;//RefinedAbstractionpublic class TUBookEdit extends BookEdit&#123; public void planBook(String [] s,String [] a)&#123; seriesBookName = s; author = new BookAuthor[seriesBookName.length]; for (int i = 0;i &lt; seriesBookName.length ;i++ ) &#123; author[i] = new BookAuthor(a[i]); author[i].startWriterBook(seriesBookName[i]); &#125; &#125; public void releaseBook()&#123; System.out.println("图书有关信息"); for (int i = 0;i &lt; seriesBookName.length ;i++ ) &#123; System.out.print("书名："+seriesBookName[i]+"-------"); System.out.println("作者："+author[i].getName()); &#125; &#125;&#125;//ConcreteImplementorpublic class BookAuthor implements BookWriter&#123; String name; BookAuthor(String s)&#123; name = s; &#125; public void startWriterBook(String s)&#123; System.out.println(name+"编著了"+s); &#125; public String getName()&#123; return name; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; TUBookEdit zhang = new TUBookEdit(); String seriesBookName [] = &#123;"C程序设计","Java程序设计","XML程序设计"&#125;; String authorName [] = &#123;"张三","李四","王五"&#125;; zhang.planBook(seriesBookName,authorName); zhang.releaseBook(); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Factory Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FFactoryPattern%2F</url>
    <content type="text"><![CDATA[Factory Pattern（工厂模式） Define an interface for creating an object,but let subclass decide which class to instantiate.Factory Method lets a class defer instantiation to subclass.（定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法是一个类的实例化延迟到其子类。） 抽象产品（Product）：一个接口或者抽象类，定义、产品必须实现的方法 具体产品（ConcreteProduct）：抽象产品的子类或者实现类 构造者（Creator）：一个接口或者抽象类，定义一个叫做工厂方法的抽象方法，该方法返回具体产品类的实例 具体构造者（ConcreteCreator）：构造者实现类或者子类 应用场景：使一个类的实例化延迟到其子类，或者是想得到某一类的子类的实例，但是却无法直接使用new（不允许与该子类形成耦合），或者不清楚该类有哪些子类可用 javac -encoding UTF-8 Application.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//Productpublic abstract class PenCore&#123; String color; public abstract void writeword(String s);&#125;//ConcreteProductpublic class RedPen extends PenCore&#123; RedPen()&#123; color = "红色"; &#125; public void writeword(String s)&#123; System.out.println("写出"+color+"的字："+s); &#125;&#125;public class BluePen extends PenCore&#123; BluePen()&#123; color = "蓝色"; &#125; public void writeword(String s)&#123; System.out.println("写出"+color+"的字："+s); &#125;&#125;public class BallPen&#123; PenCore core; public void usePenCore(PenCore core)&#123; this.core = core; &#125; public void write(String s)&#123; core.writeword(s); &#125;&#125;//AbstractFactorypublic abstract class Creator&#123; public abstract PenCore getPenCore();&#125;//ConcreteFactorypublic class RedCreator extends Creator&#123; public PenCore getPenCore()&#123; return new RedPen(); &#125;&#125;public class BlueCreator extends Creator&#123; public PenCore getPenCore()&#123; return new BluePen(); &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; PenCore core; //笔芯 Creator c = new RedCreator(); //笔芯构造者 BallPen b = new BallPen(); //圆珠笔 core = c.getPenCore(); b.usePenCore(core); b.write("哈"); c = new BlueCreator(); core = c.getPenCore(); b.usePenCore(core); b.write("ha"); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Creational_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Adapter Pattern]]></title>
    <url>%2F2017%2F07%2F22%2FAdapterPattern%2F</url>
    <content type="text"><![CDATA[Adapter Pattern（适配器模式） Convert the inface of a class into another interface clients expect.Adapter lets classes work together that couldn’t otherwise because of incompatible interface.（将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。）“系统的数据和行为都正确，单接口不符时，我们应该考虑使用适配器，目的是是控制范围之外的一个原有对象与某个接口匹配。适配器模式主要用于希望复用一些现存的类，但是接口又与复用环境不一致的情况。”（《大话设计模式》） 目标（Target）：一个接口，客户想要使用的接口 被适配器（Adaptee）：一个已经存在的接口或者抽象类 适配器(Adapter)：一个实现了目标接口并且含有被适配器引用的类 应用场景：目标和被适配器完全解耦，通过适配器来建立联系（单接口适配器） javac -encoding UTF-8 Application.java 123456789101112131415161718192021222324252627282930313233//Targetpublic interface ZhiLiuDian&#123; public String privideZhiLiuDian();&#125;//Adapteepublic interface JiaoLiuDian&#123; public String privideJiaoLiuDian();&#125;public class JiaoLiuDianHost implements JiaoLiuDian&#123; public String privideJiaoLiuDian()&#123; return "交流电"; &#125;&#125;//Adapterpublic class Adapter implements ZhiLiuDian&#123; JiaoLiuDian jiao; Adapter(JiaoLiuDian jiao)&#123; this.jiao = jiao; &#125; public String privideZhiLiuDian()&#123; String s = jiao.privideJiaoLiuDian(); return "转换"+s+"成直流电"; &#125;&#125;//Testpublic class Application&#123; public static void main(String[] args) &#123; JiaoLiuDian jiao = new JiaoLiuDianHost(); System.out.println(jiao.privideJiaoLiuDian()); ZhiLiuDian zhi = new Adapter(jiao); System.out.println(zhi.privideZhiLiuDian()); &#125;&#125;]]></content>
      <categories>
        <category>Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Pattern</tag>
        <tag>Structural_Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java架构学习心得(一)]]></title>
    <url>%2F2017%2F07%2F15%2FJava%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[序言 软件开发从最初的pc单机的人机交互模式到后来局域网的出现开启了软件开发的c/s模式（客户端/服务器模式），在到现在的b/s模式（浏览器/服务器），其实都面临的着相同的问题——代码的冗余，相似代码的大量重复导致整体代码量的庞大，所以为了减少代码的冗余，避免上述情况的产生，框架应用而生！而框架的原理其实主要就只有两部分，流程的抽象和数据类型的抽象，下面我们一一道来！（此文章适合于学过jsp及j2EE的童鞋） 正文首先我们来说流程控制，b/s模式均由浏览器向服务器发出请求，然后服务器响应相关请求并回传结果给浏览器，这是个一成不变的通用过程，所以我要做的就是抽象这个过程，类似于Struts2，把请求和响应的控制流程抽象到框架中去，让框架去拦截掉你的所有请求，然后经过处理后在传递给服务器，服务器的相响应结果同样被框架截获，然后处理后再扔给浏览器去显示，以上是大概流程，下面我们用程序代码详细道来！1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;FlowControl&gt; &lt;Action name="login"&gt; &lt;OperatePoint name="login_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;OperatePoint name="login_check"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;OperatePoint name="login_init"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;Action name="register"&gt; &lt;OperatePoint name="register_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;Action name="xxx"&gt; &lt;OperatePoint name="xxx_execute"&gt; &lt;Result name="success"&gt;success.jsp&lt;/Result&gt; &lt;Result name="error"&gt;error.jsp&lt;/Result&gt; &lt;/OperatePoint&gt; &lt;/Action&gt; &lt;/FlowControl&gt; 上面的xml配置文件类似于Struts2的struts.xml，用于表明整个项目中所有的请求与对应请求的响应，Action为我自己定义的用于处理相关的请求动作类，OperatePoint为动作类中不同的方法，用于减少过多动作类，将一组相关的动作处理放入到同一个类中，用不同的方法去处理，减少代码的冗余。123456789101112131415161718192021222324252627282930313233343536&lt;filter&gt; &lt;filter-name&gt;FrameFilter&lt;/filter-name&gt; &lt;filter-class&gt;edu.frame.web.core.FrameFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;ExcludedPages&lt;/param-name&gt; &lt;param-value&gt;/authImage,/register&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;DataBaseName&lt;/param-name&gt; &lt;param-value&gt;MySql&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;DBConfigFile&lt;/param-name&gt; &lt;param-value&gt;DBConfig.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;FlowControlConfigFile&lt;/param-name&gt; &lt;param-value&gt;flowcontrol.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;AppBasePath&lt;/param-name&gt; &lt;param-value&gt;edu.demo.web.flowcontrol&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;ConfigPath&lt;/param-name&gt; &lt;param-value&gt;config&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;JspPath&lt;/param-name&gt; &lt;param-value&gt;jsp&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;FrameFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 上述代码段来自web.xml，我们用一个名叫FrameFilter的filter来拦截浏览器发送的所有的请求然后判定请求的类别，如果是jsp页面，我们不做处理直接扔给服务器，如果是action类请求，我们获取路径分解出类名和方法名，利用Java反射机制实例化相应的的动作类执行相应的方法，然后返回结果字符串result，在根据结果result找到流程控制配置文件中对应的jsp页面扔给服务器。init-param部分为初始化参数，包括ExcludedPages（请求过滤页面），DataBaseName（选用数据库名称，我们将数据库的统一操作也封装在框架内，应用层通过配置文件来进行数据库的选择和连接），DBConfigFile（数据库配置文件）FlowControlConfigFile（流程控制文件），AppBasePath（action动作类目录），ConfigPath（配置文件地址），JspPath（页面地址）。因此FrameFilter.java为本框架中最核心的部分，下面我们来看一下此文件的具体内容123456789101112131415161718public class FrameFilter implements Filter &#123; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)&#123;&#125; //前处理，字符的乱码，数据库和流程控制配置文件的解析与实例化封装 public void perpare(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //初始化过滤器，加载web.xml文件中参数 public void init(FilterConfig config) throws ServletException &#123;&#125; //获取物理路径 private String getRealPath(FilterConfig config, String name)&#123;&#125; //请求匹配，判定是action还是jsp页面 public String actionMapping(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //action执行前的准备，action动作类名及方法的提取分离 public void prepareExecute(HttpServletRequest request, HttpServletResponse response,String functionName)&#123;&#125; //根据传来的动作类名和方法名去相应的action中执行相应的方法，返回result public String executeAction(HttpServletRequest request, HttpServletResponse response)&#123;&#125; //根据action类返回的result跳转到相应的jsp页面 public void dispatcher(HttpServletRequest request, HttpServletResponse response,String result)&#123;&#125;&#125; 上述即为流程控制的核心部分，涉及到的细节有xml配置文件的解析（需引入dom4j或者其他的xml解析jar包，例如数据库配置文件和流程控制文件的解析均需要用到），还有就是java的反射机制，已知类名和方法名的字符串实现类的实例化，及方法的执行。]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Struts</tag>
        <tag>JavaWeb</tag>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅尝MyBatis]]></title>
    <url>%2F2017%2F07%2F08%2F%E6%B5%85%E5%B0%9DMyBatis%2F</url>
    <content type="text"><![CDATA[引言什么是JDBC？ JDBC（Java DataBase Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。JDBC提供了一种基准，据此可以构建更高级的工具和接口，使数据库开发人员能够编写数据库应用程序。 有了JDBC，向各种关系数据发送SQL语句就是一件很容易的事。换言之，有了JDBC API，就不必为访问Sybase数据库专门写一个程序，为访问Oracle数据库又专门写一个程序，或为访问Informix数据库又编写另一个程序等等，程序员只需用JDBC API写一个程序就够了，它可向相应数据库发送SQL调用。同时，将Java语言和JDBC结合起来使程序员不必为不同的平台编写不同的应用程序，只须写一遍程序就可以让它在任何平台上运行，这也是Java语言“编写一次，处处运行”的优势。 JDBC的用途简单地说，JDBC 可做三件事：与数据库建立连接、发送 操作数据库的语句并处理结果。下列代码段给出了以上三步的基本示例：123456789Class.forName("sun.jdbc.odbc.JdbcOdbcDriver");Connection con = DriverManager.getConnection("jdbc:odbc:wombat","login","password");Statement stmt = con.createStatement();ResultSet rs = stmt.executeQuery("SELECT a, b, c FROM Table1");while (rs.next()) &#123; int x = rs.getInt("a"); String s = rs.getString("b"); float f = rs.getFloat("c");&#125; 正文MyBatis基本构成 SqlSessionFactoryBuilder：根据配置文件生成SqlSessionFactory 1234567891011public static SqlSessionFactory initSqlSessionFactory() &#123; try &#123; InputStream intputStream = Resources.getResourceAsStream("mybatis_config.xml"); &#125; catch (IOException e) &#123;&#125; synchronized(CLASS_LOCK)&#123; if(sqlSessionFactory == null)&#123; sqlSessionFactory = new SqlSessionFactoryBuilder().build(intputStream); &#125; &#125; return sqlSessionFactory;&#125; SqlSessionFactory：依靠工厂生成SqlSession会话 123456public static SqlSession openSqlSession()&#123; if(sqlSessionFactory == null)&#123; initSqlSessionFactory(); &#125; return sqlSessionFactory.openSession();&#125; SqlSession(类似于jdbc的Connection对象)：1)发送sql执行并返回结果，2)获取Mapper的接口 12345678910SqlSession session = sqlSessionFactory.openSession();//1)发送sql执行并返回结果，不建议使用try &#123; Role role = session.selectOne("org.mybatis.example.RoleMapper.getRole", 101); &#125; finally &#123; session.close(); &#125;//2)获取Mapper的接口，建议使用try &#123; RoleMapper mapper = session.getMapper(RoleMapper.class); Role role = mapper.getRole(101); &#125; finally &#123; session.close(); &#125; SQL Mapper：由java接口和xml文件或注解构成，需要给出对应的sql和映射规则，发送sql执行并返回结果。 XML配置文件方式实现Mapper 第一步给出java接口 123public interface RoleMapper &#123; public Role getRole(Long id);&#125; 第二步给出XML配置文件 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybtis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt; &lt;mapper namespace="com.mybatis.demo.mapper.RoleMapper"&gt; &lt;select id="getRole" parameterType="long" resultType="role"&gt; select id,role_name as roleName,role_name from t_role where id=#&#123;id&#125; &lt;/select&gt; &lt;/mapper&gt; 第三步给出javaBean类 123456789101112131415161718192021222324252627282930public class Role &#123; private Long id; private String roleName; private String note; public Role() &#123;&#125; public Role(Long id, String roleName, String note) &#123; super(); this.id = id; this.roleName = roleName; this.note = note; &#125; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getRoleName() &#123; return roleName; &#125; public void setRoleName(String roleName) &#123; this.roleName = roleName; &#125; public String getNote() &#123; return note; &#125; public void setNote(String note) &#123; this.note = note; &#125;&#125; 最后获取Mapper执行方法 123RoleMapper mapper = session.getMapper(RoleMapper.class); Role role = mapper.getRole(101); System.out.println(role.getRoleName()); java注解方式实现Mapper（不建议使用）1234public interface BlogMapper &#123; @Select("SELECT * FROM blog WHERE id = #&#123;id&#125;") Blog selectBlog(int id); &#125; MyBatis的配置上面我们用到了一个名为mybatis_config.xml的配置文件，下面我们来看一下文件具体内容123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt; &lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias = "role" type = "com.mybatis.demo.po.Role"/&gt; &lt;/typeAliases&gt; &lt;typeHandlers&gt; &lt;typeHandler handler="org.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;/typeHandlers&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="root"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="com/mybatis/demo/mapper/roleMapper.xml"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 首先我们来看数据源dataSource，引入数据源的方式有几种，我们分别介绍一下 第一种就是文件中的形式直接显示在property子元素中 1234&lt;property name="driver" value=""/&gt; &lt;property name="url" value=""/&gt; &lt;property name="username" value=""/&gt; &lt;property name="password" value=""/&gt; 第二种是使用properties配置文件 12345//jdbc.properties文件内容driver=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/mybatis username=root password=root 12//直接引入配置文件即可&lt;properties resource="jdbc.properties"/&gt; 如果properties配置文件中数据库用户名和密码是密文的形式，系统提供了解密方法DECODE(str)1234567891011121314151617181920212223public static SqlSessionFactory initSqlSessionFactory() &#123; InputStream cfgStream = null; Reader cfgReader = null; InputStream proStream = null; Reader proReader = null; Properties properties = null; try &#123; cfgStream = Resources.getResourceAsStream("mybatis_config.xml"); cfgReader = new InputStreamReader(cfgStream); proStream = Resources.getResourceAsStream("jdbc.properties"); proReader = new InputStreamReader(proStream); properties = new Properties(); properties.load(proReader); properties.setProperty("username", DECODE(properties.getProperty("username"))); properties.setProperty("password", DECODE(properties.getProperty("password"))); &#125; catch (IOException e) &#123;&#125; synchronized(CLASS_LOCK)&#123; if(sqlSessionFactory == null)&#123; sqlSessionFactory = new SqlSessionFactoryBuilder().build(cfgReader,properties); &#125; &#125; return sqlSessionFactory;&#125; 接下来我们看看typeAliases（别名） 逐个定义别名 123456&lt;typeAliases&gt; &lt;!-- 使用role来代替全路径com.mybatis.demo.po.Role --&gt; &lt;typeAlias alias = "role" type = "com.mybatis.demo.po.Role"/&gt; &lt;typeAlias alias = "a" type = "com.mybatis.demo.po.A"/&gt; ...&lt;/typeAliases&gt; 自动扫描（当定义数量较大时） 123&lt;typeAliases&gt; &lt;package name="com.mybatis.demo.po"&gt;&lt;/typeAliases&gt; 12345//当采用自动扫描方式的时候，配合注解@Alias()使用//若不使用注解则自动扫描按照当前类的首字母自动小写后为别名进行装载import org.apache.ibatis.type.Alias;@Alias("role")public class Role &#123;&#125; typeHandler类型处理器 MyBatis会在预处理语句（PrepareStatement）中设置一个参数时，或者从结果集（ResultSet）中取出一个值时，都会使用注册了的typeHandler进行处理，即实现javaType和jdbcType之间的相互转化。MyBatis中为我们提供了多种基本的typeHandler，同时我们也可以自定义typeHandler！ 自定义typeHandler 首先编写我们自己的typeHandler 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class MyStringTypeHandlerByInterface implements TypeHandler&lt;String&gt;&#123; private Logger log = Logger.getLogger(MyStringTypeHandler.class); @Override public String getResult(ResultSet rs, String columnName) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，resultSet列名获取字符串"); return rs.getString(columnName); &#125; @Override public String getResult(ResultSet rs, int columnIndex) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，resultSet下标获取字符串"); return rs.getString(columnIndex); &#125; @Override public String getResult(CallableStatement cs, int columnIndex) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler，CallableStatement下标获取字符串"); return cs.getString(columnIndex); &#125; @Override public void setParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException &#123; // TODO Auto-generated method stub log.info("使用我的typehandler"); ps.setString(i, parameter); &#125;&#125;//GenericTypeHandler.java /*You can create a generic TypeHandler that is able to handle more than one class. For that purpose add a constructor that receives the class as a parameter and MyBatis will pass the actual class when constructing the TypeHandler.*/public class GenericTypeHandler&lt;E extends MyObject&gt; extends BaseTypeHandler&lt;E&gt; &#123; private Class&lt;E&gt; type; public GenericTypeHandler(Class&lt;E&gt; type) &#123; if (type == null) throw new IllegalArgumentException("Type argument cannot be null"); this.type = type; &#125; ...``` - 然后我们有三种方法来使用自定义的typeHandler - 第一种是先在配置文件mybatis_config.xml中声明，然后在映射文件中使用 ```xml //mybatis_config.xml文件 &lt;typeHandlers&gt; &lt;typeHandler handler="com.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;!-- 自动扫描 &lt;package name="com.mybatis.demo.myTypeHandler"/&gt; --&gt; &lt;/typeHandlers&gt; //roleMapper.xml文件 &lt;resultMap type="role" id="roleMap"&gt; &lt;id column="id" property="id" javaType="long" jdbcType="BIGINT"/&gt; &lt;result column="role_name" property="roleName" javaType="String" jdbcType="VARCHAR"/&gt; &lt;/resultMap&gt; 第二种是直接在映射文件中定义具体typeHandler 12345//roleMapper.xml文件&lt;resultMap type="role" id="roleMap"&gt; &lt;id column="id" property="id" javaType="long" jdbcType="BIGINT"/&gt; &lt;result column="note" property="note" typeHandler="com.mybatis.demo.myTypeHandler.MyStringTypeHandler"/&gt; &lt;/resultMap&gt; 第三种是直接在参数中制定typeHandler 12345//roleMapper.xml文件 &lt;select id="findRole" parameterType="String" resultMap="roleMap"&gt; select id,role_name,role_name from t_role where role_name like concat('%',#&#123;roleName javaType=String, jdbcType=VARCHAR, typeHandler=com.mybatis.demo.myTypeHandler.MyStringTypeHandler&#125;, '%') &lt;/select&gt; 枚举typeHandler 系统枚举类 12345678910111213141516171819202122232425262728293031323334353637//创建性别枚举类Sexpublic enum Sex &#123; MALE(1,"男") , FEMALE(2,"女"); private int id; private String name; private Sex(int id, String name) &#123; this.id = id; this.name = name; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; //以下为自定义方法，供自定义typeHandler使用 public static Sex getSex(int id)&#123; if(id==1) return MALE; else if(id==2) return FEMALE; return null; &#125; public static Sex getSex(String name)&#123; if(name.equals("男")) return MALE; else if(name.equals("女")) return FEMALE; return null; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344mybatis_config.xml文件配置&lt;!-- 采用枚举字符串名称作为参数传递 --&gt;&lt;typeHandler handler="org.apache.ibatis.type.EnumTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt; &lt;!-- 采用整数下标作为参数传递 --&gt;&lt;typeHandler handler="org.apache.ibatis.type.EnumOrdinalTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt;roleMapper.xml文件配置&lt;result column="sex" property="sex" typeHandler="org.apache.ibatis.type.EnumTypeHandler"/&gt;&lt;result column="sex" property="sex" typeHandler="org.apache.ibatis.type.EnumOrdinalTypeHandler"/&gt;``` - 自定义枚举类，类似于前面所述的自定义typeHandler```java//创建自定义性别枚举类public class SexEnumTypeHandler implements TypeHandler&lt;Sex&gt;&#123; @Override public Sex getResult(ResultSet rs, String name) throws SQLException &#123; // TODO Auto-generated method stub /*自定义Id作为参数传递 int id = rs.getInt(name); return Sex.getSex(id);*/ //自定义Name作为参数传递 return Sex.getSex(rs.getString(name)); &#125; @Override public Sex getResult(ResultSet rs, int index) throws SQLException &#123; // TODO Auto-generated method stub /*int id = rs.getInt(index); return Sex.getSex(id);*/ return Sex.getSex(rs.getString(index)); &#125; @Override public Sex getResult(CallableStatement cs, int index) throws SQLException &#123; // TODO Auto-generated method stub /*int id = cs.getInt(index); return Sex.getSex(id);*/ return Sex.getSex(cs.getString(index)); &#125; @Override public void setParameter(PreparedStatement ps, int index, Sex sex, JdbcType jdbcType) throws SQLException &#123; // TODO Auto-generated method stub /*ps.setInt(index,sex.getId());*/ ps.setString(index, sex.getName()); &#125;&#125; 123456789101112131415161718192021222324252627 mybatis_config.xml文件配置 &lt;typeHandler handler="com.mybatis.demo.myTypeHandler.SexEnumTypeHandler" javaType="com.mybatis.demo.enums.Sex"/&gt; roleMapper.xml文件配置 &lt;result column="sex" property="sex" typeHandler="com.mybatis.demo.myTypeHandler.SexEnumTypeHandler"/&gt; ``` #### SQL元素的运用```xml&lt;sql id="userColumns"&gt; $&#123;alias&#125;.id,$&#123;alias&#125;.username,$&#123;alias&#125;.password &lt;/sql&gt;&lt;select id="selectUsers" resultType="map"&gt; select &lt;include refid="userColumns"&gt;&lt;property name="alias" value="t1"/&gt;&lt;/include&gt;, &lt;include refid="userColumns"&gt;&lt;property name="alias" value="t2"/&gt;&lt;/include&gt; from some_table t1 cross join some_table t2 &lt;/select&gt;&lt;sql id="sometable"&gt; $&#123;prefix&#125;Table &lt;/sql&gt;&lt;sql id="someinclude"&gt; from &lt;include refid="$&#123;include_target&#125;"/&gt; &lt;/sql&gt;&lt;select id="select" resultType="map"&gt; select field1, field2, field3 &lt;include refid="someinclude"&gt; &lt;property name="prefix" value="Some"/&gt; &lt;property name="include_target" value="sometable"/&gt; &lt;/include&gt; &lt;/select&gt; 级联 一对一关联 1234567891011121314151617181920&lt;!-- 方式一 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;association property="author" column="author_id" javaType="Author" select="selectAuthor"/&gt; &lt;/resultMap&gt;&lt;select id="selectBlog" resultMap="blogResult"&gt; SELECT * FROM BLOG WHERE ID = #&#123;id&#125; &lt;/select&gt;&lt;!-- 方式二 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;id property="id" column="blog_id" /&gt; &lt;result property="title" column="blog_title"/&gt; &lt;association property="author" resultMap="authorResult" /&gt; &lt;/resultMap&gt;&lt;resultMap id="authorResult" type="Author"&gt; &lt;id property="id" column="author_id"/&gt; &lt;result property="username" column="author_username"/&gt; &lt;result property="password" column="author_password"/&gt; &lt;result property="email" column="author_email"/&gt; &lt;result property="bio" column="author_bio"/&gt; &lt;/resultMap&gt; 一对多关联 12345678910111213141516171819&lt;!-- 方式一 --&gt;&lt;!-- javaType可有可无，MyBatis会自动识别返回数据类型 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;collection property="posts" javaType="ArrayList" column="id" ofType="Post" select="selectPostsForBlog"/&gt; &lt;/resultMap&gt;&lt;select id="selectBlog" resultMap="blogResult"&gt; SELECT * FROM BLOG WHERE ID = #&#123;id&#125; &lt;/select&gt;&lt;!-- 方式二 --&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;id property="id" column="blog_id" /&gt; &lt;result property="title" column="blog_title"/&gt; &lt;collection property="posts" ofType="Post" resultMap="blogPostResult" columnPrefix="post_"/&gt; &lt;/resultMap&gt;&lt;resultMap id="blogPostResult" type="Post"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="subject" column="subject"/&gt; &lt;result property="body" column="body"/&gt; &lt;/resultMap&gt; 鉴别器(eg：根据性别属性进行判定去关联不同的对象) 1234567891011121314&lt;discriminator javaType="int" column="sex"&gt; &lt;case value="1" resultType="maleStudentMap"&gt; &lt;result property="" column="" /&gt; &lt;/case&gt; &lt;case value="2" resultType="femaleStudentMap"&gt; &lt;result property="" column="" /&gt; &lt;/case&gt;&lt;/discriminator&gt;&lt;resultMap id="maleStudentMap" type="com.mybatis.demo.po.MaleStudentMap" extends="studentMap"&gt; &lt;result property="" column="" /&gt; &lt;/resultMap&gt;&lt;resultMap id="femaleStudentMap" type="com.mybatis.demo.po.FemaleStudentMap" extends="studentMap"&gt; &lt;result property="" column="" /&gt; &lt;/resultMap&gt; 延迟加载 全局变量lazyLoadingEnabled和aggressiveLazyLoading 开启lazyLoadingEnabled延迟加载，使得关联属性按需加载，而不是自动加载 当aggressiveLazyLoading为true时，MyBatis的内容按照层级加载，我们关闭它，从而实现按照我们调用需求加载 局部变量fetchType123&gt; &lt;association fetchType="lazy"/&gt; &gt; &lt;collection fetchType="lazy"/&gt; &gt; 动态SQL if 123456&lt;select id="findActiveBlogWithTitleLike" resultType="Blog"&gt; SELECT * FROM BLOG WHERE 1 = 1 &lt;if test="title != null"&gt; AND title like #&#123;title&#125; &lt;/if&gt; &lt;/select&gt; choose (when, otherwise) 1234567891011121314&lt;select id="findActiveBlogLike" resultType="Blog"&gt; SELECT * FROM BLOG WHERE 1 = 1 &lt;choose&gt; &lt;when test="title != null"&gt; AND title like #&#123;title&#125; &lt;/when&gt; &lt;when test="author != null and author.name != null"&gt; AND author_name like #&#123;author.name&#125; &lt;/when&gt; &lt;otherwise&gt; AND featured = 1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/select&gt; trim (where, set) 1234567891011121314151617181920212223242526272829303132333435&lt;select id="findActiveBlogLike" resultType="Blog"&gt; SELECT * FROM BLOG &lt;where&gt; &lt;if test="state != null"&gt; state = #&#123;state&#125; &lt;/if&gt; &lt;if test="title != null"&gt; AND title like #&#123;title&#125; &lt;/if&gt; &lt;if test="author != null and author.name != null"&gt; AND author_name like #&#123;author.name&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt;&lt;!-- prefix表示前缀为WHERE，prefixOverrides表示要去掉的元素 --&gt;&lt;trim prefix="WHERE" prefixOverrides="AND |OR "&gt; ... &lt;/trim&gt;&lt;!-- set实现动态更新，按需更新 --&gt;&lt;update id="updateAuthorIfNecessary"&gt; update Author &lt;set&gt; &lt;if test="username != null and username！=''"&gt; username=#&#123;username&#125;, &lt;/if&gt; &lt;if test="password != null"&gt; password=#&#123;password&#125;, &lt;/if&gt; &lt;if test="email != null"&gt; email=#&#123;email&#125;, &lt;/if&gt; &lt;if test="bio != null"&gt; bio=#&#123;bio&#125; &lt;/if&gt; &lt;/set&gt; where id=#&#123;id&#125; &lt;/update&gt; foreach 1234567&lt;select id="selectPostIn" resultType="domain.blog.Post"&gt; SELECT * FROM POST P WHERE ID in &lt;!-- item当前元素,index当前元素下标--&gt; &lt;foreach item="item" index="index" collection="list" open="(" separator=","close=")"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/select&gt; bind 12345&lt;!-- 不使用concat('%',#&#123;parameter&#125;, '%')实现模糊查询 --&gt;&lt;select id="selectBlogsLike" resultType="Blog"&gt; &lt;bind name="pattern" value="'%' + _parameter.getTitle() + '%'" /&gt; SELECT * FROM BLOG WHERE title LIKE #&#123;pattern&#125; &lt;/select&gt; GitHub实例——MyBatis_Example]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Database</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温JavaEE_SSH框架]]></title>
    <url>%2F2017%2F07%2F08%2F%E9%87%8D%E6%B8%A9JavaEE-SSH%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[知识只有当需要书写下来或者讲解出来的时候才显得如此匮乏——菜鸟飞 struts2 hibernate spring ssh整合及项目实例 Struts2 Struts2是一个基于MVC设计模式的Web应用框架，它本质上相当于一个servlet，在MVC设计模式中，Struts2作为控制器(Controller)来建立模型与视图的数据交互。——百度百科 在我看来，struts本质就类似于一个filter，所以在使用前需要在项目lib目录中导入相应的jar包并在项目的web.xml文件中配置如下内容12345678&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 配置完成后，所有的页面请求便会被截获到struts.xml的配置文件中，如下图所示，Struts2框架中核心组件就是Action、拦截器等，Struts2框架使用包来管理Action和拦截器等。每个包就是多个Action、多个拦截器、多个拦截器引用的集合。在struts.xml文件中package元素用于定义包配置，每个package元素定义了一个包配置。它的常用属性有： name：必填属性，用来指定包的名字。 extends：可选属性，用来指定该包继承其他包。继承其它包，可以继承其它包中的Action定义、拦截器定义等。 namespace：可选属性，用来指定该包的命名空间。(考虑到同一个Web应用中需要同名的Action，Struts2以命名空间的方式来管理Action，同一个命名空间不能有同名的Action。Struts2通过为包指定namespace属性来为包下面的所有Action指定共同的命名空间。) 其中action标签中的name属性表示与你所截获的请求名称进行匹配(也就是说将来你项目的所有页面请求在这里都会有所记录，可以清晰地体现你项目的页面跳转逻辑，同时也极大的方便了以后的更改操作)struts.xml12345678&lt;struts&gt; &lt;package name="default" extends="struts-default"&gt; &lt;action name="index" class="com.action.IndexAction"&gt; &lt;result name="success"&gt;index.jsp&lt;/result&gt; &lt;result name="error"&gt;error.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt; &lt;/struts&gt; 对应的action标签中的class属性表示该请求所对应的Action处理类，因为Struts2中的Action采用了低侵入式的设计，所以Struts2不要求Action类继承任何的Struts2的基类或实现Struts2接口。但是，我们为了方便实现Action，大多数情况下都会继承com.opensymphony.xwork2.ActionSupport类，并重写此类里的public String execute() throws Exception方法(Action处理类默认执行方法)。（因为此类中实现了很多的实用接口，提供了很多默认方法，这些默认方法包括获取国际化信息的方法、数据校验的方法、默认的处理用户请求的方法等，这样可以大大的简化Action的开发。)，Action处理类的所有方法最后都会返回一个字符串，如SUCCESS给struts.xml，而action标签内的result标签中的name属性负责匹配传回的字符串，从而跳转至不同的页面123456789101112public class IndexAction extends ActionSupport&#123; public String execute()throws Exception&#123; try &#123; &#125; return SUCCESS; &#125; catch (Exception e) &#123; e.printStackTrace(); return ERROR; &#125; &#125; public String ownMethod()throws Exception&#123;&#125;&#125; 当然你也可以去书写并执行自己的方法，这时你只需要在处理类中加入自己的ownMethod()方法，并在struts.xml文件中的对应的action标签中做如下修改即可1&lt;action name="index" class="com.action.IndexAction!ownMethod"&gt; 以下内容为struts.xml配置详解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;struts&gt; &lt;!-- include节点是struts2中组件化的方式 可以将每个功能模块独立到一个xml配置文件中 然后用include节点引用 --&gt; &lt;include file="struts-default.xml"&gt;&lt;/include&gt; &lt;!-- 所有匹配*.action的请求都由struts2处理 --&gt; &lt;constant name="struts.action.extension" value="action" /&gt; &lt;!-- 是否启用开发模式 --&gt; &lt;constant name="struts.devMode" value="true" /&gt; &lt;!-- struts配置文件改动后，是否重新加载 --&gt; &lt;constant name="struts.configuration.xml.reload" value="true" /&gt; &lt;!-- 设置浏览器是否缓存静态内容 --&gt; &lt;constant name="struts.serve.static.browserCache" value="false" /&gt; &lt;!-- 请求参数的编码方式 --&gt; &lt;constant name="struts.i18n.encoding" value="utf-8" /&gt; &lt;!-- 每次HTTP请求系统都重新加载资源文件，有助于开发 --&gt; &lt;constant name="struts.i18n.reload" value="true" /&gt; &lt;!-- 文件上传最大值 --&gt; &lt;constant name="struts.multipart.maxSize" value="104857600" /&gt; &lt;!-- 让struts2支持动态方法调用 --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="true" /&gt; &lt;!-- Action名称中是否还是用斜线 --&gt; &lt;constant name="struts.enable.SlashesInActionNames" value="false" /&gt; &lt;!-- 允许标签中使用表达式语法 --&gt; &lt;constant name="struts.tag.altSyntax" value="true" /&gt; &lt;!-- 对于WebLogic,Orion,OC4J此属性应该设置成true --&gt; &lt;constant name="struts.dispatcher.parametersWorkaround" value="false" /&gt; &lt;package name="basePackage" extends="struts-default"&gt; &lt;interceptors&gt; &lt;!-- 定义拦截器 name:拦截器名称 class:拦截器类路径 --&gt; &lt;interceptor name="timer" class="com.kay.timer"&gt;&lt;/interceptor&gt; &lt;interceptor name="logger" class="com.kay.logger"&gt;&lt;/interceptor&gt; &lt;!-- 定义拦截器栈 --&gt; &lt;interceptor-stack name="mystack"&gt; &lt;interceptor-ref name="timer"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="logger"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;!-- 定义默认的拦截器 每个Action都会自动引用 如果Action中引用了其它的拦截器 默认的拦截器将无效 --&gt; &lt;default-interceptor-ref name="mystack"&gt;&lt;/default-interceptor-ref&gt; &lt;!-- 全局results配置 --&gt; &lt;global-results&gt; &lt;result name="input"&gt;/error.jsp&lt;/result&gt; &lt;/global-results&gt; &lt;action name="" class=""&gt; &lt;!-- 引用拦截器 name:拦截器名称或拦截器栈名称 --&gt; &lt;interceptor-ref name="timer"&gt;&lt;/interceptor-ref&gt; &lt;!-- 节点配置 name : result名称 和Action中返回的值相同 type : result类型 不写则选用superpackage的type struts-default.xml中的默认为dispatcher --&gt; &lt;result name="success" type="dispatcher"&gt;/talk.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 允许一个Action内包含多个请求处理方法：动态方法调用是指：表单元素的action不直接等于某个Action的名字，而是以感叹号后加方法名来指定对应的动作名：要使用动态方法调用，必须设置Struts2允许动态方法调用，通过设置struts.enable.DynamicMethodInvocation常量来完成，该常量属性的默认值是true。1234567&lt;struts&gt; &lt;!-- //禁用动态方法调用，默认为true启用，false禁用 constant:name="struts.enable.DynamicMethodInvocation" --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="true" /&gt;&lt;/struts&gt; 默认Action： 在浏览器输入一个不存在的Action，页面将呈现404错误，为了网站更友好，我们可以设置一个默认的Action。1234&lt;default-action-ref name="defaultAction"&gt;&lt;/default-action-ref&gt; &lt;action name="defaultAction"&gt; &lt;result&gt;/error.jsp&lt;/result&gt; &lt;/action&gt; 处理结果类型： Struts2提供了对不同种类返回结果的支持，常见的有JSP，FreeMarker，Velocity等。 Struts2支持的不同类型的返回结果为：(加粗为常用) 名字 说明 chain 用来处理Action链 dispatcher 用来转向页面，通常处理JSP，这是默认的结果类型 freeMarker 处理FreeMarker模板 httpHeader 用来控制特殊的Http行为 redirect 重定向到一个URL redirect-action 重定向到一个Action stream 向浏览器发送InputSream对象，通常用来处理文件下载 velocity 处理Velocity模板 xslt 处理XML/XLST模板 plaintext 显示原始文件内容，例如文件源代码 tiles 结合Tile使用strutsUI页面标签库的引用需在jsp页面加入以下内容（详细介绍链接）1&lt;%@ taglib prefix="s" uri="/struts-tags"%&gt; Hibernate Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。——百度百科 Hibernate的API一共有6个，分别为:Session、SessionFactory、Transaction、Query、Criteria和Configuration。通过这些接口，可以对持久化对象进行存取、事务控制。 SessionSession接口负责执行被持久化对象的CRUD操作(CRUD的任务是完成与数据库的交流，包含了很多常见的SQL语句)。但需要注意的是Session对象是非线程安全的。同时，Hibernate的session不同于JSP应用中的HttpSession。这里当使用session这个术语时，其实指的是Hibernate中的session，而以后会将HttpSession对象称为用户session。 SessionFactorySessionFactory接口负责初始化Hibernate。它充当数据存储源的代理，并负责创建Session对象。这里用到了工厂模式。需要注意的是SessionFactory并不是轻量级的，因为一般情况下，一个项目通常只需要一个SessionFactory就够，当需要操作多个数据库时，可以为每个数据库指定一个SessionFactory。 TransactionTransaction 接口是一个可选的API，可以选择不使用这个接口，取而代之的是Hibernate 的设计者自己写的底层事务处理代码。 Transaction 接口是对实际事务实现的一个抽象，这些实现包括JDBC的事务、JTA 中的UserTransaction、甚至可以是CORBA 事务。之所以这样设计是能让开发者能够使用一个统一事务的操作界面，使得自己的项目可以在不同的环境和容器之间方便地移植。 QueryQuery接口让你方便地对数据库及持久对象进行查询，它可以有两种表达方式：HQL语言或本地数据库的SQL语句。Query经常被用来绑定查询参数、限制查询记录数量，并最终执行查询操作。 CriteriaCriteria接口与Query接口非常类似，允许创建并执行面向对象的标准化查询。值得注意的是Criteria接口也是轻量级的，它不能在Session之外使用。 ConfigurationConfiguration 类的作用是对Hibernate 进行配置，以及对它进行启动。在Hibernate 的启动过程中，Configuration 类的实例首先定位映射文档的位置，读取这些配置，然后创建一个SessionFactory对象。虽然Configuration 类在整个Hibernate 项目中只扮演着一个很小的角色，但它是启动hibernate 时所遇到的第一个对象。 Hibernate.xml配置 Hibernate.show_sql：是否在运行时候sql语句输出到控制台，编码阶段便于测试的。（默认设置为true） Hibernate.format_sql：输出在控制台sql语句是否进行排版，便于阅读。（默认设置为true） Hbm2ddl.auto：可帮助由Java代码生成数据库脚本，进而生成具体表结构。如：create/update/create-drop/validate。 hbm2ddl.auto: 生成表结构的策略配置update(最常用的取值): 如果当前数据库中不存在表结构,那么自动创建表结构.如果存在表结构,并且表结构与实体一致,那么不做修改如果存在表结构,并且表结构与实体不一致,那么会修改表结构.会保留原有列.create(很少):无论是否存在表结构.每次启动Hibernate都会重新创建表结构.(数据会丢失)create-drop(极少): 无论是否存在表结构.每次启动Hibernate都会重新创建表结构.每次Hibernate运行结束时,删除表结构.validate(很少):不会自动创建表结构.也不会自动维护表结构.Hibernate只校验表结构. 如果表结构不一致将会抛出异常.12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC"-//Hibernate/Hibernate Configuration DTD 3.0//EN""http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- property 元素用于配置Hibernate中的属性键:值 --&gt; &lt;!-- hibernate.connection.driver_class : 连接数据库的驱动 --&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!-- hibernate.connection.username : 连接数据库的用户名 --&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;!-- hibernate.connection.password : 连接数据库的密码 --&gt; &lt;property name="hibernate.connection.password"&gt;123&lt;/property&gt; &lt;!-- hibernate.connection.url : 连接数据库的地址,路径 --&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hibernatedemｏ&lt;/property&gt; &lt;!-- show_sql: 操作数据库时,会 向控制台打印sql语句 --&gt; &lt;property name="show_sql"&gt;true&lt;/property&gt; &lt;!-- format_sql: 打印sql语句前,会将sql语句先格式化 --&gt; &lt;property name="format_sql"&gt;true&lt;/property&gt; &lt;property name="hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 数据库方言配置org.hibernate.dialect.MySQLDialect (选择最短的)--&gt; &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- hibernate.connection.autocommit: 事务自动提交 --&gt; &lt;property name="hibernate.connection.autocommit"&gt;true&lt;/property&gt; &lt;!-- 将Session与线程绑定=&gt; 只有配置了该配置,才能使用getCurrentSession --&gt; &lt;property name="hibernate.current_session_context_class"&gt;thread&lt;/property&gt; &lt;!-- 引入ORM 映射文件 填写src之后的路径--&gt; &lt;mapping resource="com/itheima/a_hello/User.hbm.xml"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; XXXX.hbm.xml(ecplise可自动生成)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0"?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt; &lt;!-- &lt;hibernate-mapping&gt;一般不去配置，采用默认即可。 default-cascade="none"：默认的级联风格，表与表联动。 default-lazy="true"：默认延迟加载 --&gt; &lt;hibernate-mapping&gt; &lt;!-- &lt;class&gt;：使用class元素定义一个持久化类。 name="cn.javass.user.vo.UserModel"：持久化类的java全限定名； table="tbl_user"：对应数据库表名； mutable="true"：默认为true，设置为false时则不可以被应用程序更新或删除； dynamic-insert="false"：默认为false，动态修改那些有改变过的字段，而不用修改所有字段； dynamic-update="false"：默认为false，动态插入非空值字段； select-before-update="false"：默认为false，在修改之前先做一次查询，与用户的值进行对比，有变化都会真正更新； optimistic-lock="version"：默认为version(检查version/timestamp字段)，取值：all(检查全部字段)、dirty(只检查修改过的字段)、 none(不使用乐观锁定)，此参数主要用来处理并发，每条值都有固定且唯一的版本，版本为最新时才能执行操作； --&gt; &lt;class name="cn.javass.user.vo.UserModel" table="tbl_user" dynamic-insert="true" dynamic-update="true" optimistic-lock="version"&gt; &lt;!-- &lt;id&gt;：定义了该属性到数据库表主键字段的映射。 name="userId"：标识属性的名字； column="userId"：表主键字段的名字，如果不填写与name一样； --&gt; &lt;id name="userId"&gt; &lt;!-- &lt;generator&gt;：指定主键由什么生成，推荐使用uuid（随机生成唯一通用的表示符，实体类的ID必须是String）， native（让数据库自动选择用什么生成（根据底层数据库的能力选择identity，sequence或hilo中的一种））， assigned（指用户手工填入，默认）。 --&gt; &lt;generator class="uuid"/&gt; &lt;/id&gt; &lt;!-- &lt;version/&gt;：使用版本控制来处理并发，要开启optimistic-lock="version"和dynamic-update="true"。 name="version"：持久化类的属性名，column="version"：指定持有版本号的字段名； --&gt; &lt;version name="version" column="version"/&gt; &lt;!-- &lt;property&gt;：为类定义一个持久化的javaBean风格的属性。 name="name"：标识属性的名字，以小写字母开头； column="name"：表主键字段的名字，如果不填写与name一样； update="true"/insert="true"：默认为true，表示可以被更新或插入； --&gt; &lt;property name="name" column="name" /&gt; &lt;property name="sex" column="sex"/&gt; &lt;property name="age" column="age"/&gt; &lt;!-- 组件映射：把多个属性打包在一起当一个属性使用，用来把类的粒度变小。 &lt;component name="属性，这里指对象"&gt; &lt;property name="name1"&gt;&lt;/property&gt; &lt;property name="name2"&gt;&lt;/property&gt; &lt;/component&gt; --&gt; &lt;!-- &lt;join&gt;:一个对象映射多个表，该元素必须放在所有&lt;property&gt;之后。 &lt;join table="tbl_test：子表名"&gt; &lt;key column="uuid：子表主键"&gt;&lt;/key&gt; &lt;property name="name1：对象属性" column="name：子表字段"&gt;&lt;/property&gt; &lt;/join&gt; --&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; 实例 post.hbm.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping&gt; &lt;class name="com.form.Post" table="post"&gt; &lt;id name="id" type="java.lang.Integer"&gt; &lt;column name="id"/&gt; &lt;generator class="identity"/&gt; &lt;/id&gt; &lt;many-to-one name="admin" class="com.form.Admin" fetch="select" lazy="false"&gt; &lt;column name="aid"/&gt; &lt;/many-to-one&gt; &lt;many-to-one name="user" class="com.form.User" fetch="select" lazy="false"&gt; &lt;column name="uid"/&gt; &lt;/many-to-one&gt; &lt;many-to-one name="board" class="com.form.Board" fetch="select" lazy="false"&gt; &lt;column name="bid"/&gt; &lt;/many-to-one&gt; &lt;property name="name" type="string"&gt; &lt;column name="name"/&gt; &lt;/property&gt; &lt;property name="content" type="string"&gt; &lt;column name="content"/&gt; &lt;/property&gt; &lt;property name="publishTime" type="timestamp"&gt; &lt;column name="publishTime"/&gt; &lt;/property&gt; &lt;property name="count" type="java.lang.Integer"&gt; &lt;column name="count"/&gt; &lt;/property&gt; &lt;property name="photoPath" type="string"&gt; &lt;column name="photoPath"/&gt; &lt;/property&gt; &lt;set name="replies" inverse="true" cascade="all-delete-orphan" lazy="false" order-by="publishTime desc"&gt; &lt;key&gt; &lt;column name="pid" not-null="true"/&gt; &lt;/key&gt; &lt;one-to-many class="com.form.Reply"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;``` ### 说说为什么使用lazy```xml&lt;set name="replies" inverse="true" cascade="all-delete-orphan" lazy="true"&gt; 当使用Hibernate中的one-to-many、many-to one、many-to-many关系映射的时候，一个对象中会包含一个或多个Set来关联其他的对象。例如：user-groups，当程序取user 对象时，如果一个用户有多个自定义组，那么程序将把组的信息也读取出来，在log中可以看到两个sql的输出。但是在页面的显示上，也许并不需要显示这个用户相关组的信息，这样系统的消耗就白白浪费了，于是hibernate提供了lazy（延迟加载）的方法来避免这一情况的发生，我们只需要在 user.hbm.xml中设置lazy=true，就能实现延迟加载。 Spring 是一个非常强大的反转控制(IOC)框架，以帮助分离项目组件之间的依赖关系 控制反转——Spring通过一种称作控制反转（IoC）的技术促进了低耦合。当应用了IoC，一个对象依赖的其它对象会通过被动的方式传递进来，而不是这个对象自己创建或者查找依赖对象。你可以认为IoC与JNDI相反——不是对象从容器中查找依赖，而是容器在对象初始化时不等对象请求就主动将依赖传递给它。 面向切面——Spring提供了面向切面编程的丰富支持，允许通过分离应用的业务逻辑与系统级服务（例如审计（auditing）和事务（transaction）管理）进行内聚性的开发。应用对象只实现它们应该做的——完成业务逻辑——仅此而已。它们并不负责（甚至是意识）其它的系统级关注点，例如日志或事务支持。 容器——Spring包含并管理应用对象的配置和生命周期，在这个意义上它是一种容器，你可以配置你的每个bean如何被创建——基于一个可配置原型（prototype），你的bean可以创建一个单独的实例或者每次需要时都生成一个新的实例——以及它们是如何相互关联的。 web.xml配置123456789101112131415161718192021&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;filter&gt;&lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.orm.hibernate4.support.OpenSessionInViewFilter&lt;/filter-class&gt;&lt;init-param&gt; &lt;param-name&gt;org.springframework.orm.hibernate4.LocalSessionFactoryBean&lt;/param-name&gt; &lt;param-value&gt;sessionFactory&lt;/param-value&gt;&lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt;&lt;/filter-mapping&gt; 说说为什么使用OpenSessionInView1&lt;filter-name&gt;openSessionInViewFilter&lt;/filter-name&gt; 当hibernate+spring配合使用的时候，如果设置了lazy=true,那么在读取数据的时候，当读取了父数据后，hibernate会自动关闭session，这样，当要使用子数据的时候，系统会抛出lazyinit的错误，这时就需要使用spring提供的 OpenSessionInViewFilter,OpenSessionInViewFilter主要是保持Session状态知道request将全部页面发送到客户端，这样就可以解决延迟加载带来的问题 applicationContext.xml配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?xml version="1.0" encoding="UTF-8"? &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd" &lt;!-- 自动扫描与装配bean，扫描web包，将带有注解的类纳入spring容器管理 --&gt; &lt;!-- &lt;context:component-scan base-package="cn.itcast.oa"&gt;作用 Spring容器初始化时，会扫描cn.itcast.oa目录下标有@Component；@Service；@Controller；@Repository 注解的类纳入Spring容器管理 在类上，使用以下注解，实现bean的声明： @Component：泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @Service 用于标注业务层组件 @Controller 用于标注控制层组件（如springMvc的controller，struts中的action） @Repository用于标注数据访问组件，即DAO组件 在类的成员变量上，使用以下注解，实现属性的自动装配 @Autowired ：按类的类型进行装配 @Resource： 1.如果同时指定了name和type，那么从Spring上下文中找到唯一匹配的bean进行装配 2. 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常 3.如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常 4.如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配； --&gt; &lt;context:component-scan base-package="cn.itcast.oa"&gt;&lt;/context:component-scan&gt; &lt;!-- 加载外部的properties配置文件（引入jdbc的配置文件） -- &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!-- 配置数据库连接池（c3p0）这个可以在hibernate.cfg.xml中配置 -- &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;!-- 基本信息 ：jdbc的url、驱动名、数据库名字、密码-- &lt;property name="jdbcUrl" value="$&#123;jdbcUrl&#125;"&gt;&lt;/property&gt; &lt;property name="driverClass" value="$&#123;driverClass&#125;"&gt;&lt;/property&gt; &lt;property name="user" value="$&#123;username&#125;"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;password&#125;"&gt;&lt;/property&gt; &lt;!-- 其他配置 -- &lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 -- &lt;property name="initialPoolSize" value="3"&gt;&lt;/property&gt; &lt;!--连接池中保留的最小连接数。Default: 3 -- &lt;property name="minPoolSize" value="3"&gt;&lt;/property&gt; &lt;!--连接池中保留的最大连接数。Default: 15 -- &lt;property name="maxPoolSize" value="5"&gt;&lt;/property&gt; &lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 -- &lt;property name="acquireIncrement" value="3"&gt;&lt;/property&gt;&lt;!-- 控制数据源内加载的PreparedStatements数量。如果maxStatements与maxStatementsPerConnection均为0，则缓存被关闭。Default: 0 -- &lt;property name="maxStatements" value="8"&gt;&lt;/property&gt;&lt;!-- maxStatementsPerConnection定义了连接池内单个连接所拥有的最大缓存statements数。Default: 0 -- &lt;property name="maxStatementsPerConnection" value="5"&gt;&lt;/property&gt; &lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 -- &lt;property name="maxIdleTime" value="1800"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置SessionFactory （把数据源注入给session工厂）、配置映射文件将Spring与hibernate初步整合起来 -- &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.LocalSessionFactoryBean" &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property &lt;property name="configLocation" value="classpath:hibernate.cfg.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置声明式的事务管理（采用基于注解的方式） session工厂注入到事务管理器transactionManager使Spring与Hinbernate整合实现业务逻辑 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.hibernate3.HibernateTransactionManager" &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; &lt;/beans&gt; 常见问题 自动装配与扫描有问题，context的命名空间的问题1&lt;context:component-scan base-package="cn.itcast.oa"&gt;&lt;/context:component-scan&gt; &lt;beans xmlns=”http://www.springframework.org/schema/beans“ xmlns:context=”http://www.springframework.org/schema/context“ ssh整合及项目实例项目实例链接:https://github.com/LFstefan/JavaEE]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Struts</tag>
        <tag>JavaWeb</tag>
        <tag>Architecture</tag>
        <tag>Spring</tag>
        <tag>Hibernate</tag>
        <tag>Frame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树]]></title>
    <url>%2F2017%2F07%2F01%2F%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树红黑树，一种自平衡二叉查找树，又称之为”对称二叉B树”，虽然复杂，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的：它可以在logn时间内做查找，插入和删除。 红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。 红黑树是2-3-4树的一种等同。换句话说，对于每个2-3-4树，都存在至少一个数据元素是同样次序的红黑树。在2-3-4树上的插入和删除操作也等同于在红黑树中颜色翻转和旋转。这使得2-3-4树成为理解红黑树背后的逻辑的重要工具，这也是很多介绍算法的教科书在红黑树之前介绍2-3-4树的原因，尽管2-3-4树在实践中不经常使用。 性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 下面是一个具体的红黑树的图例： 这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 要知道为什么这些性质确保了这个结果，注意到性质4导致了路径不能有两个毗连的红色节点就足够了。最短的可能路径都是黑色节点，最长的可能路径有交替的红色和黑色节点。因为根据性质5所有最长的路径都有相同数目的黑色节点，这就表明了没有路径能多于任何其他路径的两倍长。 在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用”nil叶子”或”空（null）叶子”，如上图所示，它不包含数据而只充当树在此结束的指示。这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再匹配红黑树的性质。恢复红黑树的性质需要少量的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为logn次。 插入 我们首先以二叉查找树的方法增加节点并标记它为红色。（如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换和树旋转来调整。）下面要进行什么操作取决于其他临近节点的颜色。同人类的家族树中一样，我们将使用术语叔父节点来指一个节点的父节点的兄弟节点。注意： 性质1和性质3总是保持着。 性质4只在增加红色节点、重绘黑色节点为红色，或做旋转时受到威胁。 性质5只在增加黑色节点、重绘红色节点为黑色，或做旋转时受到威胁。 在下面的的代码中，将要插入的节点标为N，N的父节点标为P，N的祖父节点标为G，N的叔父节点标为U。 通过下列函数，可以找到一个节点的叔父和祖父节点：123456789public node grandparent(node n)&#123; return n.parent.parent;&#125;public node uncle(node n)&#123; if(n.parent == grandparent(n).left) return grandparent (n).right; else return grandparent (n).left;&#125; 情形1:新节点N位于树的根上，没有父节点。在这种情形下，我们把它重绘为黑色以满足性质2。因为它在每个路径上对黑节点数目增加一，性质5匹配。123456public void insert_case1(node n)&#123; if(n.parent == NULL) n.color = BLACK; else insert_case2 (n);&#125; 情形2:新节点的父节点P是黑色，所以性质4没有失效（新节点是红色的）。在这种情形下，树仍是有效的。性质5也未受到威胁，尽管新节点N有两个黑色叶子子节点；但由于新节点N是红色，通过它的每个子节点的路径就都有同通过它所取代的黑色的叶子的路径同样数目的黑色节点，所以依然满足这个性质。123456public void insert_case2(node n)&#123; if(n.parent.color == BLACK) return; /* 树仍旧有效*/ else insert_case3 (n);&#125; 注意：在下列情形下我们假定新节点的父节点为红色，所以它有祖父节点；因为如果父节点是根节点，那父节点就应当是黑色。所以新节点总有一个叔父节点，尽管在情形4和5下它可能是叶子节点。 情形3:如果父节点P和叔父节点U二者都是红色，（此时新插入节点N做为P的左子节点或右子节点都属于情形3，这里右图仅显示N做为P左子的情形）则我们可以将它们两个重绘为黑色并重绘祖父节点G为红色（用来保持性质5）。现在我们的新节点N有了一个黑色的父节点P。因为通过父节点P或叔父节点U的任何路径都必定通过祖父节点G，在这些路径上的黑节点数目没有改变。但是，红色的祖父节点G可能是根节点，这就违反了性质2，也有可能祖父节点G的父节点是红色的，这就违反了性质4。为了解决这个问题，我们在祖父节点G上递归地进行情形1的整个过程。（把G当成是新加入的节点进行各种情形的检查）12345678910public void insert_case3(node n)&#123; if(uncle(n) != NULL &amp;&amp; uncle (n).color == RED) &#123; n.parent.color = BLACK; uncle (n).color = BLACK; grandparent (n).color = RED; insert_case1(grandparent(n)); &#125; else insert_case4 (n);&#125; 注意：在余下的情形下，我们假定父节点P是其父亲G的左子节点。如果它是右子节点，情形4和情形5中的左和右应当对调。 情形4:父节点P是红色而叔父节点U是黑色或缺少，并且新节点N是其父节点P的右子节点而父节点P又是其父节点的左子节点。在这种情形下，我们进行一次左旋转调换新节点和其父节点的角色;接着，我们按情形5处理以前的父节点P以解决仍然失效的性质4。注意这个改变会导致某些路径通过它们以前不通过的新节点N（比如图中1号叶子节点）或不通过节点P（比如图中3号叶子节点），但由于这两个节点都是红色的，所以性质5仍有效。12345678910public void insert_case4(node n)&#123; if(n == n.parent.right &amp;&amp; n.parent == grandparent(n).left) &#123; rotate_left(n-&gt;parent); n = n-&gt;left; &#125; else if(n == n.parent.left &amp;&amp; n.parent == grandparent(n).right) &#123; rotate_right(n.parent); n = n.right; &#125; insert_case5 (n);&#125; 情形5：父节点P是红色而叔父节点U是黑色或缺少，新节点N是其父节点的左子节点，而父节点P又是其父节点G的左子节点。在这种情形下，我们进行针对祖父节点G的一次右旋转；在旋转产生的树中，以前的父节点P现在是新节点N和以前的祖父节点G的父节点。我们知道以前的祖父节点G是黑色，否则父节点P就不可能是红色（如果P和G都是红色就违反了性质4，所以G必须是黑色）。我们切换以前的父节点P和祖父节点G的颜色，结果的树满足性质4。性质5也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过祖父节点G，现在它们都通过以前的父节点P。在各自的情形下，这都是三个节点中唯一的黑色节点。12345678910public void insert_case5(node n)&#123; n.parent.color = BLACK; grandparent (n).color = RED; if(n == n.parent.left &amp;&amp; n.parent == grandparent(n).left) &#123; rotate_right(grandparent(n)); &#125; else &#123; /* Here, n == n.parent.right &amp;&amp; n.parent == grandparent (n).right */ rotate_left(grandparent(n)); &#125;&#125; 注意插入实际上是原地算法，因为上述所有调用都使用了尾部递归。 删除 如果需要删除的节点有两个儿子，那么问题可以被转化成删除另一个只有一个儿子的节点的问题（为了表述方便，这里所指的儿子，为非叶子节点的儿子）。对于二叉查找树，在删除带有两个非叶子儿子的节点的时候，我们找到要么在它的左子树中的最大元素、要么在它的右子树中的最小元素，并把它的值转移到要删除的节点中。我们接着删除我们从中复制出值的那个节点，它必定有少于两个非叶子的儿子。因为只是复制了一个值，不违反任何性质，这就把问题简化为如何删除最多有一个儿子的节点的问题。它不关心这个节点是最初要删除的节点还是我们从中复制出值的那个节点。 在本文余下的部分中，我们只需要讨论删除只有一个儿子的节点（如果它两个儿子都为空，即均为叶子，我们任意将其中一个看作它的儿子）。如果我们删除一个红色节点（此时该节点的儿子将都为叶子节点），它的父亲和儿子一定是黑色的。所以我们可以简单的用它的黑色儿子替换它，并不会破坏性质3和性质4。通过被删除节点的所有路径只是少了一个红色节点，这样可以继续保证性质5。另一种简单情况是在被删除节点是黑色而它的儿子是红色的时候。如果只是去除这个黑色节点，用它的红色儿子顶替上来的话，会破坏性质5，但是如果我们重绘它的儿子为黑色，则曾经通过它的所有路径将通过它的黑色儿子，这样可以继续保持性质5。 需要进一步讨论的是在要删除的节点和它的儿子二者都是黑色的时候，这是一种复杂的情况。我们首先把要删除的节点替换为它的儿子。出于方便，称呼这个儿子为N（在新的位置上），称呼它的兄弟（它父亲的另一个儿子）为S。在下面的示意图中，我们还是使用P称呼N的父亲，SL称呼S的左儿子，SR称呼S的右儿子。我们将使用下述函数找到兄弟节点： 123456public node sibling(node n)&#123; if(n == n-&gt;parent-&gt;left) return n-&gt;parent-&gt;right; else return n-&gt;parent-&gt;left;&#125; 我们可以使用下列代码进行上述的概要步骤，这里的函数replace_node替换child到n在树中的位置。出于方便，在本章节中的代码将假定空叶子被用不是NULL的实际节点对象来表示（在插入章节中的代码可以同任何一种表示一起工作）。 123456789101112public void delete_one_child(struct node *n)&#123; //Precondition: n has at most one non-null child. struct node *child = is_leaf(n-&gt;right)? n-&gt;left : n-&gt;right; replace_node(n, child); if(n-&gt;color == BLACK)&#123; if(child-&gt;color == RED) child-&gt;color = BLACK; else delete_case1 (child); &#125; free (n);&#125; 如果N和它初始的父亲是黑色，则删除它的父亲导致通过N的路径都比不通过它的路径少了一个黑色节点。因为这违反了性质5，树需要被重新平衡。有几种情形需要考虑： 情形1: N是新的根。在这种情形下，我们就做完了。我们从所有路径去除了一个黑色节点，而新根是黑色的，所以性质都保持着。1234public void delete_case1(struct node *n)&#123; if(n-&gt;parent != NULL) delete_case2 (n);&#125; 注意：在情形2、5和6下，我们假定N是它父亲的左儿子。如果它是右儿子，则在这些情形下的左和右应当对调。 情形2： S是红色。在这种情形下我们在N的父亲上做左旋转，把红色兄弟转换成N的祖父，我们接着对调N的父亲和祖父的颜色。完成这两个操作后，尽管所有路径上黑色节点的数目没有改变，但现在N有了一个黑色的兄弟和一个红色的父亲（它的新兄弟是黑色因为它是红色S的一个儿子），所以我们可以接下去按情形4、情形5或情形6来处理。 注意：N是删除了黑色节点后替换上来的子节点，所以这个过程中由P-&gt;X-&gt;N变成了P-&gt;N，实际上是少了一个黑色节点，也可以理解为Parent(Black)和Silbing(Red)那么他们的孩子黑色节点的数目肯定不等，让他们做新兄弟肯定是不平衡的，还需后面继续处理。 123456789101112public void delete_case2(struct node *n)&#123; struct node *s = sibling (n); if(s-&gt;color == RED)&#123; n-&gt;parent-&gt;color = RED; s-&gt;color = BLACK; if(n == n-&gt;parent-&gt;left) rotate_left(n-&gt;parent); else rotate_right(n-&gt;parent); &#125; delete_case3 (n);&#125; 情形3： N的父亲、S和S的儿子都是黑色的。在这种情形下，我们简单的重绘S为红色。结果是通过S的所有路径，它们就是以前不通过N的那些路径，都少了一个黑色节点。因为删除N的初始的父亲使通过N的所有路径少了一个黑色节点，这使事情都平衡了起来。但是，通过P的所有路径现在比不通过P的路径少了一个黑色节点，所以仍然违反性质5。要修正这个问题，我们要从情形1开始，在P上做重新平衡处理。123456789public void delete_case3(struct node *n)&#123; struct node *s = sibling (n); if((n-&gt;parent-&gt;color == BLACK)&amp;&amp;(s-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == BLACK)) &#123; s-&gt;color = RED; delete_case1(n-&gt;parent); &#125; else delete_case4 (n);&#125; 情形4： S和S的儿子都是黑色，但是N的父亲是红色。在这种情形下，我们简单的交换N的兄弟和父亲的颜色。这不影响不通过N的路径的黑色节点的数目，但是它在通过N的路径上对黑色节点数目增加了一，添补了在这些路径上删除的黑色节点。123456789public void delete_case4(struct node *n)&#123; struct node *s = sibling (n); if（(n-&gt;parent-&gt;color == RED)&amp;&amp;(s-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == BLACK)) &#123; s-&gt;color = RED; n-&gt;parent-&gt;color = BLACK; &#125; else delete_case5 (n);&#125; 情形5： S是黑色，S的左儿子是红色，S的右儿子是黑色，而N是它父亲的左儿子。在这种情形下我们在S上做右旋转，这样S的左儿子成为S的父亲和N的新兄弟。我们接着交换S和它的新父亲的颜色。所有路径仍有同样数目的黑色节点，但是现在N有了一个黑色兄弟，他的右儿子是红色的，所以我们进入了情形6。N和它的父亲都不受这个变换的影响。123456789101112131415public void delete_case5(struct node *n)&#123; struct node *s = sibling (n); if（s-&gt;color == BLACK)&#123; if((n == n-&gt;parent-&gt;left)&amp;&amp;(s-&gt;right-&gt;color == BLACK)&amp;&amp;(s-&gt;left-&gt;color == RED)) &#123; // this last test is trivial too due to cases 2-4. s-&gt;color = RED; s-&gt;left-&gt;color = BLACK; rotate_right (s); &#125; else if((n == n-&gt;parent-&gt;right)&amp;&amp;(s-&gt;left-&gt;color == BLACK)&amp;&amp;(s-&gt;right-&gt;color == RED)) &#123;// this last test is trivial too due to cases 2-4. s-&gt;color = RED; s-&gt;right-&gt;color = BLACK; rotate_left (s); &#125; &#125; delete_case6 (n);&#125; 情形6： S是黑色，S的右儿子是红色，而N是它父亲的左儿子。在这种情形下我们在N的父亲上做左旋转，这样S成为N的父亲（P）和S的右儿子的父亲。我们接着交换N的父亲和S的颜色，并使S的右儿子为黑色。子树在它的根上的仍是同样的颜色，所以性质3没有被违反。但是，N现在增加了一个黑色祖先：要么N的父亲变成黑色，要么它是黑色而S被增加为一个黑色祖父。所以，通过N的路径都增加了一个黑色节点。此时，如果一个路径不通过N，则有两种可能性： 它通过N的新兄弟。那么它以前和现在都必定通过S和N的父亲，而它们只是交换了颜色。所以路径保持了同样数目的黑色节点。 它通过N的新叔父，S的右儿子。那么它以前通过S、S的父亲和S的右儿子，但是现在只通过S，它被假定为它以前的父亲的颜色，和S的右儿子，它被从红色改变为黑色。合成效果是这个路径通过了同样数目的黑色节点。 在任何情况下，在这些路径上的黑色节点数目都没有改变。所以我们恢复了性质4。在示意图中的白色节点可以是红色或黑色，但是在变换前后都必须指定相同的颜色。 123456789101112public void delete_case6(node n)&#123; node s = sibling (n); s.color = n.parent.color; n.parent.color = BLACK; if(n == n.parent.left)&#123; s.right.color = BLACK; rotate_left(n.parent); &#125; else &#123; s.left.color = BLACK; rotate_right(n.parent); &#125;&#125; 同样的，函数调用都使用了尾部递归，所以算法是原地算法。此外，在旋转之后不再做递归调用，所以进行了恒定数目（最多3次）的旋转。]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2-3树]]></title>
    <url>%2F2017%2F06%2F24%2F2-3%E6%A0%91%2F</url>
    <content type="text"><![CDATA[2-3查找树 2–3树是一种树型数据结构，内部节点（存在子节点的节点）要么有2个孩子和1个数据元素，要么有3个孩子和2个数据元素，叶子节点没有孩子，并且有1个或2个数据元素。2–3树是平衡树，意味着右边，左边，中间的子树的元素数量都是相同或接近的。 如果一个内部节点拥有一个数据元素、两个子节点，则此节点为2节点。 如果一个内部节点拥有两个数据元素、三个子节点，则此节点为3节点。 当且仅当以下叙述中有一条成立时，T为2–3树： T为空。即T不包含任何节点。 T为拥有数据元素a的2节点。若T的左孩子为L、右孩子为R，则L和R是等高的非空2–3树； a大于L中的所有数据元素；同时a小于等于R中的所有数据元素。 T为拥有数据元素a和b的3节点，其中a &lt; b。若T的左孩子为L、中孩子为M、右孩子为R，则L、M、和R是等高的非空2–3树； a大于L中的所有数据元素，并且小于等于M中的所有数据元素；同时b大于M中的所有数据元素，并且小于等于R中的所有数据元素。 上面介绍了什么是2-3树，接下来我们看看2-3树有什么用，或者说是为什们会出现这种结构，下面我们先来考虑一个问题： 我们知道二叉搜索树的查找和搜索在平均情况下时间复杂度都能达到O(logn)，而且能保证数据有序。二叉搜索树的中序遍历就是数据的顺序。但是这个效率只是在平均情况下。如果数据是逆序，或者顺序，那么这棵树就会发生一边倒的情况使复杂度直接达到O(n)，就如同快排中选择到糟糕的主元(最大或者最小)。 通过上面的问题我们可以看出2-3树用来弥补二叉查找树在极端条件下的不足，因为2-3树是平衡树，所以不管数据怎么样，查找删除操作时间复杂度都至少能达到O(logn)，比起二叉查找树来有过之而无不及！2-3查找树的性质： 如果中序遍历2-3查找树，就可以得到排好序的序列； 在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。 复杂度分析： 在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为log2(N) 在最好的情况下，所有的节点都是3-node节点，查找效率为log3(N) 距离来说，对于1百万个节点的2-3树，树的高度为12-20之间，对于10亿个节点的2-3树，树的高度为18-30之间。 对于插入来说，只需要常数次操作即可完成，因为他只需要修改与该节点关联的节点即可，不需要检查其他节点，所以效率和查找类似。 但是2-3树实现比较复杂，需要掌控的情况很多，剥离节点，传递节点等操作，都需要很复杂的代码，且也会耗费不少的时间。所以我们一般不怎么用原始的2-3树，而是用2-3树的变形红黑树.]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B树和B+树]]></title>
    <url>%2F2017%2F06%2F17%2FB%E6%A0%91%E5%92%8CB%2B%E6%A0%91%2F</url>
    <content type="text"><![CDATA[平衡查找树中的2-3树以及其实现红黑树。2-3树种，一个节点最多有2个key，而红黑树则使用染色的方式来标识这两个key。 维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。 B树定义： B树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。 根节点至少有两个子节点 每个节点有M-1个key，并且以升序排列 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间 其它节点至少有M/2个子节点 可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入 B+树定义： B+树是对B树的一种变形树，它与B树的差异在于： 有k个子结点的结点必然有k个关键码；非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。 B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。 B+ 树的优点在于： 由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。 但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。 B/B+树常用于文件系统和数据库系统中，它通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。它广泛用于文件系统及数据库中，如： Windows：HPFS文件系统；Mac：HFS，HFS+文件系统；Linux：ResiserFS，XFS，Ext3FS，JFS文件系统；数据库：ORACLE，MYSQL，SQLSERVER等中。 有关B/B+树在数据库索引中的应用，请看张洋的MySQL索引背后的数据结构及算法原理这篇文章，这篇文章对MySQL中的如何使用B+树进行索引有比较详细的介绍，推荐阅读。 树表查找总结： 二叉查找树平均查找性能不错，为O(logn)，但是最坏情况会退化为O(n)。在二叉查找树的基础上进行优化，我们可以使用平衡查找树。平衡查找树中的2-3查找树，这种数据结构在插入之后能够进行自平衡操作，从而保证了树的高度在一定的范围内进而能够保证最坏情况下的时间复杂度。但是2-3查找树实现起来比较困难，红黑树是2-3树的一种简单高效的实现，他巧妙地使用颜色标记来替代2-3树中比较难处理的3-node节点问题。红黑树是一种比较高效的平衡查找树，应用非常广泛，很多编程语言的内部实现都或多或少的采用了红黑树。 除此之外，2-3查找树的另一个扩展——B/B+平衡树，在文件系统和数据库系统中有着广泛的应用。]]></content>
      <categories>
        <category>Data_Structure</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Data_Structure</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[约瑟夫环]]></title>
    <url>%2F2017%2F06%2F10%2F%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[约瑟夫环问题问题描述 ：这个问题是以弗拉维奥·约瑟夫命名的，它是1世纪的一名犹太历史学家。他在自己的日记中写道，他和他的n个战友被罗马军队包围在洞中。他们讨论是自杀还是被俘，最终决定自杀，他们围成一个圈，从第1个人开始报数，报到m的人自杀，下一个人重新开始报数，如此循环，直到所有人全都自杀为止。约瑟夫斯和另外一个人是最后两个留下的人。约瑟夫斯说服了那个人，他们将向罗马军队投降，不再自杀。约瑟夫斯把他的存活归因于运气或天意，他不知道是哪一个。 我们首先模拟整个过程将自杀顺序打印粗来，n个人用1~N来标号表示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public int showJoseph(int total, int cycle) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = 0; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; //过滤掉已经自杀的人 while (!arr[index]) &#123; index = (index + 1) % total; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = (index+1); index = (index+1) % total; &#125; &#125; return result; &#125; //限定起点位置public int showJoseph(int total, int cycle, int start) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = start - 1; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; while (!arr[index]) &#123; index = (index + 1) % total; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = index+1; index = (index+1) % total; &#125; &#125; return result; &#125; //限定起点位置递归版public int showJoseph(int total, int cycle, int start) &#123; int result = (showJoseph(total, cycle) + (start-1) -1) % total + 1; return result; &#125; //限定起点+限定循环方向private static int showJoseph(int total, int cycle, int start, boolean forward) &#123; boolean[] arr = new boolean[total]; Arrays.fill(arr, true); int kill = 0; int index = start - 1; int result = 0; while (kill &lt; total) &#123; for (int i = 0; i &lt; cycle; i++) &#123; while (!arr[index]) &#123; if (forward) &#123; //正向走 index = (++index + total) % total; &#125; else &#123; //反向走 index = (--index + total) % total; &#125; &#125; if (i == cycle - 1) &#123; System.out.print(index + 1); arr[index] = false; kill++; &#125; if(kill==total-1) result = index+1; if (forward) &#123; index = (++index + total) % total; &#125; else &#123; index = (--index + total) % total; &#125; &#125; &#125; return result; &#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最大公约数和最小公倍数]]></title>
    <url>%2F2017%2F06%2F03%2F%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%92%8C%E6%9C%80%E5%B0%8F%E5%85%AC%E5%80%8D%E6%95%B0%2F</url>
    <content type="text"><![CDATA[最大公约数和最小公倍数最大公约数123456789//欧几里德算法public long gcd(long m, long n) &#123; while(n!=0)&#123; long rem = m%n; m = n; n = rem; &#125; return m;&#125; 由于除法代价太大，所以接下来我们用减法来代替除法实现该算法，首先我们需要知道gcd(a,b)=gcd(b,a-b)，即数字A和数字B的最大公因数和数字B和数字(A-B)的最大公因数是相同的，所以我们可以得出以下的算法1234567public long gcd(long m, long n) &#123; if(m==n) return m; else&#123; return m-n&gt;0 ? gcd(n,m-n) : gcd(m,n-m); &#125;&#125; 然而存在一个问题就是减法会导致迭代次数较多，所以我们接下来想办法降低迭代次数，我们知道一个奇数和一个偶数的最大公约数其实等于这个奇数和这个(偶数/2)的最大公约数，所以程序进一步改进为：12345678910111213141516public long gcd(long m, long n) &#123; if(m==n) return m; //m,n均为奇数 else if(m&amp;1==1&amp;&amp;n&amp;1==1) return m-n&gt;0 ? gcd(n,m-n) : gcd(m,n-m); //m为偶数，n为奇数 else if(m&amp;1==0&amp;&amp;n&amp;1==1) return gcd(m&gt;&gt;1,n); //n为偶数，m为奇数 else if(m&amp;1==1&amp;&amp;n&amp;1==0) return gcd(m,n&gt;&gt;1); //m,n均为为偶数 else return 2*gcd(m&gt;&gt;1,n&gt;&gt;1);&#125; 最小公倍数123public long zxgbs(long m, long n) &#123; return m*n/gcd(m,n);&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桶排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E6%A1%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[桶排序桶排序 (Bucket sort)或所谓的箱排序的原理是将数组分到有限数量的桶子里（即基于某种映射函数 ，将待排序列的关键字k映射到第i个桶中），然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。 桶排序是稳定的 桶排序是常见排序里最快的一种,比快排还要快…大多数情况下 桶排序非常快,但是同时也非常耗空间,基本上是最耗空间的一种排序算法 假设待排序的一组数统一的分布在一个范围中，并将这一范围划分成几个子范围，也就是桶 将待排序的一组数，分档规入这些子桶，并将桶中的数据进行排序 将各个桶中的数据有序的合并起来 桶排序分析：桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值的计算，其作用就相当于快排中划分，希尔排序中的子序列，归并排序中的子问题，已经把大量数据分割成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。 对N个关键字进行桶排序的时间复杂度分为两个部分： (1) 循环计算每个关键字的桶映射函数，这个时间复杂度是O(N)。 (2) 利用先进的比较排序算法对每个桶内的所有数据进行排序，其时间复杂度为 ∑ O(Ni*logNi) 。其中Ni 为第i个桶的数据量。 很显然，第(2)部分是桶排序性能好坏的决定因素。尽量减少桶内数据的数量是提高效率的唯一办法(因为基于比较排序的最好平均时间复杂度只能达到O(N*logN)了)。因此，我们需要尽量做到下面两点： (1) 映射函数f(k)能够将N个数据平均的分配到M个桶中，这样每个桶就有[N/M]个数据量。 (2) 尽量的增大桶的数量。极限情况下每个桶只能得到一个数据，这样就完全避开了桶内数据的“比较”排序操作。当然，做到这一点很不容易，数据量巨大的情况下，f(k)函数会使得桶集合的数量巨大，空间浪费严重。这就是一个时间代价和空间代价的权衡问题了。 对于N个待排数据，M个桶，平均每个桶[N/M]个数据的桶排序平均时间复杂度为：O(N)+O(M(N/M)log(N/M))=O(N+N(logN-logM))=O(N+NlogN-N*logM)，当N=M时，即极限情况下每个桶只有一个数据时。桶排序的最好效率能够达到O(N)。总结： 桶排序的平均时间复杂度为线性的O(N+C)，其中C=N*(logN-logM)。如果相对于同样的N，桶数量M越大，其效率越高，最好的时间复杂度达到O(N)。 当然桶排序的空间复杂度 为O(N+M)，如果输入数据非常庞大，而桶的数量也非常多，则空间代价无疑是昂贵的。123456789101112131415161718192021222324252627282930public static void bucketSort(int[] arr) &#123; if(arr == null &amp;&amp; arr.length == 0) return ; int bucketNums = 10; //这里默认为10，规定待排数[0,100) List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;List&lt;Integer&gt;&gt;(); //桶的索引 for(int i=0; i&lt;10; i++) &#123; buckets.add(new LinkedList&lt;Integer&gt;()); //用链表比较合适 &#125; //划分桶 for(int i=0; i&lt;arr.length; i++) &#123; buckets.get(fun(arr[i])).add(arr[i]); &#125; //对每个桶进行排序 for(int i=0; i&lt;buckets.size(); i++) &#123; if(!buckets.get(i).isEmpty()) &#123; Collections.sort(buckets.get(i)); //对每个桶进行快排 &#125; &#125; //还原排好序的数组 int k = 0; for(List&lt;Integer&gt; bucket : buckets) &#123; for(int ele : bucket) &#123; arr[k++] = ele; &#125; &#125;&#125;//映射函数public int fun(int x) &#123; return x / 10;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[计数排序一个O(n)时间复杂度的排序算法，我们知道基于比较的排序的下限是O(nlogn)。而计数排序只需线性时间复杂度的排序，只不过有前提条件，就是待排序的数要满足一定的范围的整数，而且计数排序需要比较多的辅助空间。其基本思想是，用待排序的数作为计数数组的下标，统计每个数字的个数。然后依次输出即可得到有序序列。如果被排序序列是无重的，即意味着无需统计个数，那么我们可以使用位数组来实现该算法！ 123456789101112131415161718192021222324public void countSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int max = max(arr);//获取被排序序列中的最大值来开辟新数组 int[] count = new int[max+1]; Arrays.fill(count, 0); for(int i=0; i&lt;arr.length; i++) &#123; count[arr[i]] ++; &#125; int k = 0; for(int i=0; i&lt;=max; i++) &#123; for(int j=0; j&lt;count[i]; j++) &#123; arr[k++] = i; &#125; &#125;&#125;public int max(int[] arr) &#123; int max = Integer.MIN_VALUE; for(int ele : arr) &#123; if(ele &gt; max) max = ele; &#125; return max;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql_DATE_FORMAT_分组查询]]></title>
    <url>%2F2017%2F05%2F27%2FMySql_DATE_FORMAT_%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[MySql_DATEFORMAT分组查询12345678&lt;!-- 按日查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%m-%d') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按月查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%m') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按年查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time &lt;!-- 按周查询 --&gt; SELECT DATE_FORMAT(created_date,'%Y-%u') as time,sum(money) money FROM o_finance_detail where org_id = 1000 GROUP BY time DATE_FORMAT(date,format) :根据format字符串格式化date值。下列修饰符可以被用在format字符串中： %M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) …]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySql</tag>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组打印]]></title>
    <url>%2F2017%2F05%2F27%2F%E6%95%B0%E7%BB%84%E6%89%93%E5%8D%B0%2F</url>
    <content type="text"><![CDATA[数组打印 一维数组12345int [] num = &#123;1,2,3,4,5&#125;;System.out.println(num.toString());//输出：[I@15db9742...System.out.println(Arrays.toString(num));//输出：[1, 2, 3, 4, 5] 二维数组123456789101112int [][] nums = &#123;&#123;1,2&#125;,&#123;3,4,5&#125;,&#123;6,7&#125;&#125;;System.out.println(Arrays.toString(nums));//输出：[[I@6d06d69c, [I@7852e922, [I@4e25154f]...System.out.println(Arrays.deepToString(nums));//输出：[[1, 2], [3, 4, 5], [6, 7]]//补充int [][] a = new int[][]&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;,&#123;7,8,9&#125;&#125;;int [][] b = new int[][]&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;,&#123;7,8,9&#125;&#125;;System.out.println(Arrays.equals(a, b));//输出：FALSESystem.out.println(Arrays.deepEquals(a, b));//输出：TRUE 附上：工具类Arrays部分源码解读123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146public class Arrays &#123; private static final int MIN_ARRAY_SORT_GRAN = 1 &lt;&lt; 13; //排序底层采用快排实现 public static void sort(int[] a) &#123; DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0); &#125; //二分查找 public static int binarySearch(long[] a, long key) &#123; return binarySearch0(a, 0, a.length, key); &#125; //一维数组简单判定相等 public static boolean equals(long[] a, long[] a2) &#123; if (a==a2) return true; if (a==null || a2==null) return false; int length = a.length; if (a2.length != length) return false; for (int i=0; i&lt;length; i++) if (a[i] != a2[i]) return false; return true; &#125; //多维数组或复杂对象深度判定相等 public static boolean deepEquals(Object[] a1, Object[] a2) &#123; if (a1 == a2) return true; if (a1 == null || a2==null) return false; int length = a1.length; if (a2.length != length) return false; for (int i = 0; i &lt; length; i++) &#123; Object e1 = a1[i]; Object e2 = a2[i]; if (e1 == e2) continue; if (e1 == null) return false; // Figure out whether the two elements are equal boolean eq = deepEquals0(e1, e2); if (!eq) return false; &#125; return true; &#125; //数组填充，只能以同一个值填充数组 public static void fill(long[] a, long val) &#123; for (int i = 0, len = a.length; i &lt; len; i++) a[i] = val; &#125; //Arrays.asList()返回的是ArrayList类型，其底层构成仍然是数组 public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a); &#125; private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;implements RandomAccess, java.io.Serializable&#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; ... &#125; //一维数组打印 public static String toString(int[] a) &#123; if (a == null) return "null"; int iMax = a.length - 1; if (iMax == -1) return "[]"; StringBuilder b = new StringBuilder(); b.append('['); for (int i = 0; ; i++) &#123; b.append(a[i]); if (i == iMax) return b.append(']').toString(); b.append(", "); &#125; &#125; //多维数组或对象数组打印 public static String deepToString(Object[] a) &#123; if (a == null) return "null"; int bufLen = 20 * a.length; if (a.length != 0 &amp;&amp; bufLen &lt;= 0) bufLen = Integer.MAX_VALUE; StringBuilder buf = new StringBuilder(bufLen); deepToString(a, buf, new HashSet&lt;Object[]&gt;()); return buf.toString(); &#125; private static void deepToString(Object[] a, StringBuilder buf,Set&lt;Object[]&gt; dejaVu) &#123; if (a == null) &#123; buf.append("null"); return; &#125; int iMax = a.length - 1; if (iMax == -1) &#123; buf.append("[]"); return; &#125; dejaVu.add(a); buf.append('['); for (int i = 0; ; i++) &#123; Object element = a[i]; if (element == null) &#123; buf.append("null"); &#125; else &#123; //获取子元素类型 Class&lt;?&gt; eClass = element.getClass(); //如果子元素类型是数组类型，进而判定是哪一种数组类型 if (eClass.isArray()) &#123; if (eClass == byte[].class) buf.append(toString((byte[]) element)); else if (eClass == short[].class) buf.append(toString((short[]) element)); else if (eClass == int[].class) buf.append(toString((int[]) element)); else if (eClass == long[].class) buf.append(toString((long[]) element)); else if (eClass == char[].class) buf.append(toString((char[]) element)); else if (eClass == float[].class) buf.append(toString((float[]) element)); else if (eClass == double[].class) buf.append(toString((double[]) element)); else if (eClass == boolean[].class) buf.append(toString((boolean[]) element)); else &#123; // element is an array of object references if (dejaVu.contains(element)) buf.append("[...]"); else deepToString((Object[])element, buf, dejaVu); &#125; &#125; else &#123; // element is non-null and not an array buf.append(element.toString()); &#125; &#125; if (i == iMax) break; buf.append(", "); &#125; buf.append(']'); dejaVu.remove(a); &#125;&#125;]]></content>
      <categories>
        <category>Arrays</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Arrays</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[堆排序 堆是具有下列性质的完全二叉树:每个节点的值都大于或等于其左右孩子节点的值,称为大顶堆；或者每个节点的值都小于或等于其左右孩子节点的值,称为小顶堆。 堆排序就是利用堆进行排序的方法.基本思想是:将待排序的序列构造成一个大顶堆.此时,整个序列的最大值就是堆顶的根结点.将它移走(其实就是将其与堆数组的末尾元素交换, 此时末尾元素就是最大值),然后将剩余的n-1个序列重新构造成一个堆,这样就会得到n个元素的次大值.如此反复执行,便能得到一个有序序列了。 时间复杂度为 O(nlogn)！ 如何由一个无序序列键成一个堆？ 可以直接使用线性数组来表示一个堆，由初始的无序序列建成一个堆就需要自底向上从第一个非叶元素开始挨个调整成一个堆。 如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？ 怎么调整成堆？首先是将堆顶元素和最后一个元素交换。然后比较当前堆顶元素的左右孩子节点，因为除了当前的堆顶元素，左右孩子堆均满足条件，这时需要选择当前堆顶元素与左右孩子节点的较大者（大顶堆）交换，直至叶子节点。我们称这个自堆顶自叶子的调整成为筛选。 每次堆调整找出一个最大值/最小值，N次调整完成全部排序 使用数组构建大/小顶堆时，按照堆的层级排序从上到下，从左到右依次存入数组中，因此当各个节点的下标为i时，其左右孩子的节点下标分别为2i+1,2i+2 123456789101112131415161718192021222324252627282930313233public void heapAdjust(int[] arr, int start, int end) &#123; int temp = arr[start]; for(int i=2*start+1; i&lt;=end; i*=2) &#123; //左右孩子的节点分别为2*i+1,2*i+2 //选择出左右孩子较小的下标 if(i &lt; end &amp;&amp; arr[i] &lt; arr[i+1]) &#123; i ++; &#125; if(temp &gt;= arr[i]) &#123; break; //已经为大顶堆，=保持稳定性。 &#125; arr[start] = arr[i]; //将子节点上移 start = i; //下一轮筛选 &#125; arr[start] = temp; //插入正确的位置&#125;public void heapSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; //建立大顶堆，从第一个非叶子结点从下至上，从右至左调整结构 for(int i=arr.length/2; i&gt;=0; i--) &#123; heapAdjust(arr, i, arr.length-1); &#125; for(int i=arr.length-1; i&gt;=0; i--) &#123; swap(arr, 0, i); heapAdjust(arr, 0, i-1); &#125;&#125;public void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2F2017%2F05%2F27%2F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[归并排序归并排序使用了递归分治的思想，其基本思想是，先递归划分子问题，然后合并结果。把待排序列看成由两个有序的子序列，然后合并两个子序列，然后把子序列看成由两个有序序列。。。。。倒着来看，其实就是先两两合并，然后四四合并。。。最终形成有序序列。空间复杂度为O(n)，时间复杂度为O(nlogn)。 1234567891011121314151617181920212223242526272829303132public static void mergeSort(int[] arr, int left, int right) &#123; if(left &gt;= right) return ; int mid = (left&gt;&gt;1) + (right&gt;&gt;1); mergeSort(arr, left, mid); //递归排序左边 mergeSort(arr, mid+1, right); //递归排序右边 merge(arr, left, mid, right); //合并&#125;//合并两个有序数组public static void merge(int[] arr, int left, int mid, int right) &#123; //左数组[left, mid] 右数组[mid+1, right] int[] temp = new int[right - left + 1]; //中间数组 int i = left; int j = mid + 1; int k = 0; while(i &lt;= mid &amp;&amp; j &lt;= right) &#123; if(arr[i] &lt;= arr[j]) temp[k++] = arr[i++]; else temp[k++] = arr[j++]; &#125; while(i &lt;= mid) &#123; temp[k++] = arr[i++]; &#125; while(j &lt;= right) &#123; temp[k++] = arr[j++]; &#125; for(int p=0; p&lt;temp.length; p++) &#123; arr[left + p] = temp[p]; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LintCode_最大数]]></title>
    <url>%2F2017%2F05%2F22%2FLintCode-%E6%9C%80%E5%A4%A7%E6%95%B0%2F</url>
    <content type="text"><![CDATA[问题描述 给出一组非负整数，重新排列他们的顺序把他们组成一个最大的整数。(注意事项：最后的结果可能很大，所以我们返回一个字符串来代替这个整数。)样例：给出 [1, 20, 23, 4, 8]，返回组合最大的整数应为8423201。 思路拿到题目的第一反应就是比较大小嘛，但是继续往下想发现比较条件有点繁琐，同位数的直接比较大小即可，不同位数就比较麻烦了，需要一位一位进行比较…，然后突然间就想到了全排列，其实数据量比较小的时候是可以的，但是数据量大的情况就不行了，于是我卡在了数据样例[0,0,0,0,0,0,…,0,0,0]上，而且全然做了无用功，所以思路又回到了比较排序上，但是没想到什么好的比较方案，最终还是上网找了找资料，发现一个新思路，去比较两个数字组合后的大小，然后选择结果较大的组合，比如1和20，我们直接去比较120和201的大小，很明显201&gt; 120，所以1应该在20后面。这样一来比较就变得灰常容易，整个算法也瞬间简单明了起来！题解1234567891011121314151617181920212223242526public String largestNumber(int[] num) &#123; String[] A = new String[num.length]; int check = 0; for (int i=0;i&lt;num.length;i++) &#123; A[i] = String.valueOf(num[i]); check = Math.max(check,num[i]); &#125; if (check == 0) &#123; return "0"; &#125; Arrays.sort(A,new Comparator&lt;String&gt;() &#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;); StringBuilder s = new StringBuilder(); for (int i=0;i&lt;num.length;i++) &#123; s.append(String.valueOf(A[i])); &#125; return s.toString(); &#125; 收获一：以前只知道Arrays.sort(a[])这一种最简单的用法，今天又收获了两种更高级的用法，其中一种在本题中已用到，总结起来Arrays.sort()排序函数有以下几种用法 Arrays.sort(a[]) 排序a数组，且规则是从小到大，a可以是int,long,double,char,flaat,Object… Arrays.sort(a[], int fromIndex, int toIndex) 排序a数组的部分，从下标fromIndex到toIndex(不包括toIndex) Arrays.sort(T[] a, Comparator&lt;? super T&gt; c) 排序a数组，按照比较器中的规则 12345class MyComparator implements Comparator&lt;Integer&gt;&#123; public int compare(Integer s1, Integer s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125; 二：匿名内部类，think in java中研究了好久，只是一直没怎么使用过，如今又看到了，却也感觉熟悉而陌生，所以再拿出来简单说道说道，看代码1234567Arrays.sort(A,new Comparator&lt;String&gt;() &#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;); 完整类为123456789101112public class Main &#123; public static void main(String[] args) &#123; String[] a = &#123;9, 8, 7, 2, 3, 4, 1, 0, 6, 5&#125;; Comparator cmp = new MyComparator(); Arrays.sort(a, cmp); &#125; &#125; class MyComparator implements Comparator&lt;String&gt;&#123; public int compare(String s1, String s2) &#123; return (s2+s1).compareTo(s1+s2); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LintCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基数排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基数排序基数排序是一种借助多关键字排序思想对单逻辑关键字进行排序的方法。所谓的多关键字排序就是有多个优先级不同的关键字。比如说成绩的排序，如果两个人总分相同，则语文高的排在前面，语文成绩也相同则数学高的排在前面。。。如果对数字进行排序，那么个位、十位、百位就是不同优先级的关键字，如果要进行升序排序，那么个位、十位、百位优先级一次增加。基数排序是通过多次的收分配和收集来实现的，关键字优先级低的先进行分配和收集。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void radixSort(int[] arr) &#123; if(arr == null &amp;&amp; arr.length == 0) return ; int maxBit = getMaxBit(arr); for(int i=1; i&lt;=maxBit; i++) &#123; List&lt;List&lt;Integer&gt;&gt; buf = distribute(arr, i); //分配 collecte(arr, buf); //收集 &#125;&#125;//待分配数组public List&lt;List&lt;Integer&gt;&gt; distribute(int[] arr, int iBit) &#123; List&lt;List&lt;Integer&gt;&gt; buf = new ArrayList&lt;List&lt;Integer&gt;&gt;(); for(int j=0; j&lt;10; j++) &#123; buf.add(new LinkedList&lt;Integer&gt;()); &#125; for(int i=0; i&lt;arr.length; i++) &#123; buf.get(getNBit(arr[i], iBit)).add(arr[i]); &#125; return buf;&#125;//把分配的数据收集到arr中public void collecte(int[] arr, List&lt;List&lt;Integer&gt;&gt; buf) &#123; int k = 0; for(List&lt;Integer&gt; bucket : buf) &#123; for(int ele : bucket) &#123; arr[k++] = ele; &#125; &#125;&#125;//获取最大位数public int getMaxBit(int[] arr) &#123; int max = Integer.MIN_VALUE; for(int ele : arr) &#123; int len = (ele+"").length(); if(len &gt; max) max = len; &#125; return max;&#125;//获取x的第n位，如果没有则为0public int getNBit(int x, int n) &#123; String sx = x + ""; if(sx.length() &lt; n) return 0; else return sx.charAt(sx.length()-n) - '0';&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序快速排序在实际应用当中确实是表现最好的排序算法。但其思想是来自冒泡排序，冒泡排序是通过相邻元素的比较和交换把最小的冒泡到最顶端，而快速排序是比较和交换小数和大数，这样一来不仅把小数冒泡到上面，同时也把大数沉到下面。举个栗子：对5,3,8,6,4这个无序序列进行快速排序，思路是右指针从尾部找比基准数小的，左指针从头部找比基准数大的，然后交换之。通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。时间复杂度为O(nlogn) 12345678910111213141516171819202122232425public int partition(int[] arr, int left, int right) &#123; int pivotKey = arr[left]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; arr[right] &gt;= pivotKey) right --; arr[left] = arr[right]; //把小的移动到左边 while(left &lt; right &amp;&amp; arr[left] &lt;= pivotKey) left ++; arr[right] = arr[left]; //把大的移动到右边 &#125; arr[left] = pivotKey; //最后把pivot赋值到中间 return left;&#125;public void quickSort(int[] arr, int left, int right) &#123; if(left &gt;= right) return ; int pivotPos = partition(arr, left, right); quickSort(arr, left, pivotPos-1); quickSort(arr, pivotPos+1, right);&#125;public void sort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; quickSort(arr, 0, arr.length-1);&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希尔排序]]></title>
    <url>%2F2017%2F05%2F20%2F%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[希尔排序希尔排序是插入排序的一种高效率的实现，也叫缩小增量排序。简单的插入排序中，如果待排序列是正序时，时间复杂度是O(n)，如果序列是基本有序的，使用直接插入排序效率就非常高。希尔排序就利用了这个特点。基本思想是：先将整个待排元素序列分割成若干子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序（增量为1）。其时间复杂度为O(n^3/2),要好于直接插入排序的O(n^2) 1234567891011121314151617181920212223public void shellInsert(int[] arr, int d) &#123; for(int i=d; i&lt;arr.length; i++) &#123; int j = i - d; int temp = arr[i]; //记录要插入的数据 while (j&gt;=0&amp;&amp;arr[j]&gt;temp) &#123; //从后向前，找到比其小的数的位置 arr[j+d] = arr[j]; //向后挪动 j -= d; &#125; if (j != i - d) //存在比其小的数 arr[j+d] = temp; &#125;&#125;public void shellSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int d = arr.length / 2; while(d &gt;= 1) &#123; shellInsert(arr, d); d&gt;&gt;1; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[冒泡排序 基本思想:两两比较相邻记录的关键字,如果反序则交换 冒泡排序时间复杂度最好的情况为O(n),最坏的情况是O(n^2) 设置标志位，明显如果有一趟没有发生交换（flag = false)，说明排序已经完成 记录一轮下来标记的最后位置，下次从头部遍历到这个位置就Ok 12345678910111213141516171819public void bubbleSort(int[] array)&#123; boolean flag = true; int n = array.length; while(flag)&#123; flag = false; for(int i = 0;i &lt; n-1;i++)&#123; if(array[i] &gt; array[i+1])&#123; //数据交换，将较大的数据换至数组后方 array[i] = array[i]^array[i+1]; array[i+1] = array[i]^array[i+1]; array[i] = array[i]^array[i+1]; //设置标记，当本次循环未发生交换动作时，排序完成 flag = true; &#125; &#125; //每次循环均有一位当前最大值换至正确的位置，故每下一次循环减少一次比较 n--; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接插入排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E7%9B%B4%E6%8E%A5%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[直接插入排序 将一个记录插入到已经排好序的有序表中, 从而得到一个新的,记录数增1的有序表 时间复杂度也为O(n^2), 比冒泡法和选择排序的性能要更好一些 123456789101112131415public void insertSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; for(int i=1; i&lt;arr.length; i++) &#123; //假设第一个数位置时正确的；要往后移，必须要假设第一个。 int j = i; int target = arr[i]; //待插入的 //后移 while(j&gt;0&amp;&amp;target&lt;arr[j-1]) &#123; arr[j] = arr[j-1]; j --; &#125; //插入 arr[j] = target; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择排序]]></title>
    <url>%2F2017%2F05%2F13%2F%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[选择排序 通过n-i次关键字之间的比较,从n-i+1 个记录中选择关键字最小的记录,并和第i(1&lt;=i&lt;=n)个记录交换之 尽管与冒泡排序同为O(n^2),但简单选择排序的性能要略优于冒泡排序 12345678910111213141516171819202122public static void selectSort(int[] arr) &#123; if(arr == null || arr.length == 0) return ; int minIndex = 0; for(int i=0; i&lt;arr.length-1; i++) &#123; //只需要比较n-1次 minIndex = i; for(int j=i+1;j&lt;arr.length; j++) &#123; //从i+1开始比较，因为minIndex默认为i了，i就没必要比了。 if(arr[j]&lt;arr[minIndex]) &#123; minIndex = j; &#125; &#125; if(minIndex != i) &#123; //如果minIndex不为i，说明找到了更小的值，交换之。 swap(arr, i, minIndex); &#125; &#125;&#125;public static void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海量数据处理]]></title>
    <url>%2F2017%2F05%2F10%2F%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[海量数据处理问题 topK问题 重复问题 排序问题 相关算法 topK问题（10亿词中查找出现频率最高的10个） 单机+单核+足够大内存 10亿词（每个词占8B）中查找出现频率最高的10个 首先考虑全部放入内存，需要至少10^9*8=8GB 用HashMap（Map：key是单词，value是次数）统计频率在求出结果 词频统计构造单词树，前缀单词树（相比较map极大的节省空间） 单机+多核（意味着可以多线程）+足够大内存 在内存中用hash将数据分为n个partition，交给n个线程处理，最后有一个线程负责将结果合并 上述有一个瓶颈问题，即（数据倾斜）线程处理速度不一致，所以快的线程必须等慢的线程，速度取决最慢的线程 解决办法，将数据分成c*n个partition（c&gt;1）,依然是n个线程，快的线程处理完后主动取下一个partition进行处理，直到数据全部处理完成，最后合并结果 单机+单核+受限内存 Hash（x）%M将源文件数据切割成M个小文件，然后用（单机+单核+足够大内存）方法处理，最后合并 多机+受限内存 数据分发到各个机器，每台机器用（单机+单核+受限内存）方法进行处理 查找乱序数组中第K个最大值，或者前K个最大值（这种问题是不统计频率，只是查找第K个最大值） 方法一：全部排序 方法二：维护一个K长度的数组a[]，先读取源数据中的前K个放入数组，对该数组进行升序排序，再依次读取源数据第K个以后的数据，和数组中最小的元素（a[0]）比较，如果小于a[0]直接pass，大于的话，就丢弃最小的元素a[0]，利用二分法找到其位置，然后该位置前的数组元素整体向前移位，直到源数据读取结束。这比全部排序后统计频率效率会有很大的提高，但是当K的值较大的时候，长度为K的数据整体移位，也是非常耗时的。 方法三：找出数组中最大的元素，与第一个元素交换，再找出第二大元素，与第二个元素交换，直到找到第 $k$ 大元素便停止。 方法四：堆排序（最优） 重复问题（电话号码去重求个数，即不同的电话号码有多少个，假设电话号码为8位） HashMap去重法 位图法 8位能表示的十进制数最大为99999999，假设每个数字对应位图中的一位，大概需要内存99MB/8=7.375MB排序问题（9亿个不重复的9位整数数排序） 9亿个不重复的9位整数数排序，32位机器中整数占4B，所有数据全放入内存需0.9G*4B=3.6GB 1.利用数据库索引排序 2.分治法，将数据分断放入内存，最后合并（但是每次换入换出浪费时间） 3.位数组，声明一个可包含9位整数的bit数组，需内存大概9亿/8=120MB左右即可，数组内0、1表示是否含有此数，遍历出结果相关算法 1.hash算法 构造函数 冲突处理 2.位图法bit-map 快查，判重，判存 3.bloomfilter（位图+哈希） 判断元素是否属于集合 不属于（绝对正确） 属于（可能错误） m位的位数组+k个不同的hash（判定属于—k个哈希映射后，k位均为1，则可能存在于集合中，有位不为1，则元素肯定不在集合中） K=ln2*（m/n）n个元素，错误率最小 延伸：CBF（counter），SBF 4.倒排索引 单词指向包含他的文档（此单词在那些文档中出现过），例如论文的关键字搜索 5.trie树 利用公共前缀来减少时空消耗 6.堆 前n大/小 中位数（双堆）]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵相关运算]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[矩阵相关运算矩阵加减法（等行等列） 12345678910111213141516171819202122232425262728public int[][] add(int[][] a,int[][] b)&#123; //获取二维数组的行数 int row = a.length; //获取二维数组的列数 int column = a[row-1].length; int[][] c = new int[row][column]; for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; c[i][j]=a[i][j]+b[i][j]; &#125; &#125; return c;&#125;public int[][] sub(int[][] a,int[][] b)&#123; int row = a.length; int column = a[row-1].length; int[][] c = new int[row][column]; for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; c[i][j]=a[i][j]-b[i][j]; &#125; &#125; return c;&#125; 矩阵相乘（A[m][n]*B[n][k]=C[m][k]）1234567891011121314151617181920public int[][] add(int[][] a,int[][] b)&#123; //获取二维数组a的行数作为c的行数 int row = a.length; //获取二维数组a的列数 int n = a[row-1].length; 获取二维数组b的列数作为c的列数 int column = b[n-1].length; int[][] c = new int[row][column]; Arrays.fill(c,0); for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;column;j++) &#123; for(int k=0;k&lt;n;k++)&#123; c[i][j]+=a[i][k]*b[k][j] &#125; &#125; &#125; return c;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法]]></title>
    <url>%2F2017%2F05%2F06%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[常用查找算法顺序查找 无序或有序队列,按顺序比较每个元素，直到找到关键字为止。 时间复杂度：O(n) 123456789101112131415161718192021222324252627282930313233343536373839//用链表来实现，动态的插入和删除便于维护序列的有序性public class SequentialSearchST&lt;Key,Value&gt; &#123; private Node head; private int size=0; //插入时间复杂度为O(n) public void put(Key key,Value v)&#123; Node p=head; while(p!=null)&#123; if(p.key.equals(key))&#123; p.v=v; return; &#125; p=p.next; &#125; head=new Node(key,v,head); size++; &#125; //查找时间复杂度为O(n) public Value get(Key key)&#123; Node p=head; while (p!=null)&#123; if(p.key.equals(key))&#123; return p.v; &#125; p=p.next; &#125; return null; &#125; //删除时间复杂度为O(n) public void delete(Key key)&#123; Node p=head; while (p!=null)&#123; if(p.key.equals(key))&#123; p.v = p.next.v; p.next = p.next.next; &#125; &#125; &#125;&#125; 二分查找（折半查找） 条件：有序数组 原理： 查找过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束； 如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中重复步骤1。 如果在某一步骤数组为空，则代表找不到。 时间复杂度：O(logn)1234567891011121314public int binarySearach(int[] array,int key)&#123; int low = 0; int high = array.length-1; while(low &lt;= high)&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) high = middle-1; else if(key &gt; array[middle]) low = middle+1; else return array[middle]; &#125; return -1;//没找到目标值返回-1&#125; 插值查找 插值查找，基于折半查找的优化变种。由于折半查找这种查找方式，不是自适应的（也就是说是傻瓜式的）打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。所以插值查找克服了折半查找的傻瓜式，采用自适应查找点，从而让每次所选择的查找点更加接近被查找值，以加快查找速度。 二分查找中查找点计算如下：mid=(low+high)/2, 即mid=low+1/2*(high-low); 插值查找中查找点计算如下：mid=low+(key-a[low])/(a[high]-a[low])*(high-low) 123456789101112131415161718public int insertKeySearch(int [] a, int key)&#123; int low, high, mid; low = 0; high = a.length-1; while(low &lt;= high)&#123; /* 插值查找的计算公式 */ mid = low + (high - low)*(key - a[low])/(a[high] - a[low]); if (key &lt; a[mid])&#123; high = mid - 1; &#125; else if (key &gt; a[mid])&#123; low = mid + 1; &#125; else return mid; &#125; return 0;&#125; 复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。注：对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。斐波那契查找 在介绍斐波那契查找算法之前，先介绍一下很它紧密相连的一个概念——黄金分割。黄金比例又称黄金分割，是指事物各部分间一定的数学比例关系，即将整体一分为二，较大部分与较小部分之比等于整体与较大部分之比，其比值约为1:0.618或1.618:1。0.618被公认为最具有审美意义的比例数字，这个数值的作用不仅仅体现在诸如绘画、雕塑、音乐、建筑等艺术领域，而且在管理、工程设计等方面也有着不可忽视的作用。因此被称为黄金分割。斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。然后我们会发现，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618，利用这个特性，我们就可以将黄金比例运用到查找技术中。 斐波那契查找也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。斐波那契查找就是在二分查找的基础上根据斐波那契数列进行分割的。在斐波那契数列找一个等于略大于查找表中元素个数的数F[n]，将原查找表扩展为长度为Fn，完成后进行斐波那契分割，即F[n]个元素分割为前半部分F[n-1]个元素，后半部分F[n-2]个元素，找出要查找的元素在那一部分并递归，直到找到。相对于折半查找，一般将待比较的key值与第mid=（low+high）/2位置的元素比较，比较结果分三种情况： key值与第mid=（low+high）/2相等，mid位置的元素即为所求； key值大于第mid=（low+high）/2，则令 low=mid+1； key值小于第mid=（low+high）/2，则令high=mid-1。斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1；开始将k值与第F(k-1)位置的记录进行比较(及mid=low+F(k-1)-1)，比较结果也分为三种： key值与第mid=low+F(k-1)-1相等，则mid位置的元素即为所求； key值大于第mid=low+F(k-1)-1，则low=mid+1，k-=2；说明：low=mid+1说明待查找的元素在[mid+1,high]范围内，k-=2 说明范围[mid+1,high]内的元素个数为n-(F(k-1))=Fk-1-F(k-1)=Fk-F(k-1)-1=F(k-2)-1个，所以可以递归的应用斐波那契查找。 key值小于第mid=low+F(k-1)-1，则high=mid-1，k-=1。说明：low=mid+1说明待查找的元素在[low,mid-1]范围内，k-=1 说明范围[low,mid-1]内的元素个数为F(k-1)-1个，所以可以递归的应用斐波那契查找。 上代码我们来实际操作一番123456789101112131415161718192021222324252627public int FibonacciSearch(int [] a, int key)&#123; int [] F = &#123;0,1,1,2,3,5,8,13,21,34&#125;;//构造一个斐波那契数列 int low, high, mid, k; low = 1; high = a.length-1; k = 0; while (n &gt; F[k]-1) /* 计算n位于斐波那契数列的位置 */ k++; while (low &lt;= high) &#123; mid = low + F[k-1] -1; if (key &lt; a[mid])&#123; high = mid - 1; k -= 1; &#125; else if (key &gt; a[mid])&#123; low = mid + 1; k -= 2; &#125; else &#123; if (mid &lt;= n) return mid; else return n; &#125; &#125; return 0;&#125; 在最坏情况下，斐波那契查找的时间复杂度还是O(log2n)，且其期望复杂度也为O(log2n)，但是与折半查找相比，斐波那契查找的优点是它只涉及加法和减法运算，而不用除法，而除法比加减法要占用更多的时间，因此，斐波那契查找的运行时间理论上比折半查找小，但是还是得视具体情况而定。二叉排序树查找特性： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。在二叉查找树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则搜索左子树；否则： 查找右子树。时间复杂度：O(log_2(n)) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//查找public TreeNode BSTSearach(TreeNode root, Value value) &#123; if(root==null) return null; if(root.value==value) return root; else return root.value&lt;value ? BSTSearach(roo.right,value) : BSTSearach(root.left,value);&#125;//插入节点public void insertNode(TreeNode root,TreeNode node) &#123; if (root == NULL) root = node; else if (root.val &gt; node.val) insertNode(root.left,node); else if(root.val &lt; node.val) insertNode(root.right,node); else return;&#125; //删除二叉查找树的节点public TreeNode removeNode(TreeNode root, int value) &#123; if (root == null)&#123; return null; &#125; if (root.val == value)&#123;//当前节点值等于value值 if (root.left == null &amp;&amp; root.right == null)&#123;//当前节点没有左右孩子节点 root = null; &#125; else if (root.left == null)&#123;//当前节点只有右孩子节点 root = root.right; &#125; else if (root.right == null)&#123;//当前节点只有左孩子节点 root = root.left; &#125; else &#123;//当前节点有左右孩子节点 TreeNode tmp = root; tmp = tmp.left; while(tmp.right != null)&#123; tmp = tmp.right; &#125; root.val = tmp.val; root.left = removeNode(root.left,root.val); &#125; &#125; else if (value &lt; root.val)&#123;//当前节点值大于value if (root.left == null)&#123; return root; &#125; root.left = removeNode(root.left, value); &#125; else &#123;//当前节点值小于value if (root.right == null)&#123; return root; &#125; root.right = removeNode(root.right,value); &#125; return root;&#125; 哈希表法（散列表） 先创建哈希表（散列表） 根据键值方式(Key value)进行查找，通过散列函数，定位数据元素。 时间复杂度：几乎是O(1)，取决于产生冲突的多少。123456789101112131415161718192021222324public int searchHash(int[] hash, int hashLength, int key) &#123; // 哈希函数 int hashAddress = key % hashLength; // 指定hashAdrress对应值存在但不是关键值，则用开放寻址法解决 while (hash[hashAddress] != 0 &amp;&amp; hash[hashAddress] != key) &#123; hashAddress = (++hashAddress) % hashLength; &#125; // 查找到了开放单元，表示查找失败 if (hash[hashAddress] == 0) return -1; return hashAddress; &#125; //数据插入Hash表 public void insertHash(int[] hash, int hashLength, int data) &#123; // 哈希函数 int hashAddress = data % hashLength; // 如果key存在，则说明已经被别人占用，此时必须解决冲突 while (hash[hashAddress] != 0) &#123; // 用开放寻址法找到 hashAddress = (++hashAddress) % hashLength; &#125; // 将data存入字典中 hash[hashAddress] = data; &#125; 分块查找 将n个数据元素”按块有序”划分为m块（m ≤ n）。 每一块中的结点不必有序，但块与块之间必须”按块有序”；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，…… 然后使用二分查找确定数据所处在哪一块后用顺序查找key。123456789101112131415161718public int blockSearch(int[] index, int[] st, int key, int m) &#123; // 在序列st数组中，用分块查找方法查找关键字为key的记录 // 1.在index[ ] 中折半查找，确定要查找的key属于哪个块中 int i = binarySearch(index, key); if (i &gt;= 0) &#123; int j = i &gt; 0 ? i * m : i; int len = (i + 1) * m; // 在确定的块中用顺序查找方法查找key for (int k = j; k &lt; len; k++) &#123; if (key == st[k]) &#123; System.out.println("查询成功"); return k; &#125; &#125; &#125; System.out.println("查找失败"); return -1; &#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找]]></title>
    <url>%2F2017%2F05%2F06%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[二分查找非递归版1234567891011121314public int binarySearch(int[] array,int key)&#123; int low = 0; int high = array.length-1; while(low &lt;= high)&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) high = middle-1; else if(key &gt; array[middle]) low = middle+1; else return array[middle]; &#125; return -1;//没找到目标值返回-1&#125; 递归版12345678910111213public int binarySearch(int[] array,int key,int low,int high)&#123; if(low &gt;= high) return -1; else&#123; int middle = (low + high) &gt;&gt; 1; if(key &lt; array[middle]) binarySearach(array,key,low,middle-1); else if(key &gt; array[middle]) binarySearach(array,key,middle-1,high); else return array[middle]; &#125;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Algorithm</tag>
        <tag>BinarySearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map的遍历]]></title>
    <url>%2F2017%2F05%2F06%2FMap%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[Map的遍历 EntrySet遍历 KeySet/Values遍历 Iterator遍历 foreach遍历 使用EntrySet 1234Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue()); &#125; 使用keyset或者values 123456789Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); //遍历map中的键 for (Integer key : map.keySet()) &#123; System.out.println("Key = " + key); &#125; //遍历map中的值 for (Integer value : map.values()) &#123; System.out.println("Value = " + value); &#125; 使用Iterator(在遍历时调用iterator.remove()可以来删除entries) 123456Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator(); while (entries.hasNext()) &#123; Map.Entry&lt;Integer, Integer&gt; entry = entries.next(); System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue()); &#125; 使用foreach遍历 1234567891011121314Map&lt;String, Integer&gt; items = new HashMap&lt;&gt;();items.put("A", 10);items.put("B", 20);items.put("C", 30);items.put("D", 40);items.put("E", 50);items.put("F", 60);items.forEach((k,v)-&gt;System.out.println("Item : " + k + " Count : " + v));items.forEach((k,v)-&gt;&#123; System.out.println("Item : " + k + " Count : " + v); if("E".equals(k))&#123; System.out.println("Hello E"); &#125;&#125;);]]></content>
      <categories>
        <category>Iteration</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Iteration</tag>
        <tag>Map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初心]]></title>
    <url>%2F2017%2F04%2F30%2F%E5%88%9D%E5%BF%83%2F</url>
    <content type="text"><![CDATA[引言 2017-04-29是我阳历的生日，同时也是我第一个博客的诞辰！初心是为了能有一个可以记录自己在代码中的成长过程的空间，同时也希望能够发挥自己的一些微不足道的能力去帮助一些人，在此过程中不断提高自己。——————一只奋进的小菜鸟 随笔 起因其实可以追溯到一篇微博，内容讲述了为什么程序员要写博客，作者文笔着实不错，让我看着动了心，回想起从前码代码的日子，经历过好多的坑，走过好多的弯路，一直想可以把自己心得或者当时的想法，做法记录下来，以后可以回头看看自己当初犯过那些错，走过那些弯路，警醒一下自己，同时也可以提醒同在路上的人不要重蹈我的覆辙，为他人尽自己的一丝绵薄之力。 本人小小一程序员菜鸟，无意间对编程产生了浓厚的兴趣，遂开始了码代码的日子，由于起步较晚，基础也薄弱，希望以后的日子有幸能看我文章的小伙伴不要吝啬你们的口水，为我提出宝贵的意见，更希望各位大牛心情愉悦之际能指点一二，同路的菜鸟我们相互交流，共同学习，一起奋进！]]></content>
      <categories>
        <category>初心</category>
      </categories>
      <tags>
        <tag>初心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F04%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hello World</category>
      </categories>
      <tags>
        <tag>Hello World</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet]]></title>
    <url>%2F2017%2F02%2F25%2FServlet%2F</url>
    <content type="text"><![CDATA[Servlet 本文来自百度百科：https://baike.baidu.com/item/servlet/477555?fr=aladdin Servlet由来Servlet 是在服务器上运行的小程序。这个词是在 Java applet的环境中创造的。 Java applet 是一种当作单独文件跟网页一起发送的小程序，它通常用于在客户端运行，结果得到为用户进行运算或者根据用户互作用定位图形等服务。 服务器上需要一些程序，常常是根据用户输入访问数据库的程序。这些通常是使用公共网关接口（Common Gateway Interface，CGI）应用程序完成的。 但是，在服务器上运行 Java，这种程序可使用 Java 编程语言实现。在通信量大的服务器上，JavaServlet 的优点在于它们的执行速度更快于 CGI 程序。各个用户请求被激活成单个程序中的一个线程，而无需创建单独的进程，这意味着服务器端处理请求的系统开销将明显降低。 实现过程 最早支持 Servlet 技术的是 JavaSoft 的 Java Web Server。此后，一些其它的基于 Java 的 Web Server 开始支持标准的 Servlet API。 Servlet 的主要功能在于交互式地浏览和修改数据，生成动态 Web 内容。这个过程为： 客户端发送请求至服务器端； 服务器将请求信息发送至 Servlet； Servlet 生成响应内容并将其传给服务器。响应内容动态生成，通常取决于客户端的请求； 服务器将响应返回给客户端。 Servlet 看起来像是通常的 Java 程序。Servlet 导入特定的属于 Java Servlet API 的包。因为是对象字节码，可动态地从网络加载，可以说 Servlet 对 Server 就如同 Applet对 Client 一样，但是，由于 Servlet 运行于 Server 中，它们并不需要一个图形用户界面。从这个角度讲，Servlet 也被称为 FacelessObject。 一个 Servlet 就是 Java 编程语言中的一个类，它被用来扩展服务器的性能，服务器上驻留着可以通过“请求-响应”编程模型来访问的应用程序。虽然 Servlet 可以对任何类型的请求产生响应，但通常只用来扩展 Web 服务器的应用程序。 生命周期 客户端请求该 Servlet； 加载 Servlet 类到内存； 实例化并调用init()方法初始化该 Servlet； service()（根据请求方法不同调用doGet() 或者 doPost()，此外还有doHead()、doPut()、doTrace()、doDelete()、doOptions()、destroy())。 加载和实例化 Servlet。这项操作一般是动态执行的。然而，Server 通常会提供一个管理的选项，用于在 Server 启动时强制装载和初始化特定的 Servlet（loadOnStartUp）。 对于更多的客户端请求，Server 创建新的请求和响应对象，仍然激活此 Servlet 的 service() 方法，将这两个对象作为参数传递给它。如此重复以上的循环，但无需再次调用 init() 方法。一般 Servlet 只初始化一次(只有一个对象)，当 Server 不再需要 Servlet 时（一般当 Server 关闭时），Server 调用 Servlet 的 destroy() 方法。 比较与 Applet 的比较 相似之处： 它们不是独立的应用程序，没有 main() 方法。 它们不是由用户或程序员调用，而是由另外一个应用程序(容器)调用。 它们都有一个生存周期，包含 init() 和 destroy() 方法。 不同之处： Applet具有很好的图形界面(AWT)，与浏览器一起，在客户端运行。 Servlet 则没有图形界面，运行在服务器端。 与 CGI 比较 与传统的 CGI 和许多其他类似 CGI 的技术相比，Java Servlet 具有更高的效率，更容易使用，功能更强大，具有更好的可移植性，更节省投资。在未来的技术发展过程中，Servlet 有可能彻底取代 CGI。在传统的 CGI中，每个请求都要启动一个新的进程，如果 CGI 程序本身的执行时间较短，启动进程所需要的开销很可能反而超过实际执行时间。而在 Servlet 中，每个请求由一个轻量级的 Java 线程处理（而不是重量级的操作系统进程）。在传统 CGI 中，如果有 N 个并发的对同一 CGI程序的请求，则该CGI程序的代码在内存中重复装载了 N 次；而对于 Servlet，处理请求的是 N 个线程，只需要一份 Servlet 类代码。在性能优化方面，Servlet 也比 CGI 有着更多的选择。 方便Servlet 提供了大量的实用工具例程，例如自动地解析和解码 HTML 表单数据、读取和设置 HTTP头、处理Cookie、跟踪会话状态等。 功能强大在Servlet中，许多使用传统 CGI 程序很难完成的任务都可以轻松地完成。例如，Servlet 能够直接和 Web服务器交互，而普通的 CGI 程序不能。Servlet 还能够在各个程序之间共享数据，使得数据库连接池之类的功能很容易实现。 可移植性好Servlet 用 Java 编写，Servlet API具有完善的标准。因此，为 IPlanet Enterprise Server 写的 Servlet 无需任何实质上的改动即可移植到 Apache、MicrosoftIIS 或者 WebStar。几乎所有的主流服务器都直接或通过插件支持 Servlet。 与 JSP 比较 JSP 和 Servlet 的区别到底在应用上有哪些体现，很多人搞不清楚。简单的说，SUN 首先发展出 Servlet，其功能比较强劲，体系设计也很先进，只是，它输出 HTML 语句还是采用了老的 CGI 方式，是一句一句输出，所以，编写和修改 HTML 非常不方便。 Java Server Pages(JSP)是一种实现普通静态HTML 和动态 HTML 混合编码的技术，JSP 并没有增加任何本质上不能用 Servlet 实现的功能。但是，在 JSP 中编写静态HTML 更加方便，不必再用 println语 句来输出每一行 HTML 代码。更重要的是，借助内容和外观的分离，页面制作中不同性质的任务可以方便地分开：比如，由页面设计者进行 HTML设计，同时留出供 Servlet 程序员插入动态内容的空间。后来 SUN 推出了类似于 ASP 的镶嵌型的 JSP，把 JSP TAG 镶嵌到 HTML 语句中，这样，就大大简化和方便了网页的设计和修改。新型的网络语言如 ASP，PHP，JSP 都是镶嵌型的语言。 这是 JSP 和 Servlet 区别的运作原理层面。 从网络三层结构的角度看 JSP 和 Servlet 的区别，一个网络项目最少分三层：data layer(数据层)，business layer(业务层)，presentation layer(表现层)。当然也可以更复杂。Servlet 用来写 business layer 是很强大的，但是对于写 presentation layer 就很不方便。JSP 则主要是为了方便写 presentation layer 而设计的。当然也可以写 business layer。写惯了 ASP，PHP，CGI的朋友，经常会不自觉的把 presentation layer 和 business layer 混在一起。 根据 SUN 自己的推荐，JSP中应该仅仅存放与 presentation layer 有关的东西，也就是说，只放输出 HTML 网页的部分。而所有的数据计算，数据分析，数据库联结处理，统统是属于 business layer，应该放在 Java BEANS 中。通过 JSP 调用 Java BEANS，实现两层的整合。]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Servlet</tag>
        <tag>Web</tag>
      </tags>
  </entry>
</search>